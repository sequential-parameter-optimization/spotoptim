{
  "hash": "8ffa7b1fc2f6a510df15ba002ccf11db",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: SpotOptim\n---\n\n\n\n`SpotOptim`\n\n\n\n## Classes\n\n| Name | Description |\n| --- | --- |\n| [SpotOptim](#spotoptim.SpotOptim.SpotOptim) | SPOT optimizer compatible with scipy.optimize interface. |\n| [SpotOptimConfig](#spotoptim.SpotOptim.SpotOptimConfig) | Configuration parameters for SpotOptim. |\n| [SpotOptimState](#spotoptim.SpotOptim.SpotOptimState) | Mutable state of the optimization process. |\n\n### SpotOptim { #spotoptim.SpotOptim.SpotOptim }\n\n```python\nSpotOptim.SpotOptim(\n    fun,\n    bounds=None,\n    max_iter=20,\n    n_initial=10,\n    surrogate=None,\n    acquisition='y',\n    var_type=None,\n    var_name=None,\n    var_trans=None,\n    tolerance_x=None,\n    max_time=np.inf,\n    repeats_initial=1,\n    repeats_surrogate=1,\n    ocba_delta=0,\n    tensorboard_log=False,\n    tensorboard_path=None,\n    tensorboard_clean=False,\n    fun_mo2so=None,\n    seed=None,\n    verbose=False,\n    warnings_filter='ignore',\n    n_infill_points=1,\n    max_surrogate_points=None,\n    selection_method='distant',\n    acquisition_failure_strategy='random',\n    penalty=False,\n    penalty_val=None,\n    acquisition_fun_return_size=3,\n    acquisition_optimizer='differential_evolution',\n    restart_after_n=100,\n    restart_inject_best=True,\n    x0=None,\n    de_x0_prob=0.1,\n    tricands_fringe=False,\n    prob_de_tricands=0.8,\n    window_size=None,\n    min_tol_metric='chebyshev',\n    prob_surrogate=None,\n    n_jobs=1,\n    acquisition_optimizer_kwargs=None,\n    args=(),\n    kwargs=None,\n)\n```\n\nSPOT optimizer compatible with scipy.optimize interface.\n\n#### Parameters {.doc-section .doc-section-parameters}\n\n| Name                         | Type            | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Default                    |\n|------------------------------|-----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------|\n| fun                          | callable        | Objective function to minimize. Should accept array of shape (n_samples, n_features).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | _required_                 |\n| bounds                       | list of tuple   | Bounds for each dimension as [(low, high), ...].                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | `None`                     |\n| max_iter                     | int             | Maximum number of total function evaluations (including initial design). For example, max_iter=30 with n_initial=10 will perform 10 initial evaluations plus 20 sequential optimization iterations. Defaults to 20.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | `20`                       |\n| n_initial                    | int             | Number of initial design points. Defaults to 10.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | `10`                       |\n| surrogate                    | object          | Surrogate model with scikit-learn interface (fit/predict methods). If None, uses a Gaussian Process Regressor with Matern kernel. Default configuration::      from sklearn.gaussian_process import GaussianProcessRegressor     from sklearn.gaussian_process.kernels import Matern, ConstantKernel      kernel = ConstantKernel(1.0, (1e-2, 1e12)) * Matern(length_scale=1.0, length_scale_bounds=(1e-4, 1e2), nu=2.5)     surrogate = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=100)     surrogate = GaussianProcessRegressor(         kernel=kernel,         n_restarts_optimizer=10,         normalize_y=True,         random_state=self.seed,     )  Alternative surrogates can be provided, including SpotOptim's Kriging model, Random Forests, or any scikit-learn compatible regressor. See Examples section. Defaults to None (uses default Gaussian Process configuration). | `None`                     |\n| acquisition                  | str             | Acquisition function ('ei', 'y', 'pi'). Defaults to 'y'.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | `'y'`                      |\n| var_type                     | list of str     | Variable types for each dimension. Supported types: - 'float': Python floats, continuous optimization (no rounding) - 'int': Python int, float values will be rounded to integers - 'factor': Unordered categorical data, internally mapped to int values   (e.g., \"red\"->0, \"green\"->1, etc.) Defaults to None (which sets all dimensions to 'float').                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | `None`                     |\n| var_name                     | list of str     | Variable names for each dimension. If None, uses default names ['x0', 'x1', 'x2', ...]. Defaults to None.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | `None`                     |\n| tolerance_x                  | float           | Minimum distance between points. Defaults to np.sqrt(np.spacing(1))                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | `None`                     |\n| var_trans                    | list of str     | Variable transformations for each dimension. Supported: - 'log': Logarithmic transformation, e.g. \"log10\" for base-10 log - 'sqrt': Square root transformation, \"sqrt\" for square root - None or 'id' or 'None': No transformation Defaults to None (no transformations).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | `None`                     |\n| max_time                     | float           | Maximum runtime in minutes. If np.inf (default), no time limit. The optimization terminates when either max_iter evaluations are reached OR max_time minutes have elapsed, whichever comes first. Defaults to np.inf.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | `np.inf`                   |\n| repeats_initial              | int             | Number of times to evaluate each initial design point. Useful for noisy objective functions. If > 1, noise handling is activated and statistics (mean, variance) are tracked. Defaults to 1.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | `1`                        |\n| repeats_surrogate            | int             | Number of times to evaluate each surrogate-suggested point. Useful for noisy objective functions. If > 1, noise handling is activated and statistics (mean, variance) are tracked. Defaults to 1.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | `1`                        |\n| ocba_delta                   | int             | Number of additional evaluations to allocate using Optimal Computing Budget Allocation (OCBA) when noise handling is active. OCBA determines which existing design points should be re-evaluated to best distinguish between alternatives. Only used when noise=True (repeats > 1) and ocba_delta > 0. Requires at least 3 design points with variance information. Defaults to 0 (no OCBA).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | `0`                        |\n| tensorboard_log              | bool            | Enable TensorBoard logging. If True, optimization metrics and hyperparameters are logged to TensorBoard. View logs by running: `tensorboard --logdir=<tensorboard_path>` in a separate terminal. Defaults to False.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | `False`                    |\n| tensorboard_path             | str             | Path for TensorBoard log files. If None and tensorboard_log is True, creates a default path: runs/spotoptim_YYYYMMDD_HHMMSS. Defaults to None.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | `None`                     |\n| tensorboard_clean            | bool            | If True, removes all old TensorBoard log directories from the 'runs' folder before starting optimization. Use with caution as this permanently deletes all subdirectories in 'runs'. Defaults to False.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | `False`                    |\n| fun_mo2so                    | callable        | Function to convert multi-objective values to single-objective. Takes an array of shape (n_samples, n_objectives) and returns array of shape (n_samples,). If None and objective function returns multi-objective values, uses first objective. Defaults to None.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | `None`                     |\n| seed                         | int             | Random seed for reproducibility. Defaults to None.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | `None`                     |\n| verbose                      | bool            | Print progress information. Defaults to False.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | `False`                    |\n| warnings_filter              | str             | Filter for warnings. One of \"error\", \"ignore\", \"always\", \"all\", \"default\", \"module\", or \"once\". Defaults to \"ignore\".                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | `'ignore'`                 |\n| n_infill_points              | int             | Number of infill points to suggest at each iteration. Defaults to 1. If > 1, multiple distinct points are proposed using the optimizer and fallback strategies.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | `1`                        |\n| max_surrogate_points         | int             | Maximum number of points to use for surrogate model fitting. If None, all points are used. If the number of evaluated points exceeds this limit, a subset is selected using the selection method. Defaults to None.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | `None`                     |\n| selection_method             | str             | Method for selecting points when max_surrogate_points is exceeded. Options: 'distant' (Select points that are distant from each other via K-means clustering) or 'best' (Select all points from the cluster with the best mean objective value). Defaults to 'distant'.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | `'distant'`                |\n| acquisition_failure_strategy | str             | Strategy for handling acquisition function failures. Options: 'random' (space-filling design via Latin Hypercube Sampling) Defaults to 'random'.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | `'random'`                 |\n| penalty                      | bool            | Whether to use penalty for handling NaN/inf values in objective function evaluations. Defaults to False.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | `False`                    |\n| penalty_val                  | float           | Penalty value to replace NaN/inf values in objective function evaluations. When the objective function returns NaN or inf, these values are replaced with penalty plus a small random noise (sampled from N(0, 0.1)) to avoid identical penalty values. This allows optimization to continue despite occasional function evaluation failures. Defaults to None.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | `None`                     |\n| acquisition_fun_return_size  | int             | Number of top candidates to return from acquisition function optimization. Defaults to 3.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | `3`                        |\n| acquisition_optimizer        | str or callable | Optimizer to use for maximizing acquisition function. Can be \"differential_evolution\" (default) or any method name supported by scipy.optimize.minimize (e.g., \"Nelder-Mead\", \"L-BFGS-B\"). Can also be a callable with signature compatible with scipy.optimize.minimize (fun, x0, bounds, ...). A specific version is \"de_tricands\", which combines DE with Tricands. It can be parameterized with \"prob_de_tricands\" (probability of using DE). Defaults to \"differential_evolution\".                                                                                                                                                                                                                                                                                                                                                                                                                    | `'differential_evolution'` |\n| acquisition_optimizer_kwargs | dict            | Kwargs passed to the acquisition function optimizer and GPR surrogate optimizer. Defaults to {'maxiter': 10000, 'gtol': 1e-9}.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | `None`                     |\n| restart_after_n              | int             | Number of consecutive iterations with zero success rate before triggering a restart. Defaults to 100.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | `100`                      |\n| restart_inject_best          | bool            | Whether to inject the best solution found so far as a starting point for the next restart. Defaults to True.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | `True`                     |\n| x0                           | array - like    | Starting point for optimization, shape (n_features,). If provided, this point will be evaluated first and included in the initial design. The point should be within the bounds and will be validated before use. Defaults to None (no starting point, uses only LHS design).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | `None`                     |\n| de_x0_prob                   | float           | Probability of using the best point as starting point for differential evolution. Defaults to 0.1.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | `0.1`                      |\n| tricands_fringe              | bool            | Whether to use the fringe of the design space for the initial design. Defaults to False.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | `False`                    |\n| prob_de_tricands             | float           | Probability of using differential evolution as an optimizer on the surrogate model. 1 - prob_de_tricands is the probability of using tricands. Defaults to 0.8.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | `0.8`                      |\n| window_size                  | int             | Window size for success rate calculation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | `None`                     |\n| min_tol_metric               | str             | Distance metric used when checking `tolerance_x` for duplicate detection. Default is \"chebyshev\". Supports all metrics from scipy.spatial.distance.cdist, including: - \"chebyshev\": L-infinity distance (hypercube). Default. Matches previous behavior. - \"euclidean\": L2 distance (hypersphere). - \"minkowski\": Lp distance (default p=2). - \"cityblock\": Manhattan/L1 distance. - \"cosine\": Cosine distance. - \"correlation\": Correlation distance. - \"canberra\", \"braycurtis\", \"sqeuclidean\", etc.                                                                                                                                                                                                                                                                                                                                                                                                     | `'chebyshev'`              |\n\n#### Attributes {.doc-section .doc-section-attributes}\n\n| Name                         | Type            | Description                                                                                                                                       |\n|------------------------------|-----------------|---------------------------------------------------------------------------------------------------------------------------------------------------|\n| X_                           | ndarray         | All evaluated points, shape (n_samples, n_features).                                                                                              |\n| y_                           | ndarray         | Function values at X_, shape (n_samples,). For multi-objective problems, these are the converted single-objective values.                         |\n| y_mo                         | ndarray or None | Multi-objective function values, shape (n_samples, n_objectives). None for single-objective problems.                                             |\n| best_x_                      | ndarray         | Best point found, shape (n_features,).                                                                                                            |\n| best_y_                      | float           | Best function value found.                                                                                                                        |\n| n_iter_                      | int             | Number of iterations performed. This is not the same as counter. Provided for compatibility with scipy.optimize routines.                         |\n| counter                      | int             | Total number of function evaluations.                                                                                                             |\n| success_rate                 | float           | Rolling success rate over the last window_size evaluations. A success is counted when a new evaluation improves upon the best value found so far. |\n| warnings_filter              | str             | Filter for warnings during optimization.                                                                                                          |\n| max_surrogate_points         | int or None     | Maximum number of points for surrogate fitting.                                                                                                   |\n| selection_method             | str             | Point selection method.                                                                                                                           |\n| acquisition_failure_strategy | str             | Strategy for handling acquisition failures ('random').                                                                                            |\n| noise                        | bool            | True if noise handling is active (repeats > 1).                                                                                                   |\n| mean_X                       | ndarray or None | Aggregated unique design points (if noise=True).                                                                                                  |\n| mean_y                       | ndarray or None | Mean y values per design point (if noise=True).                                                                                                   |\n| var_y                        | ndarray or None | Variance of y values per design point (if noise=True).                                                                                            |\n| min_mean_X                   | ndarray or None | X value of best mean y (if noise=True).                                                                                                           |\n| min_mean_y                   | float or None   | Best mean y value (if noise=True).                                                                                                                |\n| min_var_y                    | float or None   | Variance of best mean y (if noise=True).                                                                                                          |\n| de_x0_prob                   | float           | Probability of using the best point as starting point for differential evolution.                                                                 |\n| tricands_fringe              | bool            | Whether to use the fringe of the design space for the initial design.                                                                             |\n| prob_de_tricands             | float           | Probability of using differential evolution as an optimizer on the surrogate model.                                                               |\n\n#### Examples {.doc-section .doc-section-examples}\n\n\n::: {#0da24707 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\n# Example 1: Basic usage (deterministic function)\nbounds = [(-5, 5), (-5, 5)]\noptimizer = SpotOptim(fun=objective, bounds=bounds, max_iter=10, n_initial=5, verbose=True)\nresult = optimizer.optimize()\nprint(\"Best x:\", result.x)\nprint(\"Best f(x):\", result.fun)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTensorBoard logging disabled\nInitial best: f(x) = 5.836017\nIter 2 | Best: 5.051219 | Rate: 0.50 | Evals: 70.0%\nIter 3 | Best: 3.440258 | Rate: 0.67 | Evals: 80.0%\nIter 4 | Best: 0.775140 | Rate: 0.75 | Evals: 90.0%\nIter 5 | Best: 0.178535 | Rate: 0.80 | Evals: 100.0%\nBest x: [-0.22868791 -0.3552983 ]\nBest f(x): 0.1785350435924863\n```\n:::\n:::\n\n\n::: {#4b73b058 .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\n# Example 2: With custom variable names\noptimizer = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    var_name=[\"param1\", \"param2\"],\n    max_iter=10,\n    n_initial=5\n)\nresult = optimizer.optimize()\n# Ensure we can use custom names in plots\noptimizer.plot_surrogate(show=False)\n```\n\n::: {.cell-output .cell-output-display}\n![](SpotOptim_files/figure-html/cell-3-output-1.png){width=1125 height=950}\n:::\n:::\n\n\n::: {#4c72e1e2 .cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\nfrom spotoptim import SpotOptim\n\n# Example 3: Noisy function with repeated evaluations\ndef noisy_objective(X):\n    base = np.sum(X**2, axis=1)\n    noise = np.random.normal(0, 0.1, size=base.shape)\n    return base + noise\n\noptimizer = SpotOptim(\n    fun=noisy_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=30,\n    n_initial=10,\n    repeats_initial=3,      # Evaluate each initial point 3 times\n    repeats_surrogate=2,    # Evaluate each new point 2 times\n    seed=42,                # For reproducibility\n    verbose=True\n)\nresult = optimizer.optimize()\n\n# Access noise statistics\nprint(\"Unique design points:\", optimizer.mean_X.shape[0])\nprint(\"Best mean value:\", optimizer.min_mean_y)\nprint(\"Variance at best point:\", optimizer.min_var_y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTensorBoard logging disabled\nInitial best: f(x) = 2.305707, mean best: f(x) = 2.367991\nUnique design points: 10\nBest mean value: 2.3679913784564808\nVariance at best point: 0.0026553713273186792\n```\n:::\n:::\n\n\n::: {#5392df04 .cell execution_count=4}\n``` {.python .cell-code}\nimport numpy as np\nfrom spotoptim import SpotOptim\n\ndef noisy_objective(X):\n    base = np.sum(X**2, axis=1)\n    noise = np.random.normal(0, 0.1, size=base.shape)\n    return base + noise\n\n# Example 4: Noisy function with OCBA (Optimal Computing Budget Allocation)\noptimizer_ocba = SpotOptim(\n    fun=noisy_objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=50,\n    n_initial=10,\n    repeats_initial=2,      # Initial repeats\n    repeats_surrogate=1,    # Surrogate repeats\n    ocba_delta=3,           # Allocate 3 additional evaluations per iteration\n    seed=42,\n    verbose=True\n)\nresult = optimizer_ocba.optimize()\n\n# OCBA intelligently re-evaluates promising points to reduce uncertainty\nprint(\"Total evaluations:\", result.nfev)\nprint(\"Unique design points:\", optimizer_ocba.mean_X.shape[0])\nprint(\"Best mean value:\", optimizer_ocba.min_mean_y)\nprint(\"Variance at best point:\", optimizer_ocba.min_var_y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTensorBoard logging disabled\nInitial best: f(x) = 2.319523, mean best: f(x) = 2.385877\n\nIn _get_ocba():\nmeans: [25.8857338  11.32118531 10.14985518  2.38587731 20.7190555  21.36600973\n 16.36904227 14.1099758  18.36970272 20.14080533]\nvars: [6.73858271e-13 1.33640624e-08 1.00799409e-03 4.40284305e-03\n 2.56053422e-03 6.35744853e-04 1.16126758e-02 3.37927306e-03\n 1.64745915e-03 1.91555606e-03]\ndelta: 3\nn_designs: 10\nRatios: [7.29707371e-11 1.00099067e-05 1.00000000e+00 3.61962598e+00\n 4.55581054e-01 1.05534624e-01 3.55166445e+00 1.47019506e+00\n 3.85623766e-01 3.63385525e-01]\nBest: 3, Second best: 2\n  OCBA: Adding 3 re-evaluation(s)\nIter 1 | Best: 2.240418 | Rate: 0.25 | Evals: 48.0% | Mean Best: 2.240418\nIter 2 | Best: 1.594454 | Rate: 0.40 | Evals: 50.0% | Mean Best: 1.594454\nIter 3 | Best: 0.500183 | Rate: 0.50 | Evals: 52.0% | Mean Best: 0.500183\nIter 4 | Best: -0.050734 | Rate: 0.57 | Evals: 54.0% | Mean Best: -0.050734\nIter 11 | Best: -0.104442 | Rate: 0.36 | Evals: 68.0% | Mean Best: -0.104442\nTotal evaluations: 50\nUnique design points: 37\nBest mean value: -0.10444213689240685\nVariance at best point: 0.0\n```\n:::\n:::\n\n\n::: {#806646dd .cell execution_count=5}\n``` {.python .cell-code}\nimport numpy as np\nimport shutil\nimport os\nfrom spotoptim import SpotOptim\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\n# Example 5: With TensorBoard logging\ntb_dir = \"runs/my_optimization\"\noptimizer_tb = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    max_iter=15,\n    n_initial=5,\n    tensorboard_log=True,   # Enable TensorBoard\n    tensorboard_path=tb_dir,  # Optional custom path\n    verbose=True\n)\nresult = optimizer_tb.optimize()\n\n# View logs in browser: tensorboard --logdir=runs/my_optimization\nprint(\"Logs saved to:\", optimizer_tb.tensorboard_path)\n\n# Cleanup log dir\nif os.path.exists(tb_dir):\n    shutil.rmtree(tb_dir)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTensorBoard logging enabled: runs/my_optimization\nInitial best: f(x) = 6.701193\nIter 3 | Best: 6.674278 | Rate: 0.33 | Evals: 53.3%\nIter 5 | Best: 3.883543 | Rate: 0.40 | Evals: 66.7%\nIter 6 | Best: 0.431344 | Rate: 0.50 | Evals: 73.3%\nIter 7 | Best: 0.062955 | Rate: 0.57 | Evals: 80.0%\nIter 8 | Best: 0.000297 | Rate: 0.62 | Evals: 86.7%\nIter 9 | Best: 0.000005 | Rate: 0.67 | Evals: 93.3%\nTensorBoard writer closed. View logs with: tensorboard --logdir=runs/my_optimization\nLogs saved to: runs/my_optimization\n```\n:::\n:::\n\n\n::: {#25d8bf78 .cell execution_count=6}\n``` {.python .cell-code}\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom spotoptim.surrogate import Kriging\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\n# Example 6: Using SpotOptim's Kriging surrogate\nkriging_model = Kriging(\n    noise=1e-10,           # Regularization parameter\n    kernel='gauss',         # Gaussian/RBF kernel\n    min_theta=-3.0,         # Min log10(theta) bound\n    max_theta=2.0,          # Max log10(theta) bound\n    seed=42\n)\noptimizer_kriging = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=kriging_model,\n    max_iter=15,\n    n_initial=5,\n    seed=42,\n    verbose=True\n)\nresult = optimizer_kriging.optimize()\nprint(\"Best solution found:\", result.x)\nprint(\"Best value:\", result.fun)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTensorBoard logging disabled\nInitial best: f(x) = 2.510989\nIter 2 | Best: 0.757941 | Rate: 0.50 | Evals: 46.7%\nIter 3 | Best: 0.462654 | Rate: 0.67 | Evals: 53.3%\nIter 4 | Best: 0.048529 | Rate: 0.75 | Evals: 60.0%\nIter 5 | Best: 0.000402 | Rate: 0.80 | Evals: 66.7%\nIter 7 | Best: 0.000349 | Rate: 0.71 | Evals: 80.0%\nIter 8 | Best: 0.000144 | Rate: 0.75 | Evals: 86.7%\nIter 9 | Best: 0.000023 | Rate: 0.78 | Evals: 93.3%\nIter 10 | Best: 0.000007 | Rate: 0.80 | Evals: 100.0%\nBest solution found: [-0.0020648  -0.00162934]\nBest value: 6.918152378371863e-06\n```\n:::\n:::\n\n\n::: {#7eba84f8 .cell execution_count=7}\n``` {.python .cell-code}\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\n# Example 7: Using sklearn Gaussian Process with custom kernel\n# Custom kernel: constant * RBF + white noise\ncustom_kernel = ConstantKernel(1.0, (1e-2, 1e2)) * RBF(\n    length_scale=1.0, length_scale_bounds=(1e-1, 10.0)\n) + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1))\n\ngp_custom = GaussianProcessRegressor(\n    kernel=custom_kernel,\n    n_restarts_optimizer=15,\n    normalize_y=True,\n    random_state=42\n)\n\noptimizer_custom_gp = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=gp_custom,\n    max_iter=15,\n    n_initial=5,\n    seed=42\n)\nresult = optimizer_custom_gp.optimize()\n```\n:::\n\n\n::: {#f585ad54 .cell execution_count=8}\n``` {.python .cell-code}\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\n# Example 8: Using Random Forest as surrogate\nrf_model = RandomForestRegressor(\n    n_estimators=100,\n    max_depth=10,\n    random_state=42\n)\n\noptimizer_rf = SpotOptim(\n    fun=objective,\n    bounds=[(-5, 5), (-5, 5)],\n    surrogate=rf_model,\n    max_iter=15,\n    n_initial=5,\n    seed=42\n)\nresult = optimizer_rf.optimize()\n\n# Note: Random Forests don't provide uncertainty estimates,\n# so Expected Improvement (EI) may be less effective.\n# Consider using acquisition='y' for pure exploitation.\n```\n:::\n\n\n::: {#64fe426f .cell execution_count=9}\n``` {.python .cell-code}\nimport numpy as np\nfrom spotoptim import SpotOptim\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import Matern, RationalQuadratic, ConstantKernel, RBF\n\ndef objective(X):\n    return np.sum(X**2, axis=1)\n\n# Example 9: Comparing different kernels for Gaussian Process\n# Matern kernel with nu=1.5 (once differentiable)\nkernel_matern15 = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=1.5)\ngp_matern15 = GaussianProcessRegressor(kernel=kernel_matern15, normalize_y=True)\n\n# Matern kernel with nu=2.5 (twice differentiable, DEFAULT)\nkernel_matern25 = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5)\ngp_matern25 = GaussianProcessRegressor(kernel=kernel_matern25, normalize_y=True)\n\n# RBF kernel (infinitely differentiable, smooth)\nkernel_rbf = ConstantKernel(1.0) * RBF(length_scale=1.0)\ngp_rbf = GaussianProcessRegressor(kernel=kernel_rbf, normalize_y=True)\n\n# Rational Quadratic kernel (mixture of RBF kernels)\nkernel_rq = ConstantKernel(1.0) * RationalQuadratic(length_scale=1.0, alpha=1.0)\ngp_rq = GaussianProcessRegressor(kernel=kernel_rq, normalize_y=True)\n\n# Use any of these as surrogate\noptimizer_rbf = SpotOptim(fun=objective, bounds=[(-5, 5), (-5, 5)],\n                          surrogate=gp_rbf, max_iter=15, n_initial=5)\nresult = optimizer_rbf.optimize()\n```\n:::\n\n\n#### Methods\n\n| Name | Description |\n| --- | --- |\n| [detect_var_type](#spotoptim.SpotOptim.SpotOptim.detect_var_type) | Auto-detect variable types based on factor mappings. |\n| [gen_design_table](#spotoptim.SpotOptim.SpotOptim.gen_design_table) | Generate a table of the design or results. |\n| [get_best_hyperparameters](#spotoptim.SpotOptim.SpotOptim.get_best_hyperparameters) | Get the best hyperparameter configuration found during optimization. |\n| [get_design_table](#spotoptim.SpotOptim.SpotOptim.get_design_table) | Get a table string showing the search space design before optimization. |\n| [get_importance](#spotoptim.SpotOptim.SpotOptim.get_importance) | Calculate variable importance scores. |\n| [get_initial_design](#spotoptim.SpotOptim.SpotOptim.get_initial_design) | Generate or process initial design points. |\n| [get_results_table](#spotoptim.SpotOptim.SpotOptim.get_results_table) | Get a comprehensive table string of optimization results. |\n| [get_stars](#spotoptim.SpotOptim.SpotOptim.get_stars) | Converts a list of values to a list of stars. |\n| [handle_default_var_trans](#spotoptim.SpotOptim.SpotOptim.handle_default_var_trans) | Handle default variable transformations. |\n| [inverse_transform_value](#spotoptim.SpotOptim.SpotOptim.inverse_transform_value) | Apply inverse transformation to a single float value. |\n| [load_experiment](#spotoptim.SpotOptim.SpotOptim.load_experiment) | Load an experiment configuration from a pickle file. |\n| [load_result](#spotoptim.SpotOptim.SpotOptim.load_result) | Load complete optimization results from a pickle file. |\n| [modify_bounds_based_on_var_type](#spotoptim.SpotOptim.SpotOptim.modify_bounds_based_on_var_type) | Modify bounds based on variable types. |\n| [optimize](#spotoptim.SpotOptim.SpotOptim.optimize) | Run the optimization process. |\n| [optimize_acquisition_func](#spotoptim.SpotOptim.SpotOptim.optimize_acquisition_func) | Optimize the acquisition function to find the next point to evaluate. |\n| [plot_importance](#spotoptim.SpotOptim.SpotOptim.plot_importance) | Plot variable importance. |\n| [plot_important_hyperparameter_contour](#spotoptim.SpotOptim.SpotOptim.plot_important_hyperparameter_contour) | Plot surrogate contours using spotoptim.plot.visualization.plot_important_hyperparameter_contour. |\n| [plot_parameter_scatter](#spotoptim.SpotOptim.SpotOptim.plot_parameter_scatter) | Plot parameter distributions showing relationship between each parameter and objective. |\n| [plot_progress](#spotoptim.SpotOptim.SpotOptim.plot_progress) | Plot optimization progress using spotoptim.plot.visualization.plot_progress. |\n| [plot_surrogate](#spotoptim.SpotOptim.SpotOptim.plot_surrogate) | Plot the surrogate model for two dimensions. |\n| [print_best](#spotoptim.SpotOptim.SpotOptim.print_best) | Print the best solution found during optimization. |\n| [print_design_table](#spotoptim.SpotOptim.SpotOptim.print_design_table) | Print (and return) a table showing the search space design before optimization. |\n| [print_results](#spotoptim.SpotOptim.SpotOptim.print_results) | Alias for print_results_table for compatibility. |\n| [print_results_table](#spotoptim.SpotOptim.SpotOptim.print_results_table) | Print (and return) a comprehensive table of optimization results. |\n| [process_factor_bounds](#spotoptim.SpotOptim.SpotOptim.process_factor_bounds) | Process bounds to handle factor variables. |\n| [save_experiment](#spotoptim.SpotOptim.SpotOptim.save_experiment) | Save the experiment configuration to a pickle file. |\n| [save_result](#spotoptim.SpotOptim.SpotOptim.save_result) | Save the complete optimization results to a pickle file. |\n| [select_new](#spotoptim.SpotOptim.SpotOptim.select_new) | Select rows from A that are not in X. |\n| [sensitivity_spearman](#spotoptim.SpotOptim.SpotOptim.sensitivity_spearman) | Compute and print Spearman correlation between parameters and objective values. |\n| [suggest_next_infill_point](#spotoptim.SpotOptim.SpotOptim.suggest_next_infill_point) | Suggest next point to evaluate (dispatcher). |\n| [to_all_dim](#spotoptim.SpotOptim.SpotOptim.to_all_dim) | Expand reduced-dimensional points to full-dimensional representation. |\n| [to_red_dim](#spotoptim.SpotOptim.SpotOptim.to_red_dim) | Reduce full-dimensional points to optimization space. |\n| [transform_bounds](#spotoptim.SpotOptim.SpotOptim.transform_bounds) | Transform bounds from original to internal scale. |\n| [transform_value](#spotoptim.SpotOptim.SpotOptim.transform_value) | Apply transformation to a single float value. |\n| [update_stats](#spotoptim.SpotOptim.SpotOptim.update_stats) | Update optimization statistics. |\n\n##### detect_var_type { #spotoptim.SpotOptim.SpotOptim.detect_var_type }\n\n```python\nSpotOptim.SpotOptim.detect_var_type()\n```\n\nAuto-detect variable types based on factor mappings.\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description                                                                                                                               |\n|--------|--------|-------------------------------------------------------------------------------------------------------------------------------------------|\n| list   | list   | List of variable types ('factor' or 'float') for each dimension.   Dimensions with factor mappings are assigned 'factor', others 'float'. |\n\n###### Examples {.doc-section .doc-section-examples}\n\n::: {#8a638c60 .cell execution_count=10}\n``` {.python .cell-code}\nfrom spotoptim import SpotOptim\n\n# Define a simple objective mapping names to values for demonstration\ndef objective(X):\n    # X has shape (n_samples, n_dimensions)\n    return X[:, 0] + X[:, 1]\n\n# The first dimension has factor levels ('red', 'green', 'blue')\n# The second dimension is continuous bounds (0, 10)\nspot = SpotOptim(fun=objective, bounds=[('red', 'green', 'blue'), (0, 10)])\nprint(spot.detect_var_type())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['factor', 'float']\n```\n:::\n:::\n\n\n##### gen_design_table { #spotoptim.SpotOptim.SpotOptim.gen_design_table }\n\n```python\nSpotOptim.SpotOptim.gen_design_table(precision=4, tablefmt='github')\n```\n\nGenerate a table of the design or results.\n\nIf optimization has been run (results available), returns the results table.\nOtherwise, returns the design table (search space configuration).\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name      | Type   | Description                                               | Default    |\n|-----------|--------|-----------------------------------------------------------|------------|\n| tablefmt  | str    | Table format. Defaults to 'github'.                       | `'github'` |\n| precision | int    | Number of decimal places for float values. Defaults to 4. | `4`        |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description             |\n|--------|--------|-------------------------|\n| str    | str    | Formatted table string. |\n\n##### get_best_hyperparameters { #spotoptim.SpotOptim.SpotOptim.get_best_hyperparameters }\n\n```python\nSpotOptim.SpotOptim.get_best_hyperparameters(as_dict=True)\n```\n\nGet the best hyperparameter configuration found during optimization.\n\nIf noise handling is active (repeats_initial > 1 or OCBA), this returns the parameter\nconfiguration associated with the best *mean* objective value. Otherwise, it returns\nthe configuration associated with the absolute best observed value.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name    | Type   | Description                                                                                                                     | Default   |\n|---------|--------|---------------------------------------------------------------------------------------------------------------------------------|-----------|\n| as_dict | bool   | If True, returns a dictionary mapping parameter names to their values. If False, returns the raw numpy array. Defaults to True. | `True`    |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type                                        | Description                                                                                                                            |\n|--------|---------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n|        | Union\\[Dict\\[str, Any\\], np.ndarray, None\\] | Union[Dict[str, Any], np.ndarray, None]: The best hyperparameter configuration. Returns None if optimization hasn't started (no data). |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>> opt = SpotOptim(fun=lambda x: np.sum(x**2), bounds=[(-5, 5)], var_name=[\"x\"])\n>>> opt.optimize()\n>>> best_params = opt.get_best_hyperparameters()\n>>> print(best_params['x']) # Should be close to 0\n```\n\n##### get_design_table { #spotoptim.SpotOptim.SpotOptim.get_design_table }\n\n```python\nSpotOptim.SpotOptim.get_design_table(tablefmt='github', precision=4)\n```\n\nGet a table string showing the search space design before optimization.\n\nThis method generates a table displaying the variable names, types, bounds,\nand defaults without requiring an optimization run. Useful for inspecting\nand documenting the search space configuration.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name      | Type   | Description                                               | Default    |\n|-----------|--------|-----------------------------------------------------------|------------|\n| tablefmt  | str    | Table format for tabulate library. Defaults to 'github'.  | `'github'` |\n| precision | int    | Number of decimal places for float values. Defaults to 4. | `4`        |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description             |\n|--------|--------|-------------------------|\n| str    | str    | Formatted table string. |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>>\n>>> # Example 1: Numeric parameters\n>>> opt = SpotOptim(\n...     fun=lambda X: np.sum(X**2, axis=1),\n...     bounds=[(-5, 5), (-10, 10), (0, 1)],\n...     var_name=[\"x1\", \"x2\", \"x3\"],\n...     var_type=[\"float\", \"int\", \"float\"],\n...     max_iter=20,\n...     n_initial=10\n... )\n>>> table = opt.get_design_table()\n>>> print(table)\n| name   | type   |   lower |   upper |   default |\n|--------|--------|---------|---------|-----------|\n| x1     | num    |    -5.0 |     5.0 |       0.0 |\n| x2     | int    |   -10.0 |    10.0 |       0.0 |\n| x3     | num    |     0.0 |     1.0 |       0.5 |\n>>>\n>>> # Example 2: With factor variables\n>>> opt = SpotOptim(\n...     fun=lambda X: np.sum(X**2, axis=1),\n...     bounds=[(10, 100), (\"SGD\", \"Adam\", \"RMSprop\"), (0.001, 0.1)],\n...     var_name=[\"neurons\", \"optimizer\", \"lr\"],\n...     var_type=[\"int\", \"factor\", \"float\"],\n...     max_iter=30,\n...     n_initial=10\n... )\n>>> table = opt.get_design_table()\n>>> print(table)\n| name      | type   | lower   | upper   | default   |\n|-----------|--------|---------|---------|-----------|\n| neurons   | int    | 10.0    | 100.0   | 55.0      |\n| optimizer | factor | SGD     | RMSprop | Adam      |\n| lr        | num    | 0.001   | 0.1     | 0.0505    |\n>>>\n>>> # Example 3: Before running optimization\n>>> def hyperparameter_objective(X):\n...     # X[:, 0]: layers, X[:, 1]: neurons, X[:, 2]: dropout\n...     return np.sum(X**2, axis=1)  # Placeholder\n>>> opt = SpotOptim(\n...     fun=hyperparameter_objective,\n...     bounds=[(1, 5), (16, 256), (0.0, 0.5)],\n...     var_name=[\"layers\", \"neurons\", \"dropout\"],\n...     var_type=[\"int\", \"int\", \"float\"],\n...     max_iter=50,\n...     n_initial=15\n... )\n>>> # Get design table before optimization\n>>> print(\"Search Space Configuration:\")\n>>> table = opt.get_design_table()\n>>> print(table)\nSearch Space Configuration:\n| name    | type   |   lower |   upper |   default |\n|---------|--------|---------|---------|-----------|\n| layers  | int    |     1.0 |     5.0 |       3.0 |\n| neurons | int    |    16.0 |   256.0 |     136.0 |\n| dropout | num    |     0.0 |     0.5 |      0.25 |\n```\n\n##### get_importance { #spotoptim.SpotOptim.SpotOptim.get_importance }\n\n```python\nSpotOptim.SpotOptim.get_importance()\n```\n\nCalculate variable importance scores.\n\nImportance is computed as the normalized sensitivity of each parameter\nbased on the variation in objective values across the evaluated points.\nHigher scores indicate parameters that have more influence on the objective.\n\nThe importance is calculated as:\n1. For each dimension, compute the correlation between parameter values\n   and objective values\n2. Normalize to percentage scale (0-100)\n3. Higher values indicate more important parameters\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type          | Description                                                      |\n|--------|---------------|------------------------------------------------------------------|\n|        | List\\[float\\] | List[float]: Importance scores for each dimension (0-100 scale). |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>>\n>>> # Example 1: Identify important parameters\n>>> def test_func(X):\n...     # x0 has strong effect, x1 has weak effect\n...     return 10 * X[:, 0]**2 + 0.1 * X[:, 1]**2\n>>> opt = SpotOptim(\n...     fun=test_func,\n...     bounds=[(-5, 5), (-5, 5)],\n...     var_name=[\"x0\", \"x1\"],\n...     max_iter=30,\n...     n_initial=10,\n...     seed=42\n... )\n>>> result = opt.optimize()\n>>> importance = opt.get_importance()\n>>> print(f\"x0 importance: {importance[0]:.2f}\")\n>>> print(f\"x1 importance: {importance[1]:.2f}\")\nx0 importance: 89.23\nx1 importance: 10.77\n>>>\n>>> # Example 2: With more dimensions\n>>> def rosenbrock(X):\n...     return np.sum(100*(X[:, 1:] - X[:, :-1]**2)**2 + (1 - X[:, :-1])**2, axis=1)\n>>> opt = SpotOptim(\n...     fun=rosenbrock,\n...     bounds=[(-2, 2)] * 4,\n...     var_name=[\"x0\", \"x1\", \"x2\", \"x3\"],\n...     max_iter=50,\n...     n_initial=20,\n...     seed=42\n... )\n>>> result = opt.optimize()\n>>> importance = opt.get_importance()\n>>> for i, imp in enumerate(importance):\n...     print(f\"x{i}: {imp:.2f}%\")\nx0: 32.15%\nx1: 28.43%\nx2: 25.67%\nx3: 13.75%\n>>>\n>>> # Example 3: Use in results table\n>>> table = opt.print_results_table(show_importance=True)\n>>> print(table)\n```\n\n##### get_initial_design { #spotoptim.SpotOptim.SpotOptim.get_initial_design }\n\n```python\nSpotOptim.SpotOptim.get_initial_design(X0=None)\n```\n\nGenerate or process initial design points.\n\nHandles three scenarios:\n1. X0 is None: Generate space-filling design using LHS\n2. X0 is None but x0 is provided: Generate LHS and include x0 as first point\n3. X0 is provided: Transform and prepare user-provided initial design\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name   | Type    | Description                                                                                                                                      | Default   |\n|--------|---------|--------------------------------------------------------------------------------------------------------------------------------------------------|-----------|\n| X0     | ndarray | User-provided initial design points in original scale, shape (n_initial, n_features). If None, generates space-filling design. Defaults to None. | `None`    |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name    | Type       | Description                                                                                               |\n|---------|------------|-----------------------------------------------------------------------------------------------------------|\n| ndarray | np.ndarray | Initial design points in internal (transformed and reduced) scale, shape (n_initial, n_features_reduced). |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>> opt = SpotOptim(\n...     fun=lambda X: np.sum(X**2, axis=1),\n...     bounds=[(-5, 5), (-5, 5)],\n...     n_initial=10\n... )\n>>> # Generate default LHS design\n>>> X0 = opt.get_initial_design()\n>>> X0.shape\n(10, 2)\n>>>\n>>> # Provide custom initial design\n>>> X0_custom = np.array([[0, 0], [1, 1], [2, 2]])\n>>> X0_processed = opt.get_initial_design(X0_custom)\n>>> X0_processed.shape\n(3, 2)\n```\n\n##### get_results_table { #spotoptim.SpotOptim.SpotOptim.get_results_table }\n\n```python\nSpotOptim.SpotOptim.get_results_table(\n    tablefmt='github',\n    precision=4,\n    show_importance=False,\n)\n```\n\nGet a comprehensive table string of optimization results.\n\nThis method generates a formatted table of the search space configuration,\nbest values found, and optionally variable importance scores.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name            | Type   | Description                                                                                                                                                                                        | Default    |\n|-----------------|--------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------|\n| tablefmt        | str    | Table format for tabulate library. Options include: 'github', 'grid', 'simple', 'plain', 'html', 'latex', etc. Defaults to 'github'.                                                               | `'github'` |\n| precision       | int    | Number of decimal places for float values. Defaults to 4.                                                                                                                                          | `4`        |\n| show_importance | bool   | Whether to include importance scores. Importance is calculated as the normalized standard deviation of each parameter's effect on the objective. Requires multiple evaluations. Defaults to False. | `False`    |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description                                          |\n|--------|--------|------------------------------------------------------|\n| str    | str    | Formatted table string that can be printed or saved. |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>>\n>>> # Example 1: Basic usage after optimization\n>>> def sphere(X):\n...     return np.sum(X**2, axis=1)\n>>> opt = SpotOptim(\n...     fun=sphere,\n...     bounds=[(-5, 5), (-5, 5), (-5, 5)],\n...     var_name=[\"x1\", \"x2\", \"x3\"],\n...     var_type=[\"float\", \"float\", \"float\"],\n...     max_iter=30,\n...     n_initial=10\n... )\n>>> result = opt.optimize()\n>>> table = opt.get_results_table()\n>>> print(table)\n| name   | type   |   lower |   upper |   tuned |\n|--------|--------|---------|---------|---------|\n| x1     | num    |    -5.0 |     5.0 |  0.0123 |\n| x2     | num    |    -5.0 |     5.0 | -0.0234 |\n| x3     | num    |    -5.0 |     5.0 |  0.0345 |\n>>>\n>>> # Example 2: With importance scores\n>>> table = opt.get_results_table(show_importance=True)\n>>> print(table)\n| name   | type   |   lower |   upper |   tuned |   importance | stars   |\n|--------|--------|---------|---------|---------|--------------|---------|\n| x1     | num    |    -5.0 |     5.0 |  0.0123 |        45.23 | **      |\n| x2     | num    |    -5.0 |     5.0 | -0.0234 |        32.17 | *       |\n| x3     | num    |    -5.0 |     5.0 |  0.0345 |        22.60 | *       |\n>>>\n>>> # Example 3: Different table format\n>>> table = opt.get_results_table(tablefmt=\"grid\")\n>>> print(table)\n+--------+--------+---------+---------+---------+\n| name   | type   |   lower |   upper |   tuned |\n+========+========+=========+=========+=========+\n| x1     | num    |    -5.0 |     5.0 |  0.0123 |\n+--------+--------+---------+---------+---------+\n...\n>>>\n>>> # Example 4: With factor variables\n>>> opt = SpotOptim(\n...     fun=lambda X: np.sum(X**2, axis=1),\n...     bounds=[(-5, 5), (\"red\", \"green\", \"blue\")],\n...     var_name=[\"size\", \"color\"],\n...     var_type=[\"float\", \"factor\"],\n...     max_iter=20,\n...     n_initial=10\n... )\n>>> result = opt.optimize()\n>>> table = opt.get_results_table()\n>>> print(table)\n| name   | type   | lower   | upper   | tuned   |\n|--------|--------|---------|---------|---------|\n| size   | num    | -5.0    | 5.0     | 0.0123  |\n| color  | factor | red     | blue    | green   |\n```\n\n##### get_stars { #spotoptim.SpotOptim.SpotOptim.get_stars }\n\n```python\nSpotOptim.SpotOptim.get_stars(input_list)\n```\n\nConverts a list of values to a list of stars.\n\nUsed to visualize the importance of a variable.\nThresholds: >99: ***, >75: **, >50: *, >10: .\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name       | Type   | Description                          | Default    |\n|------------|--------|--------------------------------------|------------|\n| input_list | list   | A list of importance scores (0-100). | _required_ |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description             |\n|--------|--------|-------------------------|\n| list   | list   | A list of star strings. |\n\n##### handle_default_var_trans { #spotoptim.SpotOptim.SpotOptim.handle_default_var_trans }\n\n```python\nSpotOptim.SpotOptim.handle_default_var_trans()\n```\n\nHandle default variable transformations.\n\nSets var_trans to a list of None values if not specified, or normalizes\ntransformation names by converting 'id', 'None', or None to None.\n\nAlso validates that var_trans length matches the number of dimensions.\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description   |\n|--------|--------|---------------|\n|        | None   | None          |\n\n###### Raises {.doc-section .doc-section-raises}\n\n| Name   | Type       | Description                              |\n|--------|------------|------------------------------------------|\n|        | ValueError | If var_trans length doesn't match n_dim. |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> from spotoptim import SpotOptim\n>>> # Default behavior - all None\n>>> spot = SpotOptim(fun=lambda x: x, bounds=[(0, 10), (0, 10)])\n>>> spot.var_trans\n[None, None]\n>>>\n>>> # Normalize transformation names\n>>> spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10), (1, 100)],\n...                  var_trans=['log10', 'id', None, 'None'])\n>>> spot.var_trans\n['log10', None, None, None]\n```\n\n##### inverse_transform_value { #spotoptim.SpotOptim.SpotOptim.inverse_transform_value }\n\n```python\nSpotOptim.SpotOptim.inverse_transform_value(x, trans)\n```\n\nApply inverse transformation to a single float value.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name   | Type            | Description          | Default    |\n|--------|-----------------|----------------------|------------|\n| x      | float           | Transformed value    | _required_ |\n| trans  | Optional\\[str\\] | Transformation name. | _required_ |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description    |\n|--------|--------|----------------|\n|        | float  | Original value |\n\n###### Notes {.doc-section .doc-section-notes}\n\nSee also transform_value.\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> from spotoptim import SpotOptim\n>>> spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10)])\n>>> spot.inverse_transform_value(10, 'log10')\n10.0\n>>> spot.inverse_transform_value(100, 'log(x)')\n10.0\n```\n\n##### load_experiment { #spotoptim.SpotOptim.SpotOptim.load_experiment }\n\n```python\nSpotOptim.SpotOptim.load_experiment(filename)\n```\n\nLoad an experiment configuration from a pickle file.\n\nLoads an experiment that was saved with save_experiment(). The loaded optimizer\nwill have the configuration and the objective function (thanks to dill).\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name     | Type   | Description                         | Default    |\n|----------|--------|-------------------------------------|------------|\n| filename | str    | Path to the experiment pickle file. | _required_ |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name      | Type      | Description                                       |\n|-----------|-----------|---------------------------------------------------|\n| SpotOptim | SpotOptim | Loaded optimizer instance (without fun attached). |\n\n###### Raises {.doc-section .doc-section-raises}\n\n| Name   | Type              | Description                          |\n|--------|-------------------|--------------------------------------|\n|        | FileNotFoundError | If the specified file doesn't exist. |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>>\n>>> # Load experiment\n>>> opt = SpotOptim.load_experiment(\"sphere_opt_exp.pkl\")\nLoaded experiment from sphere_opt_exp.pkl\n>>>\n>>> # Re-attach objective function\n>>> opt.fun = lambda X: np.sum(X**2, axis=1)\n>>>\n>>> # Run optimization\n>>> result = opt.optimize()\n```\n\n##### load_result { #spotoptim.SpotOptim.SpotOptim.load_result }\n\n```python\nSpotOptim.SpotOptim.load_result(filename)\n```\n\nLoad complete optimization results from a pickle file.\n\nLoads results that were saved with save_result(). The loaded optimizer\nwill have both configuration and all optimization results.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name     | Type   | Description                     | Default    |\n|----------|--------|---------------------------------|------------|\n| filename | str    | Path to the result pickle file. | _required_ |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name      | Type      | Description                                      |\n|-----------|-----------|--------------------------------------------------|\n| SpotOptim | SpotOptim | Loaded optimizer instance with complete results. |\n\n###### Raises {.doc-section .doc-section-raises}\n\n| Name   | Type              | Description                          |\n|--------|-------------------|--------------------------------------|\n|        | FileNotFoundError | If the specified file doesn't exist. |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>>\n>>> # Load results\n>>> opt = SpotOptim.load_result(\"sphere_opt_res.pkl\")\nLoaded result from sphere_opt_res.pkl\n>>>\n>>> # Analyze results\n>>> print(\"Best point:\", opt.best_x_)\n>>> print(\"Best value:\", opt.best_y_)\n>>> print(\"Total evaluations:\", opt.counter)\n>>> print(\"Success rate:\", opt.success_rate)\n>>>\n>>> # Continue optimization if needed\n>>> # opt.fun = lambda X: np.sum(X**2, axis=1)  # Re-attach if continuing\n>>> # opt.max_iter = 50  # Increase budget\n>>> # result = opt.optimize()\n```\n\n##### modify_bounds_based_on_var_type { #spotoptim.SpotOptim.SpotOptim.modify_bounds_based_on_var_type }\n\n```python\nSpotOptim.SpotOptim.modify_bounds_based_on_var_type()\n```\n\nModify bounds based on variable types.\n\nAdjusts bounds for each dimension according to its var_type:\n- 'int': Ensures bounds are integers (ceiling for lower, floor for upper)\n- 'factor': Bounds already set to (0, n_levels-1) by process_factor_bounds\n- 'float': Explicitly converts bounds to float\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description   |\n|--------|--------|---------------|\n|        | None   | None          |\n\n###### Raises {.doc-section .doc-section-raises}\n\n| Name   | Type       | Description                                |\n|--------|------------|--------------------------------------------|\n|        | ValueError | If an unsupported var_type is encountered. |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> from spotoptim import SpotOptim\n>>> spot = SpotOptim(fun=lambda x: x, bounds=[(0.5, 10.5)], var_type=['int'])\n>>> spot.bounds\n[(1, 10)]\n>>> spot = SpotOptim(fun=lambda x: x, bounds=[(0, 10)], var_type=['float'])\n>>> spot.bounds\n[(0.0, 10.0)]\n```\n\n##### optimize { #spotoptim.SpotOptim.SpotOptim.optimize }\n\n```python\nSpotOptim.SpotOptim.optimize(X0=None)\n```\n\nRun the optimization process.\n\nThe optimization terminates when either:\n- Total function evaluations reach max_iter (including initial design), OR\n- Runtime exceeds max_time minutes\n\nInput/Output Spaces:\n- Input X0: Expected in Natural Space (original scale, physical units).\n- Output result.x: Returned in Natural Space.\n- Output result.X: Returned in Natural Space.\n- Internal Optimization: Performed in Transformed and Mapped Space.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name   | Type    | Description                                                                                                                       | Default   |\n|--------|---------|-----------------------------------------------------------------------------------------------------------------------------------|-----------|\n| X0     | ndarray | Initial design points in Natural Space, shape (n_initial, n_features). If None, generates space-filling design. Defaults to None. | `None`    |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name           | Type           | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n|----------------|----------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| OptimizeResult | OptimizeResult | Optimization result with fields: - x: best point found in Natural Space - fun: best function value - nfev: number of function evaluations (including initial design) - nit: number of sequential optimization iterations (after initial design) - success: whether optimization succeeded - message: termination message indicating reason for stopping, including   statistics (function value, iterations, evaluations) - X: all evaluated points in Natural Space - y: all function values |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>> opt = SpotOptim(\n...     fun=lambda X: np.sum(X**2, axis=1),\n...     bounds=[(-5, 5), (-5, 5)],\n...     n_initial=5,\n...     max_iter=20,\n...     seed=0,\n...     x0=np.array([0.0, 0.0]),\n...     verbose=True\n... )\n>>> result = opt.optimize()\n>>> print(result.message.splitlines()[0])\nOptimization terminated: maximum evaluations (20) reached\n>>> print(\"Best point:\", result.x)\nBest point: [0. 0.]\n>>> print(\"Best value:\", result.fun)\nBest value: 0.0\n```\n\n##### optimize_acquisition_func { #spotoptim.SpotOptim.SpotOptim.optimize_acquisition_func }\n\n```python\nSpotOptim.SpotOptim.optimize_acquisition_func()\n```\n\nOptimize the acquisition function to find the next point to evaluate.\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name    | Type       | Description                                                                                                                                                                                                                                        |\n|---------|------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| ndarray | np.ndarray | The optimized point(s). If acquisition_fun_return_size == 1, returns 1D array of shape (n_features,). If acquisition_fun_return_size > 1, returns 2D array of shape (N, n_features), where N is min(acquisition_fun_return_size, population_size). |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>> opt = SpotOptim(\n...     fun=lambda X: np.sum(X**2, axis=1),\n...     bounds=[(-5, 5), (-5, 5)],\n...     acquisition='ei'\n... )\n>>> X_train = np.array([[0, 0], [1, 1], [2, 2]])\n>>> y_train = np.array([0, 2, 8])\n>>> opt._fit_surrogate(X_train, y_train)\n>>> x_next = opt.optimize_acquisition_func()\n>>> print(\"Next point to evaluate:\", x_next)\nNext point to evaluate: [some float values]\n```\n\n##### plot_importance { #spotoptim.SpotOptim.SpotOptim.plot_importance }\n\n```python\nSpotOptim.SpotOptim.plot_importance(threshold=0.0, figsize=(10, 6))\n```\n\nPlot variable importance.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name      | Type   | Description                                       | Default   |\n|-----------|--------|---------------------------------------------------|-----------|\n| threshold | float  | Minimum importance percentage to include in plot. | `0.0`     |\n| figsize   | tuple  | Figure size.                                      | `(10, 6)` |\n\n##### plot_important_hyperparameter_contour { #spotoptim.SpotOptim.SpotOptim.plot_important_hyperparameter_contour }\n\n```python\nSpotOptim.SpotOptim.plot_important_hyperparameter_contour(\n    max_imp=3,\n    show=True,\n    alpha=0.8,\n    cmap='jet',\n    num=100,\n    add_points=True,\n    grid_visible=True,\n    contour_levels=30,\n    figsize=(12, 10),\n)\n```\n\nPlot surrogate contours using spotoptim.plot.visualization.plot_important_hyperparameter_contour.\n\n##### plot_parameter_scatter { #spotoptim.SpotOptim.SpotOptim.plot_parameter_scatter }\n\n```python\nSpotOptim.SpotOptim.plot_parameter_scatter(\n    result=None,\n    show=True,\n    figsize=(12, 10),\n    ylabel='Objective Value',\n    cmap='viridis_r',\n    show_correlation=False,\n    log_y=False,\n)\n```\n\nPlot parameter distributions showing relationship between each parameter and objective.\n\nCreates a grid of scatter plots, one for each parameter dimension, showing how\nthe objective function value varies with each parameter. The best configuration\nis marked with a red star. Parameters with log-scale transformations (var_trans)\nare automatically displayed on a log x-axis.\n\nOptionally displays Spearman correlation coefficients in plot titles for\nsensitivity analysis. For factor (categorical) variables, correlation is not\ncomputed and they are displayed with discrete positions on the x-axis.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name             | Type           | Description                                                                                                             | Default             |\n|------------------|----------------|-------------------------------------------------------------------------------------------------------------------------|---------------------|\n| result           | OptimizeResult | Optimization result containing best parameters. If None, uses the best found values from self.best_x_ and self.best_y_. | `None`              |\n| show             | bool           | Whether to display the plot. Defaults to True.                                                                          | `True`              |\n| figsize          | tuple          | Figure size as (width, height). Defaults to (12, 10).                                                                   | `(12, 10)`          |\n| ylabel           | str            | Label for y-axis. Defaults to \"Objective Value\".                                                                        | `'Objective Value'` |\n| cmap             | str            | Colormap for scatter plot. Defaults to \"viridis_r\".                                                                     | `'viridis_r'`       |\n| show_correlation | bool           | Whether to compute and display Spearman correlation coefficients in plot titles. Requires scipy. Defaults to False.     | `False`             |\n| log_y            | bool           | Whether to use logarithmic scale for y-axis. Defaults to False.                                                         | `False`             |\n\n###### Raises {.doc-section .doc-section-raises}\n\n| Name   | Type       | Description                           |\n|--------|------------|---------------------------------------|\n|        | ValueError | If no optimization data is available. |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>> def objective(X):\n...     return np.sum(X**2, axis=1)\n>>> opt = SpotOptim(\n...     fun=objective,\n...     bounds=[(-5, 5), (-5, 5), (-5, 5), (-5, 5)],\n...     var_name=[\"x0\", \"x1\", \"x2\", \"x3\"],\n...     max_iter=30,\n...     n_initial=10,\n...     seed=42\n... )\n>>> result = opt.optimize()\n>>> # Plot parameter distributions\n>>> opt.plot_parameter_scatter(result)\n>>> # Plot with custom settings\n>>> opt.plot_parameter_scatter(result, cmap=\"plasma\", ylabel=\"Error\")\n```\n\n##### plot_progress { #spotoptim.SpotOptim.SpotOptim.plot_progress }\n\n```python\nSpotOptim.SpotOptim.plot_progress(\n    show=True,\n    log_y=False,\n    figsize=(10, 6),\n    ylabel='Objective Value',\n    mo=False,\n)\n```\n\nPlot optimization progress using spotoptim.plot.visualization.plot_progress.\n\n##### plot_surrogate { #spotoptim.SpotOptim.SpotOptim.plot_surrogate }\n\n```python\nSpotOptim.SpotOptim.plot_surrogate(\n    i=0,\n    j=1,\n    show=True,\n    alpha=0.8,\n    var_name=None,\n    cmap='jet',\n    num=100,\n    vmin=None,\n    vmax=None,\n    add_points=True,\n    grid_visible=True,\n    contour_levels=30,\n    figsize=(12, 10),\n)\n```\n\nPlot the surrogate model for two dimensions.\n\nDelegates to spotoptim.plot.visualization.plot_surrogate.\n\n##### print_best { #spotoptim.SpotOptim.SpotOptim.print_best }\n\n```python\nSpotOptim.SpotOptim.print_best(\n    result=None,\n    transformations=None,\n    show_name=True,\n    precision=4,\n)\n```\n\nPrint the best solution found during optimization.\n\nThis method displays the best hyperparameters and objective value in a\nformatted table. It supports custom transformations for parameters\n(e.g., converting log-scale values back to original scale).\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name            | Type             | Description                                                                                                                                                                                                                                                                                                                                | Default   |\n|-----------------|------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------|\n| result          | OptimizeResult   | Optimization result object from optimize(). If None, uses the stored best values from the optimizer. Defaults to None.                                                                                                                                                                                                                     | `None`    |\n| transformations | list of callable | List of transformation functions to apply to each parameter. Each function takes a single value and returns the transformed value. Use None for parameters that don't need transformation. Length must match number of dimensions. Example: [None, None, lambda x: 10**x] to convert the 3rd parameter from log10 scale. Defaults to None. | `None`    |\n| show_name       | bool             | Whether to display variable names. If False, uses generic names like 'x0', 'x1', etc. Defaults to True.                                                                                                                                                                                                                                    | `True`    |\n| precision       | int              | Number of decimal places for floating point values. Defaults to 4.                                                                                                                                                                                                                                                                         | `4`       |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>>\n>>> # Example 1: Basic usage\n>>> def sphere(X):\n...     return np.sum(X**2, axis=1)\n>>> opt = SpotOptim(\n...     fun=sphere,\n...     bounds=[(-5, 5), (-5, 5)],\n...     var_name=[\"x1\", \"x2\"],\n...     max_iter=20,\n...     n_initial=10\n... )\n>>> result = opt.optimize()\n>>> opt.print_best(result)\n\nBest Solution Found:\n--------------------------------------------------\n  x1: 0.0123\n  x2: -0.0045\n  Objective Value: 0.000173\n  Total Evaluations: 20\n>>>\n>>> # Example 2: With log-scale transformations (e.g., for learning rates)\n>>> def objective(X):\n...     # X[:, 0]: neurons (int), X[:, 1]: layers (int),\n...     # X[:, 2]: log10(lr), X[:, 3]: log10(alpha)\n...     return np.sum(X**2, axis=1)  # Placeholder\n>>> opt = SpotOptim(\n...     fun=objective,\n...     bounds=[(16, 128), (1, 4), (-3, 0), (-2, 1)],\n...     var_type=[\"int\", \"int\", \"float\", \"float\"],\n...     var_name=[\"neurons\", \"layers\", \"log10_lr\", \"log10_alpha\"],\n...     max_iter=30,\n...     n_initial=10\n... )\n>>> result = opt.optimize()\n>>> # Transform log-scale parameters back to original scale\n>>> transformations = [\n...     int,              # neurons -> int\n...     int,              # layers -> int\n...     lambda x: 10**x,  # log10_lr -> lr\n...     lambda x: 10**x   # log10_alpha -> alpha\n... ]\n>>> opt.print_best(result, transformations=transformations)\n\nBest Solution Found:\n--------------------------------------------------\n  neurons: 64\n  layers: 2\n  log10_lr: 0.0012\n  log10_alpha: 0.0345\n  Objective Value: 1.2345\n  Total Evaluations: 30\n>>>\n>>> # Example 3: Without result object (using stored values)\n>>> opt.print_best()  # Uses opt.best_x_ and opt.best_y_\n>>>\n>>> # Example 4: Hide variable names\n>>> opt.print_best(result, show_name=False)\n\nBest Solution Found:\n--------------------------------------------------\n  x0: 0.0123\n  x1: -0.0045\n  Objective Value: 0.000173\n  Total Evaluations: 20\n```\n\n##### print_design_table { #spotoptim.SpotOptim.SpotOptim.print_design_table }\n\n```python\nSpotOptim.SpotOptim.print_design_table(tablefmt='github', precision=4)\n```\n\nPrint (and return) a table showing the search space design before optimization.\n\nThis method calls `get_design_table` to generate the table string, prints it,\nand then returns it.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name      | Type   | Description                                               | Default    |\n|-----------|--------|-----------------------------------------------------------|------------|\n| tablefmt  | str    | Table format for tabulate library. Defaults to 'github'.  | `'github'` |\n| precision | int    | Number of decimal places for float values. Defaults to 4. | `4`        |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description             |\n|--------|--------|-------------------------|\n| str    | str    | Formatted table string. |\n\n##### print_results { #spotoptim.SpotOptim.SpotOptim.print_results }\n\n```python\nSpotOptim.SpotOptim.print_results(*args, **kwargs)\n```\n\nAlias for print_results_table for compatibility.\nPrints the table.\n\n##### print_results_table { #spotoptim.SpotOptim.SpotOptim.print_results_table }\n\n```python\nSpotOptim.SpotOptim.print_results_table(\n    tablefmt='github',\n    precision=4,\n    show_importance=False,\n    *args,\n    **kwargs,\n)\n```\n\nPrint (and return) a comprehensive table of optimization results.\n\nThis method calls `get_results_table` to generate the table string, prints it,\nand then returns it.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name            | Type   | Description                                    | Default    |\n|-----------------|--------|------------------------------------------------|------------|\n| tablefmt        | str    | Table format. Defaults to 'github'.            | `'github'` |\n| precision       | int    | Decimal precision. Defaults to 4.              | `4`        |\n| show_importance | bool   | Show importance column. Defaults to False.     | `False`    |\n| *args           | Any    | Arguments passed to get_results_table.         | `()`       |\n| **kwargs        | Any    | Keyword arguments passed to get_results_table. | `{}`       |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description             |\n|--------|--------|-------------------------|\n| str    | str    | Formatted table string. |\n\n##### process_factor_bounds { #spotoptim.SpotOptim.SpotOptim.process_factor_bounds }\n\n```python\nSpotOptim.SpotOptim.process_factor_bounds()\n```\n\nProcess bounds to handle factor variables.\n\nFor dimensions with tuple bounds (factor variables), creates internal\ninteger mappings and replaces bounds with (0, n_levels-1).\n\nStores mappings in self._factor_maps: {dim_idx: {int_val: str_val}}\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description   |\n|--------|--------|---------------|\n|        | None   | None          |\n\n###### Raises {.doc-section .doc-section-raises}\n\n| Name   | Type       | Description                        |\n|--------|------------|------------------------------------|\n|        | ValueError | If bounds are invalidly formatted. |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> from spotoptim import SpotOptim\n>>> spot = SpotOptim(fun=lambda x: x, bounds=[('red', 'green', 'blue'), (0, 10)])\n>>> spot.process_factor_bounds()\nFactor variable at dimension 0:\n  Levels: ['red', 'green', 'blue']\n  Mapped to integers: 0 to 2\n>>> print(spot.bounds)\n[(0, 2), (0, 10)]\n```\n\n##### save_experiment { #spotoptim.SpotOptim.SpotOptim.save_experiment }\n\n```python\nSpotOptim.SpotOptim.save_experiment(\n    filename=None,\n    prefix='experiment',\n    path=None,\n    overwrite=True,\n    unpickleables='all',\n    verbosity=0,\n)\n```\n\nSave the experiment configuration to a pickle file.\n\nAn experiment contains the optimizer configuration needed to run optimization,\nbut excludes the results. This is useful for defining experiments locally and\nexecuting them on remote machines.\n\nThe experiment includes:\n- Bounds, variable types, variable names\n- Optimization parameters (max_iter, n_initial, etc.)\n- Surrogate and acquisition settings\n- Random seed\n\nThe experiment excludes:\n- Function evaluations (X_, y_)\n- Optimization results\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name          | Type   | Description                                                                                                                                                                           | Default        |\n|---------------|--------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------|\n| filename      | str    | Filename for the experiment file. If None, generates from prefix. Defaults to None.                                                                                                   | `None`         |\n| prefix        | str    | Prefix for auto-generated filename. Defaults to \"experiment\".                                                                                                                         | `'experiment'` |\n| path          | str    | Directory path to save the file. If None, saves in current directory. Creates directory if it doesn't exist. Defaults to None.                                                        | `None`         |\n| overwrite     | bool   | If True, overwrites existing file. If False, raises error if file exists. Defaults to True.                                                                                           | `True`         |\n| unpickleables | str    | Components to exclude for pickling: - \"all\": Excludes surrogate, lhs_sampler, tb_writer (experiment only) - \"file_io\": Excludes only tb_writer (lighter exclusion) Defaults to \"all\". | `'all'`        |\n| verbosity     | int    | Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.                                                                                                                       | `0`            |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description   |\n|--------|--------|---------------|\n|        | None   | None          |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>>\n>>> # Define experiment locally\n>>> opt = SpotOptim(\n...     fun=lambda X: np.sum(X**2, axis=1),\n...     bounds=[(-5, 5), (-5, 5)],\n...     max_iter=30,\n...     n_initial=10,\n...     seed=42\n... )\n>>>\n>>> # Save experiment (without results)\n>>> opt.save_experiment(prefix=\"sphere_opt\")\nExperiment saved to sphere_opt_exp.pkl\n>>>\n>>> # On remote machine: load and run\n>>> # opt_remote = SpotOptim.load_experiment(\"sphere_opt_exp.pkl\")\n>>> # result = opt_remote.optimize()\n>>> # opt_remote.save_result(prefix=\"sphere_opt\")  # Save results\n```\n\n##### save_result { #spotoptim.SpotOptim.SpotOptim.save_result }\n\n```python\nSpotOptim.SpotOptim.save_result(\n    filename=None,\n    prefix='result',\n    path=None,\n    overwrite=True,\n    verbosity=0,\n)\n```\n\nSave the complete optimization results to a pickle file.\n\nA result contains all information from a completed optimization run, including\nthe experiment configuration and all evaluation results. This is useful for\nsaving completed runs for later analysis.\n\nThe result includes everything in an experiment plus:\n- All evaluated points (X_)\n- All function values (y_)\n- Best point and best value\n- Iteration count\n- Success rate statistics\n- Noise statistics (if applicable)\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name      | Type   | Description                                                                                                                    | Default    |\n|-----------|--------|--------------------------------------------------------------------------------------------------------------------------------|------------|\n| filename  | str    | Filename for the result file. If None, generates from prefix. Defaults to None.                                                | `None`     |\n| prefix    | str    | Prefix for auto-generated filename. Defaults to \"result\".                                                                      | `'result'` |\n| path      | str    | Directory path to save the file. If None, saves in current directory. Creates directory if it doesn't exist. Defaults to None. | `None`     |\n| overwrite | bool   | If True, overwrites existing file. If False, raises error if file exists. Defaults to True.                                    | `True`     |\n| verbosity | int    | Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.                                                                | `0`        |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description   |\n|--------|--------|---------------|\n|        | None   | None          |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>>\n>>> # Run optimization\n>>> opt = SpotOptim(\n...     fun=lambda X: np.sum(X**2, axis=1),\n...     bounds=[(-5, 5), (-5, 5)],\n...     max_iter=30,\n...     n_initial=10,\n...     seed=42\n... )\n>>> result = opt.optimize()\n>>>\n>>> # Save complete results\n>>> opt.save_result(prefix=\"sphere_opt\")\nResult saved to sphere_opt_res.pkl\n>>>\n>>> # Later: load and analyze\n>>> # opt_loaded = SpotOptim.load_result(\"sphere_opt_res.pkl\")\n>>> # print(\"Best value:\", opt_loaded.best_y_)\n>>> # opt_loaded.plot_surrogate()\n```\n\n##### select_new { #spotoptim.SpotOptim.SpotOptim.select_new }\n\n```python\nSpotOptim.SpotOptim.select_new(A, X, tolerance=0)\n```\n\nSelect rows from A that are not in X.\nUsed in suggest_next_infill_point() to avoid duplicate evaluations.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name      | Type    | Description                                    | Default    |\n|-----------|---------|------------------------------------------------|------------|\n| A         | ndarray | Array with new values.                         | _required_ |\n| X         | ndarray | Array with known values.                       | _required_ |\n| tolerance | float   | Tolerance value for comparison. Defaults to 0. | `0`        |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type                            | Description                                                                                                                  |\n|--------|---------------------------------|------------------------------------------------------------------------------------------------------------------------------|\n| tuple  | Tuple\\[np.ndarray, np.ndarray\\] | A tuple containing: - ndarray: Array with unknown (new) values. - ndarray: Array with True if value is new, otherwise False. |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>> opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1), bounds=[(-5, 5)])\n>>> A = np.array([[1, 2], [3, 4], [5, 6]])\n>>> X = np.array([[3, 4], [7, 8]])\n>>> new_A, is_new = opt.select_new(A, X)\n>>> print(\"New A:\", new_A)\nNew A: [[1 2]\n [5 6]]\n>>> print(\"Is new:\", is_new)\nIs new: [ True False  True]\n```\n\n##### sensitivity_spearman { #spotoptim.SpotOptim.SpotOptim.sensitivity_spearman }\n\n```python\nSpotOptim.SpotOptim.sensitivity_spearman()\n```\n\nCompute and print Spearman correlation between parameters and objective values.\n\nThis method analyzes the sensitivity of the objective function to each\nhyperparameter by computing Spearman rank correlations. For categorical\n(factor) variables, correlation is not computed as they require visual\ninspection instead.\n\nThe method automatically handles different parameter types:\n- Integer/float parameters: Direct correlation with objective values\n- Log-transformed parameters (log10, log, ln): Correlation in log-space\n- Factor (categorical) parameters: Skipped with informative message\n\nSignificance levels:\n- ***: p < 0.001 (highly significant)\n- **: p < 0.01 (significant)\n- *: p < 0.05 (marginally significant)\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> from spotoptim import SpotOptim\n>>> import numpy as np\n>>>\n>>> # After running optimization\n>>> opt = SpotOptim(...)\n>>> result = opt.optimize()\n>>> opt.sensitivity_spearman()\nSensitivity Analysis (Spearman Correlation):\n--------------------------------------------------\n  l1 (neurons)        : +0.005 (p=0.959)\n  num_layers          : -0.192 (p=0.056)\n  activation          : (categorical variable, use visual inspection)\n  lr_unified          : -0.040 (p=0.689)\n  alpha               : -0.233 (p=0.020) *\n```\n\n###### Note {.doc-section .doc-section-note}\n\nRequires scipy to be installed. If not available, raises ImportError.\nOnly meaningful after optimize() has been called with sufficient evaluations.\n\n##### suggest_next_infill_point { #spotoptim.SpotOptim.SpotOptim.suggest_next_infill_point }\n\n```python\nSpotOptim.SpotOptim.suggest_next_infill_point()\n```\n\nSuggest next point to evaluate (dispatcher).\n\nThe returned point is in the **Transformed and Mapped Space** (Internal Optimization Space).\nThis means:\n1. Transformations (e.g., log, sqrt) have been applied.\n2. Dimension reduction has been applied (fixed variables removed).\n\nProcess:\n1. Try candidates from acquisition function optimizer.\n2. Handle acquisition failure (fallback).\n3. Return last attempt if all fails.\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name    | Type       | Description                                                    |\n|---------|------------|----------------------------------------------------------------|\n| ndarray | np.ndarray | Next point(s) to evaluate in **Transformed and Mapped Space**. |\n|         | np.ndarray | Shape is (n_infill_points, n_features).                        |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>> opt = SpotOptim(\n...     fun=lambda X: np.sum(X**2, axis=1),\n...     bounds=[(-5, 5), (-5, 5)],\n...     n_initial=5,\n...     n_infill_points=2\n... )\n>>> # Need to initialize optimization state (X_, y_, surrogate)\n>>> # Normally done inside optimize()\n>>> np.random.seed(0)\n>>> opt.X_ = np.random.rand(10, 2)\n>>> opt.y_ = np.random.rand(10)\n>>> opt._fit_surrogate(opt.X_, opt.y_)\n>>> x_next = opt.suggest_next_infill_point()\n>>> x_next.shape\n(2, 2)\n```\n\n##### to_all_dim { #spotoptim.SpotOptim.SpotOptim.to_all_dim }\n\n```python\nSpotOptim.SpotOptim.to_all_dim(X_red)\n```\n\nExpand reduced-dimensional points to full-dimensional representation.\n\nThis method restores points from the reduced optimization space to the\nfull-dimensional space by inserting fixed values for constant dimensions.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name   | Type    | Description                                                 | Default    |\n|--------|---------|-------------------------------------------------------------|------------|\n| X_red  | ndarray | Points in reduced space, shape (n_samples, n_reduced_dims). | _required_ |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name    | Type       | Description                                               |\n|---------|------------|-----------------------------------------------------------|\n| ndarray | np.ndarray | Points in full space, shape (n_samples, n_original_dims). |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>> # Create problem with one fixed dimension\n>>> opt = SpotOptim(\n...     fun=lambda X: np.sum(X**2, axis=1),\n...     bounds=[(-5, 5), (2, 2), (-5, 5)],  # x1 is fixed at 2\n...     max_iter=1,\n...     n_initial=3\n... )\n>>> X_red = np.array([[1.0, 3.0], [2.0, 4.0]])  # Only x0 and x2\n>>> X_full = opt.to_all_dim(X_red)\n>>> X_full.shape\n(2, 3)\n>>> X_full[:, 1]  # Middle dimension should be 2.0\narray([2., 2.])\n```\n\n##### to_red_dim { #spotoptim.SpotOptim.SpotOptim.to_red_dim }\n\n```python\nSpotOptim.SpotOptim.to_red_dim(X_full)\n```\n\nReduce full-dimensional points to optimization space.\n\nThis method removes fixed dimensions from full-dimensional points,\nextracting only the varying dimensions used in optimization.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name   | Type    | Description                                               | Default    |\n|--------|---------|-----------------------------------------------------------|------------|\n| X_full | ndarray | Points in full space, shape (n_samples, n_original_dims). | _required_ |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name    | Type       | Description                                                 |\n|---------|------------|-------------------------------------------------------------|\n| ndarray | np.ndarray | Points in reduced space, shape (n_samples, n_reduced_dims). |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>> # Create problem with one fixed dimension\n>>> opt = SpotOptim(\n...     fun=lambda X: np.sum(X**2, axis=1),\n...     bounds=[(-5, 5), (2, 2), (-5, 5)],  # x1 is fixed at 2\n...     max_iter=1,\n...     n_initial=3\n... )\n>>> X_full = np.array([[1.0, 2.0, 3.0], [4.0, 2.0, 5.0]])\n>>> X_red = opt.to_red_dim(X_full)\n>>> X_red.shape\n(2, 2)\n>>> np.array_equal(X_red, np.array([[1.0, 3.0], [4.0, 5.0]]))\nTrue\n```\n\n##### transform_bounds { #spotoptim.SpotOptim.SpotOptim.transform_bounds }\n\n```python\nSpotOptim.SpotOptim.transform_bounds()\n```\n\nTransform bounds from original to internal scale.\n\nUpdates `self.bounds` (and `self.lower`, `self.upper`) from **Natural Space**\nto **Transformed Space**.\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description   |\n|--------|--------|---------------|\n|        | None   | None          |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> from spotoptim import SpotOptim\n>>> spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10), (0.1, 100)])\n>>> spot.var_trans = ['log10', 'sqrt']\n>>> spot.transform_bounds()\n>>> print(spot.bounds)\n[(0.0, 1.0), (0.31622776601683794, 10.0)]\n```\n\n##### transform_value { #spotoptim.SpotOptim.SpotOptim.transform_value }\n\n```python\nSpotOptim.SpotOptim.transform_value(x, trans)\n```\n\nApply transformation to a single float value.\n\n###### Parameters {.doc-section .doc-section-parameters}\n\n| Name   | Type            | Description                                                                                                                                                                                              | Default    |\n|--------|-----------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------|\n| x      | float           | Value to transform                                                                                                                                                                                       | _required_ |\n| trans  | Optional\\[str\\] | Transformation name. Can be one of 'id', 'log10', 'log', 'ln', 'sqrt',    'exp', 'square', 'cube', 'inv', 'reciprocal', or None.    Also supports dynamic strings like 'log(x)', 'sqrt(x)', 'pow(x, p)'. | _required_ |\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description       |\n|--------|--------|-------------------|\n|        | float  | Transformed value |\n\n###### Raises {.doc-section .doc-section-raises}\n\n| Name   | Type       | Description                                |\n|--------|------------|--------------------------------------------|\n|        | TypeError  | If x is not a float.                       |\n|        | ValueError | If an unknown transformation is specified. |\n\n###### Notes {.doc-section .doc-section-notes}\n\nSee also inverse_transform_value.\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> from spotoptim import SpotOptim\n>>> spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10)])\n>>> spot.transform_value(10, 'log10')\n1.0\n>>> spot.transform_value(100, 'log(x)')\n4.605170185988092\n```\n\n##### update_stats { #spotoptim.SpotOptim.SpotOptim.update_stats }\n\n```python\nSpotOptim.SpotOptim.update_stats()\n```\n\nUpdate optimization statistics.\n\nUpdates various statistics related to the optimization progress:\n- `min_y`: Minimum y value found so far\n- `min_X`: X value corresponding to minimum y\n- `counter`: Total number of function evaluations\n\nNote: `success_rate` is updated separately via `_update_success_rate()` method,\nwhich is called after each batch of function evaluations.\n\nIf `noise` is True (repeats > 1), additionally computes:\n1. `mean_X`: Unique design points (aggregated from repeated evaluations)\n2. `mean_y`: Mean y values per design point\n3. `var_y`: Variance of y values per design point\n4. `min_mean_X`: X value of the best mean y value\n5. `min_mean_y`: Best mean y value\n6. `min_var_y`: Variance of the best mean y value\n\n###### Returns {.doc-section .doc-section-returns}\n\n| Name   | Type   | Description   |\n|--------|--------|---------------|\n|        | None   | None          |\n\n###### Examples {.doc-section .doc-section-examples}\n\n```python\n>>> import numpy as np\n>>> from spotoptim import SpotOptim\n>>> # Without noise\n>>> opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),\n...                 bounds=[(-5, 5), (-5, 5)],\n...                 max_iter=10, n_initial=5)\n>>> opt.X_ = np.array([[1, 2], [3, 4], [0, 1]])\n>>> opt.y_ = np.array([5.0, 25.0, 1.0])\n>>> opt.update_stats()\n>>> opt.min_y\n1.0\n>>> opt.min_X\narray([0, 1])\n>>> opt.counter\n3\n>>>\n>>> # With noise\n>>> opt_noise = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),\n...                       bounds=[(-5, 5), (-5, 5)],\n...                       n_initial=5,\n...                       repeats_initial=2)\n>>> opt_noise.noise = True\n>>> opt_noise.X_ = np.array([[1, 2], [1, 2], [3, 4]])\n>>> opt_noise.y_ = np.array([5.0, 5.0, 25.0])\n>>> opt_noise.update_stats()\n>>> opt_noise.mean_y.shape\n(2,)\n```\n\n### SpotOptimConfig { #spotoptim.SpotOptim.SpotOptimConfig }\n\n```python\nSpotOptim.SpotOptimConfig(\n    bounds=None,\n    max_iter=20,\n    n_initial=10,\n    surrogate=None,\n    acquisition='y',\n    var_type=None,\n    var_name=None,\n    var_trans=None,\n    tolerance_x=None,\n    max_time=np.inf,\n    repeats_initial=1,\n    repeats_surrogate=1,\n    ocba_delta=0,\n    tensorboard_log=False,\n    tensorboard_path=None,\n    tensorboard_clean=False,\n    fun_mo2so=None,\n    seed=None,\n    verbose=False,\n    warnings_filter='ignore',\n    n_infill_points=1,\n    max_surrogate_points=None,\n    selection_method='distant',\n    acquisition_failure_strategy='random',\n    penalty=False,\n    penalty_val=None,\n    acquisition_fun_return_size=3,\n    acquisition_optimizer='differential_evolution',\n    restart_after_n=100,\n    restart_inject_best=True,\n    x0=None,\n    de_x0_prob=0.1,\n    tricands_fringe=False,\n    prob_de_tricands=0.8,\n    window_size=None,\n    min_tol_metric='chebyshev',\n    prob_surrogate=None,\n    n_jobs=1,\n    acquisition_optimizer_kwargs=None,\n    args=(),\n    kwargs=None,\n)\n```\n\nConfiguration parameters for SpotOptim.\n\n### SpotOptimState { #spotoptim.SpotOptim.SpotOptimState }\n\n```python\nSpotOptim.SpotOptimState(\n    X_=None,\n    y_=None,\n    y_mo=None,\n    best_x_=None,\n    best_y_=None,\n    n_iter_=0,\n    counter=0,\n    success_rate=0.0,\n    success_counter=0,\n    _success_history=list(),\n    _zero_success_count=0,\n    mean_X=None,\n    mean_y=None,\n    var_y=None,\n    min_mean_X=None,\n    min_mean_y=None,\n    min_var_y=None,\n    min_X=None,\n    min_y=None,\n    restarts_results_=list(),\n)\n```\n\nMutable state of the optimization process.\n\n",
    "supporting": [
      "SpotOptim_files"
    ],
    "filters": [],
    "includes": {}
  }
}