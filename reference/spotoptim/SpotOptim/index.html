
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="spotoptim - Sequential Parameter Optimization Toolbox in Python">
      
      
      
        <link rel="canonical" href="https://github.com/sequential-parameter-optimization/spotoptim/reference/spotoptim/SpotOptim/">
      
      
        <link rel="prev" href="../../..">
      
      
        <link rel="next" href="../core/data/">
      
      
        
      
      
      <link rel="icon" href="../../../images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>SpotOptim - spotoptim</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#spotoptim.SpotOptim" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="spotoptim" class="md-header__button md-logo" aria-label="spotoptim" data-md-component="logo">
      
  <img src="../../../images/spotlogo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            spotoptim
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              SpotOptim
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="blue-grey" data-md-color-accent="orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/sequential-parameter-optimization/spotoptim/tree/main" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="spotoptim" class="md-nav__button md-logo" aria-label="spotoptim" data-md-component="logo">
      
  <img src="../../../images/spotlogo.png" alt="logo">

    </a>
    spotoptim
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/sequential-parameter-optimization/spotoptim/tree/main" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
    
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Code Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Code Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" checked>
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    spotoptim
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    spotoptim
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    SpotOptim
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    SpotOptim
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptim
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptim
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SpotOptim">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.__dir__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __dir__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.__getattr__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __getattr__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.__setattr__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __setattr__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.detect_var_type" class="md-nav__link">
    <span class="md-ellipsis">
      
        detect_var_type
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.gen_design_table" class="md-nav__link">
    <span class="md-ellipsis">
      
        gen_design_table
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_best_hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_best_hyperparameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_design_table" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_design_table
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_importance" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_importance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_initial_design" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_initial_design
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_results_table" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_results_table
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_stars" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_stars
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.handle_default_var_trans" class="md-nav__link">
    <span class="md-ellipsis">
      
        handle_default_var_trans
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.inverse_transform_value" class="md-nav__link">
    <span class="md-ellipsis">
      
        inverse_transform_value
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.load_experiment" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_experiment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.load_result" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_result
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.modify_bounds_based_on_var_type" class="md-nav__link">
    <span class="md-ellipsis">
      
        modify_bounds_based_on_var_type
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.optimize" class="md-nav__link">
    <span class="md-ellipsis">
      
        optimize
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.optimize_acquisition_func" class="md-nav__link">
    <span class="md-ellipsis">
      
        optimize_acquisition_func
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_importance" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_importance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_important_hyperparameter_contour" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_important_hyperparameter_contour
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_parameter_scatter" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_parameter_scatter
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_progress" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_progress
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_surrogate" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_surrogate
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.print_best" class="md-nav__link">
    <span class="md-ellipsis">
      
        print_best
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.print_design_table" class="md-nav__link">
    <span class="md-ellipsis">
      
        print_design_table
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.print_results" class="md-nav__link">
    <span class="md-ellipsis">
      
        print_results
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.print_results_table" class="md-nav__link">
    <span class="md-ellipsis">
      
        print_results_table
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.process_factor_bounds" class="md-nav__link">
    <span class="md-ellipsis">
      
        process_factor_bounds
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.save_experiment" class="md-nav__link">
    <span class="md-ellipsis">
      
        save_experiment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.save_result" class="md-nav__link">
    <span class="md-ellipsis">
      
        save_result
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.select_new" class="md-nav__link">
    <span class="md-ellipsis">
      
        select_new
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.sensitivity_spearman" class="md-nav__link">
    <span class="md-ellipsis">
      
        sensitivity_spearman
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.suggest_next_infill_point" class="md-nav__link">
    <span class="md-ellipsis">
      
        suggest_next_infill_point
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.to_all_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        to_all_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.to_red_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        to_red_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.transform_bounds" class="md-nav__link">
    <span class="md-ellipsis">
      
        transform_bounds
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.transform_value" class="md-nav__link">
    <span class="md-ellipsis">
      
        transform_value
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.update_stats" class="md-nav__link">
    <span class="md-ellipsis">
      
        update_stats
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptimConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptimConfig
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptimState" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptimState
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../core/data/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    core
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../data/base/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    data
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../eda/plots/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    eda
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../factor_analyzer/confirmatory_factor_analyzer/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    factor_analyzer
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../function/forr08a/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    function
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../hyperparameters/parameters/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    hyperparameters
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../inspection/importance/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    inspection
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../mo/mo_mm/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    mo
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../nn/linear_regressor/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    nn
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../optimizer/schedule_free/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    optimizer
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../plot/contour/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    plot
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../sampling/design/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    sampling
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../surrogate/kernels/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    surrogate
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../tricands/tricands/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    tricands
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../utils/boundaries/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    
  
    utils
  

    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sequential-parameter-optimization-cookbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Documentation
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../download/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Download
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Examples
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../about/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    About
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptim
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptim
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SpotOptim">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.__dir__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __dir__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.__getattr__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __getattr__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.__setattr__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __setattr__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.detect_var_type" class="md-nav__link">
    <span class="md-ellipsis">
      
        detect_var_type
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.gen_design_table" class="md-nav__link">
    <span class="md-ellipsis">
      
        gen_design_table
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_best_hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_best_hyperparameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_design_table" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_design_table
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_importance" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_importance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_initial_design" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_initial_design
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_results_table" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_results_table
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.get_stars" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_stars
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.handle_default_var_trans" class="md-nav__link">
    <span class="md-ellipsis">
      
        handle_default_var_trans
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.inverse_transform_value" class="md-nav__link">
    <span class="md-ellipsis">
      
        inverse_transform_value
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.load_experiment" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_experiment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.load_result" class="md-nav__link">
    <span class="md-ellipsis">
      
        load_result
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.modify_bounds_based_on_var_type" class="md-nav__link">
    <span class="md-ellipsis">
      
        modify_bounds_based_on_var_type
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.optimize" class="md-nav__link">
    <span class="md-ellipsis">
      
        optimize
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.optimize_acquisition_func" class="md-nav__link">
    <span class="md-ellipsis">
      
        optimize_acquisition_func
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_importance" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_importance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_important_hyperparameter_contour" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_important_hyperparameter_contour
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_parameter_scatter" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_parameter_scatter
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_progress" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_progress
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.plot_surrogate" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_surrogate
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.print_best" class="md-nav__link">
    <span class="md-ellipsis">
      
        print_best
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.print_design_table" class="md-nav__link">
    <span class="md-ellipsis">
      
        print_design_table
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.print_results" class="md-nav__link">
    <span class="md-ellipsis">
      
        print_results
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.print_results_table" class="md-nav__link">
    <span class="md-ellipsis">
      
        print_results_table
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.process_factor_bounds" class="md-nav__link">
    <span class="md-ellipsis">
      
        process_factor_bounds
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.save_experiment" class="md-nav__link">
    <span class="md-ellipsis">
      
        save_experiment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.save_result" class="md-nav__link">
    <span class="md-ellipsis">
      
        save_result
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.select_new" class="md-nav__link">
    <span class="md-ellipsis">
      
        select_new
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.sensitivity_spearman" class="md-nav__link">
    <span class="md-ellipsis">
      
        sensitivity_spearman
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.suggest_next_infill_point" class="md-nav__link">
    <span class="md-ellipsis">
      
        suggest_next_infill_point
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.to_all_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        to_all_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.to_red_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        to_red_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.transform_bounds" class="md-nav__link">
    <span class="md-ellipsis">
      
        transform_bounds
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.transform_value" class="md-nav__link">
    <span class="md-ellipsis">
      
        transform_value
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptim.update_stats" class="md-nav__link">
    <span class="md-ellipsis">
      
        update_stats
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptimConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptimConfig
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spotoptim.SpotOptim.SpotOptimState" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpotOptimState
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
                



  


  <nav class="md-path" aria-label="Navigation" >
    <ol class="md-path__list">
      
        
  
  
    <li class="md-path__item">
      <a href="../../.." class="md-path__link">
        
  <span class="md-ellipsis">
    Home
  </span>

      </a>
    </li>
  

      
      
        
  
  
    
    
      
  
  
    
    
      <li class="md-path__item">
        <a href="./" class="md-path__link">
          
  <span class="md-ellipsis">
    Code Reference
  </span>

        </a>
      </li>
    
  

    
  

      
        
  
  
    
    
      <li class="md-path__item">
        <a href="./" class="md-path__link">
          
  <span class="md-ellipsis">
    spotoptim
  </span>

        </a>
      </li>
    
  

      
    </ol>
  </nav>

              
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>SpotOptim</h1>

<div class="doc doc-object doc-module">



<a id="spotoptim.SpotOptim"></a>
    <div class="doc doc-contents first">










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h2 id="spotoptim.SpotOptim.SpotOptim" class="doc doc-heading">
            <code>SpotOptim</code>


<a href="#spotoptim.SpotOptim.SpotOptim" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="sklearn.base.BaseEstimator">BaseEstimator</span></code></p>



        <p>SPOT optimizer compatible with scipy.optimize interface.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>fun</code>
            </td>
            <td>
                  <code><span title="callable">callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Objective function to minimize. Should accept array of shape (n_samples, n_features).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bounds</code>
            </td>
            <td>
                  <code>list of tuple</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bounds for each dimension as [(low, high), &hellip;].</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_iter</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of total function evaluations (including initial design).
For example, max_iter=30 with n_initial=10 will perform 10 initial evaluations plus
20 sequential optimization iterations. Defaults to 20.</p>
              </div>
            </td>
            <td>
                  <code>20</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_initial</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of initial design points. Defaults to 10.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>surrogate</code>
            </td>
            <td>
                  <code><span title="object">object</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Surrogate model with scikit-learn interface (fit/predict methods).
If None, uses a Gaussian Process Regressor with Matern kernel. Default configuration::</p>
<pre><code>from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern, ConstantKernel

kernel = ConstantKernel(1.0, (1e-2, 1e12)) * Matern(length_scale=1.0, length_scale_bounds=(1e-4, 1e2), nu=2.5)
surrogate = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=100)
surrogate = GaussianProcessRegressor(
    kernel=kernel,
    n_restarts_optimizer=10,
    normalize_y=True,
    random_state=self.seed,
)
</code></pre>
<p>Alternative surrogates can be provided, including SpotOptim&rsquo;s Kriging model,
Random Forests, or any scikit-learn compatible regressor. See Examples section.
Defaults to None (uses default Gaussian Process configuration).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>acquisition</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Acquisition function (&lsquo;ei&rsquo;, &lsquo;y&rsquo;, &lsquo;pi&rsquo;). Defaults to &lsquo;y&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;y&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>var_type</code>
            </td>
            <td>
                  <code>list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable types for each dimension. Supported types:
- &lsquo;float&rsquo;: Python floats, continuous optimization (no rounding)
- &lsquo;int&rsquo;: Python int, float values will be rounded to integers
- &lsquo;factor&rsquo;: Unordered categorical data, internally mapped to int values
  (e.g., &ldquo;red&rdquo;-&gt;0, &ldquo;green&rdquo;-&gt;1, etc.)
Defaults to None (which sets all dimensions to &lsquo;float&rsquo;).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>var_name</code>
            </td>
            <td>
                  <code>list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable names for each dimension.
If None, uses default names [&lsquo;x0&rsquo;, &lsquo;x1&rsquo;, &lsquo;x2&rsquo;, &hellip;]. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance_x</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Minimum distance between points. Defaults to np.sqrt(np.spacing(1))</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>var_trans</code>
            </td>
            <td>
                  <code>list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variable transformations for each dimension. Supported:
- &lsquo;log&rsquo;: Logarithmic transformation, e.g. &ldquo;log10&rdquo; for base-10 log
- &lsquo;sqrt&rsquo;: Square root transformation, &ldquo;sqrt&rdquo; for square root
- None or &lsquo;id&rsquo; or &lsquo;None&rsquo;: No transformation
Defaults to None (no transformations).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_time</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum runtime in minutes. If np.inf (default), no time limit.
The optimization terminates when either max_iter evaluations are reached OR max_time
minutes have elapsed, whichever comes first. Defaults to np.inf.</p>
              </div>
            </td>
            <td>
                  <code><span title="numpy.inf">inf</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>repeats_initial</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of times to evaluate each initial design point.
Useful for noisy objective functions. If &gt; 1, noise handling is activated and
statistics (mean, variance) are tracked. Defaults to 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>repeats_surrogate</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of times to evaluate each surrogate-suggested point.
Useful for noisy objective functions. If &gt; 1, noise handling is activated and
statistics (mean, variance) are tracked. Defaults to 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ocba_delta</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of additional evaluations to allocate using Optimal Computing
Budget Allocation (OCBA) when noise handling is active. OCBA determines which existing
design points should be re-evaluated to best distinguish between alternatives. Only used
when noise=True (repeats &gt; 1) and ocba_delta &gt; 0. Requires at least 3 design points with
variance information. Defaults to 0 (no OCBA).</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tensorboard_log</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Enable TensorBoard logging. If True, optimization metrics
and hyperparameters are logged to TensorBoard. View logs by running:
<code>tensorboard --logdir=&lt;tensorboard_path&gt;</code> in a separate terminal. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tensorboard_path</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path for TensorBoard log files. If None and tensorboard_log
is True, creates a default path: runs/spotoptim_YYYYMMDD_HHMMSS. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tensorboard_clean</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, removes all old TensorBoard log directories from
the &lsquo;runs&rsquo; folder before starting optimization. Use with caution as this permanently
deletes all subdirectories in &lsquo;runs&rsquo;. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fun_mo2so</code>
            </td>
            <td>
                  <code><span title="callable">callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to convert multi-objective values to single-objective.
Takes an array of shape (n_samples, n_objectives) and returns array of shape (n_samples,).
If None and objective function returns multi-objective values, uses first objective.
Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random seed for reproducibility. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbose</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Print progress information. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>warnings_filter</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Filter for warnings. One of &ldquo;error&rdquo;, &ldquo;ignore&rdquo;, &ldquo;always&rdquo;, &ldquo;all&rdquo;,
&ldquo;default&rdquo;, &ldquo;module&rdquo;, or &ldquo;once&rdquo;. Defaults to &ldquo;ignore&rdquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;ignore&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_infill_points</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of infill points to suggest at each iteration.
Defaults to 1. If &gt; 1, multiple distinct points are proposed using the optimizer
and fallback strategies.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_surrogate_points</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of points to use for surrogate model fitting.
If None, all points are used. If the number of evaluated points exceeds this limit,
a subset is selected using the selection method. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>selection_method</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Method for selecting points when max_surrogate_points is exceeded.
Options: &lsquo;distant&rsquo; (Select points that are distant from each other via K-means clustering) or
&lsquo;best&rsquo; (Select all points from the cluster with the best mean objective value).
Defaults to &lsquo;distant&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;distant&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>acquisition_failure_strategy</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Strategy for handling acquisition function failures.
Options: &lsquo;random&rsquo; (space-filling design via Latin Hypercube Sampling)
Defaults to &lsquo;random&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;random&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>penalty</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use penalty for handling NaN/inf values in objective function evaluations.
Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>penalty_val</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Penalty value to replace NaN/inf values in objective function evaluations.
When the objective function returns NaN or inf, these values are replaced with penalty plus
a small random noise (sampled from N(0, 0.1)) to avoid identical penalty values.
This allows optimization to continue despite occasional function evaluation failures.
Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>acquisition_fun_return_size</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of top candidates to return from acquisition function optimization.
Defaults to 3.</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>acquisition_optimizer</code>
            </td>
            <td>
                  <code><span title="str">str</span> or <span title="callable">callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optimizer to use for maximizing acquisition function.
Can be &ldquo;differential_evolution&rdquo; (default) or any method name supported by scipy.optimize.minimize
(e.g., &ldquo;Nelder-Mead&rdquo;, &ldquo;L-BFGS-B&rdquo;). Can also be a callable with signature compatible with
scipy.optimize.minimize (fun, x0, bounds, &hellip;). A specific version is &ldquo;de_tricands&rdquo;, which combines DE with Tricands.
It can be parameterized with &ldquo;prob_de_tricands&rdquo; (probability of using DE).
Defaults to &ldquo;differential_evolution&rdquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;differential_evolution&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>acquisition_optimizer_kwargs</code>
            </td>
            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Kwargs passed to the acquisition function optimizer
and GPR surrogate optimizer. Defaults to {&lsquo;maxiter&rsquo;: 10000, &lsquo;gtol&rsquo;: 1e-9}.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>restart_after_n</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of consecutive iterations with zero success rate
before triggering a restart. Defaults to 100.</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>restart_inject_best</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to inject the best solution found so far
as a starting point for the next restart. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>x0</code>
            </td>
            <td>
                  <code><span title="array">array</span> - <span title="like">like</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Starting point for optimization, shape (n_features,).
If provided, this point will be evaluated first and included in the initial design.
The point should be within the bounds and will be validated before use.
Defaults to None (no starting point, uses only LHS design).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>de_x0_prob</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Probability of using the best point as starting point for differential evolution.
Defaults to 0.1.</p>
              </div>
            </td>
            <td>
                  <code>0.1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tricands_fringe</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use the fringe of the design space for the initial design.
Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prob_de_tricands</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Probability of using differential evolution as an optimizer
on the surrogate model. 1 - prob_de_tricands is the probability of using tricands. Defaults to 0.8.</p>
              </div>
            </td>
            <td>
                  <code>0.8</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>window_size</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Window size for success rate calculation.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>min_tol_metric</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Distance metric used when checking <code>tolerance_x</code> for
duplicate detection. Default is &ldquo;chebyshev&rdquo;. Supports all metrics from
scipy.spatial.distance.cdist, including:
- &ldquo;chebyshev&rdquo;: L-infinity distance (hypercube). Default. Matches previous behavior.
- &ldquo;euclidean&rdquo;: L2 distance (hypersphere).
- &ldquo;minkowski&rdquo;: Lp distance (default p=2).
- &ldquo;cityblock&rdquo;: Manhattan/L1 distance.
- &ldquo;cosine&rdquo;: Cosine distance.
- &ldquo;correlation&rdquo;: Correlation distance.
- &ldquo;canberra&rdquo;, &ldquo;braycurtis&rdquo;, &ldquo;sqeuclidean&rdquo;, etc.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.X_">X_</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>All evaluated points, shape (n_samples, n_features).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.y_">y_</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function values at X_, shape (n_samples,). For multi-objective problems,
these are the converted single-objective values.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.y_mo">y_mo</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Multi-objective function values, shape (n_samples, n_objectives).
None for single-objective problems.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.best_x_">best_x_</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Best point found, shape (n_features,).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.best_y_">best_y_</span></code></td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Best function value found.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.n_iter_">n_iter_</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of iterations performed. This is not the same as counter. Provided for compatibility with scipy.optimize routines.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.counter">counter</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of function evaluations.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.success_rate">success_rate</span></code></td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Rolling success rate over the last window_size evaluations.
A success is counted when a new evaluation improves upon the best value found so far.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.warnings_filter">warnings_filter</span></code></td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Filter for warnings during optimization.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.max_surrogate_points">max_surrogate_points</span></code></td>
            <td>
                  <code><span title="int">int</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of points for surrogate fitting.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.selection_method">selection_method</span></code></td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Point selection method.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.acquisition_failure_strategy">acquisition_failure_strategy</span></code></td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Strategy for handling acquisition failures (&lsquo;random&rsquo;).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.noise">noise</span></code></td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>True if noise handling is active (repeats &gt; 1).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.mean_X">mean_X</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Aggregated unique design points (if noise=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.mean_y">mean_y</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mean y values per design point (if noise=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.var_y">var_y</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variance of y values per design point (if noise=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.min_mean_X">min_mean_X</span></code></td>
            <td>
                  <code><span title="ndarray">ndarray</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>X value of best mean y (if noise=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.min_mean_y">min_mean_y</span></code></td>
            <td>
                  <code><span title="float">float</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Best mean y value (if noise=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.min_var_y">min_var_y</span></code></td>
            <td>
                  <code><span title="float">float</span> or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Variance of best mean y (if noise=True).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.de_x0_prob">de_x0_prob</span></code></td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Probability of using the best point as starting point for differential evolution.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.tricands_fringe">tricands_fringe</span></code></td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use the fringe of the design space for the initial design.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="spotoptim.SpotOptim.SpotOptim.prob_de_tricands">prob_de_tricands</span></code></td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Probability of using differential evolution as an optimizer on the surrogate model.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">objective</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 1: Basic usage (deterministic function)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_initial</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best x:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best f(x):&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 2: With custom variable names</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;param1&quot;</span><span class="p">,</span> <span class="s2">&quot;param2&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">5</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">()</span>  <span class="c1"># Uses custom names in plot labels</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 3: Noisy function with repeated evaluations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">noisy_objective</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">... </span>    <span class="n">base</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">base</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">base</span> <span class="o">+</span> <span class="n">noise</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">noisy_objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">repeats_initial</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>      <span class="c1"># Evaluate each initial point 3 times</span>
<span class="gp">... </span>    <span class="n">repeats_surrogate</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>    <span class="c1"># Evaluate each new point 2 times</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>                <span class="c1"># For reproducibility</span>
<span class="gp">... </span>    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Access noise statistics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Unique design points:&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">mean_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best mean value:&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">min_mean_y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance at best point:&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">min_var_y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 4: Noisy function with OCBA (Optimal Computing Budget Allocation)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer_ocba</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">noisy_objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">repeats_initial</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>      <span class="c1"># Initial repeats</span>
<span class="gp">... </span>    <span class="n">repeats_surrogate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>    <span class="c1"># Surrogate repeats</span>
<span class="gp">... </span>    <span class="n">ocba_delta</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>           <span class="c1"># Allocate 3 additional evaluations per iteration</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer_ocba</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># OCBA intelligently re-evaluates promising points to reduce uncertainty</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total evaluations:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">nfev</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Unique design points:&quot;</span><span class="p">,</span> <span class="n">optimizer_ocba</span><span class="o">.</span><span class="n">mean_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best mean value:&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">min_mean_y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance at best point:&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">min_var_y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 5: With TensorBoard logging</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer_tb</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">tensorboard_log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>   <span class="c1"># Enable TensorBoard</span>
<span class="gp">... </span>    <span class="n">tensorboard_path</span><span class="o">=</span><span class="s2">&quot;runs/my_optimization&quot;</span><span class="p">,</span>  <span class="c1"># Optional custom path</span>
<span class="gp">... </span>    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer_tb</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># View logs in browser: tensorboard --logdir=runs/my_optimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Logs saved to:&quot;</span><span class="p">,</span> <span class="n">optimizer_tb</span><span class="o">.</span><span class="n">tensorboard_path</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 6: Using SpotOptim&#39;s Kriging surrogate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim.surrogate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Kriging</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kriging_model</span> <span class="o">=</span> <span class="n">Kriging</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">noise</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>           <span class="c1"># Regularization parameter</span>
<span class="gp">... </span>    <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;gauss&#39;</span><span class="p">,</span>         <span class="c1"># Gaussian/RBF kernel</span>
<span class="gp">... </span>    <span class="n">min_theta</span><span class="o">=-</span><span class="mf">3.0</span><span class="p">,</span>         <span class="c1"># Min log10(theta) bound</span>
<span class="gp">... </span>    <span class="n">max_theta</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>          <span class="c1"># Max log10(theta) bound</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer_kriging</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">surrogate</span><span class="o">=</span><span class="n">kriging_model</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer_kriging</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best solution found:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best value:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 7: Using sklearn Gaussian Process with custom kernel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.gaussian_process</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.gaussian_process.kernels</span><span class="w"> </span><span class="kn">import</span> <span class="n">RBF</span><span class="p">,</span> <span class="n">ConstantKernel</span><span class="p">,</span> <span class="n">WhiteKernel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Custom kernel: constant * RBF + white noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">custom_kernel</span> <span class="o">=</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">))</span> <span class="o">*</span> <span class="n">RBF</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-1</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
<span class="gp">... </span><span class="p">)</span> <span class="o">+</span> <span class="n">WhiteKernel</span><span class="p">(</span><span class="n">noise_level</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">noise_level_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-10</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp_custom</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">kernel</span><span class="o">=</span><span class="n">custom_kernel</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer_custom_gp</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">surrogate</span><span class="o">=</span><span class="n">gp_custom</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer_custom_gp</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 8: Using Random Forest as surrogate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer_rf</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">surrogate</span><span class="o">=</span><span class="n">rf_model</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer_rf</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Note: Random Forests don&#39;t provide uncertainty estimates,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># so Expected Improvement (EI) may be less effective.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Consider using acquisition=&#39;y&#39; for pure exploitation.</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 9: Comparing different kernels for Gaussian Process</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.gaussian_process.kernels</span><span class="w"> </span><span class="kn">import</span> <span class="n">Matern</span><span class="p">,</span> <span class="n">RationalQuadratic</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Matern kernel with nu=1.5 (once differentiable)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kernel_matern15</span> <span class="o">=</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp_matern15</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel_matern15</span><span class="p">,</span> <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Matern kernel with nu=2.5 (twice differentiable, DEFAULT)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kernel_matern25</span> <span class="o">=</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp_matern25</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel_matern25</span><span class="p">,</span> <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># RBF kernel (infinitely differentiable, smooth)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kernel_rbf</span> <span class="o">=</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp_rbf</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel_rbf</span><span class="p">,</span> <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rational Quadratic kernel (mixture of RBF kernels)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kernel_rq</span> <span class="o">=</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">RationalQuadratic</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp_rq</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel_rq</span><span class="p">,</span> <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use any of these as surrogate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer_rbf</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>                          <span class="n">surrogate</span><span class="o">=</span><span class="n">gp_rbf</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">optimizer_rbf</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
</code></pre></div>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span>
<span class="normal">1854</span>
<span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span>
<span class="normal">1879</span>
<span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span>
<span class="normal">1883</span>
<span class="normal">1884</span>
<span class="normal">1885</span>
<span class="normal">1886</span>
<span class="normal">1887</span>
<span class="normal">1888</span>
<span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span>
<span class="normal">1897</span>
<span class="normal">1898</span>
<span class="normal">1899</span>
<span class="normal">1900</span>
<span class="normal">1901</span>
<span class="normal">1902</span>
<span class="normal">1903</span>
<span class="normal">1904</span>
<span class="normal">1905</span>
<span class="normal">1906</span>
<span class="normal">1907</span>
<span class="normal">1908</span>
<span class="normal">1909</span>
<span class="normal">1910</span>
<span class="normal">1911</span>
<span class="normal">1912</span>
<span class="normal">1913</span>
<span class="normal">1914</span>
<span class="normal">1915</span>
<span class="normal">1916</span>
<span class="normal">1917</span>
<span class="normal">1918</span>
<span class="normal">1919</span>
<span class="normal">1920</span>
<span class="normal">1921</span>
<span class="normal">1922</span>
<span class="normal">1923</span>
<span class="normal">1924</span>
<span class="normal">1925</span>
<span class="normal">1926</span>
<span class="normal">1927</span>
<span class="normal">1928</span>
<span class="normal">1929</span>
<span class="normal">1930</span>
<span class="normal">1931</span>
<span class="normal">1932</span>
<span class="normal">1933</span>
<span class="normal">1934</span>
<span class="normal">1935</span>
<span class="normal">1936</span>
<span class="normal">1937</span>
<span class="normal">1938</span>
<span class="normal">1939</span>
<span class="normal">1940</span>
<span class="normal">1941</span>
<span class="normal">1942</span>
<span class="normal">1943</span>
<span class="normal">1944</span>
<span class="normal">1945</span>
<span class="normal">1946</span>
<span class="normal">1947</span>
<span class="normal">1948</span>
<span class="normal">1949</span>
<span class="normal">1950</span>
<span class="normal">1951</span>
<span class="normal">1952</span>
<span class="normal">1953</span>
<span class="normal">1954</span>
<span class="normal">1955</span>
<span class="normal">1956</span>
<span class="normal">1957</span>
<span class="normal">1958</span>
<span class="normal">1959</span>
<span class="normal">1960</span>
<span class="normal">1961</span>
<span class="normal">1962</span>
<span class="normal">1963</span>
<span class="normal">1964</span>
<span class="normal">1965</span>
<span class="normal">1966</span>
<span class="normal">1967</span>
<span class="normal">1968</span>
<span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span>
<span class="normal">2002</span>
<span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span>
<span class="normal">2023</span>
<span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span>
<span class="normal">2042</span>
<span class="normal">2043</span>
<span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span>
<span class="normal">2063</span>
<span class="normal">2064</span>
<span class="normal">2065</span>
<span class="normal">2066</span>
<span class="normal">2067</span>
<span class="normal">2068</span>
<span class="normal">2069</span>
<span class="normal">2070</span>
<span class="normal">2071</span>
<span class="normal">2072</span>
<span class="normal">2073</span>
<span class="normal">2074</span>
<span class="normal">2075</span>
<span class="normal">2076</span>
<span class="normal">2077</span>
<span class="normal">2078</span>
<span class="normal">2079</span>
<span class="normal">2080</span>
<span class="normal">2081</span>
<span class="normal">2082</span>
<span class="normal">2083</span>
<span class="normal">2084</span>
<span class="normal">2085</span>
<span class="normal">2086</span>
<span class="normal">2087</span>
<span class="normal">2088</span>
<span class="normal">2089</span>
<span class="normal">2090</span>
<span class="normal">2091</span>
<span class="normal">2092</span>
<span class="normal">2093</span>
<span class="normal">2094</span>
<span class="normal">2095</span>
<span class="normal">2096</span>
<span class="normal">2097</span>
<span class="normal">2098</span>
<span class="normal">2099</span>
<span class="normal">2100</span>
<span class="normal">2101</span>
<span class="normal">2102</span>
<span class="normal">2103</span>
<span class="normal">2104</span>
<span class="normal">2105</span>
<span class="normal">2106</span>
<span class="normal">2107</span>
<span class="normal">2108</span>
<span class="normal">2109</span>
<span class="normal">2110</span>
<span class="normal">2111</span>
<span class="normal">2112</span>
<span class="normal">2113</span>
<span class="normal">2114</span>
<span class="normal">2115</span>
<span class="normal">2116</span>
<span class="normal">2117</span>
<span class="normal">2118</span>
<span class="normal">2119</span>
<span class="normal">2120</span>
<span class="normal">2121</span>
<span class="normal">2122</span>
<span class="normal">2123</span>
<span class="normal">2124</span>
<span class="normal">2125</span>
<span class="normal">2126</span>
<span class="normal">2127</span>
<span class="normal">2128</span>
<span class="normal">2129</span>
<span class="normal">2130</span>
<span class="normal">2131</span>
<span class="normal">2132</span>
<span class="normal">2133</span>
<span class="normal">2134</span>
<span class="normal">2135</span>
<span class="normal">2136</span>
<span class="normal">2137</span>
<span class="normal">2138</span>
<span class="normal">2139</span>
<span class="normal">2140</span>
<span class="normal">2141</span>
<span class="normal">2142</span>
<span class="normal">2143</span>
<span class="normal">2144</span>
<span class="normal">2145</span>
<span class="normal">2146</span>
<span class="normal">2147</span>
<span class="normal">2148</span>
<span class="normal">2149</span>
<span class="normal">2150</span>
<span class="normal">2151</span>
<span class="normal">2152</span>
<span class="normal">2153</span>
<span class="normal">2154</span>
<span class="normal">2155</span>
<span class="normal">2156</span>
<span class="normal">2157</span>
<span class="normal">2158</span>
<span class="normal">2159</span>
<span class="normal">2160</span>
<span class="normal">2161</span>
<span class="normal">2162</span>
<span class="normal">2163</span>
<span class="normal">2164</span>
<span class="normal">2165</span>
<span class="normal">2166</span>
<span class="normal">2167</span>
<span class="normal">2168</span>
<span class="normal">2169</span>
<span class="normal">2170</span>
<span class="normal">2171</span>
<span class="normal">2172</span>
<span class="normal">2173</span>
<span class="normal">2174</span>
<span class="normal">2175</span>
<span class="normal">2176</span>
<span class="normal">2177</span>
<span class="normal">2178</span>
<span class="normal">2179</span>
<span class="normal">2180</span>
<span class="normal">2181</span>
<span class="normal">2182</span>
<span class="normal">2183</span>
<span class="normal">2184</span>
<span class="normal">2185</span>
<span class="normal">2186</span>
<span class="normal">2187</span>
<span class="normal">2188</span>
<span class="normal">2189</span>
<span class="normal">2190</span>
<span class="normal">2191</span>
<span class="normal">2192</span>
<span class="normal">2193</span>
<span class="normal">2194</span>
<span class="normal">2195</span>
<span class="normal">2196</span>
<span class="normal">2197</span>
<span class="normal">2198</span>
<span class="normal">2199</span>
<span class="normal">2200</span>
<span class="normal">2201</span>
<span class="normal">2202</span>
<span class="normal">2203</span>
<span class="normal">2204</span>
<span class="normal">2205</span>
<span class="normal">2206</span>
<span class="normal">2207</span>
<span class="normal">2208</span>
<span class="normal">2209</span>
<span class="normal">2210</span>
<span class="normal">2211</span>
<span class="normal">2212</span>
<span class="normal">2213</span>
<span class="normal">2214</span>
<span class="normal">2215</span>
<span class="normal">2216</span>
<span class="normal">2217</span>
<span class="normal">2218</span>
<span class="normal">2219</span>
<span class="normal">2220</span>
<span class="normal">2221</span>
<span class="normal">2222</span>
<span class="normal">2223</span>
<span class="normal">2224</span>
<span class="normal">2225</span>
<span class="normal">2226</span>
<span class="normal">2227</span>
<span class="normal">2228</span>
<span class="normal">2229</span>
<span class="normal">2230</span>
<span class="normal">2231</span>
<span class="normal">2232</span>
<span class="normal">2233</span>
<span class="normal">2234</span>
<span class="normal">2235</span>
<span class="normal">2236</span>
<span class="normal">2237</span>
<span class="normal">2238</span>
<span class="normal">2239</span>
<span class="normal">2240</span>
<span class="normal">2241</span>
<span class="normal">2242</span>
<span class="normal">2243</span>
<span class="normal">2244</span>
<span class="normal">2245</span>
<span class="normal">2246</span>
<span class="normal">2247</span>
<span class="normal">2248</span>
<span class="normal">2249</span>
<span class="normal">2250</span>
<span class="normal">2251</span>
<span class="normal">2252</span>
<span class="normal">2253</span>
<span class="normal">2254</span>
<span class="normal">2255</span>
<span class="normal">2256</span>
<span class="normal">2257</span>
<span class="normal">2258</span>
<span class="normal">2259</span>
<span class="normal">2260</span>
<span class="normal">2261</span>
<span class="normal">2262</span>
<span class="normal">2263</span>
<span class="normal">2264</span>
<span class="normal">2265</span>
<span class="normal">2266</span>
<span class="normal">2267</span>
<span class="normal">2268</span>
<span class="normal">2269</span>
<span class="normal">2270</span>
<span class="normal">2271</span>
<span class="normal">2272</span>
<span class="normal">2273</span>
<span class="normal">2274</span>
<span class="normal">2275</span>
<span class="normal">2276</span>
<span class="normal">2277</span>
<span class="normal">2278</span>
<span class="normal">2279</span>
<span class="normal">2280</span>
<span class="normal">2281</span>
<span class="normal">2282</span>
<span class="normal">2283</span>
<span class="normal">2284</span>
<span class="normal">2285</span>
<span class="normal">2286</span>
<span class="normal">2287</span>
<span class="normal">2288</span>
<span class="normal">2289</span>
<span class="normal">2290</span>
<span class="normal">2291</span>
<span class="normal">2292</span>
<span class="normal">2293</span>
<span class="normal">2294</span>
<span class="normal">2295</span>
<span class="normal">2296</span>
<span class="normal">2297</span>
<span class="normal">2298</span>
<span class="normal">2299</span>
<span class="normal">2300</span>
<span class="normal">2301</span>
<span class="normal">2302</span>
<span class="normal">2303</span>
<span class="normal">2304</span>
<span class="normal">2305</span>
<span class="normal">2306</span>
<span class="normal">2307</span>
<span class="normal">2308</span>
<span class="normal">2309</span>
<span class="normal">2310</span>
<span class="normal">2311</span>
<span class="normal">2312</span>
<span class="normal">2313</span>
<span class="normal">2314</span>
<span class="normal">2315</span>
<span class="normal">2316</span>
<span class="normal">2317</span>
<span class="normal">2318</span>
<span class="normal">2319</span>
<span class="normal">2320</span>
<span class="normal">2321</span>
<span class="normal">2322</span>
<span class="normal">2323</span>
<span class="normal">2324</span>
<span class="normal">2325</span>
<span class="normal">2326</span>
<span class="normal">2327</span>
<span class="normal">2328</span>
<span class="normal">2329</span>
<span class="normal">2330</span>
<span class="normal">2331</span>
<span class="normal">2332</span>
<span class="normal">2333</span>
<span class="normal">2334</span>
<span class="normal">2335</span>
<span class="normal">2336</span>
<span class="normal">2337</span>
<span class="normal">2338</span>
<span class="normal">2339</span>
<span class="normal">2340</span>
<span class="normal">2341</span>
<span class="normal">2342</span>
<span class="normal">2343</span>
<span class="normal">2344</span>
<span class="normal">2345</span>
<span class="normal">2346</span>
<span class="normal">2347</span>
<span class="normal">2348</span>
<span class="normal">2349</span>
<span class="normal">2350</span>
<span class="normal">2351</span>
<span class="normal">2352</span>
<span class="normal">2353</span>
<span class="normal">2354</span>
<span class="normal">2355</span>
<span class="normal">2356</span>
<span class="normal">2357</span>
<span class="normal">2358</span>
<span class="normal">2359</span>
<span class="normal">2360</span>
<span class="normal">2361</span>
<span class="normal">2362</span>
<span class="normal">2363</span>
<span class="normal">2364</span>
<span class="normal">2365</span>
<span class="normal">2366</span>
<span class="normal">2367</span>
<span class="normal">2368</span>
<span class="normal">2369</span>
<span class="normal">2370</span>
<span class="normal">2371</span>
<span class="normal">2372</span>
<span class="normal">2373</span>
<span class="normal">2374</span>
<span class="normal">2375</span>
<span class="normal">2376</span>
<span class="normal">2377</span>
<span class="normal">2378</span>
<span class="normal">2379</span>
<span class="normal">2380</span>
<span class="normal">2381</span>
<span class="normal">2382</span>
<span class="normal">2383</span>
<span class="normal">2384</span>
<span class="normal">2385</span>
<span class="normal">2386</span>
<span class="normal">2387</span>
<span class="normal">2388</span>
<span class="normal">2389</span>
<span class="normal">2390</span>
<span class="normal">2391</span>
<span class="normal">2392</span>
<span class="normal">2393</span>
<span class="normal">2394</span>
<span class="normal">2395</span>
<span class="normal">2396</span>
<span class="normal">2397</span>
<span class="normal">2398</span>
<span class="normal">2399</span>
<span class="normal">2400</span>
<span class="normal">2401</span>
<span class="normal">2402</span>
<span class="normal">2403</span>
<span class="normal">2404</span>
<span class="normal">2405</span>
<span class="normal">2406</span>
<span class="normal">2407</span>
<span class="normal">2408</span>
<span class="normal">2409</span>
<span class="normal">2410</span>
<span class="normal">2411</span>
<span class="normal">2412</span>
<span class="normal">2413</span>
<span class="normal">2414</span>
<span class="normal">2415</span>
<span class="normal">2416</span>
<span class="normal">2417</span>
<span class="normal">2418</span>
<span class="normal">2419</span>
<span class="normal">2420</span>
<span class="normal">2421</span>
<span class="normal">2422</span>
<span class="normal">2423</span>
<span class="normal">2424</span>
<span class="normal">2425</span>
<span class="normal">2426</span>
<span class="normal">2427</span>
<span class="normal">2428</span>
<span class="normal">2429</span>
<span class="normal">2430</span>
<span class="normal">2431</span>
<span class="normal">2432</span>
<span class="normal">2433</span>
<span class="normal">2434</span>
<span class="normal">2435</span>
<span class="normal">2436</span>
<span class="normal">2437</span>
<span class="normal">2438</span>
<span class="normal">2439</span>
<span class="normal">2440</span>
<span class="normal">2441</span>
<span class="normal">2442</span>
<span class="normal">2443</span>
<span class="normal">2444</span>
<span class="normal">2445</span>
<span class="normal">2446</span>
<span class="normal">2447</span>
<span class="normal">2448</span>
<span class="normal">2449</span>
<span class="normal">2450</span>
<span class="normal">2451</span>
<span class="normal">2452</span>
<span class="normal">2453</span>
<span class="normal">2454</span>
<span class="normal">2455</span>
<span class="normal">2456</span>
<span class="normal">2457</span>
<span class="normal">2458</span>
<span class="normal">2459</span>
<span class="normal">2460</span>
<span class="normal">2461</span>
<span class="normal">2462</span>
<span class="normal">2463</span>
<span class="normal">2464</span>
<span class="normal">2465</span>
<span class="normal">2466</span>
<span class="normal">2467</span>
<span class="normal">2468</span>
<span class="normal">2469</span>
<span class="normal">2470</span>
<span class="normal">2471</span>
<span class="normal">2472</span>
<span class="normal">2473</span>
<span class="normal">2474</span>
<span class="normal">2475</span>
<span class="normal">2476</span>
<span class="normal">2477</span>
<span class="normal">2478</span>
<span class="normal">2479</span>
<span class="normal">2480</span>
<span class="normal">2481</span>
<span class="normal">2482</span>
<span class="normal">2483</span>
<span class="normal">2484</span>
<span class="normal">2485</span>
<span class="normal">2486</span>
<span class="normal">2487</span>
<span class="normal">2488</span>
<span class="normal">2489</span>
<span class="normal">2490</span>
<span class="normal">2491</span>
<span class="normal">2492</span>
<span class="normal">2493</span>
<span class="normal">2494</span>
<span class="normal">2495</span>
<span class="normal">2496</span>
<span class="normal">2497</span>
<span class="normal">2498</span>
<span class="normal">2499</span>
<span class="normal">2500</span>
<span class="normal">2501</span>
<span class="normal">2502</span>
<span class="normal">2503</span>
<span class="normal">2504</span>
<span class="normal">2505</span>
<span class="normal">2506</span>
<span class="normal">2507</span>
<span class="normal">2508</span>
<span class="normal">2509</span>
<span class="normal">2510</span>
<span class="normal">2511</span>
<span class="normal">2512</span>
<span class="normal">2513</span>
<span class="normal">2514</span>
<span class="normal">2515</span>
<span class="normal">2516</span>
<span class="normal">2517</span>
<span class="normal">2518</span>
<span class="normal">2519</span>
<span class="normal">2520</span>
<span class="normal">2521</span>
<span class="normal">2522</span>
<span class="normal">2523</span>
<span class="normal">2524</span>
<span class="normal">2525</span>
<span class="normal">2526</span>
<span class="normal">2527</span>
<span class="normal">2528</span>
<span class="normal">2529</span>
<span class="normal">2530</span>
<span class="normal">2531</span>
<span class="normal">2532</span>
<span class="normal">2533</span>
<span class="normal">2534</span>
<span class="normal">2535</span>
<span class="normal">2536</span>
<span class="normal">2537</span>
<span class="normal">2538</span>
<span class="normal">2539</span>
<span class="normal">2540</span>
<span class="normal">2541</span>
<span class="normal">2542</span>
<span class="normal">2543</span>
<span class="normal">2544</span>
<span class="normal">2545</span>
<span class="normal">2546</span>
<span class="normal">2547</span>
<span class="normal">2548</span>
<span class="normal">2549</span>
<span class="normal">2550</span>
<span class="normal">2551</span>
<span class="normal">2552</span>
<span class="normal">2553</span>
<span class="normal">2554</span>
<span class="normal">2555</span>
<span class="normal">2556</span>
<span class="normal">2557</span>
<span class="normal">2558</span>
<span class="normal">2559</span>
<span class="normal">2560</span>
<span class="normal">2561</span>
<span class="normal">2562</span>
<span class="normal">2563</span>
<span class="normal">2564</span>
<span class="normal">2565</span>
<span class="normal">2566</span>
<span class="normal">2567</span>
<span class="normal">2568</span>
<span class="normal">2569</span>
<span class="normal">2570</span>
<span class="normal">2571</span>
<span class="normal">2572</span>
<span class="normal">2573</span>
<span class="normal">2574</span>
<span class="normal">2575</span>
<span class="normal">2576</span>
<span class="normal">2577</span>
<span class="normal">2578</span>
<span class="normal">2579</span>
<span class="normal">2580</span>
<span class="normal">2581</span>
<span class="normal">2582</span>
<span class="normal">2583</span>
<span class="normal">2584</span>
<span class="normal">2585</span>
<span class="normal">2586</span>
<span class="normal">2587</span>
<span class="normal">2588</span>
<span class="normal">2589</span>
<span class="normal">2590</span>
<span class="normal">2591</span>
<span class="normal">2592</span>
<span class="normal">2593</span>
<span class="normal">2594</span>
<span class="normal">2595</span>
<span class="normal">2596</span>
<span class="normal">2597</span>
<span class="normal">2598</span>
<span class="normal">2599</span>
<span class="normal">2600</span>
<span class="normal">2601</span>
<span class="normal">2602</span>
<span class="normal">2603</span>
<span class="normal">2604</span>
<span class="normal">2605</span>
<span class="normal">2606</span>
<span class="normal">2607</span>
<span class="normal">2608</span>
<span class="normal">2609</span>
<span class="normal">2610</span>
<span class="normal">2611</span>
<span class="normal">2612</span>
<span class="normal">2613</span>
<span class="normal">2614</span>
<span class="normal">2615</span>
<span class="normal">2616</span>
<span class="normal">2617</span>
<span class="normal">2618</span>
<span class="normal">2619</span>
<span class="normal">2620</span>
<span class="normal">2621</span>
<span class="normal">2622</span>
<span class="normal">2623</span>
<span class="normal">2624</span>
<span class="normal">2625</span>
<span class="normal">2626</span>
<span class="normal">2627</span>
<span class="normal">2628</span>
<span class="normal">2629</span>
<span class="normal">2630</span>
<span class="normal">2631</span>
<span class="normal">2632</span>
<span class="normal">2633</span>
<span class="normal">2634</span>
<span class="normal">2635</span>
<span class="normal">2636</span>
<span class="normal">2637</span>
<span class="normal">2638</span>
<span class="normal">2639</span>
<span class="normal">2640</span>
<span class="normal">2641</span>
<span class="normal">2642</span>
<span class="normal">2643</span>
<span class="normal">2644</span>
<span class="normal">2645</span>
<span class="normal">2646</span>
<span class="normal">2647</span>
<span class="normal">2648</span>
<span class="normal">2649</span>
<span class="normal">2650</span>
<span class="normal">2651</span>
<span class="normal">2652</span>
<span class="normal">2653</span>
<span class="normal">2654</span>
<span class="normal">2655</span>
<span class="normal">2656</span>
<span class="normal">2657</span>
<span class="normal">2658</span>
<span class="normal">2659</span>
<span class="normal">2660</span>
<span class="normal">2661</span>
<span class="normal">2662</span>
<span class="normal">2663</span>
<span class="normal">2664</span>
<span class="normal">2665</span>
<span class="normal">2666</span>
<span class="normal">2667</span>
<span class="normal">2668</span>
<span class="normal">2669</span>
<span class="normal">2670</span>
<span class="normal">2671</span>
<span class="normal">2672</span>
<span class="normal">2673</span>
<span class="normal">2674</span>
<span class="normal">2675</span>
<span class="normal">2676</span>
<span class="normal">2677</span>
<span class="normal">2678</span>
<span class="normal">2679</span>
<span class="normal">2680</span>
<span class="normal">2681</span>
<span class="normal">2682</span>
<span class="normal">2683</span>
<span class="normal">2684</span>
<span class="normal">2685</span>
<span class="normal">2686</span>
<span class="normal">2687</span>
<span class="normal">2688</span>
<span class="normal">2689</span>
<span class="normal">2690</span>
<span class="normal">2691</span>
<span class="normal">2692</span>
<span class="normal">2693</span>
<span class="normal">2694</span>
<span class="normal">2695</span>
<span class="normal">2696</span>
<span class="normal">2697</span>
<span class="normal">2698</span>
<span class="normal">2699</span>
<span class="normal">2700</span>
<span class="normal">2701</span>
<span class="normal">2702</span>
<span class="normal">2703</span>
<span class="normal">2704</span>
<span class="normal">2705</span>
<span class="normal">2706</span>
<span class="normal">2707</span>
<span class="normal">2708</span>
<span class="normal">2709</span>
<span class="normal">2710</span>
<span class="normal">2711</span>
<span class="normal">2712</span>
<span class="normal">2713</span>
<span class="normal">2714</span>
<span class="normal">2715</span>
<span class="normal">2716</span>
<span class="normal">2717</span>
<span class="normal">2718</span>
<span class="normal">2719</span>
<span class="normal">2720</span>
<span class="normal">2721</span>
<span class="normal">2722</span>
<span class="normal">2723</span>
<span class="normal">2724</span>
<span class="normal">2725</span>
<span class="normal">2726</span>
<span class="normal">2727</span>
<span class="normal">2728</span>
<span class="normal">2729</span>
<span class="normal">2730</span>
<span class="normal">2731</span>
<span class="normal">2732</span>
<span class="normal">2733</span>
<span class="normal">2734</span>
<span class="normal">2735</span>
<span class="normal">2736</span>
<span class="normal">2737</span>
<span class="normal">2738</span>
<span class="normal">2739</span>
<span class="normal">2740</span>
<span class="normal">2741</span>
<span class="normal">2742</span>
<span class="normal">2743</span>
<span class="normal">2744</span>
<span class="normal">2745</span>
<span class="normal">2746</span>
<span class="normal">2747</span>
<span class="normal">2748</span>
<span class="normal">2749</span>
<span class="normal">2750</span>
<span class="normal">2751</span>
<span class="normal">2752</span>
<span class="normal">2753</span>
<span class="normal">2754</span>
<span class="normal">2755</span>
<span class="normal">2756</span>
<span class="normal">2757</span>
<span class="normal">2758</span>
<span class="normal">2759</span>
<span class="normal">2760</span>
<span class="normal">2761</span>
<span class="normal">2762</span>
<span class="normal">2763</span>
<span class="normal">2764</span>
<span class="normal">2765</span>
<span class="normal">2766</span>
<span class="normal">2767</span>
<span class="normal">2768</span>
<span class="normal">2769</span>
<span class="normal">2770</span>
<span class="normal">2771</span>
<span class="normal">2772</span>
<span class="normal">2773</span>
<span class="normal">2774</span>
<span class="normal">2775</span>
<span class="normal">2776</span>
<span class="normal">2777</span>
<span class="normal">2778</span>
<span class="normal">2779</span>
<span class="normal">2780</span>
<span class="normal">2781</span>
<span class="normal">2782</span>
<span class="normal">2783</span>
<span class="normal">2784</span>
<span class="normal">2785</span>
<span class="normal">2786</span>
<span class="normal">2787</span>
<span class="normal">2788</span>
<span class="normal">2789</span>
<span class="normal">2790</span>
<span class="normal">2791</span>
<span class="normal">2792</span>
<span class="normal">2793</span>
<span class="normal">2794</span>
<span class="normal">2795</span>
<span class="normal">2796</span>
<span class="normal">2797</span>
<span class="normal">2798</span>
<span class="normal">2799</span>
<span class="normal">2800</span>
<span class="normal">2801</span>
<span class="normal">2802</span>
<span class="normal">2803</span>
<span class="normal">2804</span>
<span class="normal">2805</span>
<span class="normal">2806</span>
<span class="normal">2807</span>
<span class="normal">2808</span>
<span class="normal">2809</span>
<span class="normal">2810</span>
<span class="normal">2811</span>
<span class="normal">2812</span>
<span class="normal">2813</span>
<span class="normal">2814</span>
<span class="normal">2815</span>
<span class="normal">2816</span>
<span class="normal">2817</span>
<span class="normal">2818</span>
<span class="normal">2819</span>
<span class="normal">2820</span>
<span class="normal">2821</span>
<span class="normal">2822</span>
<span class="normal">2823</span>
<span class="normal">2824</span>
<span class="normal">2825</span>
<span class="normal">2826</span>
<span class="normal">2827</span>
<span class="normal">2828</span>
<span class="normal">2829</span>
<span class="normal">2830</span>
<span class="normal">2831</span>
<span class="normal">2832</span>
<span class="normal">2833</span>
<span class="normal">2834</span>
<span class="normal">2835</span>
<span class="normal">2836</span>
<span class="normal">2837</span>
<span class="normal">2838</span>
<span class="normal">2839</span>
<span class="normal">2840</span>
<span class="normal">2841</span>
<span class="normal">2842</span>
<span class="normal">2843</span>
<span class="normal">2844</span>
<span class="normal">2845</span>
<span class="normal">2846</span>
<span class="normal">2847</span>
<span class="normal">2848</span>
<span class="normal">2849</span>
<span class="normal">2850</span>
<span class="normal">2851</span>
<span class="normal">2852</span>
<span class="normal">2853</span>
<span class="normal">2854</span>
<span class="normal">2855</span>
<span class="normal">2856</span>
<span class="normal">2857</span>
<span class="normal">2858</span>
<span class="normal">2859</span>
<span class="normal">2860</span>
<span class="normal">2861</span>
<span class="normal">2862</span>
<span class="normal">2863</span>
<span class="normal">2864</span>
<span class="normal">2865</span>
<span class="normal">2866</span>
<span class="normal">2867</span>
<span class="normal">2868</span>
<span class="normal">2869</span>
<span class="normal">2870</span>
<span class="normal">2871</span>
<span class="normal">2872</span>
<span class="normal">2873</span>
<span class="normal">2874</span>
<span class="normal">2875</span>
<span class="normal">2876</span>
<span class="normal">2877</span>
<span class="normal">2878</span>
<span class="normal">2879</span>
<span class="normal">2880</span>
<span class="normal">2881</span>
<span class="normal">2882</span>
<span class="normal">2883</span>
<span class="normal">2884</span>
<span class="normal">2885</span>
<span class="normal">2886</span>
<span class="normal">2887</span>
<span class="normal">2888</span>
<span class="normal">2889</span>
<span class="normal">2890</span>
<span class="normal">2891</span>
<span class="normal">2892</span>
<span class="normal">2893</span>
<span class="normal">2894</span>
<span class="normal">2895</span>
<span class="normal">2896</span>
<span class="normal">2897</span>
<span class="normal">2898</span>
<span class="normal">2899</span>
<span class="normal">2900</span>
<span class="normal">2901</span>
<span class="normal">2902</span>
<span class="normal">2903</span>
<span class="normal">2904</span>
<span class="normal">2905</span>
<span class="normal">2906</span>
<span class="normal">2907</span>
<span class="normal">2908</span>
<span class="normal">2909</span>
<span class="normal">2910</span>
<span class="normal">2911</span>
<span class="normal">2912</span>
<span class="normal">2913</span>
<span class="normal">2914</span>
<span class="normal">2915</span>
<span class="normal">2916</span>
<span class="normal">2917</span>
<span class="normal">2918</span>
<span class="normal">2919</span>
<span class="normal">2920</span>
<span class="normal">2921</span>
<span class="normal">2922</span>
<span class="normal">2923</span>
<span class="normal">2924</span>
<span class="normal">2925</span>
<span class="normal">2926</span>
<span class="normal">2927</span>
<span class="normal">2928</span>
<span class="normal">2929</span>
<span class="normal">2930</span>
<span class="normal">2931</span>
<span class="normal">2932</span>
<span class="normal">2933</span>
<span class="normal">2934</span>
<span class="normal">2935</span>
<span class="normal">2936</span>
<span class="normal">2937</span>
<span class="normal">2938</span>
<span class="normal">2939</span>
<span class="normal">2940</span>
<span class="normal">2941</span>
<span class="normal">2942</span>
<span class="normal">2943</span>
<span class="normal">2944</span>
<span class="normal">2945</span>
<span class="normal">2946</span>
<span class="normal">2947</span>
<span class="normal">2948</span>
<span class="normal">2949</span>
<span class="normal">2950</span>
<span class="normal">2951</span>
<span class="normal">2952</span>
<span class="normal">2953</span>
<span class="normal">2954</span>
<span class="normal">2955</span>
<span class="normal">2956</span>
<span class="normal">2957</span>
<span class="normal">2958</span>
<span class="normal">2959</span>
<span class="normal">2960</span>
<span class="normal">2961</span>
<span class="normal">2962</span>
<span class="normal">2963</span>
<span class="normal">2964</span>
<span class="normal">2965</span>
<span class="normal">2966</span>
<span class="normal">2967</span>
<span class="normal">2968</span>
<span class="normal">2969</span>
<span class="normal">2970</span>
<span class="normal">2971</span>
<span class="normal">2972</span>
<span class="normal">2973</span>
<span class="normal">2974</span>
<span class="normal">2975</span>
<span class="normal">2976</span>
<span class="normal">2977</span>
<span class="normal">2978</span>
<span class="normal">2979</span>
<span class="normal">2980</span>
<span class="normal">2981</span>
<span class="normal">2982</span>
<span class="normal">2983</span>
<span class="normal">2984</span>
<span class="normal">2985</span>
<span class="normal">2986</span>
<span class="normal">2987</span>
<span class="normal">2988</span>
<span class="normal">2989</span>
<span class="normal">2990</span>
<span class="normal">2991</span>
<span class="normal">2992</span>
<span class="normal">2993</span>
<span class="normal">2994</span>
<span class="normal">2995</span>
<span class="normal">2996</span>
<span class="normal">2997</span>
<span class="normal">2998</span>
<span class="normal">2999</span>
<span class="normal">3000</span>
<span class="normal">3001</span>
<span class="normal">3002</span>
<span class="normal">3003</span>
<span class="normal">3004</span>
<span class="normal">3005</span>
<span class="normal">3006</span>
<span class="normal">3007</span>
<span class="normal">3008</span>
<span class="normal">3009</span>
<span class="normal">3010</span>
<span class="normal">3011</span>
<span class="normal">3012</span>
<span class="normal">3013</span>
<span class="normal">3014</span>
<span class="normal">3015</span>
<span class="normal">3016</span>
<span class="normal">3017</span>
<span class="normal">3018</span>
<span class="normal">3019</span>
<span class="normal">3020</span>
<span class="normal">3021</span>
<span class="normal">3022</span>
<span class="normal">3023</span>
<span class="normal">3024</span>
<span class="normal">3025</span>
<span class="normal">3026</span>
<span class="normal">3027</span>
<span class="normal">3028</span>
<span class="normal">3029</span>
<span class="normal">3030</span>
<span class="normal">3031</span>
<span class="normal">3032</span>
<span class="normal">3033</span>
<span class="normal">3034</span>
<span class="normal">3035</span>
<span class="normal">3036</span>
<span class="normal">3037</span>
<span class="normal">3038</span>
<span class="normal">3039</span>
<span class="normal">3040</span>
<span class="normal">3041</span>
<span class="normal">3042</span>
<span class="normal">3043</span>
<span class="normal">3044</span>
<span class="normal">3045</span>
<span class="normal">3046</span>
<span class="normal">3047</span>
<span class="normal">3048</span>
<span class="normal">3049</span>
<span class="normal">3050</span>
<span class="normal">3051</span>
<span class="normal">3052</span>
<span class="normal">3053</span>
<span class="normal">3054</span>
<span class="normal">3055</span>
<span class="normal">3056</span>
<span class="normal">3057</span>
<span class="normal">3058</span>
<span class="normal">3059</span>
<span class="normal">3060</span>
<span class="normal">3061</span>
<span class="normal">3062</span>
<span class="normal">3063</span>
<span class="normal">3064</span>
<span class="normal">3065</span>
<span class="normal">3066</span>
<span class="normal">3067</span>
<span class="normal">3068</span>
<span class="normal">3069</span>
<span class="normal">3070</span>
<span class="normal">3071</span>
<span class="normal">3072</span>
<span class="normal">3073</span>
<span class="normal">3074</span>
<span class="normal">3075</span>
<span class="normal">3076</span>
<span class="normal">3077</span>
<span class="normal">3078</span>
<span class="normal">3079</span>
<span class="normal">3080</span>
<span class="normal">3081</span>
<span class="normal">3082</span>
<span class="normal">3083</span>
<span class="normal">3084</span>
<span class="normal">3085</span>
<span class="normal">3086</span>
<span class="normal">3087</span>
<span class="normal">3088</span>
<span class="normal">3089</span>
<span class="normal">3090</span>
<span class="normal">3091</span>
<span class="normal">3092</span>
<span class="normal">3093</span>
<span class="normal">3094</span>
<span class="normal">3095</span>
<span class="normal">3096</span>
<span class="normal">3097</span>
<span class="normal">3098</span>
<span class="normal">3099</span>
<span class="normal">3100</span>
<span class="normal">3101</span>
<span class="normal">3102</span>
<span class="normal">3103</span>
<span class="normal">3104</span>
<span class="normal">3105</span>
<span class="normal">3106</span>
<span class="normal">3107</span>
<span class="normal">3108</span>
<span class="normal">3109</span>
<span class="normal">3110</span>
<span class="normal">3111</span>
<span class="normal">3112</span>
<span class="normal">3113</span>
<span class="normal">3114</span>
<span class="normal">3115</span>
<span class="normal">3116</span>
<span class="normal">3117</span>
<span class="normal">3118</span>
<span class="normal">3119</span>
<span class="normal">3120</span>
<span class="normal">3121</span>
<span class="normal">3122</span>
<span class="normal">3123</span>
<span class="normal">3124</span>
<span class="normal">3125</span>
<span class="normal">3126</span>
<span class="normal">3127</span>
<span class="normal">3128</span>
<span class="normal">3129</span>
<span class="normal">3130</span>
<span class="normal">3131</span>
<span class="normal">3132</span>
<span class="normal">3133</span>
<span class="normal">3134</span>
<span class="normal">3135</span>
<span class="normal">3136</span>
<span class="normal">3137</span>
<span class="normal">3138</span>
<span class="normal">3139</span>
<span class="normal">3140</span>
<span class="normal">3141</span>
<span class="normal">3142</span>
<span class="normal">3143</span>
<span class="normal">3144</span>
<span class="normal">3145</span>
<span class="normal">3146</span>
<span class="normal">3147</span>
<span class="normal">3148</span>
<span class="normal">3149</span>
<span class="normal">3150</span>
<span class="normal">3151</span>
<span class="normal">3152</span>
<span class="normal">3153</span>
<span class="normal">3154</span>
<span class="normal">3155</span>
<span class="normal">3156</span>
<span class="normal">3157</span>
<span class="normal">3158</span>
<span class="normal">3159</span>
<span class="normal">3160</span>
<span class="normal">3161</span>
<span class="normal">3162</span>
<span class="normal">3163</span>
<span class="normal">3164</span>
<span class="normal">3165</span>
<span class="normal">3166</span>
<span class="normal">3167</span>
<span class="normal">3168</span>
<span class="normal">3169</span>
<span class="normal">3170</span>
<span class="normal">3171</span>
<span class="normal">3172</span>
<span class="normal">3173</span>
<span class="normal">3174</span>
<span class="normal">3175</span>
<span class="normal">3176</span>
<span class="normal">3177</span>
<span class="normal">3178</span>
<span class="normal">3179</span>
<span class="normal">3180</span>
<span class="normal">3181</span>
<span class="normal">3182</span>
<span class="normal">3183</span>
<span class="normal">3184</span>
<span class="normal">3185</span>
<span class="normal">3186</span>
<span class="normal">3187</span>
<span class="normal">3188</span>
<span class="normal">3189</span>
<span class="normal">3190</span>
<span class="normal">3191</span>
<span class="normal">3192</span>
<span class="normal">3193</span>
<span class="normal">3194</span>
<span class="normal">3195</span>
<span class="normal">3196</span>
<span class="normal">3197</span>
<span class="normal">3198</span>
<span class="normal">3199</span>
<span class="normal">3200</span>
<span class="normal">3201</span>
<span class="normal">3202</span>
<span class="normal">3203</span>
<span class="normal">3204</span>
<span class="normal">3205</span>
<span class="normal">3206</span>
<span class="normal">3207</span>
<span class="normal">3208</span>
<span class="normal">3209</span>
<span class="normal">3210</span>
<span class="normal">3211</span>
<span class="normal">3212</span>
<span class="normal">3213</span>
<span class="normal">3214</span>
<span class="normal">3215</span>
<span class="normal">3216</span>
<span class="normal">3217</span>
<span class="normal">3218</span>
<span class="normal">3219</span>
<span class="normal">3220</span>
<span class="normal">3221</span>
<span class="normal">3222</span>
<span class="normal">3223</span>
<span class="normal">3224</span>
<span class="normal">3225</span>
<span class="normal">3226</span>
<span class="normal">3227</span>
<span class="normal">3228</span>
<span class="normal">3229</span>
<span class="normal">3230</span>
<span class="normal">3231</span>
<span class="normal">3232</span>
<span class="normal">3233</span>
<span class="normal">3234</span>
<span class="normal">3235</span>
<span class="normal">3236</span>
<span class="normal">3237</span>
<span class="normal">3238</span>
<span class="normal">3239</span>
<span class="normal">3240</span>
<span class="normal">3241</span>
<span class="normal">3242</span>
<span class="normal">3243</span>
<span class="normal">3244</span>
<span class="normal">3245</span>
<span class="normal">3246</span>
<span class="normal">3247</span>
<span class="normal">3248</span>
<span class="normal">3249</span>
<span class="normal">3250</span>
<span class="normal">3251</span>
<span class="normal">3252</span>
<span class="normal">3253</span>
<span class="normal">3254</span>
<span class="normal">3255</span>
<span class="normal">3256</span>
<span class="normal">3257</span>
<span class="normal">3258</span>
<span class="normal">3259</span>
<span class="normal">3260</span>
<span class="normal">3261</span>
<span class="normal">3262</span>
<span class="normal">3263</span>
<span class="normal">3264</span>
<span class="normal">3265</span>
<span class="normal">3266</span>
<span class="normal">3267</span>
<span class="normal">3268</span>
<span class="normal">3269</span>
<span class="normal">3270</span>
<span class="normal">3271</span>
<span class="normal">3272</span>
<span class="normal">3273</span>
<span class="normal">3274</span>
<span class="normal">3275</span>
<span class="normal">3276</span>
<span class="normal">3277</span>
<span class="normal">3278</span>
<span class="normal">3279</span>
<span class="normal">3280</span>
<span class="normal">3281</span>
<span class="normal">3282</span>
<span class="normal">3283</span>
<span class="normal">3284</span>
<span class="normal">3285</span>
<span class="normal">3286</span>
<span class="normal">3287</span>
<span class="normal">3288</span>
<span class="normal">3289</span>
<span class="normal">3290</span>
<span class="normal">3291</span>
<span class="normal">3292</span>
<span class="normal">3293</span>
<span class="normal">3294</span>
<span class="normal">3295</span>
<span class="normal">3296</span>
<span class="normal">3297</span>
<span class="normal">3298</span>
<span class="normal">3299</span>
<span class="normal">3300</span>
<span class="normal">3301</span>
<span class="normal">3302</span>
<span class="normal">3303</span>
<span class="normal">3304</span>
<span class="normal">3305</span>
<span class="normal">3306</span>
<span class="normal">3307</span>
<span class="normal">3308</span>
<span class="normal">3309</span>
<span class="normal">3310</span>
<span class="normal">3311</span>
<span class="normal">3312</span>
<span class="normal">3313</span>
<span class="normal">3314</span>
<span class="normal">3315</span>
<span class="normal">3316</span>
<span class="normal">3317</span>
<span class="normal">3318</span>
<span class="normal">3319</span>
<span class="normal">3320</span>
<span class="normal">3321</span>
<span class="normal">3322</span>
<span class="normal">3323</span>
<span class="normal">3324</span>
<span class="normal">3325</span>
<span class="normal">3326</span>
<span class="normal">3327</span>
<span class="normal">3328</span>
<span class="normal">3329</span>
<span class="normal">3330</span>
<span class="normal">3331</span>
<span class="normal">3332</span>
<span class="normal">3333</span>
<span class="normal">3334</span>
<span class="normal">3335</span>
<span class="normal">3336</span>
<span class="normal">3337</span>
<span class="normal">3338</span>
<span class="normal">3339</span>
<span class="normal">3340</span>
<span class="normal">3341</span>
<span class="normal">3342</span>
<span class="normal">3343</span>
<span class="normal">3344</span>
<span class="normal">3345</span>
<span class="normal">3346</span>
<span class="normal">3347</span>
<span class="normal">3348</span>
<span class="normal">3349</span>
<span class="normal">3350</span>
<span class="normal">3351</span>
<span class="normal">3352</span>
<span class="normal">3353</span>
<span class="normal">3354</span>
<span class="normal">3355</span>
<span class="normal">3356</span>
<span class="normal">3357</span>
<span class="normal">3358</span>
<span class="normal">3359</span>
<span class="normal">3360</span>
<span class="normal">3361</span>
<span class="normal">3362</span>
<span class="normal">3363</span>
<span class="normal">3364</span>
<span class="normal">3365</span>
<span class="normal">3366</span>
<span class="normal">3367</span>
<span class="normal">3368</span>
<span class="normal">3369</span>
<span class="normal">3370</span>
<span class="normal">3371</span>
<span class="normal">3372</span>
<span class="normal">3373</span>
<span class="normal">3374</span>
<span class="normal">3375</span>
<span class="normal">3376</span>
<span class="normal">3377</span>
<span class="normal">3378</span>
<span class="normal">3379</span>
<span class="normal">3380</span>
<span class="normal">3381</span>
<span class="normal">3382</span>
<span class="normal">3383</span>
<span class="normal">3384</span>
<span class="normal">3385</span>
<span class="normal">3386</span>
<span class="normal">3387</span>
<span class="normal">3388</span>
<span class="normal">3389</span>
<span class="normal">3390</span>
<span class="normal">3391</span>
<span class="normal">3392</span>
<span class="normal">3393</span>
<span class="normal">3394</span>
<span class="normal">3395</span>
<span class="normal">3396</span>
<span class="normal">3397</span>
<span class="normal">3398</span>
<span class="normal">3399</span>
<span class="normal">3400</span>
<span class="normal">3401</span>
<span class="normal">3402</span>
<span class="normal">3403</span>
<span class="normal">3404</span>
<span class="normal">3405</span>
<span class="normal">3406</span>
<span class="normal">3407</span>
<span class="normal">3408</span>
<span class="normal">3409</span>
<span class="normal">3410</span>
<span class="normal">3411</span>
<span class="normal">3412</span>
<span class="normal">3413</span>
<span class="normal">3414</span>
<span class="normal">3415</span>
<span class="normal">3416</span>
<span class="normal">3417</span>
<span class="normal">3418</span>
<span class="normal">3419</span>
<span class="normal">3420</span>
<span class="normal">3421</span>
<span class="normal">3422</span>
<span class="normal">3423</span>
<span class="normal">3424</span>
<span class="normal">3425</span>
<span class="normal">3426</span>
<span class="normal">3427</span>
<span class="normal">3428</span>
<span class="normal">3429</span>
<span class="normal">3430</span>
<span class="normal">3431</span>
<span class="normal">3432</span>
<span class="normal">3433</span>
<span class="normal">3434</span>
<span class="normal">3435</span>
<span class="normal">3436</span>
<span class="normal">3437</span>
<span class="normal">3438</span>
<span class="normal">3439</span>
<span class="normal">3440</span>
<span class="normal">3441</span>
<span class="normal">3442</span>
<span class="normal">3443</span>
<span class="normal">3444</span>
<span class="normal">3445</span>
<span class="normal">3446</span>
<span class="normal">3447</span>
<span class="normal">3448</span>
<span class="normal">3449</span>
<span class="normal">3450</span>
<span class="normal">3451</span>
<span class="normal">3452</span>
<span class="normal">3453</span>
<span class="normal">3454</span>
<span class="normal">3455</span>
<span class="normal">3456</span>
<span class="normal">3457</span>
<span class="normal">3458</span>
<span class="normal">3459</span>
<span class="normal">3460</span>
<span class="normal">3461</span>
<span class="normal">3462</span>
<span class="normal">3463</span>
<span class="normal">3464</span>
<span class="normal">3465</span>
<span class="normal">3466</span>
<span class="normal">3467</span>
<span class="normal">3468</span>
<span class="normal">3469</span>
<span class="normal">3470</span>
<span class="normal">3471</span>
<span class="normal">3472</span>
<span class="normal">3473</span>
<span class="normal">3474</span>
<span class="normal">3475</span>
<span class="normal">3476</span>
<span class="normal">3477</span>
<span class="normal">3478</span>
<span class="normal">3479</span>
<span class="normal">3480</span>
<span class="normal">3481</span>
<span class="normal">3482</span>
<span class="normal">3483</span>
<span class="normal">3484</span>
<span class="normal">3485</span>
<span class="normal">3486</span>
<span class="normal">3487</span>
<span class="normal">3488</span>
<span class="normal">3489</span>
<span class="normal">3490</span>
<span class="normal">3491</span>
<span class="normal">3492</span>
<span class="normal">3493</span>
<span class="normal">3494</span>
<span class="normal">3495</span>
<span class="normal">3496</span>
<span class="normal">3497</span>
<span class="normal">3498</span>
<span class="normal">3499</span>
<span class="normal">3500</span>
<span class="normal">3501</span>
<span class="normal">3502</span>
<span class="normal">3503</span>
<span class="normal">3504</span>
<span class="normal">3505</span>
<span class="normal">3506</span>
<span class="normal">3507</span>
<span class="normal">3508</span>
<span class="normal">3509</span>
<span class="normal">3510</span>
<span class="normal">3511</span>
<span class="normal">3512</span>
<span class="normal">3513</span>
<span class="normal">3514</span>
<span class="normal">3515</span>
<span class="normal">3516</span>
<span class="normal">3517</span>
<span class="normal">3518</span>
<span class="normal">3519</span>
<span class="normal">3520</span>
<span class="normal">3521</span>
<span class="normal">3522</span>
<span class="normal">3523</span>
<span class="normal">3524</span>
<span class="normal">3525</span>
<span class="normal">3526</span>
<span class="normal">3527</span>
<span class="normal">3528</span>
<span class="normal">3529</span>
<span class="normal">3530</span>
<span class="normal">3531</span>
<span class="normal">3532</span>
<span class="normal">3533</span>
<span class="normal">3534</span>
<span class="normal">3535</span>
<span class="normal">3536</span>
<span class="normal">3537</span>
<span class="normal">3538</span>
<span class="normal">3539</span>
<span class="normal">3540</span>
<span class="normal">3541</span>
<span class="normal">3542</span>
<span class="normal">3543</span>
<span class="normal">3544</span>
<span class="normal">3545</span>
<span class="normal">3546</span>
<span class="normal">3547</span>
<span class="normal">3548</span>
<span class="normal">3549</span>
<span class="normal">3550</span>
<span class="normal">3551</span>
<span class="normal">3552</span>
<span class="normal">3553</span>
<span class="normal">3554</span>
<span class="normal">3555</span>
<span class="normal">3556</span>
<span class="normal">3557</span>
<span class="normal">3558</span>
<span class="normal">3559</span>
<span class="normal">3560</span>
<span class="normal">3561</span>
<span class="normal">3562</span>
<span class="normal">3563</span>
<span class="normal">3564</span>
<span class="normal">3565</span>
<span class="normal">3566</span>
<span class="normal">3567</span>
<span class="normal">3568</span>
<span class="normal">3569</span>
<span class="normal">3570</span>
<span class="normal">3571</span>
<span class="normal">3572</span>
<span class="normal">3573</span>
<span class="normal">3574</span>
<span class="normal">3575</span>
<span class="normal">3576</span>
<span class="normal">3577</span>
<span class="normal">3578</span>
<span class="normal">3579</span>
<span class="normal">3580</span>
<span class="normal">3581</span>
<span class="normal">3582</span>
<span class="normal">3583</span>
<span class="normal">3584</span>
<span class="normal">3585</span>
<span class="normal">3586</span>
<span class="normal">3587</span>
<span class="normal">3588</span>
<span class="normal">3589</span>
<span class="normal">3590</span>
<span class="normal">3591</span>
<span class="normal">3592</span>
<span class="normal">3593</span>
<span class="normal">3594</span>
<span class="normal">3595</span>
<span class="normal">3596</span>
<span class="normal">3597</span>
<span class="normal">3598</span>
<span class="normal">3599</span>
<span class="normal">3600</span>
<span class="normal">3601</span>
<span class="normal">3602</span>
<span class="normal">3603</span>
<span class="normal">3604</span>
<span class="normal">3605</span>
<span class="normal">3606</span>
<span class="normal">3607</span>
<span class="normal">3608</span>
<span class="normal">3609</span>
<span class="normal">3610</span>
<span class="normal">3611</span>
<span class="normal">3612</span>
<span class="normal">3613</span>
<span class="normal">3614</span>
<span class="normal">3615</span>
<span class="normal">3616</span>
<span class="normal">3617</span>
<span class="normal">3618</span>
<span class="normal">3619</span>
<span class="normal">3620</span>
<span class="normal">3621</span>
<span class="normal">3622</span>
<span class="normal">3623</span>
<span class="normal">3624</span>
<span class="normal">3625</span>
<span class="normal">3626</span>
<span class="normal">3627</span>
<span class="normal">3628</span>
<span class="normal">3629</span>
<span class="normal">3630</span>
<span class="normal">3631</span>
<span class="normal">3632</span>
<span class="normal">3633</span>
<span class="normal">3634</span>
<span class="normal">3635</span>
<span class="normal">3636</span>
<span class="normal">3637</span>
<span class="normal">3638</span>
<span class="normal">3639</span>
<span class="normal">3640</span>
<span class="normal">3641</span>
<span class="normal">3642</span>
<span class="normal">3643</span>
<span class="normal">3644</span>
<span class="normal">3645</span>
<span class="normal">3646</span>
<span class="normal">3647</span>
<span class="normal">3648</span>
<span class="normal">3649</span>
<span class="normal">3650</span>
<span class="normal">3651</span>
<span class="normal">3652</span>
<span class="normal">3653</span>
<span class="normal">3654</span>
<span class="normal">3655</span>
<span class="normal">3656</span>
<span class="normal">3657</span>
<span class="normal">3658</span>
<span class="normal">3659</span>
<span class="normal">3660</span>
<span class="normal">3661</span>
<span class="normal">3662</span>
<span class="normal">3663</span>
<span class="normal">3664</span>
<span class="normal">3665</span>
<span class="normal">3666</span>
<span class="normal">3667</span>
<span class="normal">3668</span>
<span class="normal">3669</span>
<span class="normal">3670</span>
<span class="normal">3671</span>
<span class="normal">3672</span>
<span class="normal">3673</span>
<span class="normal">3674</span>
<span class="normal">3675</span>
<span class="normal">3676</span>
<span class="normal">3677</span>
<span class="normal">3678</span>
<span class="normal">3679</span>
<span class="normal">3680</span>
<span class="normal">3681</span>
<span class="normal">3682</span>
<span class="normal">3683</span>
<span class="normal">3684</span>
<span class="normal">3685</span>
<span class="normal">3686</span>
<span class="normal">3687</span>
<span class="normal">3688</span>
<span class="normal">3689</span>
<span class="normal">3690</span>
<span class="normal">3691</span>
<span class="normal">3692</span>
<span class="normal">3693</span>
<span class="normal">3694</span>
<span class="normal">3695</span>
<span class="normal">3696</span>
<span class="normal">3697</span>
<span class="normal">3698</span>
<span class="normal">3699</span>
<span class="normal">3700</span>
<span class="normal">3701</span>
<span class="normal">3702</span>
<span class="normal">3703</span>
<span class="normal">3704</span>
<span class="normal">3705</span>
<span class="normal">3706</span>
<span class="normal">3707</span>
<span class="normal">3708</span>
<span class="normal">3709</span>
<span class="normal">3710</span>
<span class="normal">3711</span>
<span class="normal">3712</span>
<span class="normal">3713</span>
<span class="normal">3714</span>
<span class="normal">3715</span>
<span class="normal">3716</span>
<span class="normal">3717</span>
<span class="normal">3718</span>
<span class="normal">3719</span>
<span class="normal">3720</span>
<span class="normal">3721</span>
<span class="normal">3722</span>
<span class="normal">3723</span>
<span class="normal">3724</span>
<span class="normal">3725</span>
<span class="normal">3726</span>
<span class="normal">3727</span>
<span class="normal">3728</span>
<span class="normal">3729</span>
<span class="normal">3730</span>
<span class="normal">3731</span>
<span class="normal">3732</span>
<span class="normal">3733</span>
<span class="normal">3734</span>
<span class="normal">3735</span>
<span class="normal">3736</span>
<span class="normal">3737</span>
<span class="normal">3738</span>
<span class="normal">3739</span>
<span class="normal">3740</span>
<span class="normal">3741</span>
<span class="normal">3742</span>
<span class="normal">3743</span>
<span class="normal">3744</span>
<span class="normal">3745</span>
<span class="normal">3746</span>
<span class="normal">3747</span>
<span class="normal">3748</span>
<span class="normal">3749</span>
<span class="normal">3750</span>
<span class="normal">3751</span>
<span class="normal">3752</span>
<span class="normal">3753</span>
<span class="normal">3754</span>
<span class="normal">3755</span>
<span class="normal">3756</span>
<span class="normal">3757</span>
<span class="normal">3758</span>
<span class="normal">3759</span>
<span class="normal">3760</span>
<span class="normal">3761</span>
<span class="normal">3762</span>
<span class="normal">3763</span>
<span class="normal">3764</span>
<span class="normal">3765</span>
<span class="normal">3766</span>
<span class="normal">3767</span>
<span class="normal">3768</span>
<span class="normal">3769</span>
<span class="normal">3770</span>
<span class="normal">3771</span>
<span class="normal">3772</span>
<span class="normal">3773</span>
<span class="normal">3774</span>
<span class="normal">3775</span>
<span class="normal">3776</span>
<span class="normal">3777</span>
<span class="normal">3778</span>
<span class="normal">3779</span>
<span class="normal">3780</span>
<span class="normal">3781</span>
<span class="normal">3782</span>
<span class="normal">3783</span>
<span class="normal">3784</span>
<span class="normal">3785</span>
<span class="normal">3786</span>
<span class="normal">3787</span>
<span class="normal">3788</span>
<span class="normal">3789</span>
<span class="normal">3790</span>
<span class="normal">3791</span>
<span class="normal">3792</span>
<span class="normal">3793</span>
<span class="normal">3794</span>
<span class="normal">3795</span>
<span class="normal">3796</span>
<span class="normal">3797</span>
<span class="normal">3798</span>
<span class="normal">3799</span>
<span class="normal">3800</span>
<span class="normal">3801</span>
<span class="normal">3802</span>
<span class="normal">3803</span>
<span class="normal">3804</span>
<span class="normal">3805</span>
<span class="normal">3806</span>
<span class="normal">3807</span>
<span class="normal">3808</span>
<span class="normal">3809</span>
<span class="normal">3810</span>
<span class="normal">3811</span>
<span class="normal">3812</span>
<span class="normal">3813</span>
<span class="normal">3814</span>
<span class="normal">3815</span>
<span class="normal">3816</span>
<span class="normal">3817</span>
<span class="normal">3818</span>
<span class="normal">3819</span>
<span class="normal">3820</span>
<span class="normal">3821</span>
<span class="normal">3822</span>
<span class="normal">3823</span>
<span class="normal">3824</span>
<span class="normal">3825</span>
<span class="normal">3826</span>
<span class="normal">3827</span>
<span class="normal">3828</span>
<span class="normal">3829</span>
<span class="normal">3830</span>
<span class="normal">3831</span>
<span class="normal">3832</span>
<span class="normal">3833</span>
<span class="normal">3834</span>
<span class="normal">3835</span>
<span class="normal">3836</span>
<span class="normal">3837</span>
<span class="normal">3838</span>
<span class="normal">3839</span>
<span class="normal">3840</span>
<span class="normal">3841</span>
<span class="normal">3842</span>
<span class="normal">3843</span>
<span class="normal">3844</span>
<span class="normal">3845</span>
<span class="normal">3846</span>
<span class="normal">3847</span>
<span class="normal">3848</span>
<span class="normal">3849</span>
<span class="normal">3850</span>
<span class="normal">3851</span>
<span class="normal">3852</span>
<span class="normal">3853</span>
<span class="normal">3854</span>
<span class="normal">3855</span>
<span class="normal">3856</span>
<span class="normal">3857</span>
<span class="normal">3858</span>
<span class="normal">3859</span>
<span class="normal">3860</span>
<span class="normal">3861</span>
<span class="normal">3862</span>
<span class="normal">3863</span>
<span class="normal">3864</span>
<span class="normal">3865</span>
<span class="normal">3866</span>
<span class="normal">3867</span>
<span class="normal">3868</span>
<span class="normal">3869</span>
<span class="normal">3870</span>
<span class="normal">3871</span>
<span class="normal">3872</span>
<span class="normal">3873</span>
<span class="normal">3874</span>
<span class="normal">3875</span>
<span class="normal">3876</span>
<span class="normal">3877</span>
<span class="normal">3878</span>
<span class="normal">3879</span>
<span class="normal">3880</span>
<span class="normal">3881</span>
<span class="normal">3882</span>
<span class="normal">3883</span>
<span class="normal">3884</span>
<span class="normal">3885</span>
<span class="normal">3886</span>
<span class="normal">3887</span>
<span class="normal">3888</span>
<span class="normal">3889</span>
<span class="normal">3890</span>
<span class="normal">3891</span>
<span class="normal">3892</span>
<span class="normal">3893</span>
<span class="normal">3894</span>
<span class="normal">3895</span>
<span class="normal">3896</span>
<span class="normal">3897</span>
<span class="normal">3898</span>
<span class="normal">3899</span>
<span class="normal">3900</span>
<span class="normal">3901</span>
<span class="normal">3902</span>
<span class="normal">3903</span>
<span class="normal">3904</span>
<span class="normal">3905</span>
<span class="normal">3906</span>
<span class="normal">3907</span>
<span class="normal">3908</span>
<span class="normal">3909</span>
<span class="normal">3910</span>
<span class="normal">3911</span>
<span class="normal">3912</span>
<span class="normal">3913</span>
<span class="normal">3914</span>
<span class="normal">3915</span>
<span class="normal">3916</span>
<span class="normal">3917</span>
<span class="normal">3918</span>
<span class="normal">3919</span>
<span class="normal">3920</span>
<span class="normal">3921</span>
<span class="normal">3922</span>
<span class="normal">3923</span>
<span class="normal">3924</span>
<span class="normal">3925</span>
<span class="normal">3926</span>
<span class="normal">3927</span>
<span class="normal">3928</span>
<span class="normal">3929</span>
<span class="normal">3930</span>
<span class="normal">3931</span>
<span class="normal">3932</span>
<span class="normal">3933</span>
<span class="normal">3934</span>
<span class="normal">3935</span>
<span class="normal">3936</span>
<span class="normal">3937</span>
<span class="normal">3938</span>
<span class="normal">3939</span>
<span class="normal">3940</span>
<span class="normal">3941</span>
<span class="normal">3942</span>
<span class="normal">3943</span>
<span class="normal">3944</span>
<span class="normal">3945</span>
<span class="normal">3946</span>
<span class="normal">3947</span>
<span class="normal">3948</span>
<span class="normal">3949</span>
<span class="normal">3950</span>
<span class="normal">3951</span>
<span class="normal">3952</span>
<span class="normal">3953</span>
<span class="normal">3954</span>
<span class="normal">3955</span>
<span class="normal">3956</span>
<span class="normal">3957</span>
<span class="normal">3958</span>
<span class="normal">3959</span>
<span class="normal">3960</span>
<span class="normal">3961</span>
<span class="normal">3962</span>
<span class="normal">3963</span>
<span class="normal">3964</span>
<span class="normal">3965</span>
<span class="normal">3966</span>
<span class="normal">3967</span>
<span class="normal">3968</span>
<span class="normal">3969</span>
<span class="normal">3970</span>
<span class="normal">3971</span>
<span class="normal">3972</span>
<span class="normal">3973</span>
<span class="normal">3974</span>
<span class="normal">3975</span>
<span class="normal">3976</span>
<span class="normal">3977</span>
<span class="normal">3978</span>
<span class="normal">3979</span>
<span class="normal">3980</span>
<span class="normal">3981</span>
<span class="normal">3982</span>
<span class="normal">3983</span>
<span class="normal">3984</span>
<span class="normal">3985</span>
<span class="normal">3986</span>
<span class="normal">3987</span>
<span class="normal">3988</span>
<span class="normal">3989</span>
<span class="normal">3990</span>
<span class="normal">3991</span>
<span class="normal">3992</span>
<span class="normal">3993</span>
<span class="normal">3994</span>
<span class="normal">3995</span>
<span class="normal">3996</span>
<span class="normal">3997</span>
<span class="normal">3998</span>
<span class="normal">3999</span>
<span class="normal">4000</span>
<span class="normal">4001</span>
<span class="normal">4002</span>
<span class="normal">4003</span>
<span class="normal">4004</span>
<span class="normal">4005</span>
<span class="normal">4006</span>
<span class="normal">4007</span>
<span class="normal">4008</span>
<span class="normal">4009</span>
<span class="normal">4010</span>
<span class="normal">4011</span>
<span class="normal">4012</span>
<span class="normal">4013</span>
<span class="normal">4014</span>
<span class="normal">4015</span>
<span class="normal">4016</span>
<span class="normal">4017</span>
<span class="normal">4018</span>
<span class="normal">4019</span>
<span class="normal">4020</span>
<span class="normal">4021</span>
<span class="normal">4022</span>
<span class="normal">4023</span>
<span class="normal">4024</span>
<span class="normal">4025</span>
<span class="normal">4026</span>
<span class="normal">4027</span>
<span class="normal">4028</span>
<span class="normal">4029</span>
<span class="normal">4030</span>
<span class="normal">4031</span>
<span class="normal">4032</span>
<span class="normal">4033</span>
<span class="normal">4034</span>
<span class="normal">4035</span>
<span class="normal">4036</span>
<span class="normal">4037</span>
<span class="normal">4038</span>
<span class="normal">4039</span>
<span class="normal">4040</span>
<span class="normal">4041</span>
<span class="normal">4042</span>
<span class="normal">4043</span>
<span class="normal">4044</span>
<span class="normal">4045</span>
<span class="normal">4046</span>
<span class="normal">4047</span>
<span class="normal">4048</span>
<span class="normal">4049</span>
<span class="normal">4050</span>
<span class="normal">4051</span>
<span class="normal">4052</span>
<span class="normal">4053</span>
<span class="normal">4054</span>
<span class="normal">4055</span>
<span class="normal">4056</span>
<span class="normal">4057</span>
<span class="normal">4058</span>
<span class="normal">4059</span>
<span class="normal">4060</span>
<span class="normal">4061</span>
<span class="normal">4062</span>
<span class="normal">4063</span>
<span class="normal">4064</span>
<span class="normal">4065</span>
<span class="normal">4066</span>
<span class="normal">4067</span>
<span class="normal">4068</span>
<span class="normal">4069</span>
<span class="normal">4070</span>
<span class="normal">4071</span>
<span class="normal">4072</span>
<span class="normal">4073</span>
<span class="normal">4074</span>
<span class="normal">4075</span>
<span class="normal">4076</span>
<span class="normal">4077</span>
<span class="normal">4078</span>
<span class="normal">4079</span>
<span class="normal">4080</span>
<span class="normal">4081</span>
<span class="normal">4082</span>
<span class="normal">4083</span>
<span class="normal">4084</span>
<span class="normal">4085</span>
<span class="normal">4086</span>
<span class="normal">4087</span>
<span class="normal">4088</span>
<span class="normal">4089</span>
<span class="normal">4090</span>
<span class="normal">4091</span>
<span class="normal">4092</span>
<span class="normal">4093</span>
<span class="normal">4094</span>
<span class="normal">4095</span>
<span class="normal">4096</span>
<span class="normal">4097</span>
<span class="normal">4098</span>
<span class="normal">4099</span>
<span class="normal">4100</span>
<span class="normal">4101</span>
<span class="normal">4102</span>
<span class="normal">4103</span>
<span class="normal">4104</span>
<span class="normal">4105</span>
<span class="normal">4106</span>
<span class="normal">4107</span>
<span class="normal">4108</span>
<span class="normal">4109</span>
<span class="normal">4110</span>
<span class="normal">4111</span>
<span class="normal">4112</span>
<span class="normal">4113</span>
<span class="normal">4114</span>
<span class="normal">4115</span>
<span class="normal">4116</span>
<span class="normal">4117</span>
<span class="normal">4118</span>
<span class="normal">4119</span>
<span class="normal">4120</span>
<span class="normal">4121</span>
<span class="normal">4122</span>
<span class="normal">4123</span>
<span class="normal">4124</span>
<span class="normal">4125</span>
<span class="normal">4126</span>
<span class="normal">4127</span>
<span class="normal">4128</span>
<span class="normal">4129</span>
<span class="normal">4130</span>
<span class="normal">4131</span>
<span class="normal">4132</span>
<span class="normal">4133</span>
<span class="normal">4134</span>
<span class="normal">4135</span>
<span class="normal">4136</span>
<span class="normal">4137</span>
<span class="normal">4138</span>
<span class="normal">4139</span>
<span class="normal">4140</span>
<span class="normal">4141</span>
<span class="normal">4142</span>
<span class="normal">4143</span>
<span class="normal">4144</span>
<span class="normal">4145</span>
<span class="normal">4146</span>
<span class="normal">4147</span>
<span class="normal">4148</span>
<span class="normal">4149</span>
<span class="normal">4150</span>
<span class="normal">4151</span>
<span class="normal">4152</span>
<span class="normal">4153</span>
<span class="normal">4154</span>
<span class="normal">4155</span>
<span class="normal">4156</span>
<span class="normal">4157</span>
<span class="normal">4158</span>
<span class="normal">4159</span>
<span class="normal">4160</span>
<span class="normal">4161</span>
<span class="normal">4162</span>
<span class="normal">4163</span>
<span class="normal">4164</span>
<span class="normal">4165</span>
<span class="normal">4166</span>
<span class="normal">4167</span>
<span class="normal">4168</span>
<span class="normal">4169</span>
<span class="normal">4170</span>
<span class="normal">4171</span>
<span class="normal">4172</span>
<span class="normal">4173</span>
<span class="normal">4174</span>
<span class="normal">4175</span>
<span class="normal">4176</span>
<span class="normal">4177</span>
<span class="normal">4178</span>
<span class="normal">4179</span>
<span class="normal">4180</span>
<span class="normal">4181</span>
<span class="normal">4182</span>
<span class="normal">4183</span>
<span class="normal">4184</span>
<span class="normal">4185</span>
<span class="normal">4186</span>
<span class="normal">4187</span>
<span class="normal">4188</span>
<span class="normal">4189</span>
<span class="normal">4190</span>
<span class="normal">4191</span>
<span class="normal">4192</span>
<span class="normal">4193</span>
<span class="normal">4194</span>
<span class="normal">4195</span>
<span class="normal">4196</span>
<span class="normal">4197</span>
<span class="normal">4198</span>
<span class="normal">4199</span>
<span class="normal">4200</span>
<span class="normal">4201</span>
<span class="normal">4202</span>
<span class="normal">4203</span>
<span class="normal">4204</span>
<span class="normal">4205</span>
<span class="normal">4206</span>
<span class="normal">4207</span>
<span class="normal">4208</span>
<span class="normal">4209</span>
<span class="normal">4210</span>
<span class="normal">4211</span>
<span class="normal">4212</span>
<span class="normal">4213</span>
<span class="normal">4214</span>
<span class="normal">4215</span>
<span class="normal">4216</span>
<span class="normal">4217</span>
<span class="normal">4218</span>
<span class="normal">4219</span>
<span class="normal">4220</span>
<span class="normal">4221</span>
<span class="normal">4222</span>
<span class="normal">4223</span>
<span class="normal">4224</span>
<span class="normal">4225</span>
<span class="normal">4226</span>
<span class="normal">4227</span>
<span class="normal">4228</span>
<span class="normal">4229</span>
<span class="normal">4230</span>
<span class="normal">4231</span>
<span class="normal">4232</span>
<span class="normal">4233</span>
<span class="normal">4234</span>
<span class="normal">4235</span>
<span class="normal">4236</span>
<span class="normal">4237</span>
<span class="normal">4238</span>
<span class="normal">4239</span>
<span class="normal">4240</span>
<span class="normal">4241</span>
<span class="normal">4242</span>
<span class="normal">4243</span>
<span class="normal">4244</span>
<span class="normal">4245</span>
<span class="normal">4246</span>
<span class="normal">4247</span>
<span class="normal">4248</span>
<span class="normal">4249</span>
<span class="normal">4250</span>
<span class="normal">4251</span>
<span class="normal">4252</span>
<span class="normal">4253</span>
<span class="normal">4254</span>
<span class="normal">4255</span>
<span class="normal">4256</span>
<span class="normal">4257</span>
<span class="normal">4258</span>
<span class="normal">4259</span>
<span class="normal">4260</span>
<span class="normal">4261</span>
<span class="normal">4262</span>
<span class="normal">4263</span>
<span class="normal">4264</span>
<span class="normal">4265</span>
<span class="normal">4266</span>
<span class="normal">4267</span>
<span class="normal">4268</span>
<span class="normal">4269</span>
<span class="normal">4270</span>
<span class="normal">4271</span>
<span class="normal">4272</span>
<span class="normal">4273</span>
<span class="normal">4274</span>
<span class="normal">4275</span>
<span class="normal">4276</span>
<span class="normal">4277</span>
<span class="normal">4278</span>
<span class="normal">4279</span>
<span class="normal">4280</span>
<span class="normal">4281</span>
<span class="normal">4282</span>
<span class="normal">4283</span>
<span class="normal">4284</span>
<span class="normal">4285</span>
<span class="normal">4286</span>
<span class="normal">4287</span>
<span class="normal">4288</span>
<span class="normal">4289</span>
<span class="normal">4290</span>
<span class="normal">4291</span>
<span class="normal">4292</span>
<span class="normal">4293</span>
<span class="normal">4294</span>
<span class="normal">4295</span>
<span class="normal">4296</span>
<span class="normal">4297</span>
<span class="normal">4298</span>
<span class="normal">4299</span>
<span class="normal">4300</span>
<span class="normal">4301</span>
<span class="normal">4302</span>
<span class="normal">4303</span>
<span class="normal">4304</span>
<span class="normal">4305</span>
<span class="normal">4306</span>
<span class="normal">4307</span>
<span class="normal">4308</span>
<span class="normal">4309</span>
<span class="normal">4310</span>
<span class="normal">4311</span>
<span class="normal">4312</span>
<span class="normal">4313</span>
<span class="normal">4314</span>
<span class="normal">4315</span>
<span class="normal">4316</span>
<span class="normal">4317</span>
<span class="normal">4318</span>
<span class="normal">4319</span>
<span class="normal">4320</span>
<span class="normal">4321</span>
<span class="normal">4322</span>
<span class="normal">4323</span>
<span class="normal">4324</span>
<span class="normal">4325</span>
<span class="normal">4326</span>
<span class="normal">4327</span>
<span class="normal">4328</span>
<span class="normal">4329</span>
<span class="normal">4330</span>
<span class="normal">4331</span>
<span class="normal">4332</span>
<span class="normal">4333</span>
<span class="normal">4334</span>
<span class="normal">4335</span>
<span class="normal">4336</span>
<span class="normal">4337</span>
<span class="normal">4338</span>
<span class="normal">4339</span>
<span class="normal">4340</span>
<span class="normal">4341</span>
<span class="normal">4342</span>
<span class="normal">4343</span>
<span class="normal">4344</span>
<span class="normal">4345</span>
<span class="normal">4346</span>
<span class="normal">4347</span>
<span class="normal">4348</span>
<span class="normal">4349</span>
<span class="normal">4350</span>
<span class="normal">4351</span>
<span class="normal">4352</span>
<span class="normal">4353</span>
<span class="normal">4354</span>
<span class="normal">4355</span>
<span class="normal">4356</span>
<span class="normal">4357</span>
<span class="normal">4358</span>
<span class="normal">4359</span>
<span class="normal">4360</span>
<span class="normal">4361</span>
<span class="normal">4362</span>
<span class="normal">4363</span>
<span class="normal">4364</span>
<span class="normal">4365</span>
<span class="normal">4366</span>
<span class="normal">4367</span>
<span class="normal">4368</span>
<span class="normal">4369</span>
<span class="normal">4370</span>
<span class="normal">4371</span>
<span class="normal">4372</span>
<span class="normal">4373</span>
<span class="normal">4374</span>
<span class="normal">4375</span>
<span class="normal">4376</span>
<span class="normal">4377</span>
<span class="normal">4378</span>
<span class="normal">4379</span>
<span class="normal">4380</span>
<span class="normal">4381</span>
<span class="normal">4382</span>
<span class="normal">4383</span>
<span class="normal">4384</span>
<span class="normal">4385</span>
<span class="normal">4386</span>
<span class="normal">4387</span>
<span class="normal">4388</span>
<span class="normal">4389</span>
<span class="normal">4390</span>
<span class="normal">4391</span>
<span class="normal">4392</span>
<span class="normal">4393</span>
<span class="normal">4394</span>
<span class="normal">4395</span>
<span class="normal">4396</span>
<span class="normal">4397</span>
<span class="normal">4398</span>
<span class="normal">4399</span>
<span class="normal">4400</span>
<span class="normal">4401</span>
<span class="normal">4402</span>
<span class="normal">4403</span>
<span class="normal">4404</span>
<span class="normal">4405</span>
<span class="normal">4406</span>
<span class="normal">4407</span>
<span class="normal">4408</span>
<span class="normal">4409</span>
<span class="normal">4410</span>
<span class="normal">4411</span>
<span class="normal">4412</span>
<span class="normal">4413</span>
<span class="normal">4414</span>
<span class="normal">4415</span>
<span class="normal">4416</span>
<span class="normal">4417</span>
<span class="normal">4418</span>
<span class="normal">4419</span>
<span class="normal">4420</span>
<span class="normal">4421</span>
<span class="normal">4422</span>
<span class="normal">4423</span>
<span class="normal">4424</span>
<span class="normal">4425</span>
<span class="normal">4426</span>
<span class="normal">4427</span>
<span class="normal">4428</span>
<span class="normal">4429</span>
<span class="normal">4430</span>
<span class="normal">4431</span>
<span class="normal">4432</span>
<span class="normal">4433</span>
<span class="normal">4434</span>
<span class="normal">4435</span>
<span class="normal">4436</span>
<span class="normal">4437</span>
<span class="normal">4438</span>
<span class="normal">4439</span>
<span class="normal">4440</span>
<span class="normal">4441</span>
<span class="normal">4442</span>
<span class="normal">4443</span>
<span class="normal">4444</span>
<span class="normal">4445</span>
<span class="normal">4446</span>
<span class="normal">4447</span>
<span class="normal">4448</span>
<span class="normal">4449</span>
<span class="normal">4450</span>
<span class="normal">4451</span>
<span class="normal">4452</span>
<span class="normal">4453</span>
<span class="normal">4454</span>
<span class="normal">4455</span>
<span class="normal">4456</span>
<span class="normal">4457</span>
<span class="normal">4458</span>
<span class="normal">4459</span>
<span class="normal">4460</span>
<span class="normal">4461</span>
<span class="normal">4462</span>
<span class="normal">4463</span>
<span class="normal">4464</span>
<span class="normal">4465</span>
<span class="normal">4466</span>
<span class="normal">4467</span>
<span class="normal">4468</span>
<span class="normal">4469</span>
<span class="normal">4470</span>
<span class="normal">4471</span>
<span class="normal">4472</span>
<span class="normal">4473</span>
<span class="normal">4474</span>
<span class="normal">4475</span>
<span class="normal">4476</span>
<span class="normal">4477</span>
<span class="normal">4478</span>
<span class="normal">4479</span>
<span class="normal">4480</span>
<span class="normal">4481</span>
<span class="normal">4482</span>
<span class="normal">4483</span>
<span class="normal">4484</span>
<span class="normal">4485</span>
<span class="normal">4486</span>
<span class="normal">4487</span>
<span class="normal">4488</span>
<span class="normal">4489</span>
<span class="normal">4490</span>
<span class="normal">4491</span>
<span class="normal">4492</span>
<span class="normal">4493</span>
<span class="normal">4494</span>
<span class="normal">4495</span>
<span class="normal">4496</span>
<span class="normal">4497</span>
<span class="normal">4498</span>
<span class="normal">4499</span>
<span class="normal">4500</span>
<span class="normal">4501</span>
<span class="normal">4502</span>
<span class="normal">4503</span>
<span class="normal">4504</span>
<span class="normal">4505</span>
<span class="normal">4506</span>
<span class="normal">4507</span>
<span class="normal">4508</span>
<span class="normal">4509</span>
<span class="normal">4510</span>
<span class="normal">4511</span>
<span class="normal">4512</span>
<span class="normal">4513</span>
<span class="normal">4514</span>
<span class="normal">4515</span>
<span class="normal">4516</span>
<span class="normal">4517</span>
<span class="normal">4518</span>
<span class="normal">4519</span>
<span class="normal">4520</span>
<span class="normal">4521</span>
<span class="normal">4522</span>
<span class="normal">4523</span>
<span class="normal">4524</span>
<span class="normal">4525</span>
<span class="normal">4526</span>
<span class="normal">4527</span>
<span class="normal">4528</span>
<span class="normal">4529</span>
<span class="normal">4530</span>
<span class="normal">4531</span>
<span class="normal">4532</span>
<span class="normal">4533</span>
<span class="normal">4534</span>
<span class="normal">4535</span>
<span class="normal">4536</span>
<span class="normal">4537</span>
<span class="normal">4538</span>
<span class="normal">4539</span>
<span class="normal">4540</span>
<span class="normal">4541</span>
<span class="normal">4542</span>
<span class="normal">4543</span>
<span class="normal">4544</span>
<span class="normal">4545</span>
<span class="normal">4546</span>
<span class="normal">4547</span>
<span class="normal">4548</span>
<span class="normal">4549</span>
<span class="normal">4550</span>
<span class="normal">4551</span>
<span class="normal">4552</span>
<span class="normal">4553</span>
<span class="normal">4554</span>
<span class="normal">4555</span>
<span class="normal">4556</span>
<span class="normal">4557</span>
<span class="normal">4558</span>
<span class="normal">4559</span>
<span class="normal">4560</span>
<span class="normal">4561</span>
<span class="normal">4562</span>
<span class="normal">4563</span>
<span class="normal">4564</span>
<span class="normal">4565</span>
<span class="normal">4566</span>
<span class="normal">4567</span>
<span class="normal">4568</span>
<span class="normal">4569</span>
<span class="normal">4570</span>
<span class="normal">4571</span>
<span class="normal">4572</span>
<span class="normal">4573</span>
<span class="normal">4574</span>
<span class="normal">4575</span>
<span class="normal">4576</span>
<span class="normal">4577</span>
<span class="normal">4578</span>
<span class="normal">4579</span>
<span class="normal">4580</span>
<span class="normal">4581</span>
<span class="normal">4582</span>
<span class="normal">4583</span>
<span class="normal">4584</span>
<span class="normal">4585</span>
<span class="normal">4586</span>
<span class="normal">4587</span>
<span class="normal">4588</span>
<span class="normal">4589</span>
<span class="normal">4590</span>
<span class="normal">4591</span>
<span class="normal">4592</span>
<span class="normal">4593</span>
<span class="normal">4594</span>
<span class="normal">4595</span>
<span class="normal">4596</span>
<span class="normal">4597</span>
<span class="normal">4598</span>
<span class="normal">4599</span>
<span class="normal">4600</span>
<span class="normal">4601</span>
<span class="normal">4602</span>
<span class="normal">4603</span>
<span class="normal">4604</span>
<span class="normal">4605</span>
<span class="normal">4606</span>
<span class="normal">4607</span>
<span class="normal">4608</span>
<span class="normal">4609</span>
<span class="normal">4610</span>
<span class="normal">4611</span>
<span class="normal">4612</span>
<span class="normal">4613</span>
<span class="normal">4614</span>
<span class="normal">4615</span>
<span class="normal">4616</span>
<span class="normal">4617</span>
<span class="normal">4618</span>
<span class="normal">4619</span>
<span class="normal">4620</span>
<span class="normal">4621</span>
<span class="normal">4622</span>
<span class="normal">4623</span>
<span class="normal">4624</span>
<span class="normal">4625</span>
<span class="normal">4626</span>
<span class="normal">4627</span>
<span class="normal">4628</span>
<span class="normal">4629</span>
<span class="normal">4630</span>
<span class="normal">4631</span>
<span class="normal">4632</span>
<span class="normal">4633</span>
<span class="normal">4634</span>
<span class="normal">4635</span>
<span class="normal">4636</span>
<span class="normal">4637</span>
<span class="normal">4638</span>
<span class="normal">4639</span>
<span class="normal">4640</span>
<span class="normal">4641</span>
<span class="normal">4642</span>
<span class="normal">4643</span>
<span class="normal">4644</span>
<span class="normal">4645</span>
<span class="normal">4646</span>
<span class="normal">4647</span>
<span class="normal">4648</span>
<span class="normal">4649</span>
<span class="normal">4650</span>
<span class="normal">4651</span>
<span class="normal">4652</span>
<span class="normal">4653</span>
<span class="normal">4654</span>
<span class="normal">4655</span>
<span class="normal">4656</span>
<span class="normal">4657</span>
<span class="normal">4658</span>
<span class="normal">4659</span>
<span class="normal">4660</span>
<span class="normal">4661</span>
<span class="normal">4662</span>
<span class="normal">4663</span>
<span class="normal">4664</span>
<span class="normal">4665</span>
<span class="normal">4666</span>
<span class="normal">4667</span>
<span class="normal">4668</span>
<span class="normal">4669</span>
<span class="normal">4670</span>
<span class="normal">4671</span>
<span class="normal">4672</span>
<span class="normal">4673</span>
<span class="normal">4674</span>
<span class="normal">4675</span>
<span class="normal">4676</span>
<span class="normal">4677</span>
<span class="normal">4678</span>
<span class="normal">4679</span>
<span class="normal">4680</span>
<span class="normal">4681</span>
<span class="normal">4682</span>
<span class="normal">4683</span>
<span class="normal">4684</span>
<span class="normal">4685</span>
<span class="normal">4686</span>
<span class="normal">4687</span>
<span class="normal">4688</span>
<span class="normal">4689</span>
<span class="normal">4690</span>
<span class="normal">4691</span>
<span class="normal">4692</span>
<span class="normal">4693</span>
<span class="normal">4694</span>
<span class="normal">4695</span>
<span class="normal">4696</span>
<span class="normal">4697</span>
<span class="normal">4698</span>
<span class="normal">4699</span>
<span class="normal">4700</span>
<span class="normal">4701</span>
<span class="normal">4702</span>
<span class="normal">4703</span>
<span class="normal">4704</span>
<span class="normal">4705</span>
<span class="normal">4706</span>
<span class="normal">4707</span>
<span class="normal">4708</span>
<span class="normal">4709</span>
<span class="normal">4710</span>
<span class="normal">4711</span>
<span class="normal">4712</span>
<span class="normal">4713</span>
<span class="normal">4714</span>
<span class="normal">4715</span>
<span class="normal">4716</span>
<span class="normal">4717</span>
<span class="normal">4718</span>
<span class="normal">4719</span>
<span class="normal">4720</span>
<span class="normal">4721</span>
<span class="normal">4722</span>
<span class="normal">4723</span>
<span class="normal">4724</span>
<span class="normal">4725</span>
<span class="normal">4726</span>
<span class="normal">4727</span>
<span class="normal">4728</span>
<span class="normal">4729</span>
<span class="normal">4730</span>
<span class="normal">4731</span>
<span class="normal">4732</span>
<span class="normal">4733</span>
<span class="normal">4734</span>
<span class="normal">4735</span>
<span class="normal">4736</span>
<span class="normal">4737</span>
<span class="normal">4738</span>
<span class="normal">4739</span>
<span class="normal">4740</span>
<span class="normal">4741</span>
<span class="normal">4742</span>
<span class="normal">4743</span>
<span class="normal">4744</span>
<span class="normal">4745</span>
<span class="normal">4746</span>
<span class="normal">4747</span>
<span class="normal">4748</span>
<span class="normal">4749</span>
<span class="normal">4750</span>
<span class="normal">4751</span>
<span class="normal">4752</span>
<span class="normal">4753</span>
<span class="normal">4754</span>
<span class="normal">4755</span>
<span class="normal">4756</span>
<span class="normal">4757</span>
<span class="normal">4758</span>
<span class="normal">4759</span>
<span class="normal">4760</span>
<span class="normal">4761</span>
<span class="normal">4762</span>
<span class="normal">4763</span>
<span class="normal">4764</span>
<span class="normal">4765</span>
<span class="normal">4766</span>
<span class="normal">4767</span>
<span class="normal">4768</span>
<span class="normal">4769</span>
<span class="normal">4770</span>
<span class="normal">4771</span>
<span class="normal">4772</span>
<span class="normal">4773</span>
<span class="normal">4774</span>
<span class="normal">4775</span>
<span class="normal">4776</span>
<span class="normal">4777</span>
<span class="normal">4778</span>
<span class="normal">4779</span>
<span class="normal">4780</span>
<span class="normal">4781</span>
<span class="normal">4782</span>
<span class="normal">4783</span>
<span class="normal">4784</span>
<span class="normal">4785</span>
<span class="normal">4786</span>
<span class="normal">4787</span>
<span class="normal">4788</span>
<span class="normal">4789</span>
<span class="normal">4790</span>
<span class="normal">4791</span>
<span class="normal">4792</span>
<span class="normal">4793</span>
<span class="normal">4794</span>
<span class="normal">4795</span>
<span class="normal">4796</span>
<span class="normal">4797</span>
<span class="normal">4798</span>
<span class="normal">4799</span>
<span class="normal">4800</span>
<span class="normal">4801</span>
<span class="normal">4802</span>
<span class="normal">4803</span>
<span class="normal">4804</span>
<span class="normal">4805</span>
<span class="normal">4806</span>
<span class="normal">4807</span>
<span class="normal">4808</span>
<span class="normal">4809</span>
<span class="normal">4810</span>
<span class="normal">4811</span>
<span class="normal">4812</span>
<span class="normal">4813</span>
<span class="normal">4814</span>
<span class="normal">4815</span>
<span class="normal">4816</span>
<span class="normal">4817</span>
<span class="normal">4818</span>
<span class="normal">4819</span>
<span class="normal">4820</span>
<span class="normal">4821</span>
<span class="normal">4822</span>
<span class="normal">4823</span>
<span class="normal">4824</span>
<span class="normal">4825</span>
<span class="normal">4826</span>
<span class="normal">4827</span>
<span class="normal">4828</span>
<span class="normal">4829</span>
<span class="normal">4830</span>
<span class="normal">4831</span>
<span class="normal">4832</span>
<span class="normal">4833</span>
<span class="normal">4834</span>
<span class="normal">4835</span>
<span class="normal">4836</span>
<span class="normal">4837</span>
<span class="normal">4838</span>
<span class="normal">4839</span>
<span class="normal">4840</span>
<span class="normal">4841</span>
<span class="normal">4842</span>
<span class="normal">4843</span>
<span class="normal">4844</span>
<span class="normal">4845</span>
<span class="normal">4846</span>
<span class="normal">4847</span>
<span class="normal">4848</span>
<span class="normal">4849</span>
<span class="normal">4850</span>
<span class="normal">4851</span>
<span class="normal">4852</span>
<span class="normal">4853</span>
<span class="normal">4854</span>
<span class="normal">4855</span>
<span class="normal">4856</span>
<span class="normal">4857</span>
<span class="normal">4858</span>
<span class="normal">4859</span>
<span class="normal">4860</span>
<span class="normal">4861</span>
<span class="normal">4862</span>
<span class="normal">4863</span>
<span class="normal">4864</span>
<span class="normal">4865</span>
<span class="normal">4866</span>
<span class="normal">4867</span>
<span class="normal">4868</span>
<span class="normal">4869</span>
<span class="normal">4870</span>
<span class="normal">4871</span>
<span class="normal">4872</span>
<span class="normal">4873</span>
<span class="normal">4874</span>
<span class="normal">4875</span>
<span class="normal">4876</span>
<span class="normal">4877</span>
<span class="normal">4878</span>
<span class="normal">4879</span>
<span class="normal">4880</span>
<span class="normal">4881</span>
<span class="normal">4882</span>
<span class="normal">4883</span>
<span class="normal">4884</span>
<span class="normal">4885</span>
<span class="normal">4886</span>
<span class="normal">4887</span>
<span class="normal">4888</span>
<span class="normal">4889</span>
<span class="normal">4890</span>
<span class="normal">4891</span>
<span class="normal">4892</span>
<span class="normal">4893</span>
<span class="normal">4894</span>
<span class="normal">4895</span>
<span class="normal">4896</span>
<span class="normal">4897</span>
<span class="normal">4898</span>
<span class="normal">4899</span>
<span class="normal">4900</span>
<span class="normal">4901</span>
<span class="normal">4902</span>
<span class="normal">4903</span>
<span class="normal">4904</span>
<span class="normal">4905</span>
<span class="normal">4906</span>
<span class="normal">4907</span>
<span class="normal">4908</span>
<span class="normal">4909</span>
<span class="normal">4910</span>
<span class="normal">4911</span>
<span class="normal">4912</span>
<span class="normal">4913</span>
<span class="normal">4914</span>
<span class="normal">4915</span>
<span class="normal">4916</span>
<span class="normal">4917</span>
<span class="normal">4918</span>
<span class="normal">4919</span>
<span class="normal">4920</span>
<span class="normal">4921</span>
<span class="normal">4922</span>
<span class="normal">4923</span>
<span class="normal">4924</span>
<span class="normal">4925</span>
<span class="normal">4926</span>
<span class="normal">4927</span>
<span class="normal">4928</span>
<span class="normal">4929</span>
<span class="normal">4930</span>
<span class="normal">4931</span>
<span class="normal">4932</span>
<span class="normal">4933</span>
<span class="normal">4934</span>
<span class="normal">4935</span>
<span class="normal">4936</span>
<span class="normal">4937</span>
<span class="normal">4938</span>
<span class="normal">4939</span>
<span class="normal">4940</span>
<span class="normal">4941</span>
<span class="normal">4942</span>
<span class="normal">4943</span>
<span class="normal">4944</span>
<span class="normal">4945</span>
<span class="normal">4946</span>
<span class="normal">4947</span>
<span class="normal">4948</span>
<span class="normal">4949</span>
<span class="normal">4950</span>
<span class="normal">4951</span>
<span class="normal">4952</span>
<span class="normal">4953</span>
<span class="normal">4954</span>
<span class="normal">4955</span>
<span class="normal">4956</span>
<span class="normal">4957</span>
<span class="normal">4958</span>
<span class="normal">4959</span>
<span class="normal">4960</span>
<span class="normal">4961</span>
<span class="normal">4962</span>
<span class="normal">4963</span>
<span class="normal">4964</span>
<span class="normal">4965</span>
<span class="normal">4966</span>
<span class="normal">4967</span>
<span class="normal">4968</span>
<span class="normal">4969</span>
<span class="normal">4970</span>
<span class="normal">4971</span>
<span class="normal">4972</span>
<span class="normal">4973</span>
<span class="normal">4974</span>
<span class="normal">4975</span>
<span class="normal">4976</span>
<span class="normal">4977</span>
<span class="normal">4978</span>
<span class="normal">4979</span>
<span class="normal">4980</span>
<span class="normal">4981</span>
<span class="normal">4982</span>
<span class="normal">4983</span>
<span class="normal">4984</span>
<span class="normal">4985</span>
<span class="normal">4986</span>
<span class="normal">4987</span>
<span class="normal">4988</span>
<span class="normal">4989</span>
<span class="normal">4990</span>
<span class="normal">4991</span>
<span class="normal">4992</span>
<span class="normal">4993</span>
<span class="normal">4994</span>
<span class="normal">4995</span>
<span class="normal">4996</span>
<span class="normal">4997</span>
<span class="normal">4998</span>
<span class="normal">4999</span>
<span class="normal">5000</span>
<span class="normal">5001</span>
<span class="normal">5002</span>
<span class="normal">5003</span>
<span class="normal">5004</span>
<span class="normal">5005</span>
<span class="normal">5006</span>
<span class="normal">5007</span>
<span class="normal">5008</span>
<span class="normal">5009</span>
<span class="normal">5010</span>
<span class="normal">5011</span>
<span class="normal">5012</span>
<span class="normal">5013</span>
<span class="normal">5014</span>
<span class="normal">5015</span>
<span class="normal">5016</span>
<span class="normal">5017</span>
<span class="normal">5018</span>
<span class="normal">5019</span>
<span class="normal">5020</span>
<span class="normal">5021</span>
<span class="normal">5022</span>
<span class="normal">5023</span>
<span class="normal">5024</span>
<span class="normal">5025</span>
<span class="normal">5026</span>
<span class="normal">5027</span>
<span class="normal">5028</span>
<span class="normal">5029</span>
<span class="normal">5030</span>
<span class="normal">5031</span>
<span class="normal">5032</span>
<span class="normal">5033</span>
<span class="normal">5034</span>
<span class="normal">5035</span>
<span class="normal">5036</span>
<span class="normal">5037</span>
<span class="normal">5038</span>
<span class="normal">5039</span>
<span class="normal">5040</span>
<span class="normal">5041</span>
<span class="normal">5042</span>
<span class="normal">5043</span>
<span class="normal">5044</span>
<span class="normal">5045</span>
<span class="normal">5046</span>
<span class="normal">5047</span>
<span class="normal">5048</span>
<span class="normal">5049</span>
<span class="normal">5050</span>
<span class="normal">5051</span>
<span class="normal">5052</span>
<span class="normal">5053</span>
<span class="normal">5054</span>
<span class="normal">5055</span>
<span class="normal">5056</span>
<span class="normal">5057</span>
<span class="normal">5058</span>
<span class="normal">5059</span>
<span class="normal">5060</span>
<span class="normal">5061</span>
<span class="normal">5062</span>
<span class="normal">5063</span>
<span class="normal">5064</span>
<span class="normal">5065</span>
<span class="normal">5066</span>
<span class="normal">5067</span>
<span class="normal">5068</span>
<span class="normal">5069</span>
<span class="normal">5070</span>
<span class="normal">5071</span>
<span class="normal">5072</span>
<span class="normal">5073</span>
<span class="normal">5074</span>
<span class="normal">5075</span>
<span class="normal">5076</span>
<span class="normal">5077</span>
<span class="normal">5078</span>
<span class="normal">5079</span>
<span class="normal">5080</span>
<span class="normal">5081</span>
<span class="normal">5082</span>
<span class="normal">5083</span>
<span class="normal">5084</span>
<span class="normal">5085</span>
<span class="normal">5086</span>
<span class="normal">5087</span>
<span class="normal">5088</span>
<span class="normal">5089</span>
<span class="normal">5090</span>
<span class="normal">5091</span>
<span class="normal">5092</span>
<span class="normal">5093</span>
<span class="normal">5094</span>
<span class="normal">5095</span>
<span class="normal">5096</span>
<span class="normal">5097</span>
<span class="normal">5098</span>
<span class="normal">5099</span>
<span class="normal">5100</span>
<span class="normal">5101</span>
<span class="normal">5102</span>
<span class="normal">5103</span>
<span class="normal">5104</span>
<span class="normal">5105</span>
<span class="normal">5106</span>
<span class="normal">5107</span>
<span class="normal">5108</span>
<span class="normal">5109</span>
<span class="normal">5110</span>
<span class="normal">5111</span>
<span class="normal">5112</span>
<span class="normal">5113</span>
<span class="normal">5114</span>
<span class="normal">5115</span>
<span class="normal">5116</span>
<span class="normal">5117</span>
<span class="normal">5118</span>
<span class="normal">5119</span>
<span class="normal">5120</span>
<span class="normal">5121</span>
<span class="normal">5122</span>
<span class="normal">5123</span>
<span class="normal">5124</span>
<span class="normal">5125</span>
<span class="normal">5126</span>
<span class="normal">5127</span>
<span class="normal">5128</span>
<span class="normal">5129</span>
<span class="normal">5130</span>
<span class="normal">5131</span>
<span class="normal">5132</span>
<span class="normal">5133</span>
<span class="normal">5134</span>
<span class="normal">5135</span>
<span class="normal">5136</span>
<span class="normal">5137</span>
<span class="normal">5138</span>
<span class="normal">5139</span>
<span class="normal">5140</span>
<span class="normal">5141</span>
<span class="normal">5142</span>
<span class="normal">5143</span>
<span class="normal">5144</span>
<span class="normal">5145</span>
<span class="normal">5146</span>
<span class="normal">5147</span>
<span class="normal">5148</span>
<span class="normal">5149</span>
<span class="normal">5150</span>
<span class="normal">5151</span>
<span class="normal">5152</span>
<span class="normal">5153</span>
<span class="normal">5154</span>
<span class="normal">5155</span>
<span class="normal">5156</span>
<span class="normal">5157</span>
<span class="normal">5158</span>
<span class="normal">5159</span>
<span class="normal">5160</span>
<span class="normal">5161</span>
<span class="normal">5162</span>
<span class="normal">5163</span>
<span class="normal">5164</span>
<span class="normal">5165</span>
<span class="normal">5166</span>
<span class="normal">5167</span>
<span class="normal">5168</span>
<span class="normal">5169</span>
<span class="normal">5170</span>
<span class="normal">5171</span>
<span class="normal">5172</span>
<span class="normal">5173</span>
<span class="normal">5174</span>
<span class="normal">5175</span>
<span class="normal">5176</span>
<span class="normal">5177</span>
<span class="normal">5178</span>
<span class="normal">5179</span>
<span class="normal">5180</span>
<span class="normal">5181</span>
<span class="normal">5182</span>
<span class="normal">5183</span>
<span class="normal">5184</span>
<span class="normal">5185</span>
<span class="normal">5186</span>
<span class="normal">5187</span>
<span class="normal">5188</span>
<span class="normal">5189</span>
<span class="normal">5190</span>
<span class="normal">5191</span>
<span class="normal">5192</span>
<span class="normal">5193</span>
<span class="normal">5194</span>
<span class="normal">5195</span>
<span class="normal">5196</span>
<span class="normal">5197</span>
<span class="normal">5198</span>
<span class="normal">5199</span>
<span class="normal">5200</span>
<span class="normal">5201</span>
<span class="normal">5202</span>
<span class="normal">5203</span>
<span class="normal">5204</span>
<span class="normal">5205</span>
<span class="normal">5206</span>
<span class="normal">5207</span>
<span class="normal">5208</span>
<span class="normal">5209</span>
<span class="normal">5210</span>
<span class="normal">5211</span>
<span class="normal">5212</span>
<span class="normal">5213</span>
<span class="normal">5214</span>
<span class="normal">5215</span>
<span class="normal">5216</span>
<span class="normal">5217</span>
<span class="normal">5218</span>
<span class="normal">5219</span>
<span class="normal">5220</span>
<span class="normal">5221</span>
<span class="normal">5222</span>
<span class="normal">5223</span>
<span class="normal">5224</span>
<span class="normal">5225</span>
<span class="normal">5226</span>
<span class="normal">5227</span>
<span class="normal">5228</span>
<span class="normal">5229</span>
<span class="normal">5230</span>
<span class="normal">5231</span>
<span class="normal">5232</span>
<span class="normal">5233</span>
<span class="normal">5234</span>
<span class="normal">5235</span>
<span class="normal">5236</span>
<span class="normal">5237</span>
<span class="normal">5238</span>
<span class="normal">5239</span>
<span class="normal">5240</span>
<span class="normal">5241</span>
<span class="normal">5242</span>
<span class="normal">5243</span>
<span class="normal">5244</span>
<span class="normal">5245</span>
<span class="normal">5246</span>
<span class="normal">5247</span>
<span class="normal">5248</span>
<span class="normal">5249</span>
<span class="normal">5250</span>
<span class="normal">5251</span>
<span class="normal">5252</span>
<span class="normal">5253</span>
<span class="normal">5254</span>
<span class="normal">5255</span>
<span class="normal">5256</span>
<span class="normal">5257</span>
<span class="normal">5258</span>
<span class="normal">5259</span>
<span class="normal">5260</span>
<span class="normal">5261</span>
<span class="normal">5262</span>
<span class="normal">5263</span>
<span class="normal">5264</span>
<span class="normal">5265</span>
<span class="normal">5266</span>
<span class="normal">5267</span>
<span class="normal">5268</span>
<span class="normal">5269</span>
<span class="normal">5270</span>
<span class="normal">5271</span>
<span class="normal">5272</span>
<span class="normal">5273</span>
<span class="normal">5274</span>
<span class="normal">5275</span>
<span class="normal">5276</span>
<span class="normal">5277</span>
<span class="normal">5278</span>
<span class="normal">5279</span>
<span class="normal">5280</span>
<span class="normal">5281</span>
<span class="normal">5282</span>
<span class="normal">5283</span>
<span class="normal">5284</span>
<span class="normal">5285</span>
<span class="normal">5286</span>
<span class="normal">5287</span>
<span class="normal">5288</span>
<span class="normal">5289</span>
<span class="normal">5290</span>
<span class="normal">5291</span>
<span class="normal">5292</span>
<span class="normal">5293</span>
<span class="normal">5294</span>
<span class="normal">5295</span>
<span class="normal">5296</span>
<span class="normal">5297</span>
<span class="normal">5298</span>
<span class="normal">5299</span>
<span class="normal">5300</span>
<span class="normal">5301</span>
<span class="normal">5302</span>
<span class="normal">5303</span>
<span class="normal">5304</span>
<span class="normal">5305</span>
<span class="normal">5306</span>
<span class="normal">5307</span>
<span class="normal">5308</span>
<span class="normal">5309</span>
<span class="normal">5310</span>
<span class="normal">5311</span>
<span class="normal">5312</span>
<span class="normal">5313</span>
<span class="normal">5314</span>
<span class="normal">5315</span>
<span class="normal">5316</span>
<span class="normal">5317</span>
<span class="normal">5318</span>
<span class="normal">5319</span>
<span class="normal">5320</span>
<span class="normal">5321</span>
<span class="normal">5322</span>
<span class="normal">5323</span>
<span class="normal">5324</span>
<span class="normal">5325</span>
<span class="normal">5326</span>
<span class="normal">5327</span>
<span class="normal">5328</span>
<span class="normal">5329</span>
<span class="normal">5330</span>
<span class="normal">5331</span>
<span class="normal">5332</span>
<span class="normal">5333</span>
<span class="normal">5334</span>
<span class="normal">5335</span>
<span class="normal">5336</span>
<span class="normal">5337</span>
<span class="normal">5338</span>
<span class="normal">5339</span>
<span class="normal">5340</span>
<span class="normal">5341</span>
<span class="normal">5342</span>
<span class="normal">5343</span>
<span class="normal">5344</span>
<span class="normal">5345</span>
<span class="normal">5346</span>
<span class="normal">5347</span>
<span class="normal">5348</span>
<span class="normal">5349</span>
<span class="normal">5350</span>
<span class="normal">5351</span>
<span class="normal">5352</span>
<span class="normal">5353</span>
<span class="normal">5354</span>
<span class="normal">5355</span>
<span class="normal">5356</span>
<span class="normal">5357</span>
<span class="normal">5358</span>
<span class="normal">5359</span>
<span class="normal">5360</span>
<span class="normal">5361</span>
<span class="normal">5362</span>
<span class="normal">5363</span>
<span class="normal">5364</span>
<span class="normal">5365</span>
<span class="normal">5366</span>
<span class="normal">5367</span>
<span class="normal">5368</span>
<span class="normal">5369</span>
<span class="normal">5370</span>
<span class="normal">5371</span>
<span class="normal">5372</span>
<span class="normal">5373</span>
<span class="normal">5374</span>
<span class="normal">5375</span>
<span class="normal">5376</span>
<span class="normal">5377</span>
<span class="normal">5378</span>
<span class="normal">5379</span>
<span class="normal">5380</span>
<span class="normal">5381</span>
<span class="normal">5382</span>
<span class="normal">5383</span>
<span class="normal">5384</span>
<span class="normal">5385</span>
<span class="normal">5386</span>
<span class="normal">5387</span>
<span class="normal">5388</span>
<span class="normal">5389</span>
<span class="normal">5390</span>
<span class="normal">5391</span>
<span class="normal">5392</span>
<span class="normal">5393</span>
<span class="normal">5394</span>
<span class="normal">5395</span>
<span class="normal">5396</span>
<span class="normal">5397</span>
<span class="normal">5398</span>
<span class="normal">5399</span>
<span class="normal">5400</span>
<span class="normal">5401</span>
<span class="normal">5402</span>
<span class="normal">5403</span>
<span class="normal">5404</span>
<span class="normal">5405</span>
<span class="normal">5406</span>
<span class="normal">5407</span>
<span class="normal">5408</span>
<span class="normal">5409</span>
<span class="normal">5410</span>
<span class="normal">5411</span>
<span class="normal">5412</span>
<span class="normal">5413</span>
<span class="normal">5414</span>
<span class="normal">5415</span>
<span class="normal">5416</span>
<span class="normal">5417</span>
<span class="normal">5418</span>
<span class="normal">5419</span>
<span class="normal">5420</span>
<span class="normal">5421</span>
<span class="normal">5422</span>
<span class="normal">5423</span>
<span class="normal">5424</span>
<span class="normal">5425</span>
<span class="normal">5426</span>
<span class="normal">5427</span>
<span class="normal">5428</span>
<span class="normal">5429</span>
<span class="normal">5430</span>
<span class="normal">5431</span>
<span class="normal">5432</span>
<span class="normal">5433</span>
<span class="normal">5434</span>
<span class="normal">5435</span>
<span class="normal">5436</span>
<span class="normal">5437</span>
<span class="normal">5438</span>
<span class="normal">5439</span>
<span class="normal">5440</span>
<span class="normal">5441</span>
<span class="normal">5442</span>
<span class="normal">5443</span>
<span class="normal">5444</span>
<span class="normal">5445</span>
<span class="normal">5446</span>
<span class="normal">5447</span>
<span class="normal">5448</span>
<span class="normal">5449</span>
<span class="normal">5450</span>
<span class="normal">5451</span>
<span class="normal">5452</span>
<span class="normal">5453</span>
<span class="normal">5454</span>
<span class="normal">5455</span>
<span class="normal">5456</span>
<span class="normal">5457</span>
<span class="normal">5458</span>
<span class="normal">5459</span>
<span class="normal">5460</span>
<span class="normal">5461</span>
<span class="normal">5462</span>
<span class="normal">5463</span>
<span class="normal">5464</span>
<span class="normal">5465</span>
<span class="normal">5466</span>
<span class="normal">5467</span>
<span class="normal">5468</span>
<span class="normal">5469</span>
<span class="normal">5470</span>
<span class="normal">5471</span>
<span class="normal">5472</span>
<span class="normal">5473</span>
<span class="normal">5474</span>
<span class="normal">5475</span>
<span class="normal">5476</span>
<span class="normal">5477</span>
<span class="normal">5478</span>
<span class="normal">5479</span>
<span class="normal">5480</span>
<span class="normal">5481</span>
<span class="normal">5482</span>
<span class="normal">5483</span>
<span class="normal">5484</span>
<span class="normal">5485</span>
<span class="normal">5486</span>
<span class="normal">5487</span>
<span class="normal">5488</span>
<span class="normal">5489</span>
<span class="normal">5490</span>
<span class="normal">5491</span>
<span class="normal">5492</span>
<span class="normal">5493</span>
<span class="normal">5494</span>
<span class="normal">5495</span>
<span class="normal">5496</span>
<span class="normal">5497</span>
<span class="normal">5498</span>
<span class="normal">5499</span>
<span class="normal">5500</span>
<span class="normal">5501</span>
<span class="normal">5502</span>
<span class="normal">5503</span>
<span class="normal">5504</span>
<span class="normal">5505</span>
<span class="normal">5506</span>
<span class="normal">5507</span>
<span class="normal">5508</span>
<span class="normal">5509</span>
<span class="normal">5510</span>
<span class="normal">5511</span>
<span class="normal">5512</span>
<span class="normal">5513</span>
<span class="normal">5514</span>
<span class="normal">5515</span>
<span class="normal">5516</span>
<span class="normal">5517</span>
<span class="normal">5518</span>
<span class="normal">5519</span>
<span class="normal">5520</span>
<span class="normal">5521</span>
<span class="normal">5522</span>
<span class="normal">5523</span>
<span class="normal">5524</span>
<span class="normal">5525</span>
<span class="normal">5526</span>
<span class="normal">5527</span>
<span class="normal">5528</span>
<span class="normal">5529</span>
<span class="normal">5530</span>
<span class="normal">5531</span>
<span class="normal">5532</span>
<span class="normal">5533</span>
<span class="normal">5534</span>
<span class="normal">5535</span>
<span class="normal">5536</span>
<span class="normal">5537</span>
<span class="normal">5538</span>
<span class="normal">5539</span>
<span class="normal">5540</span>
<span class="normal">5541</span>
<span class="normal">5542</span>
<span class="normal">5543</span>
<span class="normal">5544</span>
<span class="normal">5545</span>
<span class="normal">5546</span>
<span class="normal">5547</span>
<span class="normal">5548</span>
<span class="normal">5549</span>
<span class="normal">5550</span>
<span class="normal">5551</span>
<span class="normal">5552</span>
<span class="normal">5553</span>
<span class="normal">5554</span>
<span class="normal">5555</span>
<span class="normal">5556</span>
<span class="normal">5557</span>
<span class="normal">5558</span>
<span class="normal">5559</span>
<span class="normal">5560</span>
<span class="normal">5561</span>
<span class="normal">5562</span>
<span class="normal">5563</span>
<span class="normal">5564</span>
<span class="normal">5565</span>
<span class="normal">5566</span>
<span class="normal">5567</span>
<span class="normal">5568</span>
<span class="normal">5569</span>
<span class="normal">5570</span>
<span class="normal">5571</span>
<span class="normal">5572</span>
<span class="normal">5573</span>
<span class="normal">5574</span>
<span class="normal">5575</span>
<span class="normal">5576</span>
<span class="normal">5577</span>
<span class="normal">5578</span>
<span class="normal">5579</span>
<span class="normal">5580</span>
<span class="normal">5581</span>
<span class="normal">5582</span>
<span class="normal">5583</span>
<span class="normal">5584</span>
<span class="normal">5585</span>
<span class="normal">5586</span>
<span class="normal">5587</span>
<span class="normal">5588</span>
<span class="normal">5589</span>
<span class="normal">5590</span>
<span class="normal">5591</span>
<span class="normal">5592</span>
<span class="normal">5593</span>
<span class="normal">5594</span>
<span class="normal">5595</span>
<span class="normal">5596</span>
<span class="normal">5597</span>
<span class="normal">5598</span>
<span class="normal">5599</span>
<span class="normal">5600</span>
<span class="normal">5601</span>
<span class="normal">5602</span>
<span class="normal">5603</span>
<span class="normal">5604</span>
<span class="normal">5605</span>
<span class="normal">5606</span>
<span class="normal">5607</span>
<span class="normal">5608</span>
<span class="normal">5609</span>
<span class="normal">5610</span>
<span class="normal">5611</span>
<span class="normal">5612</span>
<span class="normal">5613</span>
<span class="normal">5614</span>
<span class="normal">5615</span>
<span class="normal">5616</span>
<span class="normal">5617</span>
<span class="normal">5618</span>
<span class="normal">5619</span>
<span class="normal">5620</span>
<span class="normal">5621</span>
<span class="normal">5622</span>
<span class="normal">5623</span>
<span class="normal">5624</span>
<span class="normal">5625</span>
<span class="normal">5626</span>
<span class="normal">5627</span>
<span class="normal">5628</span>
<span class="normal">5629</span>
<span class="normal">5630</span>
<span class="normal">5631</span>
<span class="normal">5632</span>
<span class="normal">5633</span>
<span class="normal">5634</span>
<span class="normal">5635</span>
<span class="normal">5636</span>
<span class="normal">5637</span>
<span class="normal">5638</span>
<span class="normal">5639</span>
<span class="normal">5640</span>
<span class="normal">5641</span>
<span class="normal">5642</span>
<span class="normal">5643</span>
<span class="normal">5644</span>
<span class="normal">5645</span>
<span class="normal">5646</span>
<span class="normal">5647</span>
<span class="normal">5648</span>
<span class="normal">5649</span>
<span class="normal">5650</span>
<span class="normal">5651</span>
<span class="normal">5652</span>
<span class="normal">5653</span>
<span class="normal">5654</span>
<span class="normal">5655</span>
<span class="normal">5656</span>
<span class="normal">5657</span>
<span class="normal">5658</span>
<span class="normal">5659</span>
<span class="normal">5660</span>
<span class="normal">5661</span>
<span class="normal">5662</span>
<span class="normal">5663</span>
<span class="normal">5664</span>
<span class="normal">5665</span>
<span class="normal">5666</span>
<span class="normal">5667</span>
<span class="normal">5668</span>
<span class="normal">5669</span>
<span class="normal">5670</span>
<span class="normal">5671</span>
<span class="normal">5672</span>
<span class="normal">5673</span>
<span class="normal">5674</span>
<span class="normal">5675</span>
<span class="normal">5676</span>
<span class="normal">5677</span>
<span class="normal">5678</span>
<span class="normal">5679</span>
<span class="normal">5680</span>
<span class="normal">5681</span>
<span class="normal">5682</span>
<span class="normal">5683</span>
<span class="normal">5684</span>
<span class="normal">5685</span>
<span class="normal">5686</span>
<span class="normal">5687</span>
<span class="normal">5688</span>
<span class="normal">5689</span>
<span class="normal">5690</span>
<span class="normal">5691</span>
<span class="normal">5692</span>
<span class="normal">5693</span>
<span class="normal">5694</span>
<span class="normal">5695</span>
<span class="normal">5696</span>
<span class="normal">5697</span>
<span class="normal">5698</span>
<span class="normal">5699</span>
<span class="normal">5700</span>
<span class="normal">5701</span>
<span class="normal">5702</span>
<span class="normal">5703</span>
<span class="normal">5704</span>
<span class="normal">5705</span>
<span class="normal">5706</span>
<span class="normal">5707</span>
<span class="normal">5708</span>
<span class="normal">5709</span>
<span class="normal">5710</span>
<span class="normal">5711</span>
<span class="normal">5712</span>
<span class="normal">5713</span>
<span class="normal">5714</span>
<span class="normal">5715</span>
<span class="normal">5716</span>
<span class="normal">5717</span>
<span class="normal">5718</span>
<span class="normal">5719</span>
<span class="normal">5720</span>
<span class="normal">5721</span>
<span class="normal">5722</span>
<span class="normal">5723</span>
<span class="normal">5724</span>
<span class="normal">5725</span>
<span class="normal">5726</span>
<span class="normal">5727</span>
<span class="normal">5728</span>
<span class="normal">5729</span>
<span class="normal">5730</span>
<span class="normal">5731</span>
<span class="normal">5732</span>
<span class="normal">5733</span>
<span class="normal">5734</span>
<span class="normal">5735</span>
<span class="normal">5736</span>
<span class="normal">5737</span>
<span class="normal">5738</span>
<span class="normal">5739</span>
<span class="normal">5740</span>
<span class="normal">5741</span>
<span class="normal">5742</span>
<span class="normal">5743</span>
<span class="normal">5744</span>
<span class="normal">5745</span>
<span class="normal">5746</span>
<span class="normal">5747</span>
<span class="normal">5748</span>
<span class="normal">5749</span>
<span class="normal">5750</span>
<span class="normal">5751</span>
<span class="normal">5752</span>
<span class="normal">5753</span>
<span class="normal">5754</span>
<span class="normal">5755</span>
<span class="normal">5756</span>
<span class="normal">5757</span>
<span class="normal">5758</span>
<span class="normal">5759</span>
<span class="normal">5760</span>
<span class="normal">5761</span>
<span class="normal">5762</span>
<span class="normal">5763</span>
<span class="normal">5764</span>
<span class="normal">5765</span>
<span class="normal">5766</span>
<span class="normal">5767</span>
<span class="normal">5768</span>
<span class="normal">5769</span>
<span class="normal">5770</span>
<span class="normal">5771</span>
<span class="normal">5772</span>
<span class="normal">5773</span>
<span class="normal">5774</span>
<span class="normal">5775</span>
<span class="normal">5776</span>
<span class="normal">5777</span>
<span class="normal">5778</span>
<span class="normal">5779</span>
<span class="normal">5780</span>
<span class="normal">5781</span>
<span class="normal">5782</span>
<span class="normal">5783</span>
<span class="normal">5784</span>
<span class="normal">5785</span>
<span class="normal">5786</span>
<span class="normal">5787</span>
<span class="normal">5788</span>
<span class="normal">5789</span>
<span class="normal">5790</span>
<span class="normal">5791</span>
<span class="normal">5792</span>
<span class="normal">5793</span>
<span class="normal">5794</span>
<span class="normal">5795</span>
<span class="normal">5796</span>
<span class="normal">5797</span>
<span class="normal">5798</span>
<span class="normal">5799</span>
<span class="normal">5800</span>
<span class="normal">5801</span>
<span class="normal">5802</span>
<span class="normal">5803</span>
<span class="normal">5804</span>
<span class="normal">5805</span>
<span class="normal">5806</span>
<span class="normal">5807</span>
<span class="normal">5808</span>
<span class="normal">5809</span>
<span class="normal">5810</span>
<span class="normal">5811</span>
<span class="normal">5812</span>
<span class="normal">5813</span>
<span class="normal">5814</span>
<span class="normal">5815</span>
<span class="normal">5816</span>
<span class="normal">5817</span>
<span class="normal">5818</span>
<span class="normal">5819</span>
<span class="normal">5820</span>
<span class="normal">5821</span>
<span class="normal">5822</span>
<span class="normal">5823</span>
<span class="normal">5824</span>
<span class="normal">5825</span>
<span class="normal">5826</span>
<span class="normal">5827</span>
<span class="normal">5828</span>
<span class="normal">5829</span>
<span class="normal">5830</span>
<span class="normal">5831</span>
<span class="normal">5832</span>
<span class="normal">5833</span>
<span class="normal">5834</span>
<span class="normal">5835</span>
<span class="normal">5836</span>
<span class="normal">5837</span>
<span class="normal">5838</span>
<span class="normal">5839</span>
<span class="normal">5840</span>
<span class="normal">5841</span>
<span class="normal">5842</span>
<span class="normal">5843</span>
<span class="normal">5844</span>
<span class="normal">5845</span>
<span class="normal">5846</span>
<span class="normal">5847</span>
<span class="normal">5848</span>
<span class="normal">5849</span>
<span class="normal">5850</span>
<span class="normal">5851</span>
<span class="normal">5852</span>
<span class="normal">5853</span>
<span class="normal">5854</span>
<span class="normal">5855</span>
<span class="normal">5856</span>
<span class="normal">5857</span>
<span class="normal">5858</span>
<span class="normal">5859</span>
<span class="normal">5860</span>
<span class="normal">5861</span>
<span class="normal">5862</span>
<span class="normal">5863</span>
<span class="normal">5864</span>
<span class="normal">5865</span>
<span class="normal">5866</span>
<span class="normal">5867</span>
<span class="normal">5868</span>
<span class="normal">5869</span>
<span class="normal">5870</span>
<span class="normal">5871</span>
<span class="normal">5872</span>
<span class="normal">5873</span>
<span class="normal">5874</span>
<span class="normal">5875</span>
<span class="normal">5876</span>
<span class="normal">5877</span>
<span class="normal">5878</span>
<span class="normal">5879</span>
<span class="normal">5880</span>
<span class="normal">5881</span>
<span class="normal">5882</span>
<span class="normal">5883</span>
<span class="normal">5884</span>
<span class="normal">5885</span>
<span class="normal">5886</span>
<span class="normal">5887</span>
<span class="normal">5888</span>
<span class="normal">5889</span>
<span class="normal">5890</span>
<span class="normal">5891</span>
<span class="normal">5892</span>
<span class="normal">5893</span>
<span class="normal">5894</span>
<span class="normal">5895</span>
<span class="normal">5896</span>
<span class="normal">5897</span>
<span class="normal">5898</span>
<span class="normal">5899</span>
<span class="normal">5900</span>
<span class="normal">5901</span>
<span class="normal">5902</span>
<span class="normal">5903</span>
<span class="normal">5904</span>
<span class="normal">5905</span>
<span class="normal">5906</span>
<span class="normal">5907</span>
<span class="normal">5908</span>
<span class="normal">5909</span>
<span class="normal">5910</span>
<span class="normal">5911</span>
<span class="normal">5912</span>
<span class="normal">5913</span>
<span class="normal">5914</span>
<span class="normal">5915</span>
<span class="normal">5916</span>
<span class="normal">5917</span>
<span class="normal">5918</span>
<span class="normal">5919</span>
<span class="normal">5920</span>
<span class="normal">5921</span>
<span class="normal">5922</span>
<span class="normal">5923</span>
<span class="normal">5924</span>
<span class="normal">5925</span>
<span class="normal">5926</span>
<span class="normal">5927</span>
<span class="normal">5928</span>
<span class="normal">5929</span>
<span class="normal">5930</span>
<span class="normal">5931</span>
<span class="normal">5932</span>
<span class="normal">5933</span>
<span class="normal">5934</span>
<span class="normal">5935</span>
<span class="normal">5936</span>
<span class="normal">5937</span>
<span class="normal">5938</span>
<span class="normal">5939</span>
<span class="normal">5940</span>
<span class="normal">5941</span>
<span class="normal">5942</span>
<span class="normal">5943</span>
<span class="normal">5944</span>
<span class="normal">5945</span>
<span class="normal">5946</span>
<span class="normal">5947</span>
<span class="normal">5948</span>
<span class="normal">5949</span>
<span class="normal">5950</span>
<span class="normal">5951</span>
<span class="normal">5952</span>
<span class="normal">5953</span>
<span class="normal">5954</span>
<span class="normal">5955</span>
<span class="normal">5956</span>
<span class="normal">5957</span>
<span class="normal">5958</span>
<span class="normal">5959</span>
<span class="normal">5960</span>
<span class="normal">5961</span>
<span class="normal">5962</span>
<span class="normal">5963</span>
<span class="normal">5964</span>
<span class="normal">5965</span>
<span class="normal">5966</span>
<span class="normal">5967</span>
<span class="normal">5968</span>
<span class="normal">5969</span>
<span class="normal">5970</span>
<span class="normal">5971</span>
<span class="normal">5972</span>
<span class="normal">5973</span>
<span class="normal">5974</span>
<span class="normal">5975</span>
<span class="normal">5976</span>
<span class="normal">5977</span>
<span class="normal">5978</span>
<span class="normal">5979</span>
<span class="normal">5980</span>
<span class="normal">5981</span>
<span class="normal">5982</span>
<span class="normal">5983</span>
<span class="normal">5984</span>
<span class="normal">5985</span>
<span class="normal">5986</span>
<span class="normal">5987</span>
<span class="normal">5988</span>
<span class="normal">5989</span>
<span class="normal">5990</span>
<span class="normal">5991</span>
<span class="normal">5992</span>
<span class="normal">5993</span>
<span class="normal">5994</span>
<span class="normal">5995</span>
<span class="normal">5996</span>
<span class="normal">5997</span>
<span class="normal">5998</span>
<span class="normal">5999</span>
<span class="normal">6000</span>
<span class="normal">6001</span>
<span class="normal">6002</span>
<span class="normal">6003</span>
<span class="normal">6004</span>
<span class="normal">6005</span>
<span class="normal">6006</span>
<span class="normal">6007</span>
<span class="normal">6008</span>
<span class="normal">6009</span>
<span class="normal">6010</span>
<span class="normal">6011</span>
<span class="normal">6012</span>
<span class="normal">6013</span>
<span class="normal">6014</span>
<span class="normal">6015</span>
<span class="normal">6016</span>
<span class="normal">6017</span>
<span class="normal">6018</span>
<span class="normal">6019</span>
<span class="normal">6020</span>
<span class="normal">6021</span>
<span class="normal">6022</span>
<span class="normal">6023</span>
<span class="normal">6024</span>
<span class="normal">6025</span>
<span class="normal">6026</span>
<span class="normal">6027</span>
<span class="normal">6028</span>
<span class="normal">6029</span>
<span class="normal">6030</span>
<span class="normal">6031</span>
<span class="normal">6032</span>
<span class="normal">6033</span>
<span class="normal">6034</span>
<span class="normal">6035</span>
<span class="normal">6036</span>
<span class="normal">6037</span>
<span class="normal">6038</span>
<span class="normal">6039</span>
<span class="normal">6040</span>
<span class="normal">6041</span>
<span class="normal">6042</span>
<span class="normal">6043</span>
<span class="normal">6044</span>
<span class="normal">6045</span>
<span class="normal">6046</span>
<span class="normal">6047</span>
<span class="normal">6048</span>
<span class="normal">6049</span>
<span class="normal">6050</span>
<span class="normal">6051</span>
<span class="normal">6052</span>
<span class="normal">6053</span>
<span class="normal">6054</span>
<span class="normal">6055</span>
<span class="normal">6056</span>
<span class="normal">6057</span>
<span class="normal">6058</span>
<span class="normal">6059</span>
<span class="normal">6060</span>
<span class="normal">6061</span>
<span class="normal">6062</span>
<span class="normal">6063</span>
<span class="normal">6064</span>
<span class="normal">6065</span>
<span class="normal">6066</span>
<span class="normal">6067</span>
<span class="normal">6068</span>
<span class="normal">6069</span>
<span class="normal">6070</span>
<span class="normal">6071</span>
<span class="normal">6072</span>
<span class="normal">6073</span>
<span class="normal">6074</span>
<span class="normal">6075</span>
<span class="normal">6076</span>
<span class="normal">6077</span>
<span class="normal">6078</span>
<span class="normal">6079</span>
<span class="normal">6080</span>
<span class="normal">6081</span>
<span class="normal">6082</span>
<span class="normal">6083</span>
<span class="normal">6084</span>
<span class="normal">6085</span>
<span class="normal">6086</span>
<span class="normal">6087</span>
<span class="normal">6088</span>
<span class="normal">6089</span>
<span class="normal">6090</span>
<span class="normal">6091</span>
<span class="normal">6092</span>
<span class="normal">6093</span>
<span class="normal">6094</span>
<span class="normal">6095</span>
<span class="normal">6096</span>
<span class="normal">6097</span>
<span class="normal">6098</span>
<span class="normal">6099</span>
<span class="normal">6100</span>
<span class="normal">6101</span>
<span class="normal">6102</span>
<span class="normal">6103</span>
<span class="normal">6104</span>
<span class="normal">6105</span>
<span class="normal">6106</span>
<span class="normal">6107</span>
<span class="normal">6108</span>
<span class="normal">6109</span>
<span class="normal">6110</span>
<span class="normal">6111</span>
<span class="normal">6112</span>
<span class="normal">6113</span>
<span class="normal">6114</span>
<span class="normal">6115</span>
<span class="normal">6116</span>
<span class="normal">6117</span>
<span class="normal">6118</span>
<span class="normal">6119</span>
<span class="normal">6120</span>
<span class="normal">6121</span>
<span class="normal">6122</span>
<span class="normal">6123</span>
<span class="normal">6124</span>
<span class="normal">6125</span>
<span class="normal">6126</span>
<span class="normal">6127</span>
<span class="normal">6128</span>
<span class="normal">6129</span>
<span class="normal">6130</span>
<span class="normal">6131</span>
<span class="normal">6132</span>
<span class="normal">6133</span>
<span class="normal">6134</span>
<span class="normal">6135</span>
<span class="normal">6136</span>
<span class="normal">6137</span>
<span class="normal">6138</span>
<span class="normal">6139</span>
<span class="normal">6140</span>
<span class="normal">6141</span>
<span class="normal">6142</span>
<span class="normal">6143</span>
<span class="normal">6144</span>
<span class="normal">6145</span>
<span class="normal">6146</span>
<span class="normal">6147</span>
<span class="normal">6148</span>
<span class="normal">6149</span>
<span class="normal">6150</span>
<span class="normal">6151</span>
<span class="normal">6152</span>
<span class="normal">6153</span>
<span class="normal">6154</span>
<span class="normal">6155</span>
<span class="normal">6156</span>
<span class="normal">6157</span>
<span class="normal">6158</span>
<span class="normal">6159</span>
<span class="normal">6160</span>
<span class="normal">6161</span>
<span class="normal">6162</span>
<span class="normal">6163</span>
<span class="normal">6164</span>
<span class="normal">6165</span>
<span class="normal">6166</span>
<span class="normal">6167</span>
<span class="normal">6168</span>
<span class="normal">6169</span>
<span class="normal">6170</span>
<span class="normal">6171</span>
<span class="normal">6172</span>
<span class="normal">6173</span>
<span class="normal">6174</span>
<span class="normal">6175</span>
<span class="normal">6176</span>
<span class="normal">6177</span>
<span class="normal">6178</span>
<span class="normal">6179</span>
<span class="normal">6180</span>
<span class="normal">6181</span>
<span class="normal">6182</span>
<span class="normal">6183</span>
<span class="normal">6184</span>
<span class="normal">6185</span>
<span class="normal">6186</span>
<span class="normal">6187</span>
<span class="normal">6188</span>
<span class="normal">6189</span>
<span class="normal">6190</span>
<span class="normal">6191</span>
<span class="normal">6192</span>
<span class="normal">6193</span>
<span class="normal">6194</span>
<span class="normal">6195</span>
<span class="normal">6196</span>
<span class="normal">6197</span>
<span class="normal">6198</span>
<span class="normal">6199</span>
<span class="normal">6200</span>
<span class="normal">6201</span>
<span class="normal">6202</span>
<span class="normal">6203</span>
<span class="normal">6204</span>
<span class="normal">6205</span>
<span class="normal">6206</span>
<span class="normal">6207</span>
<span class="normal">6208</span>
<span class="normal">6209</span>
<span class="normal">6210</span>
<span class="normal">6211</span>
<span class="normal">6212</span>
<span class="normal">6213</span>
<span class="normal">6214</span>
<span class="normal">6215</span>
<span class="normal">6216</span>
<span class="normal">6217</span>
<span class="normal">6218</span>
<span class="normal">6219</span>
<span class="normal">6220</span>
<span class="normal">6221</span>
<span class="normal">6222</span>
<span class="normal">6223</span>
<span class="normal">6224</span>
<span class="normal">6225</span>
<span class="normal">6226</span>
<span class="normal">6227</span>
<span class="normal">6228</span>
<span class="normal">6229</span>
<span class="normal">6230</span>
<span class="normal">6231</span>
<span class="normal">6232</span>
<span class="normal">6233</span>
<span class="normal">6234</span>
<span class="normal">6235</span>
<span class="normal">6236</span>
<span class="normal">6237</span>
<span class="normal">6238</span>
<span class="normal">6239</span>
<span class="normal">6240</span>
<span class="normal">6241</span>
<span class="normal">6242</span>
<span class="normal">6243</span>
<span class="normal">6244</span>
<span class="normal">6245</span>
<span class="normal">6246</span>
<span class="normal">6247</span>
<span class="normal">6248</span>
<span class="normal">6249</span>
<span class="normal">6250</span>
<span class="normal">6251</span>
<span class="normal">6252</span>
<span class="normal">6253</span>
<span class="normal">6254</span>
<span class="normal">6255</span>
<span class="normal">6256</span>
<span class="normal">6257</span>
<span class="normal">6258</span>
<span class="normal">6259</span>
<span class="normal">6260</span>
<span class="normal">6261</span>
<span class="normal">6262</span>
<span class="normal">6263</span>
<span class="normal">6264</span>
<span class="normal">6265</span>
<span class="normal">6266</span>
<span class="normal">6267</span>
<span class="normal">6268</span>
<span class="normal">6269</span>
<span class="normal">6270</span>
<span class="normal">6271</span>
<span class="normal">6272</span>
<span class="normal">6273</span>
<span class="normal">6274</span>
<span class="normal">6275</span>
<span class="normal">6276</span>
<span class="normal">6277</span>
<span class="normal">6278</span>
<span class="normal">6279</span>
<span class="normal">6280</span>
<span class="normal">6281</span>
<span class="normal">6282</span>
<span class="normal">6283</span>
<span class="normal">6284</span>
<span class="normal">6285</span>
<span class="normal">6286</span>
<span class="normal">6287</span>
<span class="normal">6288</span>
<span class="normal">6289</span>
<span class="normal">6290</span>
<span class="normal">6291</span>
<span class="normal">6292</span>
<span class="normal">6293</span>
<span class="normal">6294</span>
<span class="normal">6295</span>
<span class="normal">6296</span>
<span class="normal">6297</span>
<span class="normal">6298</span>
<span class="normal">6299</span>
<span class="normal">6300</span>
<span class="normal">6301</span>
<span class="normal">6302</span>
<span class="normal">6303</span>
<span class="normal">6304</span>
<span class="normal">6305</span>
<span class="normal">6306</span>
<span class="normal">6307</span>
<span class="normal">6308</span>
<span class="normal">6309</span>
<span class="normal">6310</span>
<span class="normal">6311</span>
<span class="normal">6312</span>
<span class="normal">6313</span>
<span class="normal">6314</span>
<span class="normal">6315</span>
<span class="normal">6316</span>
<span class="normal">6317</span>
<span class="normal">6318</span>
<span class="normal">6319</span>
<span class="normal">6320</span>
<span class="normal">6321</span>
<span class="normal">6322</span>
<span class="normal">6323</span>
<span class="normal">6324</span>
<span class="normal">6325</span>
<span class="normal">6326</span>
<span class="normal">6327</span>
<span class="normal">6328</span>
<span class="normal">6329</span>
<span class="normal">6330</span>
<span class="normal">6331</span>
<span class="normal">6332</span>
<span class="normal">6333</span>
<span class="normal">6334</span>
<span class="normal">6335</span>
<span class="normal">6336</span>
<span class="normal">6337</span>
<span class="normal">6338</span>
<span class="normal">6339</span>
<span class="normal">6340</span>
<span class="normal">6341</span>
<span class="normal">6342</span>
<span class="normal">6343</span>
<span class="normal">6344</span>
<span class="normal">6345</span>
<span class="normal">6346</span>
<span class="normal">6347</span>
<span class="normal">6348</span>
<span class="normal">6349</span>
<span class="normal">6350</span>
<span class="normal">6351</span>
<span class="normal">6352</span>
<span class="normal">6353</span>
<span class="normal">6354</span>
<span class="normal">6355</span>
<span class="normal">6356</span>
<span class="normal">6357</span>
<span class="normal">6358</span>
<span class="normal">6359</span>
<span class="normal">6360</span>
<span class="normal">6361</span>
<span class="normal">6362</span>
<span class="normal">6363</span>
<span class="normal">6364</span>
<span class="normal">6365</span>
<span class="normal">6366</span>
<span class="normal">6367</span>
<span class="normal">6368</span>
<span class="normal">6369</span>
<span class="normal">6370</span>
<span class="normal">6371</span>
<span class="normal">6372</span>
<span class="normal">6373</span>
<span class="normal">6374</span>
<span class="normal">6375</span>
<span class="normal">6376</span>
<span class="normal">6377</span>
<span class="normal">6378</span>
<span class="normal">6379</span>
<span class="normal">6380</span>
<span class="normal">6381</span>
<span class="normal">6382</span>
<span class="normal">6383</span>
<span class="normal">6384</span>
<span class="normal">6385</span>
<span class="normal">6386</span>
<span class="normal">6387</span>
<span class="normal">6388</span>
<span class="normal">6389</span>
<span class="normal">6390</span>
<span class="normal">6391</span>
<span class="normal">6392</span>
<span class="normal">6393</span>
<span class="normal">6394</span>
<span class="normal">6395</span>
<span class="normal">6396</span>
<span class="normal">6397</span>
<span class="normal">6398</span>
<span class="normal">6399</span>
<span class="normal">6400</span>
<span class="normal">6401</span>
<span class="normal">6402</span>
<span class="normal">6403</span>
<span class="normal">6404</span>
<span class="normal">6405</span>
<span class="normal">6406</span>
<span class="normal">6407</span>
<span class="normal">6408</span>
<span class="normal">6409</span>
<span class="normal">6410</span>
<span class="normal">6411</span>
<span class="normal">6412</span>
<span class="normal">6413</span>
<span class="normal">6414</span>
<span class="normal">6415</span>
<span class="normal">6416</span>
<span class="normal">6417</span>
<span class="normal">6418</span>
<span class="normal">6419</span>
<span class="normal">6420</span>
<span class="normal">6421</span>
<span class="normal">6422</span>
<span class="normal">6423</span>
<span class="normal">6424</span>
<span class="normal">6425</span>
<span class="normal">6426</span>
<span class="normal">6427</span>
<span class="normal">6428</span>
<span class="normal">6429</span>
<span class="normal">6430</span>
<span class="normal">6431</span>
<span class="normal">6432</span>
<span class="normal">6433</span>
<span class="normal">6434</span>
<span class="normal">6435</span>
<span class="normal">6436</span>
<span class="normal">6437</span>
<span class="normal">6438</span>
<span class="normal">6439</span>
<span class="normal">6440</span>
<span class="normal">6441</span>
<span class="normal">6442</span>
<span class="normal">6443</span>
<span class="normal">6444</span>
<span class="normal">6445</span>
<span class="normal">6446</span>
<span class="normal">6447</span>
<span class="normal">6448</span>
<span class="normal">6449</span>
<span class="normal">6450</span>
<span class="normal">6451</span>
<span class="normal">6452</span>
<span class="normal">6453</span>
<span class="normal">6454</span>
<span class="normal">6455</span>
<span class="normal">6456</span>
<span class="normal">6457</span>
<span class="normal">6458</span>
<span class="normal">6459</span>
<span class="normal">6460</span>
<span class="normal">6461</span>
<span class="normal">6462</span>
<span class="normal">6463</span>
<span class="normal">6464</span>
<span class="normal">6465</span>
<span class="normal">6466</span>
<span class="normal">6467</span>
<span class="normal">6468</span>
<span class="normal">6469</span>
<span class="normal">6470</span>
<span class="normal">6471</span>
<span class="normal">6472</span>
<span class="normal">6473</span>
<span class="normal">6474</span>
<span class="normal">6475</span>
<span class="normal">6476</span>
<span class="normal">6477</span>
<span class="normal">6478</span>
<span class="normal">6479</span>
<span class="normal">6480</span>
<span class="normal">6481</span>
<span class="normal">6482</span>
<span class="normal">6483</span>
<span class="normal">6484</span>
<span class="normal">6485</span>
<span class="normal">6486</span>
<span class="normal">6487</span>
<span class="normal">6488</span>
<span class="normal">6489</span>
<span class="normal">6490</span>
<span class="normal">6491</span>
<span class="normal">6492</span>
<span class="normal">6493</span>
<span class="normal">6494</span>
<span class="normal">6495</span>
<span class="normal">6496</span>
<span class="normal">6497</span>
<span class="normal">6498</span>
<span class="normal">6499</span>
<span class="normal">6500</span>
<span class="normal">6501</span>
<span class="normal">6502</span>
<span class="normal">6503</span>
<span class="normal">6504</span>
<span class="normal">6505</span>
<span class="normal">6506</span>
<span class="normal">6507</span>
<span class="normal">6508</span>
<span class="normal">6509</span>
<span class="normal">6510</span>
<span class="normal">6511</span>
<span class="normal">6512</span>
<span class="normal">6513</span>
<span class="normal">6514</span>
<span class="normal">6515</span>
<span class="normal">6516</span>
<span class="normal">6517</span>
<span class="normal">6518</span>
<span class="normal">6519</span>
<span class="normal">6520</span>
<span class="normal">6521</span>
<span class="normal">6522</span>
<span class="normal">6523</span>
<span class="normal">6524</span>
<span class="normal">6525</span>
<span class="normal">6526</span>
<span class="normal">6527</span>
<span class="normal">6528</span>
<span class="normal">6529</span>
<span class="normal">6530</span>
<span class="normal">6531</span>
<span class="normal">6532</span>
<span class="normal">6533</span>
<span class="normal">6534</span>
<span class="normal">6535</span>
<span class="normal">6536</span>
<span class="normal">6537</span>
<span class="normal">6538</span>
<span class="normal">6539</span>
<span class="normal">6540</span>
<span class="normal">6541</span>
<span class="normal">6542</span>
<span class="normal">6543</span>
<span class="normal">6544</span>
<span class="normal">6545</span>
<span class="normal">6546</span>
<span class="normal">6547</span>
<span class="normal">6548</span>
<span class="normal">6549</span>
<span class="normal">6550</span>
<span class="normal">6551</span>
<span class="normal">6552</span>
<span class="normal">6553</span>
<span class="normal">6554</span>
<span class="normal">6555</span>
<span class="normal">6556</span>
<span class="normal">6557</span>
<span class="normal">6558</span>
<span class="normal">6559</span>
<span class="normal">6560</span>
<span class="normal">6561</span>
<span class="normal">6562</span>
<span class="normal">6563</span>
<span class="normal">6564</span>
<span class="normal">6565</span>
<span class="normal">6566</span>
<span class="normal">6567</span>
<span class="normal">6568</span>
<span class="normal">6569</span>
<span class="normal">6570</span>
<span class="normal">6571</span>
<span class="normal">6572</span>
<span class="normal">6573</span>
<span class="normal">6574</span>
<span class="normal">6575</span>
<span class="normal">6576</span>
<span class="normal">6577</span>
<span class="normal">6578</span>
<span class="normal">6579</span>
<span class="normal">6580</span>
<span class="normal">6581</span>
<span class="normal">6582</span>
<span class="normal">6583</span>
<span class="normal">6584</span>
<span class="normal">6585</span>
<span class="normal">6586</span>
<span class="normal">6587</span>
<span class="normal">6588</span>
<span class="normal">6589</span>
<span class="normal">6590</span>
<span class="normal">6591</span>
<span class="normal">6592</span>
<span class="normal">6593</span>
<span class="normal">6594</span>
<span class="normal">6595</span>
<span class="normal">6596</span>
<span class="normal">6597</span>
<span class="normal">6598</span>
<span class="normal">6599</span>
<span class="normal">6600</span>
<span class="normal">6601</span>
<span class="normal">6602</span>
<span class="normal">6603</span>
<span class="normal">6604</span>
<span class="normal">6605</span>
<span class="normal">6606</span>
<span class="normal">6607</span>
<span class="normal">6608</span>
<span class="normal">6609</span>
<span class="normal">6610</span>
<span class="normal">6611</span>
<span class="normal">6612</span>
<span class="normal">6613</span>
<span class="normal">6614</span>
<span class="normal">6615</span>
<span class="normal">6616</span>
<span class="normal">6617</span>
<span class="normal">6618</span>
<span class="normal">6619</span>
<span class="normal">6620</span>
<span class="normal">6621</span>
<span class="normal">6622</span>
<span class="normal">6623</span>
<span class="normal">6624</span>
<span class="normal">6625</span>
<span class="normal">6626</span>
<span class="normal">6627</span>
<span class="normal">6628</span>
<span class="normal">6629</span>
<span class="normal">6630</span>
<span class="normal">6631</span>
<span class="normal">6632</span>
<span class="normal">6633</span>
<span class="normal">6634</span>
<span class="normal">6635</span>
<span class="normal">6636</span>
<span class="normal">6637</span>
<span class="normal">6638</span>
<span class="normal">6639</span>
<span class="normal">6640</span>
<span class="normal">6641</span>
<span class="normal">6642</span>
<span class="normal">6643</span>
<span class="normal">6644</span>
<span class="normal">6645</span>
<span class="normal">6646</span>
<span class="normal">6647</span>
<span class="normal">6648</span>
<span class="normal">6649</span>
<span class="normal">6650</span>
<span class="normal">6651</span>
<span class="normal">6652</span>
<span class="normal">6653</span>
<span class="normal">6654</span>
<span class="normal">6655</span>
<span class="normal">6656</span>
<span class="normal">6657</span>
<span class="normal">6658</span>
<span class="normal">6659</span>
<span class="normal">6660</span>
<span class="normal">6661</span>
<span class="normal">6662</span>
<span class="normal">6663</span>
<span class="normal">6664</span>
<span class="normal">6665</span>
<span class="normal">6666</span>
<span class="normal">6667</span>
<span class="normal">6668</span>
<span class="normal">6669</span>
<span class="normal">6670</span>
<span class="normal">6671</span>
<span class="normal">6672</span>
<span class="normal">6673</span>
<span class="normal">6674</span>
<span class="normal">6675</span>
<span class="normal">6676</span>
<span class="normal">6677</span>
<span class="normal">6678</span>
<span class="normal">6679</span>
<span class="normal">6680</span>
<span class="normal">6681</span>
<span class="normal">6682</span>
<span class="normal">6683</span>
<span class="normal">6684</span>
<span class="normal">6685</span>
<span class="normal">6686</span>
<span class="normal">6687</span>
<span class="normal">6688</span>
<span class="normal">6689</span>
<span class="normal">6690</span>
<span class="normal">6691</span>
<span class="normal">6692</span>
<span class="normal">6693</span>
<span class="normal">6694</span>
<span class="normal">6695</span>
<span class="normal">6696</span>
<span class="normal">6697</span>
<span class="normal">6698</span>
<span class="normal">6699</span>
<span class="normal">6700</span>
<span class="normal">6701</span>
<span class="normal">6702</span>
<span class="normal">6703</span>
<span class="normal">6704</span>
<span class="normal">6705</span>
<span class="normal">6706</span>
<span class="normal">6707</span>
<span class="normal">6708</span>
<span class="normal">6709</span>
<span class="normal">6710</span>
<span class="normal">6711</span>
<span class="normal">6712</span>
<span class="normal">6713</span>
<span class="normal">6714</span>
<span class="normal">6715</span>
<span class="normal">6716</span>
<span class="normal">6717</span>
<span class="normal">6718</span>
<span class="normal">6719</span>
<span class="normal">6720</span>
<span class="normal">6721</span>
<span class="normal">6722</span>
<span class="normal">6723</span>
<span class="normal">6724</span>
<span class="normal">6725</span>
<span class="normal">6726</span>
<span class="normal">6727</span>
<span class="normal">6728</span>
<span class="normal">6729</span>
<span class="normal">6730</span>
<span class="normal">6731</span>
<span class="normal">6732</span>
<span class="normal">6733</span>
<span class="normal">6734</span>
<span class="normal">6735</span>
<span class="normal">6736</span>
<span class="normal">6737</span>
<span class="normal">6738</span>
<span class="normal">6739</span>
<span class="normal">6740</span>
<span class="normal">6741</span>
<span class="normal">6742</span>
<span class="normal">6743</span>
<span class="normal">6744</span>
<span class="normal">6745</span>
<span class="normal">6746</span>
<span class="normal">6747</span>
<span class="normal">6748</span>
<span class="normal">6749</span>
<span class="normal">6750</span>
<span class="normal">6751</span>
<span class="normal">6752</span>
<span class="normal">6753</span>
<span class="normal">6754</span>
<span class="normal">6755</span>
<span class="normal">6756</span>
<span class="normal">6757</span>
<span class="normal">6758</span>
<span class="normal">6759</span>
<span class="normal">6760</span>
<span class="normal">6761</span>
<span class="normal">6762</span>
<span class="normal">6763</span>
<span class="normal">6764</span>
<span class="normal">6765</span>
<span class="normal">6766</span>
<span class="normal">6767</span>
<span class="normal">6768</span>
<span class="normal">6769</span>
<span class="normal">6770</span>
<span class="normal">6771</span>
<span class="normal">6772</span>
<span class="normal">6773</span>
<span class="normal">6774</span>
<span class="normal">6775</span>
<span class="normal">6776</span>
<span class="normal">6777</span>
<span class="normal">6778</span>
<span class="normal">6779</span>
<span class="normal">6780</span>
<span class="normal">6781</span>
<span class="normal">6782</span>
<span class="normal">6783</span>
<span class="normal">6784</span>
<span class="normal">6785</span>
<span class="normal">6786</span>
<span class="normal">6787</span>
<span class="normal">6788</span>
<span class="normal">6789</span>
<span class="normal">6790</span>
<span class="normal">6791</span>
<span class="normal">6792</span>
<span class="normal">6793</span>
<span class="normal">6794</span>
<span class="normal">6795</span>
<span class="normal">6796</span>
<span class="normal">6797</span>
<span class="normal">6798</span>
<span class="normal">6799</span>
<span class="normal">6800</span>
<span class="normal">6801</span>
<span class="normal">6802</span>
<span class="normal">6803</span>
<span class="normal">6804</span>
<span class="normal">6805</span>
<span class="normal">6806</span>
<span class="normal">6807</span>
<span class="normal">6808</span>
<span class="normal">6809</span>
<span class="normal">6810</span>
<span class="normal">6811</span>
<span class="normal">6812</span>
<span class="normal">6813</span>
<span class="normal">6814</span>
<span class="normal">6815</span>
<span class="normal">6816</span>
<span class="normal">6817</span>
<span class="normal">6818</span>
<span class="normal">6819</span>
<span class="normal">6820</span>
<span class="normal">6821</span>
<span class="normal">6822</span>
<span class="normal">6823</span>
<span class="normal">6824</span>
<span class="normal">6825</span>
<span class="normal">6826</span>
<span class="normal">6827</span>
<span class="normal">6828</span>
<span class="normal">6829</span>
<span class="normal">6830</span>
<span class="normal">6831</span>
<span class="normal">6832</span>
<span class="normal">6833</span>
<span class="normal">6834</span>
<span class="normal">6835</span>
<span class="normal">6836</span>
<span class="normal">6837</span>
<span class="normal">6838</span>
<span class="normal">6839</span>
<span class="normal">6840</span>
<span class="normal">6841</span>
<span class="normal">6842</span>
<span class="normal">6843</span>
<span class="normal">6844</span>
<span class="normal">6845</span>
<span class="normal">6846</span>
<span class="normal">6847</span>
<span class="normal">6848</span>
<span class="normal">6849</span>
<span class="normal">6850</span>
<span class="normal">6851</span>
<span class="normal">6852</span>
<span class="normal">6853</span>
<span class="normal">6854</span>
<span class="normal">6855</span>
<span class="normal">6856</span>
<span class="normal">6857</span>
<span class="normal">6858</span>
<span class="normal">6859</span>
<span class="normal">6860</span>
<span class="normal">6861</span>
<span class="normal">6862</span>
<span class="normal">6863</span>
<span class="normal">6864</span>
<span class="normal">6865</span>
<span class="normal">6866</span>
<span class="normal">6867</span>
<span class="normal">6868</span>
<span class="normal">6869</span>
<span class="normal">6870</span>
<span class="normal">6871</span>
<span class="normal">6872</span>
<span class="normal">6873</span>
<span class="normal">6874</span>
<span class="normal">6875</span>
<span class="normal">6876</span>
<span class="normal">6877</span>
<span class="normal">6878</span>
<span class="normal">6879</span>
<span class="normal">6880</span>
<span class="normal">6881</span>
<span class="normal">6882</span>
<span class="normal">6883</span>
<span class="normal">6884</span>
<span class="normal">6885</span>
<span class="normal">6886</span>
<span class="normal">6887</span>
<span class="normal">6888</span>
<span class="normal">6889</span>
<span class="normal">6890</span>
<span class="normal">6891</span>
<span class="normal">6892</span>
<span class="normal">6893</span>
<span class="normal">6894</span>
<span class="normal">6895</span>
<span class="normal">6896</span>
<span class="normal">6897</span>
<span class="normal">6898</span>
<span class="normal">6899</span>
<span class="normal">6900</span>
<span class="normal">6901</span>
<span class="normal">6902</span>
<span class="normal">6903</span>
<span class="normal">6904</span>
<span class="normal">6905</span>
<span class="normal">6906</span>
<span class="normal">6907</span>
<span class="normal">6908</span>
<span class="normal">6909</span>
<span class="normal">6910</span>
<span class="normal">6911</span>
<span class="normal">6912</span>
<span class="normal">6913</span>
<span class="normal">6914</span>
<span class="normal">6915</span>
<span class="normal">6916</span>
<span class="normal">6917</span>
<span class="normal">6918</span>
<span class="normal">6919</span>
<span class="normal">6920</span>
<span class="normal">6921</span>
<span class="normal">6922</span>
<span class="normal">6923</span>
<span class="normal">6924</span>
<span class="normal">6925</span>
<span class="normal">6926</span>
<span class="normal">6927</span>
<span class="normal">6928</span>
<span class="normal">6929</span>
<span class="normal">6930</span>
<span class="normal">6931</span>
<span class="normal">6932</span>
<span class="normal">6933</span>
<span class="normal">6934</span>
<span class="normal">6935</span>
<span class="normal">6936</span>
<span class="normal">6937</span>
<span class="normal">6938</span>
<span class="normal">6939</span>
<span class="normal">6940</span>
<span class="normal">6941</span>
<span class="normal">6942</span>
<span class="normal">6943</span>
<span class="normal">6944</span>
<span class="normal">6945</span>
<span class="normal">6946</span>
<span class="normal">6947</span>
<span class="normal">6948</span>
<span class="normal">6949</span>
<span class="normal">6950</span>
<span class="normal">6951</span>
<span class="normal">6952</span>
<span class="normal">6953</span>
<span class="normal">6954</span>
<span class="normal">6955</span>
<span class="normal">6956</span>
<span class="normal">6957</span>
<span class="normal">6958</span>
<span class="normal">6959</span>
<span class="normal">6960</span>
<span class="normal">6961</span>
<span class="normal">6962</span>
<span class="normal">6963</span>
<span class="normal">6964</span>
<span class="normal">6965</span>
<span class="normal">6966</span>
<span class="normal">6967</span>
<span class="normal">6968</span>
<span class="normal">6969</span>
<span class="normal">6970</span>
<span class="normal">6971</span>
<span class="normal">6972</span>
<span class="normal">6973</span>
<span class="normal">6974</span>
<span class="normal">6975</span>
<span class="normal">6976</span>
<span class="normal">6977</span>
<span class="normal">6978</span>
<span class="normal">6979</span>
<span class="normal">6980</span>
<span class="normal">6981</span>
<span class="normal">6982</span>
<span class="normal">6983</span>
<span class="normal">6984</span>
<span class="normal">6985</span>
<span class="normal">6986</span>
<span class="normal">6987</span>
<span class="normal">6988</span>
<span class="normal">6989</span>
<span class="normal">6990</span>
<span class="normal">6991</span>
<span class="normal">6992</span>
<span class="normal">6993</span>
<span class="normal">6994</span>
<span class="normal">6995</span>
<span class="normal">6996</span>
<span class="normal">6997</span>
<span class="normal">6998</span>
<span class="normal">6999</span>
<span class="normal">7000</span>
<span class="normal">7001</span>
<span class="normal">7002</span>
<span class="normal">7003</span>
<span class="normal">7004</span>
<span class="normal">7005</span>
<span class="normal">7006</span>
<span class="normal">7007</span>
<span class="normal">7008</span>
<span class="normal">7009</span>
<span class="normal">7010</span>
<span class="normal">7011</span>
<span class="normal">7012</span>
<span class="normal">7013</span>
<span class="normal">7014</span>
<span class="normal">7015</span>
<span class="normal">7016</span>
<span class="normal">7017</span>
<span class="normal">7018</span>
<span class="normal">7019</span>
<span class="normal">7020</span>
<span class="normal">7021</span>
<span class="normal">7022</span>
<span class="normal">7023</span>
<span class="normal">7024</span>
<span class="normal">7025</span>
<span class="normal">7026</span>
<span class="normal">7027</span>
<span class="normal">7028</span>
<span class="normal">7029</span>
<span class="normal">7030</span>
<span class="normal">7031</span>
<span class="normal">7032</span>
<span class="normal">7033</span>
<span class="normal">7034</span>
<span class="normal">7035</span>
<span class="normal">7036</span>
<span class="normal">7037</span>
<span class="normal">7038</span>
<span class="normal">7039</span>
<span class="normal">7040</span>
<span class="normal">7041</span>
<span class="normal">7042</span>
<span class="normal">7043</span>
<span class="normal">7044</span>
<span class="normal">7045</span>
<span class="normal">7046</span>
<span class="normal">7047</span>
<span class="normal">7048</span>
<span class="normal">7049</span>
<span class="normal">7050</span>
<span class="normal">7051</span>
<span class="normal">7052</span>
<span class="normal">7053</span>
<span class="normal">7054</span>
<span class="normal">7055</span>
<span class="normal">7056</span>
<span class="normal">7057</span>
<span class="normal">7058</span>
<span class="normal">7059</span>
<span class="normal">7060</span>
<span class="normal">7061</span>
<span class="normal">7062</span>
<span class="normal">7063</span>
<span class="normal">7064</span>
<span class="normal">7065</span>
<span class="normal">7066</span>
<span class="normal">7067</span>
<span class="normal">7068</span>
<span class="normal">7069</span>
<span class="normal">7070</span>
<span class="normal">7071</span>
<span class="normal">7072</span>
<span class="normal">7073</span>
<span class="normal">7074</span>
<span class="normal">7075</span>
<span class="normal">7076</span>
<span class="normal">7077</span>
<span class="normal">7078</span>
<span class="normal">7079</span>
<span class="normal">7080</span>
<span class="normal">7081</span>
<span class="normal">7082</span>
<span class="normal">7083</span>
<span class="normal">7084</span>
<span class="normal">7085</span>
<span class="normal">7086</span>
<span class="normal">7087</span>
<span class="normal">7088</span>
<span class="normal">7089</span>
<span class="normal">7090</span>
<span class="normal">7091</span>
<span class="normal">7092</span>
<span class="normal">7093</span>
<span class="normal">7094</span>
<span class="normal">7095</span>
<span class="normal">7096</span>
<span class="normal">7097</span>
<span class="normal">7098</span>
<span class="normal">7099</span>
<span class="normal">7100</span>
<span class="normal">7101</span>
<span class="normal">7102</span>
<span class="normal">7103</span>
<span class="normal">7104</span>
<span class="normal">7105</span>
<span class="normal">7106</span>
<span class="normal">7107</span>
<span class="normal">7108</span>
<span class="normal">7109</span>
<span class="normal">7110</span>
<span class="normal">7111</span>
<span class="normal">7112</span>
<span class="normal">7113</span>
<span class="normal">7114</span>
<span class="normal">7115</span>
<span class="normal">7116</span>
<span class="normal">7117</span>
<span class="normal">7118</span>
<span class="normal">7119</span>
<span class="normal">7120</span>
<span class="normal">7121</span>
<span class="normal">7122</span>
<span class="normal">7123</span>
<span class="normal">7124</span>
<span class="normal">7125</span>
<span class="normal">7126</span>
<span class="normal">7127</span>
<span class="normal">7128</span>
<span class="normal">7129</span>
<span class="normal">7130</span>
<span class="normal">7131</span>
<span class="normal">7132</span>
<span class="normal">7133</span>
<span class="normal">7134</span>
<span class="normal">7135</span>
<span class="normal">7136</span>
<span class="normal">7137</span>
<span class="normal">7138</span>
<span class="normal">7139</span>
<span class="normal">7140</span>
<span class="normal">7141</span>
<span class="normal">7142</span>
<span class="normal">7143</span>
<span class="normal">7144</span>
<span class="normal">7145</span>
<span class="normal">7146</span>
<span class="normal">7147</span>
<span class="normal">7148</span>
<span class="normal">7149</span>
<span class="normal">7150</span>
<span class="normal">7151</span>
<span class="normal">7152</span>
<span class="normal">7153</span>
<span class="normal">7154</span>
<span class="normal">7155</span>
<span class="normal">7156</span>
<span class="normal">7157</span>
<span class="normal">7158</span>
<span class="normal">7159</span>
<span class="normal">7160</span>
<span class="normal">7161</span>
<span class="normal">7162</span>
<span class="normal">7163</span>
<span class="normal">7164</span>
<span class="normal">7165</span>
<span class="normal">7166</span>
<span class="normal">7167</span>
<span class="normal">7168</span>
<span class="normal">7169</span>
<span class="normal">7170</span>
<span class="normal">7171</span>
<span class="normal">7172</span>
<span class="normal">7173</span>
<span class="normal">7174</span>
<span class="normal">7175</span>
<span class="normal">7176</span>
<span class="normal">7177</span>
<span class="normal">7178</span>
<span class="normal">7179</span>
<span class="normal">7180</span>
<span class="normal">7181</span>
<span class="normal">7182</span>
<span class="normal">7183</span>
<span class="normal">7184</span>
<span class="normal">7185</span>
<span class="normal">7186</span>
<span class="normal">7187</span>
<span class="normal">7188</span>
<span class="normal">7189</span>
<span class="normal">7190</span>
<span class="normal">7191</span>
<span class="normal">7192</span>
<span class="normal">7193</span>
<span class="normal">7194</span>
<span class="normal">7195</span>
<span class="normal">7196</span>
<span class="normal">7197</span>
<span class="normal">7198</span>
<span class="normal">7199</span>
<span class="normal">7200</span>
<span class="normal">7201</span>
<span class="normal">7202</span>
<span class="normal">7203</span>
<span class="normal">7204</span>
<span class="normal">7205</span>
<span class="normal">7206</span>
<span class="normal">7207</span>
<span class="normal">7208</span>
<span class="normal">7209</span>
<span class="normal">7210</span>
<span class="normal">7211</span>
<span class="normal">7212</span>
<span class="normal">7213</span>
<span class="normal">7214</span>
<span class="normal">7215</span>
<span class="normal">7216</span>
<span class="normal">7217</span>
<span class="normal">7218</span>
<span class="normal">7219</span>
<span class="normal">7220</span>
<span class="normal">7221</span>
<span class="normal">7222</span>
<span class="normal">7223</span>
<span class="normal">7224</span>
<span class="normal">7225</span>
<span class="normal">7226</span>
<span class="normal">7227</span>
<span class="normal">7228</span>
<span class="normal">7229</span>
<span class="normal">7230</span>
<span class="normal">7231</span>
<span class="normal">7232</span>
<span class="normal">7233</span>
<span class="normal">7234</span>
<span class="normal">7235</span>
<span class="normal">7236</span>
<span class="normal">7237</span>
<span class="normal">7238</span>
<span class="normal">7239</span>
<span class="normal">7240</span>
<span class="normal">7241</span>
<span class="normal">7242</span>
<span class="normal">7243</span>
<span class="normal">7244</span>
<span class="normal">7245</span>
<span class="normal">7246</span>
<span class="normal">7247</span>
<span class="normal">7248</span>
<span class="normal">7249</span>
<span class="normal">7250</span>
<span class="normal">7251</span>
<span class="normal">7252</span>
<span class="normal">7253</span>
<span class="normal">7254</span>
<span class="normal">7255</span>
<span class="normal">7256</span>
<span class="normal">7257</span>
<span class="normal">7258</span>
<span class="normal">7259</span>
<span class="normal">7260</span>
<span class="normal">7261</span>
<span class="normal">7262</span>
<span class="normal">7263</span>
<span class="normal">7264</span>
<span class="normal">7265</span>
<span class="normal">7266</span>
<span class="normal">7267</span>
<span class="normal">7268</span>
<span class="normal">7269</span>
<span class="normal">7270</span>
<span class="normal">7271</span>
<span class="normal">7272</span>
<span class="normal">7273</span>
<span class="normal">7274</span>
<span class="normal">7275</span>
<span class="normal">7276</span>
<span class="normal">7277</span>
<span class="normal">7278</span>
<span class="normal">7279</span>
<span class="normal">7280</span>
<span class="normal">7281</span>
<span class="normal">7282</span>
<span class="normal">7283</span>
<span class="normal">7284</span>
<span class="normal">7285</span>
<span class="normal">7286</span>
<span class="normal">7287</span>
<span class="normal">7288</span>
<span class="normal">7289</span>
<span class="normal">7290</span>
<span class="normal">7291</span>
<span class="normal">7292</span>
<span class="normal">7293</span>
<span class="normal">7294</span>
<span class="normal">7295</span>
<span class="normal">7296</span>
<span class="normal">7297</span>
<span class="normal">7298</span>
<span class="normal">7299</span>
<span class="normal">7300</span>
<span class="normal">7301</span>
<span class="normal">7302</span>
<span class="normal">7303</span>
<span class="normal">7304</span>
<span class="normal">7305</span>
<span class="normal">7306</span>
<span class="normal">7307</span>
<span class="normal">7308</span>
<span class="normal">7309</span>
<span class="normal">7310</span>
<span class="normal">7311</span>
<span class="normal">7312</span>
<span class="normal">7313</span>
<span class="normal">7314</span>
<span class="normal">7315</span>
<span class="normal">7316</span>
<span class="normal">7317</span>
<span class="normal">7318</span>
<span class="normal">7319</span>
<span class="normal">7320</span>
<span class="normal">7321</span>
<span class="normal">7322</span>
<span class="normal">7323</span>
<span class="normal">7324</span>
<span class="normal">7325</span>
<span class="normal">7326</span>
<span class="normal">7327</span>
<span class="normal">7328</span>
<span class="normal">7329</span>
<span class="normal">7330</span>
<span class="normal">7331</span>
<span class="normal">7332</span>
<span class="normal">7333</span>
<span class="normal">7334</span>
<span class="normal">7335</span>
<span class="normal">7336</span>
<span class="normal">7337</span>
<span class="normal">7338</span>
<span class="normal">7339</span>
<span class="normal">7340</span>
<span class="normal">7341</span>
<span class="normal">7342</span>
<span class="normal">7343</span>
<span class="normal">7344</span>
<span class="normal">7345</span>
<span class="normal">7346</span>
<span class="normal">7347</span>
<span class="normal">7348</span>
<span class="normal">7349</span>
<span class="normal">7350</span>
<span class="normal">7351</span>
<span class="normal">7352</span>
<span class="normal">7353</span>
<span class="normal">7354</span>
<span class="normal">7355</span>
<span class="normal">7356</span>
<span class="normal">7357</span>
<span class="normal">7358</span>
<span class="normal">7359</span>
<span class="normal">7360</span>
<span class="normal">7361</span>
<span class="normal">7362</span>
<span class="normal">7363</span>
<span class="normal">7364</span>
<span class="normal">7365</span>
<span class="normal">7366</span>
<span class="normal">7367</span>
<span class="normal">7368</span>
<span class="normal">7369</span>
<span class="normal">7370</span>
<span class="normal">7371</span>
<span class="normal">7372</span>
<span class="normal">7373</span>
<span class="normal">7374</span>
<span class="normal">7375</span>
<span class="normal">7376</span>
<span class="normal">7377</span>
<span class="normal">7378</span>
<span class="normal">7379</span>
<span class="normal">7380</span>
<span class="normal">7381</span>
<span class="normal">7382</span>
<span class="normal">7383</span>
<span class="normal">7384</span>
<span class="normal">7385</span>
<span class="normal">7386</span>
<span class="normal">7387</span>
<span class="normal">7388</span>
<span class="normal">7389</span>
<span class="normal">7390</span>
<span class="normal">7391</span>
<span class="normal">7392</span>
<span class="normal">7393</span>
<span class="normal">7394</span>
<span class="normal">7395</span>
<span class="normal">7396</span>
<span class="normal">7397</span>
<span class="normal">7398</span>
<span class="normal">7399</span>
<span class="normal">7400</span>
<span class="normal">7401</span>
<span class="normal">7402</span>
<span class="normal">7403</span>
<span class="normal">7404</span>
<span class="normal">7405</span>
<span class="normal">7406</span>
<span class="normal">7407</span>
<span class="normal">7408</span>
<span class="normal">7409</span>
<span class="normal">7410</span>
<span class="normal">7411</span>
<span class="normal">7412</span>
<span class="normal">7413</span>
<span class="normal">7414</span>
<span class="normal">7415</span>
<span class="normal">7416</span>
<span class="normal">7417</span>
<span class="normal">7418</span>
<span class="normal">7419</span>
<span class="normal">7420</span>
<span class="normal">7421</span>
<span class="normal">7422</span>
<span class="normal">7423</span>
<span class="normal">7424</span>
<span class="normal">7425</span>
<span class="normal">7426</span>
<span class="normal">7427</span>
<span class="normal">7428</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">SpotOptim</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SPOT optimizer compatible with scipy.optimize interface.</span>

<span class="sd">    Args:</span>
<span class="sd">        fun (callable): Objective function to minimize. Should accept array of shape (n_samples, n_features).</span>
<span class="sd">        bounds (list of tuple): Bounds for each dimension as [(low, high), ...].</span>
<span class="sd">        max_iter (int, optional): Maximum number of total function evaluations (including initial design).</span>
<span class="sd">            For example, max_iter=30 with n_initial=10 will perform 10 initial evaluations plus</span>
<span class="sd">            20 sequential optimization iterations. Defaults to 20.</span>
<span class="sd">        n_initial (int, optional): Number of initial design points. Defaults to 10.</span>
<span class="sd">        surrogate (object, optional): Surrogate model with scikit-learn interface (fit/predict methods).</span>
<span class="sd">            If None, uses a Gaussian Process Regressor with Matern kernel. Default configuration::</span>

<span class="sd">                from sklearn.gaussian_process import GaussianProcessRegressor</span>
<span class="sd">                from sklearn.gaussian_process.kernels import Matern, ConstantKernel</span>

<span class="sd">                kernel = ConstantKernel(1.0, (1e-2, 1e12)) * Matern(length_scale=1.0, length_scale_bounds=(1e-4, 1e2), nu=2.5)</span>
<span class="sd">                surrogate = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=100)</span>
<span class="sd">                surrogate = GaussianProcessRegressor(</span>
<span class="sd">                    kernel=kernel,</span>
<span class="sd">                    n_restarts_optimizer=10,</span>
<span class="sd">                    normalize_y=True,</span>
<span class="sd">                    random_state=self.seed,</span>
<span class="sd">                )</span>

<span class="sd">            Alternative surrogates can be provided, including SpotOptim&#39;s Kriging model,</span>
<span class="sd">            Random Forests, or any scikit-learn compatible regressor. See Examples section.</span>
<span class="sd">            Defaults to None (uses default Gaussian Process configuration).</span>
<span class="sd">        acquisition (str, optional): Acquisition function (&#39;ei&#39;, &#39;y&#39;, &#39;pi&#39;). Defaults to &#39;y&#39;.</span>
<span class="sd">        var_type (list of str, optional): Variable types for each dimension. Supported types:</span>
<span class="sd">            - &#39;float&#39;: Python floats, continuous optimization (no rounding)</span>
<span class="sd">            - &#39;int&#39;: Python int, float values will be rounded to integers</span>
<span class="sd">            - &#39;factor&#39;: Unordered categorical data, internally mapped to int values</span>
<span class="sd">              (e.g., &quot;red&quot;-&gt;0, &quot;green&quot;-&gt;1, etc.)</span>
<span class="sd">            Defaults to None (which sets all dimensions to &#39;float&#39;).</span>
<span class="sd">        var_name (list of str, optional): Variable names for each dimension.</span>
<span class="sd">            If None, uses default names [&#39;x0&#39;, &#39;x1&#39;, &#39;x2&#39;, ...]. Defaults to None.</span>
<span class="sd">        tolerance_x (float, optional): Minimum distance between points. Defaults to np.sqrt(np.spacing(1))</span>
<span class="sd">        var_trans (list of str, optional): Variable transformations for each dimension. Supported:</span>
<span class="sd">            - &#39;log&#39;: Logarithmic transformation, e.g. &quot;log10&quot; for base-10 log</span>
<span class="sd">            - &#39;sqrt&#39;: Square root transformation, &quot;sqrt&quot; for square root</span>
<span class="sd">            - None or &#39;id&#39; or &#39;None&#39;: No transformation</span>
<span class="sd">            Defaults to None (no transformations).</span>
<span class="sd">        max_time (float, optional): Maximum runtime in minutes. If np.inf (default), no time limit.</span>
<span class="sd">            The optimization terminates when either max_iter evaluations are reached OR max_time</span>
<span class="sd">            minutes have elapsed, whichever comes first. Defaults to np.inf.</span>
<span class="sd">        repeats_initial (int, optional): Number of times to evaluate each initial design point.</span>
<span class="sd">            Useful for noisy objective functions. If &gt; 1, noise handling is activated and</span>
<span class="sd">            statistics (mean, variance) are tracked. Defaults to 1.</span>
<span class="sd">        repeats_surrogate (int, optional): Number of times to evaluate each surrogate-suggested point.</span>
<span class="sd">            Useful for noisy objective functions. If &gt; 1, noise handling is activated and</span>
<span class="sd">            statistics (mean, variance) are tracked. Defaults to 1.</span>
<span class="sd">        ocba_delta (int, optional): Number of additional evaluations to allocate using Optimal Computing</span>
<span class="sd">            Budget Allocation (OCBA) when noise handling is active. OCBA determines which existing</span>
<span class="sd">            design points should be re-evaluated to best distinguish between alternatives. Only used</span>
<span class="sd">            when noise=True (repeats &gt; 1) and ocba_delta &gt; 0. Requires at least 3 design points with</span>
<span class="sd">            variance information. Defaults to 0 (no OCBA).</span>
<span class="sd">        tensorboard_log (bool, optional): Enable TensorBoard logging. If True, optimization metrics</span>
<span class="sd">            and hyperparameters are logged to TensorBoard. View logs by running:</span>
<span class="sd">            `tensorboard --logdir=&lt;tensorboard_path&gt;` in a separate terminal. Defaults to False.</span>
<span class="sd">        tensorboard_path (str, optional): Path for TensorBoard log files. If None and tensorboard_log</span>
<span class="sd">            is True, creates a default path: runs/spotoptim_YYYYMMDD_HHMMSS. Defaults to None.</span>
<span class="sd">        tensorboard_clean (bool, optional): If True, removes all old TensorBoard log directories from</span>
<span class="sd">            the &#39;runs&#39; folder before starting optimization. Use with caution as this permanently</span>
<span class="sd">            deletes all subdirectories in &#39;runs&#39;. Defaults to False.</span>
<span class="sd">        fun_mo2so (callable, optional): Function to convert multi-objective values to single-objective.</span>
<span class="sd">            Takes an array of shape (n_samples, n_objectives) and returns array of shape (n_samples,).</span>
<span class="sd">            If None and objective function returns multi-objective values, uses first objective.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        seed (int, optional): Random seed for reproducibility. Defaults to None.</span>
<span class="sd">        verbose (bool, optional): Print progress information. Defaults to False.</span>
<span class="sd">        warnings_filter (str, optional): Filter for warnings. One of &quot;error&quot;, &quot;ignore&quot;, &quot;always&quot;, &quot;all&quot;,</span>
<span class="sd">            &quot;default&quot;, &quot;module&quot;, or &quot;once&quot;. Defaults to &quot;ignore&quot;.</span>
<span class="sd">        n_infill_points (int, optional): Number of infill points to suggest at each iteration.</span>
<span class="sd">            Defaults to 1. If &gt; 1, multiple distinct points are proposed using the optimizer</span>
<span class="sd">            and fallback strategies.</span>
<span class="sd">        max_surrogate_points (int, optional): Maximum number of points to use for surrogate model fitting.</span>
<span class="sd">            If None, all points are used. If the number of evaluated points exceeds this limit,</span>
<span class="sd">            a subset is selected using the selection method. Defaults to None.</span>
<span class="sd">        selection_method (str, optional): Method for selecting points when max_surrogate_points is exceeded.</span>
<span class="sd">            Options: &#39;distant&#39; (Select points that are distant from each other via K-means clustering) or</span>
<span class="sd">            &#39;best&#39; (Select all points from the cluster with the best mean objective value).</span>
<span class="sd">            Defaults to &#39;distant&#39;.</span>
<span class="sd">        acquisition_failure_strategy (str, optional): Strategy for handling acquisition function failures.</span>
<span class="sd">            Options: &#39;random&#39; (space-filling design via Latin Hypercube Sampling)</span>
<span class="sd">            Defaults to &#39;random&#39;.</span>
<span class="sd">        penalty (bool, optional): Whether to use penalty for handling NaN/inf values in objective function evaluations.</span>
<span class="sd">            Defaults to False.</span>
<span class="sd">        penalty_val (float, optional): Penalty value to replace NaN/inf values in objective function evaluations.</span>
<span class="sd">            When the objective function returns NaN or inf, these values are replaced with penalty plus</span>
<span class="sd">            a small random noise (sampled from N(0, 0.1)) to avoid identical penalty values.</span>
<span class="sd">            This allows optimization to continue despite occasional function evaluation failures.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        acquisition_fun_return_size (int, optional): Number of top candidates to return from acquisition function optimization.</span>
<span class="sd">            Defaults to 3.</span>
<span class="sd">        acquisition_optimizer (str or callable, optional): Optimizer to use for maximizing acquisition function.</span>
<span class="sd">            Can be &quot;differential_evolution&quot; (default) or any method name supported by scipy.optimize.minimize</span>
<span class="sd">            (e.g., &quot;Nelder-Mead&quot;, &quot;L-BFGS-B&quot;). Can also be a callable with signature compatible with</span>
<span class="sd">            scipy.optimize.minimize (fun, x0, bounds, ...). A specific version is &quot;de_tricands&quot;, which combines DE with Tricands.</span>
<span class="sd">            It can be parameterized with &quot;prob_de_tricands&quot; (probability of using DE).</span>
<span class="sd">            Defaults to &quot;differential_evolution&quot;.</span>
<span class="sd">        acquisition_optimizer_kwargs (dict, optional): Kwargs passed to the acquisition function optimizer</span>
<span class="sd">            and GPR surrogate optimizer. Defaults to {&#39;maxiter&#39;: 10000, &#39;gtol&#39;: 1e-9}.</span>
<span class="sd">        restart_after_n (int, optional): Number of consecutive iterations with zero success rate</span>
<span class="sd">            before triggering a restart. Defaults to 100.</span>
<span class="sd">        restart_inject_best (bool, optional): Whether to inject the best solution found so far</span>
<span class="sd">            as a starting point for the next restart. Defaults to True.</span>
<span class="sd">        x0 (array-like, optional): Starting point for optimization, shape (n_features,).</span>
<span class="sd">            If provided, this point will be evaluated first and included in the initial design.</span>
<span class="sd">            The point should be within the bounds and will be validated before use.</span>
<span class="sd">            Defaults to None (no starting point, uses only LHS design).</span>
<span class="sd">        de_x0_prob (float, optional): Probability of using the best point as starting point for differential evolution.</span>
<span class="sd">            Defaults to 0.1.</span>
<span class="sd">        tricands_fringe (bool, optional): Whether to use the fringe of the design space for the initial design.</span>
<span class="sd">            Defaults to False.</span>
<span class="sd">        prob_de_tricands (float, optional): Probability of using differential evolution as an optimizer</span>
<span class="sd">            on the surrogate model. 1 - prob_de_tricands is the probability of using tricands. Defaults to 0.8.</span>
<span class="sd">        window_size (int, optional): Window size for success rate calculation.</span>
<span class="sd">        min_tol_metric (str, optional): Distance metric used when checking `tolerance_x` for</span>
<span class="sd">            duplicate detection. Default is &quot;chebyshev&quot;. Supports all metrics from</span>
<span class="sd">            scipy.spatial.distance.cdist, including:</span>
<span class="sd">            - &quot;chebyshev&quot;: L-infinity distance (hypercube). Default. Matches previous behavior.</span>
<span class="sd">            - &quot;euclidean&quot;: L2 distance (hypersphere).</span>
<span class="sd">            - &quot;minkowski&quot;: Lp distance (default p=2).</span>
<span class="sd">            - &quot;cityblock&quot;: Manhattan/L1 distance.</span>
<span class="sd">            - &quot;cosine&quot;: Cosine distance.</span>
<span class="sd">            - &quot;correlation&quot;: Correlation distance.</span>
<span class="sd">            - &quot;canberra&quot;, &quot;braycurtis&quot;, &quot;sqeuclidean&quot;, etc.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        X_ (ndarray): All evaluated points, shape (n_samples, n_features).</span>
<span class="sd">        y_ (ndarray): Function values at X_, shape (n_samples,). For multi-objective problems,</span>
<span class="sd">            these are the converted single-objective values.</span>
<span class="sd">        y_mo (ndarray or None): Multi-objective function values, shape (n_samples, n_objectives).</span>
<span class="sd">            None for single-objective problems.</span>
<span class="sd">        best_x_ (ndarray): Best point found, shape (n_features,).</span>
<span class="sd">        best_y_ (float): Best function value found.</span>
<span class="sd">        n_iter_ (int): Number of iterations performed. This is not the same as counter. Provided for compatibility with scipy.optimize routines.</span>
<span class="sd">        counter (int): Total number of function evaluations.</span>
<span class="sd">        success_rate (float): Rolling success rate over the last window_size evaluations.</span>
<span class="sd">            A success is counted when a new evaluation improves upon the best value found so far.</span>
<span class="sd">        warnings_filter (str): Filter for warnings during optimization.</span>
<span class="sd">        max_surrogate_points (int or None): Maximum number of points for surrogate fitting.</span>
<span class="sd">        selection_method (str): Point selection method.</span>
<span class="sd">        acquisition_failure_strategy (str): Strategy for handling acquisition failures (&#39;random&#39;).</span>
<span class="sd">        noise (bool): True if noise handling is active (repeats &gt; 1).</span>
<span class="sd">        mean_X (ndarray or None): Aggregated unique design points (if noise=True).</span>
<span class="sd">        mean_y (ndarray or None): Mean y values per design point (if noise=True).</span>
<span class="sd">        var_y (ndarray or None): Variance of y values per design point (if noise=True).</span>
<span class="sd">        min_mean_X (ndarray or None): X value of best mean y (if noise=True).</span>
<span class="sd">        min_mean_y (float or None): Best mean y value (if noise=True).</span>
<span class="sd">        min_var_y (float or None): Variance of best mean y (if noise=True).</span>
<span class="sd">        de_x0_prob (float): Probability of using the best point as starting point for differential evolution.</span>
<span class="sd">        tricands_fringe (bool): Whether to use the fringe of the design space for the initial design.</span>
<span class="sd">        prob_de_tricands (float): Probability of using differential evolution as an optimizer on the surrogate model.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; def objective(X):</span>
<span class="sd">        ...     return np.sum(X**2, axis=1)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Example 1: Basic usage (deterministic function)</span>
<span class="sd">        &gt;&gt;&gt; bounds = [(-5, 5), (-5, 5)]</span>
<span class="sd">        &gt;&gt;&gt; optimizer = SpotOptim(fun=objective, bounds=bounds, max_iter=10, n_initial=5, verbose=True)</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer.optimize()</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best x:&quot;, result.x)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best f(x):&quot;, result.fun)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 2: With custom variable names</span>
<span class="sd">        &gt;&gt;&gt; optimizer = SpotOptim(</span>
<span class="sd">        ...     fun=objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     var_name=[&quot;param1&quot;, &quot;param2&quot;],</span>
<span class="sd">        ...     max_iter=10,</span>
<span class="sd">        ...     n_initial=5</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer.optimize()</span>
<span class="sd">        &gt;&gt;&gt; optimizer.plot_surrogate()  # Uses custom names in plot labels</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 3: Noisy function with repeated evaluations</span>
<span class="sd">        &gt;&gt;&gt; def noisy_objective(X):</span>
<span class="sd">        ...     import numpy as np</span>
<span class="sd">        ...     base = np.sum(X**2, axis=1)</span>
<span class="sd">        ...     noise = np.random.normal(0, 0.1, size=base.shape)</span>
<span class="sd">        ...     return base + noise</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; optimizer = SpotOptim(</span>
<span class="sd">        ...     fun=noisy_objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     repeats_initial=3,      # Evaluate each initial point 3 times</span>
<span class="sd">        ...     repeats_surrogate=2,    # Evaluate each new point 2 times</span>
<span class="sd">        ...     seed=42,                # For reproducibility</span>
<span class="sd">        ...     verbose=True</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # Access noise statistics</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Unique design points:&quot;, optimizer.mean_X.shape[0])</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best mean value:&quot;, optimizer.min_mean_y)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Variance at best point:&quot;, optimizer.min_var_y)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 4: Noisy function with OCBA (Optimal Computing Budget Allocation)</span>
<span class="sd">        &gt;&gt;&gt; optimizer_ocba = SpotOptim(</span>
<span class="sd">        ...     fun=noisy_objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     max_iter=50,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     repeats_initial=2,      # Initial repeats</span>
<span class="sd">        ...     repeats_surrogate=1,    # Surrogate repeats</span>
<span class="sd">        ...     ocba_delta=3,           # Allocate 3 additional evaluations per iteration</span>
<span class="sd">        ...     seed=42,</span>
<span class="sd">        ...     verbose=True</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer_ocba.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # OCBA intelligently re-evaluates promising points to reduce uncertainty</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Total evaluations:&quot;, result.nfev)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Unique design points:&quot;, optimizer_ocba.mean_X.shape[0])</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best mean value:&quot;, optimizer.min_mean_y)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Variance at best point:&quot;, optimizer.min_var_y)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 5: With TensorBoard logging</span>
<span class="sd">        &gt;&gt;&gt; optimizer_tb = SpotOptim(</span>
<span class="sd">        ...     fun=objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     tensorboard_log=True,   # Enable TensorBoard</span>
<span class="sd">        ...     tensorboard_path=&quot;runs/my_optimization&quot;,  # Optional custom path</span>
<span class="sd">        ...     verbose=True</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer_tb.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # View logs in browser: tensorboard --logdir=runs/my_optimization</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Logs saved to:&quot;, optimizer_tb.tensorboard_path)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 6: Using SpotOptim&#39;s Kriging surrogate</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim.surrogate import Kriging</span>
<span class="sd">        &gt;&gt;&gt; kriging_model = Kriging(</span>
<span class="sd">        ...     noise=1e-10,           # Regularization parameter</span>
<span class="sd">        ...     kernel=&#39;gauss&#39;,         # Gaussian/RBF kernel</span>
<span class="sd">        ...     min_theta=-3.0,         # Min log10(theta) bound</span>
<span class="sd">        ...     max_theta=2.0,          # Max log10(theta) bound</span>
<span class="sd">        ...     seed=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; optimizer_kriging = SpotOptim(</span>
<span class="sd">        ...     fun=objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     surrogate=kriging_model,</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     seed=42,</span>
<span class="sd">        ...     verbose=True</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer_kriging.optimize()</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best solution found:&quot;, result.x)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best value:&quot;, result.fun)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 7: Using sklearn Gaussian Process with custom kernel</span>
<span class="sd">        &gt;&gt;&gt; from sklearn.gaussian_process import GaussianProcessRegressor</span>
<span class="sd">        &gt;&gt;&gt; from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel</span>
<span class="sd">        &gt;&gt;&gt; # Custom kernel: constant * RBF + white noise</span>
<span class="sd">        &gt;&gt;&gt; custom_kernel = ConstantKernel(1.0, (1e-2, 1e2)) * RBF(</span>
<span class="sd">        ...     length_scale=1.0, length_scale_bounds=(1e-1, 10.0)</span>
<span class="sd">        ... ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1))</span>
<span class="sd">        &gt;&gt;&gt; gp_custom = GaussianProcessRegressor(</span>
<span class="sd">        ...     kernel=custom_kernel,</span>
<span class="sd">        ...     n_restarts_optimizer=15,</span>
<span class="sd">        ...     normalize_y=True,</span>
<span class="sd">        ...     random_state=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; optimizer_custom_gp = SpotOptim(</span>
<span class="sd">        ...     fun=objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     surrogate=gp_custom,</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     seed=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer_custom_gp.optimize()</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 8: Using Random Forest as surrogate</span>
<span class="sd">        &gt;&gt;&gt; from sklearn.ensemble import RandomForestRegressor</span>
<span class="sd">        &gt;&gt;&gt; rf_model = RandomForestRegressor(</span>
<span class="sd">        ...     n_estimators=100,</span>
<span class="sd">        ...     max_depth=10,</span>
<span class="sd">        ...     random_state=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; optimizer_rf = SpotOptim(</span>
<span class="sd">        ...     fun=objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     surrogate=rf_model,</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     seed=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer_rf.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # Note: Random Forests don&#39;t provide uncertainty estimates,</span>
<span class="sd">        &gt;&gt;&gt; # so Expected Improvement (EI) may be less effective.</span>
<span class="sd">        &gt;&gt;&gt; # Consider using acquisition=&#39;y&#39; for pure exploitation.</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 9: Comparing different kernels for Gaussian Process</span>
<span class="sd">        &gt;&gt;&gt; from sklearn.gaussian_process.kernels import Matern, RationalQuadratic</span>
<span class="sd">        &gt;&gt;&gt; # Matern kernel with nu=1.5 (once differentiable)</span>
<span class="sd">        &gt;&gt;&gt; kernel_matern15 = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=1.5)</span>
<span class="sd">        &gt;&gt;&gt; gp_matern15 = GaussianProcessRegressor(kernel=kernel_matern15, normalize_y=True)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Matern kernel with nu=2.5 (twice differentiable, DEFAULT)</span>
<span class="sd">        &gt;&gt;&gt; kernel_matern25 = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5)</span>
<span class="sd">        &gt;&gt;&gt; gp_matern25 = GaussianProcessRegressor(kernel=kernel_matern25, normalize_y=True)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # RBF kernel (infinitely differentiable, smooth)</span>
<span class="sd">        &gt;&gt;&gt; kernel_rbf = ConstantKernel(1.0) * RBF(length_scale=1.0)</span>
<span class="sd">        &gt;&gt;&gt; gp_rbf = GaussianProcessRegressor(kernel=kernel_rbf, normalize_y=True)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Rational Quadratic kernel (mixture of RBF kernels)</span>
<span class="sd">        &gt;&gt;&gt; kernel_rq = ConstantKernel(1.0) * RationalQuadratic(length_scale=1.0, alpha=1.0)</span>
<span class="sd">        &gt;&gt;&gt; gp_rq = GaussianProcessRegressor(kernel=kernel_rq, normalize_y=True)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use any of these as surrogate</span>
<span class="sd">        &gt;&gt;&gt; optimizer_rbf = SpotOptim(fun=objective, bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...                           surrogate=gp_rbf, max_iter=30, n_initial=10)</span>
<span class="sd">        &gt;&gt;&gt; result = optimizer_rbf.optimize()</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># ====================</span>
    <span class="c1"># Core</span>
    <span class="c1"># ====================</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fun</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">bounds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">n_initial</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">surrogate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">object</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">acquisition</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span>
        <span class="n">var_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">var_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">var_trans</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tolerance_x</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_time</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
        <span class="n">repeats_initial</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">repeats_surrogate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">ocba_delta</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">tensorboard_log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">tensorboard_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tensorboard_clean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fun_mo2so</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">warnings_filter</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ignore&quot;</span><span class="p">,</span>
        <span class="n">n_infill_points</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">max_surrogate_points</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">selection_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;distant&quot;</span><span class="p">,</span>
        <span class="n">acquisition_failure_strategy</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;random&quot;</span><span class="p">,</span>
        <span class="n">penalty</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">penalty_val</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">acquisition_fun_return_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">acquisition_optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;differential_evolution&quot;</span><span class="p">,</span>
        <span class="n">restart_after_n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">restart_inject_best</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">x0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">de_x0_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">tricands_fringe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">prob_de_tricands</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="n">window_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_tol_metric</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
        <span class="n">prob_surrogate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">acquisition_optimizer_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span> <span class="o">=</span> <span class="p">(),</span>
        <span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">warnings_filter</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">spacing</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">tolerance_x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tolerance_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span>

        <span class="c1"># Infer parameters from objective function if not provided</span>
        <span class="k">if</span> <span class="n">bounds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="s2">&quot;bounds&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">bounds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Bounds must be provided either as an argument or via the objective function.&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">var_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">var_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="s2">&quot;var_type&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">var_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">var_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="s2">&quot;var_name&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">var_trans</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">var_trans</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="s2">&quot;var_trans&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Validate parameters</span>
        <span class="k">if</span> <span class="n">max_iter</span> <span class="o">&lt;</span> <span class="n">n_initial</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;max_iter (</span><span class="si">{</span><span class="n">max_iter</span><span class="si">}</span><span class="s2">) must be &gt;= n_initial (</span><span class="si">{</span><span class="n">n_initial</span><span class="si">}</span><span class="s2">). &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;max_iter represents the total function evaluation budget including initial design.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">acquisition_optimizer_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">acquisition_optimizer_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="mi">10000</span><span class="p">,</span> <span class="s2">&quot;gtol&quot;</span><span class="p">:</span> <span class="mf">1e-9</span><span class="p">}</span>

        <span class="c1"># Initialize Configuration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">SpotOptimConfig</span><span class="p">(</span>
            <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">n_initial</span><span class="o">=</span><span class="n">n_initial</span><span class="p">,</span>
            <span class="n">surrogate</span><span class="o">=</span><span class="n">surrogate</span><span class="p">,</span>
            <span class="n">acquisition</span><span class="o">=</span><span class="n">acquisition</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span>
            <span class="n">var_type</span><span class="o">=</span><span class="n">var_type</span><span class="p">,</span>
            <span class="n">var_name</span><span class="o">=</span><span class="n">var_name</span><span class="p">,</span>
            <span class="n">var_trans</span><span class="o">=</span><span class="n">var_trans</span><span class="p">,</span>
            <span class="n">tolerance_x</span><span class="o">=</span><span class="n">tolerance_x</span><span class="p">,</span>
            <span class="n">max_time</span><span class="o">=</span><span class="n">max_time</span><span class="p">,</span>
            <span class="n">repeats_initial</span><span class="o">=</span><span class="n">repeats_initial</span><span class="p">,</span>
            <span class="n">repeats_surrogate</span><span class="o">=</span><span class="n">repeats_surrogate</span><span class="p">,</span>
            <span class="n">ocba_delta</span><span class="o">=</span><span class="n">ocba_delta</span><span class="p">,</span>
            <span class="n">tensorboard_log</span><span class="o">=</span><span class="n">tensorboard_log</span><span class="p">,</span>
            <span class="n">tensorboard_path</span><span class="o">=</span><span class="n">tensorboard_path</span><span class="p">,</span>
            <span class="n">tensorboard_clean</span><span class="o">=</span><span class="n">tensorboard_clean</span><span class="p">,</span>
            <span class="n">fun_mo2so</span><span class="o">=</span><span class="n">fun_mo2so</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">warnings_filter</span><span class="o">=</span><span class="n">warnings_filter</span><span class="p">,</span>
            <span class="n">n_infill_points</span><span class="o">=</span><span class="n">n_infill_points</span><span class="p">,</span>
            <span class="n">max_surrogate_points</span><span class="o">=</span><span class="n">max_surrogate_points</span><span class="p">,</span>
            <span class="n">selection_method</span><span class="o">=</span><span class="n">selection_method</span><span class="p">,</span>
            <span class="n">acquisition_failure_strategy</span><span class="o">=</span><span class="n">acquisition_failure_strategy</span><span class="p">,</span>
            <span class="n">penalty</span><span class="o">=</span><span class="n">penalty</span><span class="p">,</span>
            <span class="n">penalty_val</span><span class="o">=</span><span class="n">penalty_val</span><span class="p">,</span>
            <span class="n">acquisition_fun_return_size</span><span class="o">=</span><span class="n">acquisition_fun_return_size</span><span class="p">,</span>
            <span class="n">acquisition_optimizer</span><span class="o">=</span><span class="n">acquisition_optimizer</span><span class="p">,</span>
            <span class="n">restart_after_n</span><span class="o">=</span><span class="n">restart_after_n</span><span class="p">,</span>
            <span class="n">restart_inject_best</span><span class="o">=</span><span class="n">restart_inject_best</span><span class="p">,</span>
            <span class="n">x0</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span>
            <span class="n">de_x0_prob</span><span class="o">=</span><span class="n">de_x0_prob</span><span class="p">,</span>
            <span class="n">tricands_fringe</span><span class="o">=</span><span class="n">tricands_fringe</span><span class="p">,</span>
            <span class="n">prob_de_tricands</span><span class="o">=</span><span class="n">prob_de_tricands</span><span class="p">,</span>
            <span class="n">window_size</span><span class="o">=</span><span class="n">window_size</span><span class="p">,</span>
            <span class="n">min_tol_metric</span><span class="o">=</span><span class="n">min_tol_metric</span><span class="p">,</span>
            <span class="n">prob_surrogate</span><span class="o">=</span><span class="n">prob_surrogate</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">acquisition_optimizer_kwargs</span><span class="o">=</span><span class="n">acquisition_optimizer_kwargs</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
            <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Initialize State</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">SpotOptimState</span><span class="p">()</span>

        <span class="c1"># Other attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fun</span> <span class="o">=</span> <span class="n">fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective_names</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
            <span class="n">fun</span><span class="p">,</span> <span class="s2">&quot;objective_names&quot;</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Initialize persistent RNG</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_seed</span><span class="p">()</span>

        <span class="c1"># Process bounds and factor variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Maps dimension index to {int: str} mapping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_original_bounds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># Store original bounds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">process_factor_bounds</span><span class="p">()</span>  <span class="c1"># Maps factor bounds to integer indices (updates config.bounds)</span>

        <span class="c1"># Derived attribute dimension n_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span>

        <span class="c1"># Default variable types</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detect_var_type</span><span class="p">()</span>

        <span class="c1"># Modify bounds based on var_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modify_bounds_based_on_var_type</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">])</span>

        <span class="c1"># Default variable names</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">)]</span>

        <span class="c1"># Handle default variable transformations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">handle_default_var_trans</span><span class="p">()</span>

        <span class="c1"># Apply transformations to bounds (internal representation)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_original_upper</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform_bounds</span><span class="p">()</span>

        <span class="c1"># Dimension reduction: backup original bounds and identify fixed dimensions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_dimension_reduction</span><span class="p">()</span>

        <span class="c1"># Validate and process starting point if provided</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_x0</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x0</span><span class="p">)</span>

        <span class="c1"># Initialize surrogate if not provided</span>
        <span class="c1"># Initialize surrogate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_prob_surrogate</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Surrogate list cannot be empty.&quot;</span><span class="p">)</span>

            <span class="c1"># Handle probabilities</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">prob_surrogate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Uniform probability</span>
                <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_prob_surrogate</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="n">n</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">prob_surrogate</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Length of prob_surrogate (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span><span class="si">}</span><span class="s2">) must match &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;number of surrogates (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span><span class="p">)</span><span class="si">}</span><span class="s2">).&quot;</span>
                    <span class="p">)</span>
                <span class="c1"># Normalize probabilities</span>
                <span class="n">total</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">total</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span> <span class="ow">and</span> <span class="n">total</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_prob_surrogate</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="o">/</span> <span class="n">total</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">probs</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_prob_surrogate</span> <span class="o">=</span> <span class="n">probs</span>

            <span class="c1"># Handle max_surrogate_points list</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_max_surrogate_points_list</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_surrogate_points</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_surrogate_points</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Length of max_surrogate_points (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_surrogate_points</span><span class="p">)</span><span class="si">}</span><span class="s2">) &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;must match number of surrogates (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span><span class="p">)</span><span class="si">}</span><span class="s2">).&quot;</span>
                    <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_max_surrogate_points_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_surrogate_points</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># If int or None, broadcast to list for easier indexing</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_max_surrogate_points_list</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_surrogate_points</span>
                <span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span><span class="p">)</span>

            <span class="c1"># Set initial surrogate and max points</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_active_max_surrogate_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_surrogate_points_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Default single surrogate case</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_max_surrogate_points_list</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_active_max_surrogate_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_surrogate_points</span>

            <span class="n">kernel</span> <span class="o">=</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e12</span><span class="p">))</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span>
                <span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">),</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span>
            <span class="p">)</span>

            <span class="c1"># Determine optimizer for GPR</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="s2">&quot;fmin_l_bfgs_b&quot;</span>  <span class="c1"># Default used by sklearn</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">acquisition_optimizer_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                    <span class="n">_gpr_minimize_wrapper</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">acquisition_optimizer_kwargs</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span>
                <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span>
                <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Design generator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span> <span class="o">=</span> <span class="n">LatinHypercube</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Logic for window_size default based on restart_after_n</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restart_after_n</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">restart_after_n</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="mi">100</span>

        <span class="c1"># Clean old TensorBoard logs if requested</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_clean_tensorboard_logs</span><span class="p">()</span>

        <span class="c1"># Initialize TensorBoard writer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_tensorboard_writer</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Proxy attribute access to config and state.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;state&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&#39; object has no attribute &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Proxy attribute assignment to config and state.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="s2">&quot;state&quot;</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
                <span class="k">return</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;state&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
                <span class="k">return</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Include config and state attributes in dir().&quot;&quot;&quot;</span>
        <span class="n">d</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">())</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">)</span>
            <span class="n">d</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dir</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;state&quot;</span><span class="p">)</span>
            <span class="c1"># Filter internal methods/fields from dir if desired, but good for now</span>
            <span class="n">d</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dir</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

    <span class="c1"># ====================</span>
    <span class="c1"># Configuration &amp; Helpers</span>
    <span class="c1"># ====================</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set global random seeds for reproducibility.</span>

<span class="sd">        Sets seeds for:</span>
<span class="sd">        - random</span>
<span class="sd">        - numpy.random</span>
<span class="sd">        - torch (cpu and cuda)</span>

<span class="sd">        Only performs actions if self.seed is not None.</span>

<span class="sd">        Args:</span>
<span class="sd">            None</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(0, 1)], seed=42)</span>
<span class="sd">            &gt;&gt;&gt; spot._set_seed()</span>
<span class="sd">            &gt;&gt;&gt; np.random.rand()  # Should be deterministic</span>
<span class="sd">            0.3745401188473625</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">detect_var_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Auto-detect variable types based on factor mappings.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: List of variable types (&#39;factor&#39; or &#39;float&#39;) for each dimension.</span>
<span class="sd">                  Dimensions with factor mappings are assigned &#39;factor&#39;, others &#39;float&#39;.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;), (0, 10)])</span>
<span class="sd">            &gt;&gt;&gt; spot.detect_var_type()</span>
<span class="sd">            [&#39;factor&#39;, &#39;float&#39;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="s2">&quot;factor&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span> <span class="k">else</span> <span class="s2">&quot;float&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">modify_bounds_based_on_var_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Modify bounds based on variable types.</span>

<span class="sd">        Adjusts bounds for each dimension according to its var_type:</span>
<span class="sd">        - &#39;int&#39;: Ensures bounds are integers (ceiling for lower, floor for upper)</span>
<span class="sd">        - &#39;factor&#39;: Bounds already set to (0, n_levels-1) by process_factor_bounds</span>
<span class="sd">        - &#39;float&#39;: Explicitly converts bounds to float</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If an unsupported var_type is encountered.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(0.5, 10.5)], var_type=[&#39;int&#39;])</span>
<span class="sd">            &gt;&gt;&gt; spot.bounds</span>
<span class="sd">            [(1, 10)]</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(0, 10)], var_type=[&#39;float&#39;])</span>
<span class="sd">            &gt;&gt;&gt; spot.bounds</span>
<span class="sd">            [(0.0, 10.0)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">vtype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">vtype</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
                <span class="c1"># For integer variables, ensure bounds are integers</span>
                <span class="c1"># Use Python&#39;s int() to convert numpy types to native Python int</span>
                <span class="n">lower</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
                <span class="n">upper</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">vtype</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span><span class="p">:</span>
                <span class="c1"># For factor variables, bounds are already set to (0, n_levels-1)</span>
                <span class="c1"># Ensure they are Python int, not numpy int64</span>
                <span class="n">lower</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">upper</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">vtype</span> <span class="o">==</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
                <span class="c1"># Continuous variable, convert explicitly to float bounds</span>
                <span class="c1"># Use Python&#39;s float() to convert numpy types to native Python float</span>
                <span class="n">lower</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">upper</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Unsupported var_type &#39;</span><span class="si">{</span><span class="n">vtype</span><span class="si">}</span><span class="s2">&#39; at dimension </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Supported types are &#39;float&#39;, &#39;int&#39;, &#39;factor&#39;.&quot;</span>
                <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">handle_default_var_trans</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Handle default variable transformations.</span>

<span class="sd">        Sets var_trans to a list of None values if not specified, or normalizes</span>
<span class="sd">        transformation names by converting &#39;id&#39;, &#39;None&#39;, or None to None.</span>

<span class="sd">        Also validates that var_trans length matches the number of dimensions.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If var_trans length doesn&#39;t match n_dim.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Default behavior - all None</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(0, 10), (0, 10)])</span>
<span class="sd">            &gt;&gt;&gt; spot.var_trans</span>
<span class="sd">            [None, None]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Normalize transformation names</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10), (1, 100)],</span>
<span class="sd">            ...                  var_trans=[&#39;log10&#39;, &#39;id&#39;, None, &#39;None&#39;])</span>
<span class="sd">            &gt;&gt;&gt; spot.var_trans</span>
<span class="sd">            [&#39;log10&#39;, None, None, None]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Default variable transformations (None means no transformation)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Normalize transformation names</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="o">=</span> <span class="p">[</span>
                <span class="kc">None</span> <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">t</span> <span class="o">==</span> <span class="s2">&quot;id&quot;</span> <span class="ow">or</span> <span class="n">t</span> <span class="o">==</span> <span class="s2">&quot;None&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">t</span>
                <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span>
            <span class="p">]</span>

        <span class="c1"># Validate var_trans length</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Length of var_trans (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">)</span><span class="si">}</span><span class="s2">) must match &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;number of dimensions (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">process_factor_bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process bounds to handle factor variables.</span>

<span class="sd">        For dimensions with tuple bounds (factor variables), creates internal</span>
<span class="sd">        integer mappings and replaces bounds with (0, n_levels-1).</span>

<span class="sd">        Stores mappings in self._factor_maps: {dim_idx: {int_val: str_val}}</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If bounds are invalidly formatted.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;), (0, 10)])</span>
<span class="sd">            &gt;&gt;&gt; spot.process_factor_bounds()</span>
<span class="sd">            Factor variable at dimension 0:</span>
<span class="sd">              Levels: [&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;]</span>
<span class="sd">              Mapped to integers: 0 to 2</span>
<span class="sd">            &gt;&gt;&gt; print(spot.bounds)</span>
<span class="sd">            [(0, 2), (0, 10)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">processed_bounds</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">dim_idx</span><span class="p">,</span> <span class="n">bound</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bound</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">bound</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># Check if this is a factor variable (contains strings)</span>
                <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">bound</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">bound</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Factor variable: create integer mapping</span>
                    <span class="n">factor_levels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">bound</span><span class="p">)</span>
                    <span class="n">n_levels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">factor_levels</span><span class="p">)</span>

                    <span class="c1"># Create mapping: {0: &quot;level1&quot;, 1: &quot;level2&quot;, ...}</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">[</span><span class="n">dim_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="n">i</span><span class="p">:</span> <span class="n">level</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">level</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">factor_levels</span><span class="p">)</span>
                    <span class="p">}</span>

                    <span class="c1"># Replace with integer bounds (use Python int, not numpy types)</span>
                    <span class="n">processed_bounds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_levels</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Factor variable at dimension </span><span class="si">{</span><span class="n">dim_idx</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Levels: </span><span class="si">{</span><span class="n">factor_levels</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mapped to integers: 0 to </span><span class="si">{</span><span class="n">n_levels</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">bound</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">))</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">bound</span>
                <span class="p">):</span>
                    <span class="c1"># Numeric bound tuple (accepts Python and numpy numeric types)</span>
                    <span class="c1"># Always cast to Python float/int</span>
                    <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">bound</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="n">bound</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

                    <span class="c1"># Convert to int if both are integer-valued</span>
                    <span class="k">if</span> <span class="n">low</span><span class="o">.</span><span class="n">is_integer</span><span class="p">()</span> <span class="ow">and</span> <span class="n">high</span><span class="o">.</span><span class="n">is_integer</span><span class="p">():</span>
                        <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">low</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">high</span><span class="p">)</span>

                    <span class="n">processed_bounds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Invalid bound at dimension </span><span class="si">{</span><span class="n">dim_idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">bound</span><span class="si">}</span><span class="s2">. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Expected either (lower, upper) for numeric variables or &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;tuple of strings for factor variables.&quot;</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Invalid bound at dimension </span><span class="si">{</span><span class="n">dim_idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">bound</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected a tuple/list with at least 1 element.&quot;</span>
                <span class="p">)</span>

        <span class="c1"># Update bounds with processed values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="n">processed_bounds</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_best_hyperparameters</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">as_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the best hyperparameter configuration found during optimization.</span>

<span class="sd">        If noise handling is active (repeats_initial &gt; 1 or OCBA), this returns the parameter</span>
<span class="sd">        configuration associated with the best *mean* objective value. Otherwise, it returns</span>
<span class="sd">        the configuration associated with the absolute best observed value.</span>

<span class="sd">        Args:</span>
<span class="sd">            as_dict (bool, optional): If True, returns a dictionary mapping parameter names</span>
<span class="sd">                to their values. If False, returns the raw numpy array. Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[Dict[str, Any], np.ndarray, None]: The best hyperparameter configuration.</span>
<span class="sd">                Returns None if optimization hasn&#39;t started (no data).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda x: np.sum(x**2), bounds=[(-5, 5)], var_name=[&quot;x&quot;])</span>
<span class="sd">            &gt;&gt;&gt; opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; best_params = opt.get_best_hyperparameters()</span>
<span class="sd">            &gt;&gt;&gt; print(best_params[&#39;x&#39;]) # Should be close to 0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="c1"># Determine which &quot;best&quot; to use</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;min_mean_X&quot;</span>
        <span class="p">):</span>
            <span class="n">best_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_X</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">best_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">as_dict</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">best_x</span>

        <span class="c1"># Map factors using existing method (handles 2D, returns 2D)</span>
        <span class="c1"># We pass best_x as (1, D) and get (1, D) back</span>
        <span class="n">mapped_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_to_factor_values</span><span class="p">(</span><span class="n">best_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Convert to dictionary with types</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">names</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;p</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">best_x</span><span class="p">))]</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">names</span><span class="p">):</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">mapped_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># Handle types if available (specifically int, as factors are already mapped)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">:</span>
                <span class="n">v_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">v_type</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
                    <span class="n">val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">val</span><span class="p">))</span>

            <span class="n">params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>

        <span class="k">return</span> <span class="n">params</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_repair_non_numeric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">var_type</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Round non-numeric values to integers based on variable type.</span>

<span class="sd">        This method applies rounding to variables that are not continuous:</span>
<span class="sd">        - &#39;float&#39;: No rounding (continuous values)</span>
<span class="sd">        - &#39;int&#39;: Rounded to integers</span>
<span class="sd">        - &#39;factor&#39;: Rounded to integers (representing categorical values)</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): X array with values to potentially round.</span>
<span class="sd">            var_type (list of str): List with type information for each dimension.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: X array with non-continuous values rounded to integers.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 var_type=[&#39;int&#39;, &#39;float&#39;])</span>
<span class="sd">            &gt;&gt;&gt; X = np.array([[1.2, 2.5], [3.7, 4.1], [5.9, 6.8]])</span>
<span class="sd">            &gt;&gt;&gt; X_repaired = opt._repair_non_numeric(X, opt.var_type)</span>
<span class="sd">            &gt;&gt;&gt; print(X_repaired)</span>
<span class="sd">            [[1. 2.5]</span>
<span class="sd">             [4. 4.1]</span>
<span class="sd">             [6. 6.8]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Don&#39;t round float or num types (continuous values)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">var_type</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">],</span> <span class="n">invert</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">X</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">X</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reinitialize_components</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reinitialize components that were excluded during pickling.</span>

<span class="sd">        This method recreates the surrogate model and LHS sampler that were</span>
<span class="sd">        excluded when saving an experiment or result.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Load experiment</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim.load_experiment(&quot;sphere_opt_exp.pkl&quot;)</span>
<span class="sd">            &gt;&gt;&gt; # Reinitialize components</span>
<span class="sd">            &gt;&gt;&gt; opt._reinitialize_components()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Reinitialize LHS sampler if needed</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lhs_sampler&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span> <span class="o">=</span> <span class="n">LatinHypercube</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Reinitialize surrogate if needed</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;surrogate&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e12</span><span class="p">))</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span>
                <span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">),</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span>
                <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span>
                <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_pickle_safe_optimizer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">unpickleables</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;file_io&quot;</span><span class="p">,</span> <span class="n">verbosity</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SpotOptim&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a pickle-safe copy of the optimizer.</span>

<span class="sd">        This method creates a copy of the optimizer instance with unpickleable components removed</span>
<span class="sd">        or set to None to enable safe serialization.</span>

<span class="sd">        Args:</span>
<span class="sd">            unpickleables (str): Type of unpickleable components to exclude.</span>
<span class="sd">                - &quot;file_io&quot;: Excludes only file I/O components (tb_writer) and fun</span>
<span class="sd">                - &quot;all&quot;: Excludes file I/O, fun, surrogate, and lhs_sampler</span>
<span class="sd">                Defaults to &quot;file_io&quot;.</span>
<span class="sd">            verbosity (int): Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            SpotOptim: A copy of the optimizer with unpickleable components removed.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Define optimizer</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=30,</span>
<span class="sd">            ...     n_initial=10,</span>
<span class="sd">            ...     seed=42</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Create pickle-safe copy excluding all unpickleables</span>
<span class="sd">            &gt;&gt;&gt; opt_safe = opt._get_pickle_safe_optimizer(unpickleables=&quot;all&quot;, verbosity=1)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Always exclude tb_writer (can&#39;t reliably pickle file handles)</span>
        <span class="c1"># Determine which additional attributes to exclude</span>
        <span class="k">if</span> <span class="n">unpickleables</span> <span class="o">==</span> <span class="s2">&quot;file_io&quot;</span><span class="p">:</span>
            <span class="n">unpickleable_attrs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;tb_writer&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># &quot;all&quot; or specific exclusions</span>
            <span class="n">unpickleable_attrs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;tb_writer&quot;</span><span class="p">,</span> <span class="s2">&quot;surrogate&quot;</span><span class="p">,</span> <span class="s2">&quot;lhs_sampler&quot;</span><span class="p">]</span>

        <span class="c1"># Prepare picklable state dictionary</span>
        <span class="n">picklable_state</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unpickleable_attrs</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Test if attribute can be pickled</span>
                    <span class="n">dill</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">dill</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>
                    <span class="n">picklable_state</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                    <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Attribute &#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&#39; is picklable and will be included.&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Attribute &#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&#39; is not picklable and will be excluded: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                    <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbosity</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Attribute &#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&#39; explicitly excluded from pickling.&quot;</span><span class="p">)</span>

        <span class="c1"># Create new instance with picklable state</span>
        <span class="n">picklable_instance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>
        <span class="n">picklable_instance</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">picklable_state</span><span class="p">)</span>

        <span class="c1"># Set excluded attributes to None</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">unpickleable_attrs</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">picklable_instance</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">picklable_instance</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">picklable_instance</span>

    <span class="c1"># ====================</span>
    <span class="c1"># Dimension Reduction</span>
    <span class="c1"># ====================</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_dimension_reduction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up dimension reduction by identifying fixed dimensions.</span>

<span class="sd">        identifies dimensions where lower and upper bounds are equal in **Transformed Space**.</span>
<span class="sd">        Reduces `self.bounds`, `self.lower`, `self.upper`, etc., to the **Mapped Space**</span>
<span class="sd">        (active variables only).</span>

<span class="sd">        The resulting `self.bounds` defines the **Transformed and Mapped Space** used</span>
<span class="sd">        for optimization.</span>

<span class="sd">        This method identifies variables that are fixed (constant) and excludes them</span>
<span class="sd">        from the optimization process. It stores:</span>
<span class="sd">        - Original bounds and metadata in `all_*` attributes</span>
<span class="sd">        - Boolean mask of fixed dimensions in `ident`</span>
<span class="sd">        - Reduced bounds, types, and names for optimization</span>
<span class="sd">        - `red_dim` flag indicating if reduction occurred</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10), (5, 5), (0, 1)])</span>
<span class="sd">            &gt;&gt;&gt; spot._setup_dimension_reduction()</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Original lower bounds:&quot;, spot.all_lower)</span>
<span class="sd">            Original lower bounds: [ 1  5  0]</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Original upper bounds:&quot;, spot.all_upper)</span>
<span class="sd">            Original upper bounds: [10  5  1]</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Fixed dimensions mask:&quot;, spot.ident)</span>
<span class="sd">            Fixed dimensions mask: [False  True False]</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Reduced lower bounds:&quot;, spot.lower)</span>
<span class="sd">            Reduced lower bounds: [1 0]</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Reduced upper bounds:&quot;, spot.upper)</span>
<span class="sd">            Reduced upper bounds: [10  1]</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Reduced variable names:&quot;, spot.var_name)</span>
<span class="sd">            Reduced variable names: [&#39;x0&#39;, &#39;x2&#39;]</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Is dimension reduction active?&quot;, spot.red_dim)</span>
<span class="sd">            Is dimension reduction active? True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Backup original values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_upper</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># Identify fixed dimensions (lower == upper)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ident</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="c1"># Check if any dimension is fixed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="c1"># Reduce bounds to only varying dimensions</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">]</span>

            <span class="c1"># Update dimension count</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="o">.</span><span class="n">size</span>

            <span class="c1"># Reduce variable types and names</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">vtype</span>
                <span class="k">for</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">fixed</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">fixed</span>
            <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">vname</span>
                <span class="k">for</span> <span class="n">vname</span><span class="p">,</span> <span class="n">fixed</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">fixed</span>
            <span class="p">]</span>

            <span class="c1"># Reduce transformations</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">vtrans</span>
                <span class="k">for</span> <span class="n">vtrans</span><span class="p">,</span> <span class="n">fixed</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_var_trans</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">fixed</span>
            <span class="p">]</span>

            <span class="c1"># Update bounds list for reduced dimensions</span>
            <span class="c1"># Convert numpy types to Python native types (int or float based on var_type)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">):</span>
                <span class="c1"># Check if var_type has this index (handle mismatched lengths)</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span>
                <span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>

            <span class="c1"># Recreate LHS sampler with reduced dimensions</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span> <span class="o">=</span> <span class="n">LatinHypercube</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">to_red_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_full</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reduce full-dimensional points to optimization space.</span>

<span class="sd">        This method removes fixed dimensions from full-dimensional points,</span>
<span class="sd">        extracting only the varying dimensions used in optimization.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_full (ndarray): Points in full space, shape (n_samples, n_original_dims).</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Points in reduced space, shape (n_samples, n_reduced_dims).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Create problem with one fixed dimension</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (2, 2), (-5, 5)],  # x1 is fixed at 2</span>
<span class="sd">            ...     max_iter=1,</span>
<span class="sd">            ...     n_initial=3</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X_full = np.array([[1.0, 2.0, 3.0], [4.0, 2.0, 5.0]])</span>
<span class="sd">            &gt;&gt;&gt; X_red = opt.to_red_dim(X_full)</span>
<span class="sd">            &gt;&gt;&gt; X_red.shape</span>
<span class="sd">            (2, 2)</span>
<span class="sd">            &gt;&gt;&gt; np.array_equal(X_red, np.array([[1.0, 3.0], [4.0, 5.0]]))</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="c1"># No reduction occurred, return as-is</span>
            <span class="k">return</span> <span class="n">X_full</span>

        <span class="c1"># Handle 1D array</span>
        <span class="k">if</span> <span class="n">X_full</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">X_full</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">]</span>

        <span class="c1"># Select only non-fixed dimensions (2D)</span>
        <span class="k">return</span> <span class="n">X_full</span><span class="p">[:,</span> <span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_red</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Expand reduced-dimensional points to full-dimensional representation.</span>

<span class="sd">        This method restores points from the reduced optimization space to the</span>
<span class="sd">        full-dimensional space by inserting fixed values for constant dimensions.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_red (ndarray): Points in reduced space, shape (n_samples, n_reduced_dims).</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Points in full space, shape (n_samples, n_original_dims).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Create problem with one fixed dimension</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (2, 2), (-5, 5)],  # x1 is fixed at 2</span>
<span class="sd">            ...     max_iter=1,</span>
<span class="sd">            ...     n_initial=3</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X_red = np.array([[1.0, 3.0], [2.0, 4.0]])  # Only x0 and x2</span>
<span class="sd">            &gt;&gt;&gt; X_full = opt.to_all_dim(X_red)</span>
<span class="sd">            &gt;&gt;&gt; X_full.shape</span>
<span class="sd">            (2, 3)</span>
<span class="sd">            &gt;&gt;&gt; X_full[:, 1]  # Middle dimension should be 2.0</span>
<span class="sd">            array([2., 2.])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="c1"># No reduction occurred, return as-is</span>
            <span class="k">return</span> <span class="n">X_red</span>

        <span class="c1"># Number of samples and full dimensions</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_red</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_full_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">)</span>

        <span class="c1"># Initialize full-dimensional array</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_full_dims</span><span class="p">))</span>

        <span class="c1"># Track index in reduced array</span>
        <span class="n">red_idx</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Fill in values dimension by dimension</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_full_dims</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="c1"># Fixed dimension: use stored value</span>
                <span class="n">X_full</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Varying dimension: use value from reduced array</span>
                <span class="n">X_full</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_red</span><span class="p">[:,</span> <span class="n">red_idx</span><span class="p">]</span>
                <span class="n">red_idx</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">X_full</span>

    <span class="c1"># ====================</span>
    <span class="c1"># Variable Transformation</span>
    <span class="c1"># ====================</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">trans</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply transformation to a single float value.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Value to transform</span>
<span class="sd">            trans: Transformation name. Can be one of &#39;id&#39;, &#39;log10&#39;, &#39;log&#39;, &#39;ln&#39;, &#39;sqrt&#39;,</span>
<span class="sd">                   &#39;exp&#39;, &#39;square&#39;, &#39;cube&#39;, &#39;inv&#39;, &#39;reciprocal&#39;, or None.</span>
<span class="sd">                   Also supports dynamic strings like &#39;log(x)&#39;, &#39;sqrt(x)&#39;, &#39;pow(x, p)&#39;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Transformed value</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If x is not a float.</span>
<span class="sd">            ValueError: If an unknown transformation is specified.</span>

<span class="sd">        Notes:</span>
<span class="sd">            See also inverse_transform_value.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10)])</span>
<span class="sd">            &gt;&gt;&gt; spot.transform_value(10, &#39;log10&#39;)</span>
<span class="sd">            1.0</span>
<span class="sd">            &gt;&gt;&gt; spot.transform_value(100, &#39;log(x)&#39;)</span>
<span class="sd">            4.605170185988092</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Ensure x is a float</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;transform_value expects a float, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (value: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">)&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">trans</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;id&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log10&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log&quot;</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;ln&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;square&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;cube&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">3</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;inv&quot;</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;reciprocal&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">x</span>

        <span class="c1"># Dynamic Transformations</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

        <span class="k">if</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log(x)&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;sqrt(x)&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;pow\(x,\s*([0-9.]+)\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="n">p</span>

        <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;pow\(([0-9.]+),\s*x\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
            <span class="n">base</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">base</span><span class="o">**</span><span class="n">x</span>

        <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;log\(x,\s*([0-9.]+)\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
            <span class="n">base</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">base</span><span class="p">)</span>

        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown transformation: </span><span class="si">{</span><span class="n">trans</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">inverse_transform_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">trans</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply inverse transformation to a single float value.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Transformed value</span>
<span class="sd">            trans: Transformation name.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Original value</span>

<span class="sd">        Notes:</span>
<span class="sd">            See also transform_value.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10)])</span>
<span class="sd">            &gt;&gt;&gt; spot.inverse_transform_value(10, &#39;log10&#39;)</span>
<span class="sd">            10.0</span>
<span class="sd">            &gt;&gt;&gt; spot.inverse_transform_value(100, &#39;log(x)&#39;)</span>
<span class="sd">            10.0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Ensure x is a float</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;transform_value expects a float, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (value: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">)&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">trans</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;id&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log10&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">10</span><span class="o">**</span><span class="n">x</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log&quot;</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;ln&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;square&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;cube&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">3.0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;inv&quot;</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;reciprocal&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">x</span>

        <span class="c1"># Dynamic Transformations (Inverses)</span>
        <span class="k">if</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log(x)&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;sqrt(x)&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>

        <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;pow\(x,\s*([0-9.]+)\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span>

        <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;pow\(([0-9.]+),\s*x\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
            <span class="n">base</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">base</span><span class="p">)</span>

        <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;log\(x,\s*([0-9.]+)\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
            <span class="n">base</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">base</span><span class="o">**</span><span class="n">x</span>

        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown transformation: </span><span class="si">{</span><span class="n">trans</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_transform_X</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform parameter array from original to internal scale.</span>

<span class="sd">        Converts from **Natural Space** (Original) to **Transformed Space** (Full Dimension).</span>
<span class="sd">        Does NOT handle dimension reduction (mapping).</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Array in **Natural Space**, shape (n_samples, n_features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Array in **Transformed Space** (Full Dimension)</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10)])</span>
<span class="sd">            &gt;&gt;&gt; X_orig = np.array([[1], [10], [100]])</span>
<span class="sd">            &gt;&gt;&gt; spot._transform_X(X_orig)</span>
<span class="sd">            array([[0.        ],</span>
<span class="sd">                   [1.        ],</span>
<span class="sd">                   [2.        ]])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_transformed</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># Handle 1D array</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">trans</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">X_transformed</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_value</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">trans</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">X_transformed</span>

        <span class="c1"># Handle 2D array</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">trans</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">X_transformed</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                    <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">transform_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]]</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">X_transformed</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_inverse_transform_X</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform parameter array from internal to original scale.</span>

<span class="sd">        Converts from **Transformed Space** (Full Dimension) to **Natural Space** (Original).</span>
<span class="sd">        Does NOT handle dimension expansion (un-mapping).</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Array in **Transformed Space**, shape (n_samples, n_features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Array in **Natural Space**</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10)])</span>
<span class="sd">            &gt;&gt;&gt; X_trans = np.array([[0], [1], [2]])</span>
<span class="sd">            &gt;&gt;&gt; spot._inverse_transform_X(X_trans)</span>
<span class="sd">            array([[  1.],</span>
<span class="sd">                   [ 10.],</span>
<span class="sd">                   [100.]])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_original</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># Handle 1D array (single sample)</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">trans</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># Element-wise transformation for 1D array</span>
                    <span class="n">X_original</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverse_transform_value</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">trans</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">X_original</span>

        <span class="c1"># Handle 2D array (multiple samples)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">trans</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">X_original</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                    <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inverse_transform_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]]</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">X_original</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform bounds from original to internal scale.</span>

<span class="sd">        Updates `self.bounds` (and `self.lower`, `self.upper`) from **Natural Space**</span>
<span class="sd">        to **Transformed Space**.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10), (0.1, 100)])</span>
<span class="sd">            &gt;&gt;&gt; spot.var_trans = [&#39;log10&#39;, &#39;sqrt&#39;]</span>
<span class="sd">            &gt;&gt;&gt; spot.transform_bounds()</span>
<span class="sd">            &gt;&gt;&gt; print(spot.bounds)</span>
<span class="sd">            [(0.0, 1.0), (0.31622776601683794, 10.0)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">trans</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">lower_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">trans</span><span class="p">)</span>
                <span class="n">upper_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">trans</span><span class="p">)</span>

                <span class="c1"># Handle reversed bounds (e.g., reciprocal transformation)</span>
                <span class="k">if</span> <span class="n">lower_t</span> <span class="o">&gt;</span> <span class="n">upper_t</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">upper_t</span><span class="p">,</span> <span class="n">lower_t</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">lower_t</span><span class="p">,</span> <span class="n">upper_t</span>

        <span class="c1"># Update self.bounds to reflect transformed bounds</span>
        <span class="c1"># Convert numpy types to Python native types (int or float based on var_type)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)):</span>
            <span class="c1"># Check if var_type has this index (handle mismatched lengths)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_map_to_factor_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Map internal integer factor values back to string labels.</span>

<span class="sd">        For factor variables, converts integer indices back to original string values.</span>
<span class="sd">        Other variable types remain unchanged.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design points with integer values for factors,</span>
<span class="sd">                shape (n_samples, n_features).</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Design points with factor integers replaced by string labels.</span>
<span class="sd">                Dtype will be object or string if mixed types are present.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; spot = SpotOptim(</span>
<span class="sd">            ...     fun=lambda x: x,</span>
<span class="sd">            ...     bounds=[(&#39;red&#39;, &#39;blue&#39;), (0, 10)]</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; spot.process_factor_bounds()</span>
<span class="sd">            &gt;&gt;&gt; X_int = np.array([[0, 5.0], [1, 8.0]])</span>
<span class="sd">            &gt;&gt;&gt; X_str = spot._map_to_factor_values(X_int)</span>
<span class="sd">            &gt;&gt;&gt; print(X_str[0])</span>
<span class="sd">            [&#39;red&#39; 5.0]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">:</span>
            <span class="c1"># No factor variables</span>
            <span class="k">return</span> <span class="n">X</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># Create object array to hold mixed types (strings and numbers)</span>
        <span class="n">X_mapped</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="n">X_mapped</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">X</span>  <span class="c1"># Copy numeric values</span>

        <span class="k">for</span> <span class="n">dim_idx</span><span class="p">,</span> <span class="n">mapping</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># Check if already mapped (strings) or needs mapping (numeric)</span>
            <span class="n">col_values</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">dim_idx</span><span class="p">]</span>

            <span class="c1"># If already strings, keep them</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">col_values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">continue</span>

            <span class="c1"># Round to nearest integer and map to string</span>
            <span class="n">int_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">col_values</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            <span class="c1"># Clip to valid range</span>
            <span class="n">int_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">int_values</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Map to strings</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">int_values</span><span class="p">):</span>
                <span class="n">X_mapped</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">dim_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">mapping</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">val</span><span class="p">)]</span>

        <span class="k">return</span> <span class="n">X_mapped</span>

    <span class="c1"># ====================</span>
    <span class="c1"># Initial Design</span>
    <span class="c1"># ====================</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_initial_design</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate or process initial design points.</span>

<span class="sd">        Handles three scenarios:</span>
<span class="sd">        1. X0 is None: Generate space-filling design using LHS</span>
<span class="sd">        2. X0 is None but x0 is provided: Generate LHS and include x0 as first point</span>
<span class="sd">        3. X0 is provided: Transform and prepare user-provided initial design</span>

<span class="sd">        Args:</span>
<span class="sd">            X0 (ndarray, optional): User-provided initial design points in original scale,</span>
<span class="sd">                shape (n_initial, n_features). If None, generates space-filling design.</span>
<span class="sd">                Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Initial design points in internal (transformed and reduced) scale,</span>
<span class="sd">                shape (n_initial, n_features_reduced).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=10</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Generate default LHS design</span>
<span class="sd">            &gt;&gt;&gt; X0 = opt.get_initial_design()</span>
<span class="sd">            &gt;&gt;&gt; X0.shape</span>
<span class="sd">            (10, 2)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Provide custom initial design</span>
<span class="sd">            &gt;&gt;&gt; X0_custom = np.array([[0, 0], [1, 1], [2, 2]])</span>
<span class="sd">            &gt;&gt;&gt; X0_processed = opt.get_initial_design(X0_custom)</span>
<span class="sd">            &gt;&gt;&gt; X0_processed.shape</span>
<span class="sd">            (3, 2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Generate or use provided initial design</span>
        <span class="k">if</span> <span class="n">X0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_initial_design</span><span class="p">()</span>

            <span class="c1"># If starting point x0 was provided, include it in initial design</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># x0 is already validated and in internal scale</span>
                <span class="c1"># Check if x0 is 1D or 2D</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">x0_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">x0_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span>

                <span class="n">n_x0</span> <span class="o">=</span> <span class="n">x0_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

                <span class="c1"># If we have more x0 points than n_initial, use all x0 points</span>
                <span class="k">if</span> <span class="n">n_x0</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="p">:</span>
                    <span class="n">X0</span> <span class="o">=</span> <span class="n">x0_points</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using provided x0 points (</span><span class="si">{</span><span class="n">n_x0</span><span class="si">}</span><span class="s2">) as initial design.&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Replace the first n_x0 points of LHS with x0 points</span>
                    <span class="n">X0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">x0_points</span><span class="p">,</span> <span class="n">X0</span><span class="p">[:</span><span class="o">-</span><span class="n">n_x0</span><span class="p">]])</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Including </span><span class="si">{</span><span class="n">n_x0</span><span class="si">}</span><span class="s2"> starting points from x0 in initial design.&quot;</span>
                        <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
            <span class="c1"># If user provided X0, it&#39;s in original scale - transform it</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_X</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
            <span class="c1"># If X0 is in full dimensions and we have dimension reduction, reduce it</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="ow">and</span> <span class="n">X0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">):</span>
                <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_red_dim</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_initial_design</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate initial space-filling design using Latin Hypercube Sampling.</span>
<span class="sd">        Used in the optimize() method to create the initial set of design points.</span>

<span class="sd">        Args:</span>
<span class="sd">            None</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Initial design points, shape (n_initial, n_features).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 n_initial=10)</span>
<span class="sd">            &gt;&gt;&gt; X0 = opt._generate_initial_design()</span>
<span class="sd">            &gt;&gt;&gt; X0.shape</span>
<span class="sd">            (10, 2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Generate samples in [0, 1]^d</span>
        <span class="n">X0_unit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="p">)</span>

        <span class="c1"># Scale to [lower, upper]</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">+</span> <span class="n">X0_unit</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_curate_initial_design</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Remove duplicates and ensure sufficient unique points in initial design.</span>

<span class="sd">        This method handles deduplication that can occur after rounding integer/factor</span>
<span class="sd">        variables. If duplicates are found, it generates additional points to reach</span>
<span class="sd">        the target n_initial unique points. Also handles repeating points when</span>
<span class="sd">        repeats_initial &gt; 1.</span>

<span class="sd">        Args:</span>
<span class="sd">            X0 (ndarray): Initial design points in internal scale,</span>
<span class="sd">                shape (n_samples, n_features).</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Curated initial design with duplicates removed and repeated</span>
<span class="sd">                if necessary, shape (n_unique * repeats_initial, n_features).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=10,</span>
<span class="sd">            ...     var_type=[&#39;int&#39;, &#39;int&#39;]  # Integer variables may cause duplicates</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X0 = opt.get_initial_design()</span>
<span class="sd">            &gt;&gt;&gt; X0_curated = opt._curate_initial_design(X0)</span>
<span class="sd">            &gt;&gt;&gt; X0_curated.shape[0] == 10  # Should have n_initial unique points</span>
<span class="sd">            True</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # With repeats</span>
<span class="sd">            &gt;&gt;&gt; opt_repeat = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     repeats_initial=3</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X0 = opt_repeat.get_initial_design()</span>
<span class="sd">            &gt;&gt;&gt; X0_curated = opt_repeat._curate_initial_design(X0)</span>
<span class="sd">            &gt;&gt;&gt; X0_curated.shape[0] == 15  # 5 unique points * 3 repeats</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Remove duplicates from initial design (can occur after rounding integers/factors)</span>
        <span class="c1"># Keep only unique rows based on rounded values</span>
        <span class="n">X0_unique</span><span class="p">,</span> <span class="n">unique_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">return_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X0_unique</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X0</span><span class="p">):</span>
            <span class="n">n_duplicates</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">X0_unique</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Removed </span><span class="si">{</span><span class="n">n_duplicates</span><span class="si">}</span><span class="s2"> duplicate(s) from initial design after rounding&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Generate additional points to reach n_initial unique points</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X0_unique</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="p">:</span>
                <span class="n">n_additional</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">X0_unique</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Generating </span><span class="si">{</span><span class="n">n_additional</span><span class="si">}</span><span class="s2"> additional point(s) to reach n_initial=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

                <span class="c1"># Generate extra points and deduplicate again</span>
                <span class="n">max_gen_attempts</span> <span class="o">=</span> <span class="mi">10</span>
                <span class="k">for</span> <span class="n">gen_attempt</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_gen_attempts</span><span class="p">):</span>
                    <span class="n">X_extra_unit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span><span class="o">.</span><span class="n">random</span><span class="p">(</span>
                        <span class="n">n</span><span class="o">=</span><span class="n">n_additional</span> <span class="o">*</span> <span class="mi">2</span>
                    <span class="p">)</span>  <span class="c1"># Generate extras</span>
                    <span class="n">X_extra</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">+</span> <span class="n">X_extra_unit</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)</span>
                    <span class="n">X_extra</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">X_extra</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span>

                    <span class="c1"># Combine and get unique</span>
                    <span class="n">X_combined</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">X0_unique</span><span class="p">,</span> <span class="n">X_extra</span><span class="p">])</span>
                    <span class="n">X_combined_unique</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X_combined</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_combined_unique</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="p">:</span>
                        <span class="n">X0</span> <span class="o">=</span> <span class="n">X_combined_unique</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="p">]</span>
                        <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># If still not enough unique points, just use what we have</span>
                    <span class="n">X0</span> <span class="o">=</span> <span class="n">X_combined_unique</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Warning: Could only generate </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span><span class="si">}</span><span class="s2"> unique initial points (target was </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="si">}</span><span class="s2">)&quot;</span>
                        <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">X0</span> <span class="o">=</span> <span class="n">X0_unique</span>

        <span class="c1"># Repeat initial design points if repeats_initial &gt; 1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_rm_NA_values</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y0</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Remove NaN/inf values from initial design evaluations.</span>

<span class="sd">        This method filters out design points that returned NaN or inf values</span>
<span class="sd">        during initial evaluation. Unlike the sequential optimization phase where</span>
<span class="sd">        penalties are applied, initial design points with invalid values are</span>
<span class="sd">        simply removed.</span>

<span class="sd">        Args:</span>
<span class="sd">            X0 (ndarray): Initial design points in internal scale,</span>
<span class="sd">                shape (n_samples, n_features).</span>
<span class="sd">            y0 (ndarray): Function values at X0, shape (n_samples,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[ndarray, ndarray, int]: Filtered (X0, y0) with only finite values</span>
<span class="sd">                and the original count before filtering. X0 has shape (n_valid, n_features),</span>
<span class="sd">                y0 has shape (n_valid,), and the int is the original size.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=10</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X0 = np.array([[1, 2], [3, 4], [5, 6]])</span>
<span class="sd">            &gt;&gt;&gt; y0 = np.array([5.0, np.nan, np.inf])</span>
<span class="sd">            &gt;&gt;&gt; X0_clean, y0_clean, n_eval = opt._rm_NA_values(X0, y0)</span>
<span class="sd">            &gt;&gt;&gt; X0_clean.shape</span>
<span class="sd">            (1, 2)</span>
<span class="sd">            &gt;&gt;&gt; y0_clean</span>
<span class="sd">            array([5.])</span>
<span class="sd">            &gt;&gt;&gt; n_eval</span>
<span class="sd">            3</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # All valid values - no filtering</span>
<span class="sd">            &gt;&gt;&gt; X0 = np.array([[1, 2], [3, 4]])</span>
<span class="sd">            &gt;&gt;&gt; y0 = np.array([5.0, 25.0])</span>
<span class="sd">            &gt;&gt;&gt; X0_clean, y0_clean, n_eval = opt._rm_NA_values(X0, y0)</span>
<span class="sd">            &gt;&gt;&gt; X0_clean.shape</span>
<span class="sd">            (2, 2)</span>
<span class="sd">            &gt;&gt;&gt; n_eval</span>
<span class="sd">            2</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle NaN/inf values in initial design - REMOVE them instead of applying penalty</span>

        <span class="c1"># If y0 contains None (object dtype), convert None to NaN and ensure float dtype</span>
        <span class="k">if</span> <span class="n">y0</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="nb">object</span><span class="p">:</span>
            <span class="c1"># Create a float array, replacing None with NaN</span>
            <span class="c1"># Use list comprehension for safe conversion of None</span>
            <span class="n">y0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">y0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

        <span class="n">finite_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y0</span><span class="p">)</span>
        <span class="n">n_non_finite</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">finite_mask</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_non_finite</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Warning: </span><span class="si">{</span><span class="n">n_non_finite</span><span class="si">}</span><span class="s2"> initial design point(s) returned NaN/inf &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;and will be ignored (reduced from </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y0</span><span class="p">)</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">finite_mask</span><span class="p">)</span><span class="si">}</span><span class="s2"> points)&quot;</span>
                <span class="p">)</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="n">X0</span><span class="p">[</span><span class="n">finite_mask</span><span class="p">]</span>
            <span class="n">y0</span> <span class="o">=</span> <span class="n">y0</span><span class="p">[</span><span class="n">finite_mask</span><span class="p">]</span>

            <span class="c1"># Also filter y_mo if it exists (must match y0 size)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">finite_mask</span><span class="p">):</span>  <span class="c1"># Safety check</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span><span class="p">[</span><span class="n">finite_mask</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Fallback or warning if sizes already mismatched (shouldn&#39;t happen here normally)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Warning: y_mo size (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span><span class="p">)</span><span class="si">}</span><span class="s2">) != mask size (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">finite_mask</span><span class="p">)</span><span class="si">}</span><span class="s2">) in initial design filtering&quot;</span>
                        <span class="p">)</span>
                    <span class="c1"># Try to filter only if sizes match, otherwise we might be in inconsistent state</span>

        <span class="k">return</span> <span class="n">X0</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">finite_mask</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_x0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate and process starting point x0.</span>

<span class="sd">        This method checks that x0:</span>
<span class="sd">        - Is a numpy array</span>
<span class="sd">        - Has the correct number of dimensions</span>
<span class="sd">        - Has values within bounds (in original scale)</span>
<span class="sd">        - Is properly transformed to internal scale</span>

<span class="sd">        Args:</span>
<span class="sd">            x0 (array-like): Starting point in original scale</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Validated and transformed x0 in internal scale, shape (n_features,)</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If x0 is invalid</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     x0=np.array([1.0, 2.0])</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # x0 is validated during initialization</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Convert to numpy array</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>

        <span class="c1"># Check if x0 is 1D or can be flattened to 1D</span>
        <span class="k">if</span> <span class="n">x0</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;x0 must be a 1D array-like, got scalar value. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Expected shape: (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">)</span><span class="si">}</span><span class="s2">,)&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">x0</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;x0 must be a 1D array-like, got </span><span class="si">{</span><span class="n">x0</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">D array. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Expected shape: (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">)</span><span class="si">}</span><span class="s2">,)&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">x0</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">pass</span>  <span class="c1"># 2D array is allowed now for x0</span>
            <span class="k">if</span> <span class="n">x0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x0</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

        <span class="c1"># Check number of dimensions (compare with original full dimensions before reduction)</span>
        <span class="c1"># Check number of dimensions</span>
        <span class="n">expected_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">x0</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span> <span class="o">!=</span> <span class="n">expected_dim</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;x0 has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span><span class="si">}</span><span class="s2"> dimensions, but expected </span><span class="si">{</span><span class="n">expected_dim</span><span class="si">}</span><span class="s2"> dimensions. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Bounds specify </span><span class="si">{</span><span class="n">expected_dim</span><span class="si">}</span><span class="s2"> parameters: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">x0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">expected_dim</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;x0 has </span><span class="si">{</span><span class="n">x0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> dimensions, but expected </span><span class="si">{</span><span class="n">expected_dim</span><span class="si">}</span><span class="s2"> dimensions. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Bounds specify </span><span class="si">{</span><span class="n">expected_dim</span><span class="si">}</span><span class="s2"> parameters: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="c1"># Helper to validate a single point</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">check_point</span><span class="p">(</span><span class="n">pt</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_upper</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="c1"># Ensure val is scalar for comparison (zip iterates elements, but be safe)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;x0 (</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2"> is a fixed dimension and must equal </span><span class="si">{</span><span class="n">low</span><span class="si">}</span><span class="s2">. &quot;</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">low</span> <span class="o">&lt;=</span> <span class="n">val</span> <span class="o">&lt;=</span> <span class="n">high</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;x0 (</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2"> is outside bounds [</span><span class="si">{</span><span class="n">low</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">high</span><span class="si">}</span><span class="s2">]. &quot;</span>
                        <span class="p">)</span>

        <span class="k">if</span> <span class="n">x0</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">check_point</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
            <span class="c1"># Apply transformations to x0 (from original to internal scale)</span>
            <span class="n">x0_transformed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_X</span><span class="p">(</span><span class="n">x0</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># 2D case</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">pt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x0</span><span class="p">):</span>
                <span class="n">check_point</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
            <span class="n">x0_transformed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_X</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>

        <span class="c1"># If dimension reduction is active, reduce x0 to non-fixed dimensions</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="n">x0_transformed</span> <span class="o">=</span> <span class="n">x0_transformed</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting point x0 validated and processed successfully.&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Original scale: </span><span class="si">{</span><span class="n">x0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Internal scale: </span><span class="si">{</span><span class="n">x0_transformed</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x0_transformed</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_check_size_initial_design</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y0</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">n_evaluated</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate that initial design has sufficient points for surrogate fitting.</span>

<span class="sd">        Checks if the number of valid initial design points meets the minimum</span>
<span class="sd">        requirement for fitting a surrogate model. The minimum required is the</span>
<span class="sd">        smaller of: (a) typical minimum for surrogate fitting (3 for multi-dimensional,</span>
<span class="sd">        2 for 1D), or (b) what the user requested (n_initial).</span>

<span class="sd">        Args:</span>
<span class="sd">            y0 (ndarray): Function values at initial design points (after filtering),</span>
<span class="sd">                shape (n_valid,).</span>
<span class="sd">            n_evaluated (int): Original number of points evaluated before filtering.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the number of valid points is less than the minimum required.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=10</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Sufficient points - no error</span>
<span class="sd">            &gt;&gt;&gt; y0 = np.array([1.0, 2.0, 3.0, 4.0, 5.0])</span>
<span class="sd">            &gt;&gt;&gt; opt._check_size_initial_design(y0, n_evaluated=10)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Insufficient points - raises ValueError</span>
<span class="sd">            &gt;&gt;&gt; y0_small = np.array([1.0])</span>
<span class="sd">            &gt;&gt;&gt; try:</span>
<span class="sd">            ...     opt._check_size_initial_design(y0_small, n_evaluated=10)</span>
<span class="sd">            ... except ValueError as e:</span>
<span class="sd">            ...     print(f&quot;Error: {e}&quot;)</span>
<span class="sd">            Error: Insufficient valid initial design points: only 1 finite value(s) out of 10 evaluated...</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # With verbose output</span>
<span class="sd">            &gt;&gt;&gt; opt_verbose = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=10,</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; y0_reduced = np.array([1.0, 2.0, 3.0])  # Less than n_initial but valid</span>
<span class="sd">            &gt;&gt;&gt; opt_verbose._check_size_initial_design(y0_reduced, n_evaluated=10)</span>
<span class="sd">            Note: Initial design size (3) is smaller than requested (10) due to NaN/inf values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if we have enough points to continue</span>
        <span class="c1"># Use the smaller of: (a) typical minimum for surrogate fitting, or (b) what user requested</span>
        <span class="n">min_points_typical</span> <span class="o">=</span> <span class="mi">3</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">2</span>
        <span class="n">min_points_required</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">min_points_typical</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">min_points_required</span><span class="p">:</span>
            <span class="n">error_msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Insufficient valid initial design points: only </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y0</span><span class="p">)</span><span class="si">}</span><span class="s2"> finite value(s) &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;out of </span><span class="si">{</span><span class="n">n_evaluated</span><span class="si">}</span><span class="s2"> evaluated. Need at least </span><span class="si">{</span><span class="n">min_points_required</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;points to fit surrogate model. Please check your objective function or increase n_initial.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Note: Initial design size (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y0</span><span class="p">)</span><span class="si">}</span><span class="s2">) is smaller than requested &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="si">}</span><span class="s2">) due to NaN/inf values&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_best_xy_initial_design</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Determine and store the best point from initial design.</span>

<span class="sd">        Finds the best (minimum) function value in the initial design,</span>
<span class="sd">        stores the corresponding point and value in instance attributes,</span>
<span class="sd">        and optionally prints the results if verbose mode is enabled.</span>

<span class="sd">        For noisy functions, also reports the mean best value.</span>

<span class="sd">        Note:</span>
<span class="sd">            This method assumes self.X_ and self.y_ have been initialized</span>
<span class="sd">            with the initial design evaluations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Simulate initial design (normally done in optimize())</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.array([[1, 2], [0, 0], [2, 1]])</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.array([5.0, 0.0, 5.0])</span>
<span class="sd">            &gt;&gt;&gt; opt._get_best_xy_initial_design()</span>
<span class="sd">            Initial best: f(x) = 0.000000</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Best x: {opt.best_x_}&quot;)</span>
<span class="sd">            Best x: [0 0]</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Best y: {opt.best_y_}&quot;)</span>
<span class="sd">            Best y: 0.0</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # With noisy function</span>
<span class="sd">            &gt;&gt;&gt; opt_noise = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     noise=True,</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.X_ = np.array([[1, 2], [0, 0], [2, 1]])</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.y_ = np.array([5.0, 0.0, 5.0])</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.min_mean_y = 0.5  # Simulated mean best</span>
<span class="sd">            &gt;&gt;&gt; opt_noise._get_best_xy_initial_design()</span>
<span class="sd">            Initial best: f(x) = 0.000000, mean best: f(x) = 0.500000</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initial best</span>
        <span class="n">best_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Initial best: f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, mean best: f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial best: f(x) = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_update_repeats_infill_points</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_next</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Repeat infill point for noisy function evaluation.</span>

<span class="sd">        For noisy objective functions (repeats_surrogate &gt; 1), creates multiple</span>
<span class="sd">        copies of the suggested point for repeated evaluation. Otherwise, returns</span>
<span class="sd">        the point in 2D array format.</span>

<span class="sd">        Args:</span>
<span class="sd">            x_next (ndarray): Next point to evaluate, shape (n_features,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Points to evaluate, shape (repeats_surrogate, n_features)</span>
<span class="sd">                or (1, n_features) if repeats_surrogate == 1.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Without repeats</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     repeats_surrogate=1</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; x_next = np.array([1.0, 2.0])</span>
<span class="sd">            &gt;&gt;&gt; x_repeated = opt._update_repeats_infill_points(x_next)</span>
<span class="sd">            &gt;&gt;&gt; x_repeated.shape</span>
<span class="sd">            (1, 2)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # With repeats for noisy function</span>
<span class="sd">            &gt;&gt;&gt; opt_noisy = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     repeats_surrogate=3</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; x_next = np.array([1.0, 2.0])</span>
<span class="sd">            &gt;&gt;&gt; x_repeated = opt_noisy._update_repeats_infill_points(x_next)</span>
<span class="sd">            &gt;&gt;&gt; x_repeated.shape</span>
<span class="sd">            (3, 2)</span>
<span class="sd">            &gt;&gt;&gt; # All three copies should be identical</span>
<span class="sd">            &gt;&gt;&gt; np.all(x_repeated[0] == x_repeated[1])</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">x_next</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x_next</span> <span class="o">=</span> <span class="n">x_next</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Repeat each row repeats_surrogate times</span>
            <span class="c1"># Note: np.repeat with axis=0 repeats rows [r1, r1, r2, r2...]</span>
            <span class="n">x_next_repeated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">x_next</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_next_repeated</span> <span class="o">=</span> <span class="n">x_next</span>
        <span class="k">return</span> <span class="n">x_next_repeated</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_remove_nan</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">stop_on_zero_return</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Remove rows where y contains NaN or inf values.</span>
<span class="sd">        Used in the optimize() method after function evaluations.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design matrix, shape (n_samples, n_features).</span>
<span class="sd">            y (ndarray): Objective values, shape (n_samples,).</span>
<span class="sd">            stop_on_zero_return (bool): If True, raise error when all values are removed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: (X_clean, y_clean) with NaN/inf rows removed.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If all values are NaN/inf and stop_on_zero_return is True.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1), bounds=[(-5, 5)])</span>
<span class="sd">            &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])</span>
<span class="sd">            &gt;&gt;&gt; y = np.array([1.0, np.nan, np.inf])</span>
<span class="sd">            &gt;&gt;&gt; X_clean, y_clean = opt._remove_nan(X, y, stop_on_zero_return=False)</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Clean X:&quot;, X_clean)</span>
<span class="sd">            Clean X: [[1 2]]</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Clean y:&quot;, y_clean)</span>
<span class="sd">            Clean y: [1.]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Find finite values</span>
        <span class="n">finite_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">finite_mask</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;All objective function values are NaN or inf.&quot;</span>
            <span class="k">if</span> <span class="n">stop_on_zero_return</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2"> Returning empty arrays.&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>

        <span class="c1"># Filter out non-finite values</span>
        <span class="n">n_removed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">finite_mask</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_removed</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Removed </span><span class="si">{</span><span class="n">n_removed</span><span class="si">}</span><span class="s2"> sample(s) with NaN/inf values&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="n">finite_mask</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">finite_mask</span><span class="p">]</span>

    <span class="c1"># ====================</span>
    <span class="c1"># Surrogate &amp; Acquisition</span>
    <span class="c1"># ====================</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_fit_surrogate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit surrogate model to data.</span>
<span class="sd">        Used in optimize() to fit the surrogate model.</span>

<span class="sd">        If the number of points exceeds `self.max_surrogate_points`,</span>
<span class="sd">        a subset of points is selected using the selection dispatcher.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design points, shape (n_samples, n_features).</span>
<span class="sd">            y (ndarray): Function values at X, shape (n_samples,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; from sklearn.gaussian_process import GaussianProcessRegressor</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_surrogate_points=10,</span>
<span class="sd">            ...                 surrogate=GaussianProcessRegressor())</span>
<span class="sd">            &gt;&gt;&gt; X = np.random.rand(50, 2)</span>
<span class="sd">            &gt;&gt;&gt; y = np.random.rand(50)</span>
<span class="sd">            &gt;&gt;&gt; opt._fit_surrogate(X, y)</span>
<span class="sd">            &gt;&gt;&gt; # Surrogate is now fitted</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_fit</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">y_fit</span> <span class="o">=</span> <span class="n">y</span>

        <span class="c1"># Select subset if needed</span>
        <span class="c1"># Resolve active max points</span>
        <span class="n">max_k</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_active_max_surrogate_points&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_surrogate_points</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">max_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">max_k</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Selecting subset of </span><span class="si">{</span><span class="n">max_k</span><span class="si">}</span><span class="s2"> points &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;from </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> total points for surrogate fitting.&quot;</span>
                <span class="p">)</span>
            <span class="n">X_fit</span><span class="p">,</span> <span class="n">y_fit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_selection_dispatcher</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_fit</span><span class="p">,</span> <span class="n">y_fit</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_fit_scheduler</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit surrogate model using appropriate data based on noise handling.</span>

<span class="sd">        This method selects the appropriate training data for surrogate fitting:</span>
<span class="sd">        - For noisy functions (noise=True): Uses mean_X and mean_y (aggregated values)</span>
<span class="sd">        - For deterministic functions: Uses X_ and y_ (all evaluated points)</span>

<span class="sd">        The data is transformed to internal scale before fitting the surrogate.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; from sklearn.gaussian_process import GaussianProcessRegressor</span>
<span class="sd">            &gt;&gt;&gt; # Deterministic function</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     surrogate=GaussianProcessRegressor(),</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Simulate optimization state</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.array([[1, 2], [0, 0], [2, 1]])</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.array([5.0, 0.0, 5.0])</span>
<span class="sd">            &gt;&gt;&gt; opt._fit_scheduler()</span>
<span class="sd">            &gt;&gt;&gt; # Surrogate fitted with X_ and y_</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Noisy function</span>
<span class="sd">            &gt;&gt;&gt; opt_noise = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     surrogate=GaussianProcessRegressor(),</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     repeats_initial=3,</span>
<span class="sd">            ...     noise=True  # Activates noise handling</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Simulate noisy optimization state</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.mean_X = np.array([[1, 2], [0, 0]])</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.mean_y = np.array([5.0, 0.0])</span>
<span class="sd">            &gt;&gt;&gt; opt_noise._fit_scheduler()</span>
<span class="sd">            &gt;&gt;&gt; # Surrogate fitted with mean_X and mean_y</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Fit surrogate (use mean_y if noise, otherwise y_)</span>
        <span class="c1"># Transform X to internal scale for surrogate fitting</span>

        <span class="c1"># Handle multi-surrogate selection</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_surrogates_list&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_prob_surrogate</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_surrogates_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="c1"># Update active max surrogate points</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_active_max_surrogate_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_surrogate_points_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="c1"># Optional: print selected surrogate? separate from verbose maybe</span>
                <span class="k">pass</span>

        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">X_for_surrogate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_X</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fit_surrogate</span><span class="p">(</span><span class="n">X_for_surrogate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_for_surrogate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_X</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fit_surrogate</span><span class="p">(</span><span class="n">X_for_surrogate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_predict_with_uncertainty</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict with uncertainty estimates, handling surrogates without return_std.</span>
<span class="sd">        Used in the _acquisition_function() method and in the plot_surrogate() method.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: Input points, shape (n_samples, n_features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple of (predictions, std_deviations). If surrogate doesn&#39;t support</span>
<span class="sd">            return_std, returns predictions with zeros for std.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; from sklearn.gaussian_process import GaussianProcessRegressor</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     surrogate=GaussianProcessRegressor()</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X_train = np.array([[0, 0], [1, 1], [2, 2]])</span>
<span class="sd">            &gt;&gt;&gt; y_train = np.array([0, 2, 8])</span>
<span class="sd">            &gt;&gt;&gt; opt._fit_surrogate(X_train, y_train)</span>
<span class="sd">            &gt;&gt;&gt; X_test = np.array([[1.5, 1.5], [3.0, 3.0]])</span>
<span class="sd">            &gt;&gt;&gt; preds, stds = opt._predict_with_uncertainty(X_test)</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Predictions:&quot;, preds)</span>
<span class="sd">            Predictions: [4.5 9. ]</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Standard deviations:&quot;, stds)</span>
<span class="sd">            Standard deviations: [some values or zeros depending on surrogate]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Try to get uncertainty estimates</span>
            <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_std</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
            <span class="c1"># Surrogate doesn&#39;t support return_std (e.g., Random Forest, XGBoost)</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_std</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_acquisition_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute acquisition function value.</span>
<span class="sd">        Used in the suggest_next_infill_point() method.</span>

<span class="sd">        This implements &quot;Infill Criteria&quot; as described in Forrester et al. (2008),</span>
<span class="sd">        Section 3 &quot;Exploring and Exploiting&quot;.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (ndarray): Point to evaluate, shape (n_features,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: Acquisition function value (to be minimized).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; from sklearn.gaussian_process import GaussianProcessRegressor</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     surrogate=GaussianProcessRegressor(),</span>
<span class="sd">            ...     acquisition=&#39;ei&#39;</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X_train = np.array([[0, 0], [1, 1], [2, 2]])</span>
<span class="sd">            &gt;&gt;&gt; y_train = np.array([0, 2, 8])</span>
<span class="sd">            &gt;&gt;&gt; opt._fit_surrogate(X_train, y_train)</span>
<span class="sd">            &gt;&gt;&gt; x_eval = np.array([1.5, 1.5])</span>
<span class="sd">            &gt;&gt;&gt; acq_value = opt._acquisition_function(x_eval)</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Acquisition function value:&quot;, acq_value)</span>
<span class="sd">            Acquisition function value: [some float value]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition</span> <span class="o">==</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span>
            <span class="c1"># Predicted mean</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition</span> <span class="o">==</span> <span class="s2">&quot;ei&quot;</span><span class="p">:</span>
            <span class="c1"># Expected Improvement</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_with_uncertainty</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">sigma</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">0.0</span>

            <span class="n">y_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
            <span class="n">improvement</span> <span class="o">=</span> <span class="n">y_best</span> <span class="o">-</span> <span class="n">mu</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">improvement</span> <span class="o">/</span> <span class="n">sigma</span>
            <span class="n">ei</span> <span class="o">=</span> <span class="n">improvement</span> <span class="o">*</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">ei</span>  <span class="c1"># Minimize negative EI</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition</span> <span class="o">==</span> <span class="s2">&quot;pi&quot;</span><span class="p">:</span>
            <span class="c1"># Probability of Improvement</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_with_uncertainty</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">sigma</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">0.0</span>

            <span class="n">y_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_best</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span>
            <span class="n">pi</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">pi</span>  <span class="c1"># Minimize negative PI</span>

            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown acquisition function: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_optimize_acquisition_tricands</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimize using geometric infill strategy via triangulation candidates.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: The optimized point(s).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Requires points to work</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.random.rand(10, 2)</span>
<span class="sd">            &gt;&gt;&gt; x_next = opt._optimize_acquisition_tricands()</span>
<span class="sd">            &gt;&gt;&gt; x_next.shape[1] == 2</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Use X_ (all evaluated points) as basis for triangulation</span>
        <span class="c1"># If no points yet (e.g. before initial design), fallback to LHS or random</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;X_&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Not enough points for valid triangulation (need n &gt;= m + 1)</span>
            <span class="c1"># Fallback to random search using existing logic logic in &#39;else&#39; block or explicit call pass</span>
            <span class="c1"># Will fall through to &#39;else&#39; block which handles generic minimize/random x0</span>
            <span class="c1"># BUT &#39;tricands&#39; isn&#39;t a valid minimize method, so we should handle this fallback specifically.</span>
            <span class="c1"># Actually, let&#39;s just use random sampling here for fallback.</span>

            <span class="c1"># Fallback to random search using generate_uniform_design</span>
            <span class="c1"># Return size defaults to 1 unless specified</span>
            <span class="n">n_design</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_fun_return_size</span><span class="p">)</span>
            <span class="n">x0</span> <span class="o">=</span> <span class="n">generate_uniform_design</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span> <span class="n">n_design</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="p">)</span>

            <span class="c1"># If we requested ONLY 1 point, return expected shape (n_dim,) for flatten behavior</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_fun_return_size</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">x0</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">x0</span>

        <span class="c1"># Generate candidates</span>
        <span class="c1"># Default nmax to a reasonable multiple of desired return size, or just large enough</span>
        <span class="c1"># tricands handles nmax internally (default 100*m).</span>
        <span class="c1"># We pass nmax as max(100*m, acquisition_fun_return_size * 10) to ensure we have enough.</span>
        <span class="n">nmax</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_fun_return_size</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

        <span class="c1"># Wrapper for tricands: Normalize -&gt; Gen Candidates -&gt; Denormalize</span>
        <span class="c1"># This handles non-hypercube bounds correctly as tricands assumes [lower, upper]^m box.</span>

        <span class="c1"># Normalize X_ to [0, 1] relative to bounds</span>
        <span class="n">X_norm</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)</span>

        <span class="c1"># Generate candidates in [0, 1] space</span>
        <span class="n">X_cands_norm</span> <span class="o">=</span> <span class="n">tricands</span><span class="p">(</span>
            <span class="n">X_norm</span><span class="p">,</span> <span class="n">nmax</span><span class="o">=</span><span class="n">nmax</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">fringe</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tricands_fringe</span>
        <span class="p">)</span>

        <span class="c1"># Denormalize candidates back to original space</span>
        <span class="n">X_cands</span> <span class="o">=</span> <span class="n">X_cands_norm</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span>

        <span class="c1"># Evaluate acquisition function on all candidates</span>
        <span class="c1"># _acquisition_function returns NEGATIVE acquisition values (minimization)</span>
        <span class="c1"># We iterate to ensure correct handling of 1D/2D shapes by _acquisition_function</span>
        <span class="n">acq_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_acquisition_function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X_cands</span><span class="p">])</span>

        <span class="c1"># Sort indices (smallest is best because of negation)</span>
        <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">acq_values</span><span class="p">)</span>

        <span class="c1"># Select top n</span>
        <span class="n">top_n</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_fun_return_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_indices</span><span class="p">))</span>
        <span class="n">best_indices</span> <span class="o">=</span> <span class="n">sorted_indices</span><span class="p">[:</span><span class="n">top_n</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">X_cands</span><span class="p">[</span><span class="n">best_indices</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_prepare_de_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Prepare kwargs for differential_evolution, extracting options if necessary.&quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">acquisition_optimizer_kwargs</span> <span class="ow">or</span> <span class="p">{})</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># Extract &#39;options&#39; if present (compatibility with minimize structure)</span>
        <span class="k">if</span> <span class="s2">&quot;options&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;options&quot;</span><span class="p">],</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">options</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;options&quot;</span><span class="p">)</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>

        <span class="c1"># Define valid arguments for differential_evolution</span>
        <span class="n">valid_de_args</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;strategy&quot;</span><span class="p">,</span>
            <span class="s2">&quot;maxiter&quot;</span><span class="p">,</span>
            <span class="s2">&quot;popsize&quot;</span><span class="p">,</span>
            <span class="s2">&quot;tol&quot;</span><span class="p">,</span>
            <span class="s2">&quot;mutation&quot;</span><span class="p">,</span>
            <span class="s2">&quot;recombination&quot;</span><span class="p">,</span>
            <span class="s2">&quot;seed&quot;</span><span class="p">,</span>
            <span class="s2">&quot;callback&quot;</span><span class="p">,</span>
            <span class="s2">&quot;disp&quot;</span><span class="p">,</span>
            <span class="s2">&quot;polish&quot;</span><span class="p">,</span>
            <span class="s2">&quot;init&quot;</span><span class="p">,</span>
            <span class="s2">&quot;atol&quot;</span><span class="p">,</span>
            <span class="s2">&quot;updating&quot;</span><span class="p">,</span>
            <span class="s2">&quot;workers&quot;</span><span class="p">,</span>
            <span class="s2">&quot;constraints&quot;</span><span class="p">,</span>
            <span class="s2">&quot;x0&quot;</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Filter kwargs to only include valid DE arguments</span>
        <span class="c1"># This prevents errors when passing shared kwargs that contain</span>
        <span class="c1"># optimizer-specific options for the surrogate (e.g. &#39;gtol&#39; for L-BFGS-B)</span>
        <span class="n">filtered_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">valid_de_args</span><span class="p">}</span>

        <span class="c1"># Set defaults if not provided</span>
        <span class="k">if</span> <span class="s2">&quot;maxiter&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">filtered_kwargs</span><span class="p">:</span>
            <span class="n">filtered_kwargs</span><span class="p">[</span><span class="s2">&quot;maxiter&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span>

        <span class="k">return</span> <span class="n">filtered_kwargs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_optimize_acquisition_de</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimize using differential evolution.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: The optimized point(s).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Requires surrogate model and points to work effectively</span>
<span class="sd">            &gt;&gt;&gt; # but can run without them (will return randomish or best_x if set)</span>
<span class="sd">            &gt;&gt;&gt; x_next = opt._optimize_acquisition_de()</span>
<span class="sd">            &gt;&gt;&gt; x_next.shape[0] &gt;= 0</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Variables to capture population from callback</span>
        <span class="n">population</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">population_energies</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># with probability .5 select best_x_ as x0 or None</span>
        <span class="c1"># Determine which &quot;best&quot; to use</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;min_mean_X&quot;</span>
        <span class="p">):</span>
            <span class="n">best_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_X</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">best_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>

        <span class="k">if</span> <span class="n">best_x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">best_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_X</span><span class="p">(</span><span class="n">best_x</span><span class="p">)</span>
            <span class="n">best_X</span> <span class="o">=</span> <span class="n">best_x</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">de_x0_prob</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">best_X</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">callback</span><span class="p">(</span><span class="n">intermediate_result</span><span class="p">:</span> <span class="n">OptimizeResult</span><span class="p">):</span>
            <span class="k">nonlocal</span> <span class="n">population</span><span class="p">,</span> <span class="n">population_energies</span>
            <span class="c1"># Capture population if available (requires scipy &gt;= 1.10.0)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">intermediate_result</span><span class="p">,</span> <span class="s2">&quot;population&quot;</span><span class="p">):</span>
                <span class="n">population</span> <span class="o">=</span> <span class="n">intermediate_result</span><span class="o">.</span><span class="n">population</span>
                <span class="n">population_energies</span> <span class="o">=</span> <span class="n">intermediate_result</span><span class="o">.</span><span class="n">population_energies</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">differential_evolution</span><span class="p">(</span>
            <span class="n">func</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_acquisition_function</span><span class="p">,</span>
            <span class="n">bounds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="p">,</span>
            <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span>
            <span class="n">x0</span><span class="o">=</span><span class="n">best_X</span><span class="p">,</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_prepare_de_kwargs</span><span class="p">(</span><span class="n">best_X</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_fun_return_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">population</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">population_energies</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Sort by energy (ascending, since DE minimizes)</span>
                <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">population_energies</span><span class="p">)</span>

                <span class="c1"># Determine how many to take</span>
                <span class="n">top_n</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_fun_return_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_indices</span><span class="p">))</span>

                <span class="c1"># First candidate is always the polished result (best)</span>
                <span class="n">candidates</span> <span class="o">=</span> <span class="p">[</span><span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="p">]</span>

                <span class="c1"># Add remaining candidates from population (skipping the best unpolished one which corresponds to result.x)</span>
                <span class="k">if</span> <span class="n">top_n</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># Take next (top_n - 1) indices</span>
                    <span class="c1"># Start from 1 because 0 is the best unpolished</span>
                    <span class="n">next_indices</span> <span class="o">=</span> <span class="n">sorted_indices</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">top_n</span><span class="p">]</span>
                    <span class="n">candidates</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">population</span><span class="p">[</span><span class="n">next_indices</span><span class="p">])</span>

                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Fallback if population not available (e.g. very fast convergence or old scipy)</span>
                <span class="c1"># Just return the best point as 2D array</span>
                <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_optimize_acquisition_scipy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimize using scipy.optimize.minimize interface (default).</span>

<span class="sd">        Args:</span>
<span class="sd">            None</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: The optimized acquisition function values.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If acquisition optimizer is not a string or callable.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Define objective function</span>
<span class="sd">            &gt;&gt;&gt; def fun(x): return np.sum(x**2, axis=1)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Initialize optimizer with a scipy-compatible acquisition optimizer</span>
<span class="sd">            &gt;&gt;&gt; # Note: default is &#39;differential_evolution&#39; which uses a different method</span>
<span class="sd">            &gt;&gt;&gt; optimizer = SpotOptim(</span>
<span class="sd">            ...     fun=fun,</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     acquisition_optimizer=&quot;L-BFGS-B&quot;</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create some dummy data to fit the surrogate model</span>
<span class="sd">            &gt;&gt;&gt; X = np.array([[0.0, 0.0], [1.0, 1.0], [2.0, 2.0]])</span>
<span class="sd">            &gt;&gt;&gt; y = fun(X)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Fit the surrogate model manually</span>
<span class="sd">            &gt;&gt;&gt; # Note: this is normally handled inside optimize()</span>
<span class="sd">            &gt;&gt;&gt; optimizer._fit_surrogate(X, y)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Optimize the acquisition function using scipy&#39;s minimize</span>
<span class="sd">            &gt;&gt;&gt; x_next = optimizer._optimize_acquisition_scipy()</span>
<span class="sd">            &gt;&gt;&gt; x_next.shape</span>
<span class="sd">            (2,)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Use scipy.optimize.minimize interface</span>
        <span class="c1"># Generate random x0 within bounds</span>
        <span class="n">low</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">])</span>
        <span class="n">high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">])</span>
        <span class="c1"># Use persistent RNG</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_optimizer</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">acquisition_optimizer_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>

            <span class="c1"># Avoid duplicate method args if kwargs has it, but self.acquisition_optimizer is the primary source</span>
            <span class="c1"># However, if user passes kwargs={&#39;method&#39;: &#39;...&#39;}, it might conflict if acquisition_optimizer is also a string.</span>
            <span class="c1"># Strategy: self.acquisition_optimizer takes precedence if it&#39;s a specific string like &quot;L-BFGS-B&quot;</span>
            <span class="c1"># But wait, acquisition_optimizer default is &quot;differential_evolution&quot;.</span>
            <span class="c1"># If user sets acquisition_optimizer=&quot;Nelder-Mead&quot;, we use that.</span>

            <span class="n">run_kwargs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">if</span> <span class="s2">&quot;method&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">run_kwargs</span><span class="p">:</span>
                <span class="n">run_kwargs</span><span class="p">[</span><span class="s2">&quot;method&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_optimizer</span>

            <span class="c1"># Define valid arguments for minimize() (excluding fun, x0, bounds which we pass explicitly)</span>
            <span class="n">valid_minimize_args</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;args&quot;</span><span class="p">,</span>
                <span class="s2">&quot;method&quot;</span><span class="p">,</span>
                <span class="s2">&quot;jac&quot;</span><span class="p">,</span>
                <span class="s2">&quot;hess&quot;</span><span class="p">,</span>
                <span class="s2">&quot;hessp&quot;</span><span class="p">,</span>
                <span class="s2">&quot;constraints&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tol&quot;</span><span class="p">,</span>
                <span class="s2">&quot;callback&quot;</span><span class="p">,</span>
                <span class="s2">&quot;options&quot;</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="c1"># Move any argument that is NOT a valid minimize() argument into &#39;options&#39;</span>
            <span class="k">if</span> <span class="s2">&quot;options&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">run_kwargs</span><span class="p">:</span>
                <span class="n">run_kwargs</span><span class="p">[</span><span class="s2">&quot;options&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="n">keys_to_move</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">run_kwargs</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_minimize_args</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keys_to_move</span><span class="p">:</span>
                <span class="n">run_kwargs</span><span class="p">[</span><span class="s2">&quot;options&quot;</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">run_kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

            <span class="c1"># It&#39;s a method name for minimize (e.g. &quot;Nelder-Mead&quot;)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span>
                <span class="n">fun</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_acquisition_function</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span> <span class="o">**</span><span class="n">run_kwargs</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_optimizer</span><span class="p">):</span>
            <span class="c1"># It&#39;s a custom callable compatible with minimize</span>
            <span class="c1"># We pass kwargs if the callable supports it?</span>
            <span class="c1"># Safest is to just call it as before, or assume it handles kwargs if documented.</span>
            <span class="c1"># Let&#39;s pass kwargs if we can, but the standard protocol might not expect it.</span>
            <span class="c1"># We&#39;ll assume the callable is configured or wraps kwargs itself.</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_optimizer</span><span class="p">(</span>
                <span class="n">fun</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_acquisition_function</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unknown acquisition optimizer type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_optimizer</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Minimize-based optimizers typically return a single point</span>
        <span class="c1"># If acquisition_fun_return_size &gt; 1, we map to 2D array but only 1 unique point</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_fun_return_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_try_optimizer_candidates</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">n_needed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">current_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Try candidates proposed by the acquisition result optimizer.</span>

<span class="sd">        Args:</span>
<span class="sd">            n_needed (int): Number of candidates needed.</span>
<span class="sd">            current_batch (list): Points already selected in current iteration (to check distance against).</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[ndarray]: List of unique valid candidate points found.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">valid_candidates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">current_batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">current_batch</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Phase 1: Try candidates from acquisition function optimizer</span>
        <span class="c1"># These can be multiple if acquisition_fun_return_size &gt; 1</span>
        <span class="n">x_next_candidates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimize_acquisition_func</span><span class="p">()</span>

        <span class="c1"># Ensure iterable of 1D arrays</span>
        <span class="k">if</span> <span class="n">x_next_candidates</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">obs_candidates</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_next_candidates</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">obs_candidates</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">x_next_candidates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x_next_candidates</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="p">]</span>

        <span class="c1"># Combine existing points and previously found candidates for distance check</span>
        <span class="c1"># We need to check against (X_ + current_batch + valid_candidates)</span>
        <span class="c1"># _select_new checks against X passed to it.</span>
        <span class="c1"># We should construct the reference set once or update it.</span>

        <span class="n">X_transformed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_X</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">)</span>

        <span class="c1"># Helper to check if a point is valid</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">is_valid</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">reference_set</span><span class="p">):</span>
            <span class="n">p_rounded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># Check distance</span>
            <span class="n">p_2d</span> <span class="o">=</span> <span class="n">p_rounded</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># select_new returns subset of A that is distant from X</span>
            <span class="n">x_new</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_new</span><span class="p">(</span>
                <span class="n">A</span><span class="o">=</span><span class="n">p_2d</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">reference_set</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance_x</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">p_rounded</span> <span class="k">if</span> <span class="n">x_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x_next</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">obs_candidates</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_candidates</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">n_needed</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="c1"># Build current reference set: X_ + current_batch + valid_candidates_so_far</span>
            <span class="c1"># Note: This can be expensive if X_ is large, but n_infill is usually small.</span>
            <span class="n">ref_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_transformed</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">current_batch</span><span class="p">:</span>
                <span class="n">ref_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">current_batch</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">valid_candidates</span><span class="p">:</span>
                <span class="n">ref_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valid_candidates</span><span class="p">))</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ref_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">reference_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">ref_list</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">reference_set</span> <span class="o">=</span> <span class="n">ref_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">candidate</span> <span class="o">=</span> <span class="n">is_valid</span><span class="p">(</span><span class="n">x_next</span><span class="p">,</span> <span class="n">reference_set</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">candidate</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">valid_candidates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">candidate</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Optimizer candidate </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">obs_candidates</span><span class="p">)</span><span class="si">}</span><span class="s2"> was duplicate/invalid.&quot;</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">valid_candidates</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_handle_acquisition_failure</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Handle acquisition failure by proposing new design points.</span>
<span class="sd">        Used in the suggest_next_infill_point() method.</span>

<span class="sd">        This method is called when no new design points can be suggested</span>
<span class="sd">        by the surrogate model (e.g., when the proposed point is too close</span>
<span class="sd">        to existing points). It proposes a random space-filling design as a fallback.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: New design point as a fallback, shape (n_features,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     acquisition_failure_strategy=&#39;random&#39;</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.array([[0, 0], [1, 1]])</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.array([0, 2])</span>
<span class="sd">            &gt;&gt;&gt; x_fallback = opt._handle_acquisition_failure()</span>
<span class="sd">            &gt;&gt;&gt; x_fallback.shape</span>
<span class="sd">            (2,)</span>
<span class="sd">            &gt;&gt;&gt; print(x_fallback)</span>
<span class="sd">            [some new point within bounds]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_failure_strategy</span> <span class="o">==</span> <span class="s2">&quot;random&quot;</span><span class="p">:</span>
            <span class="c1"># Default: random space-filling design (Latin Hypercube Sampling)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;Acquisition failure: Using random space-filling design as fallback.&quot;</span>
                <span class="p">)</span>
            <span class="n">x_new_unit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">x_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span> <span class="o">+</span> <span class="n">x_new_unit</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">x_new</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_try_fallback_strategy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">max_attempts</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">current_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Try fallback strategy (e.g. random search) to find a unique point.</span>
<span class="sd">        Calls _handle_acquisition_failure.</span>

<span class="sd">        Args:</span>
<span class="sd">            max_attempts (int): Maximum number of fallback attempts.</span>
<span class="sd">            current_batch (list): Points already selected in current iteration.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[Optional[ndarray], ndarray]:</span>
<span class="sd">                - The first element is the unique valid candidate point if found, else None.</span>
<span class="sd">                - The second element is the last attempted point.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x_last</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">current_batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">current_batch</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">X_transformed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_X</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">)</span>
        <span class="c1"># Build reference set once if possible or dynamically</span>
        <span class="c1"># Since fallback is random, we check against X + current_batch</span>

        <span class="k">for</span> <span class="n">attempt</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_attempts</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Fallback attempt </span><span class="si">{</span><span class="n">attempt</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">max_attempts</span><span class="si">}</span><span class="s2">: Using fallback strategy&quot;</span>
                <span class="p">)</span>
            <span class="n">x_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_acquisition_failure</span><span class="p">()</span>

            <span class="n">x_next_rounded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span>
                <span class="n">x_next</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">x_last</span> <span class="o">=</span> <span class="n">x_next_rounded</span>

            <span class="n">x_next_2d</span> <span class="o">=</span> <span class="n">x_next_rounded</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Reference set</span>
            <span class="n">ref_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_transformed</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_batch</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">ref_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">current_batch</span><span class="p">))</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ref_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">reference_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">ref_list</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">reference_set</span> <span class="o">=</span> <span class="n">ref_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">x_new</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_new</span><span class="p">(</span>
                <span class="n">A</span><span class="o">=</span><span class="n">x_next_2d</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">reference_set</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance_x</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">x_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">x_next_rounded</span><span class="p">,</span> <span class="n">x_last</span>

        <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="n">x_last</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the shape of the objective function output.</span>

<span class="sd">        Args:</span>
<span class="sd">            y (ndarray): Objective function output, shape (n_samples,) or (n_samples, n_objectives).</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: (n_samples, n_objectives) where n_objectives is None for single-objective.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; y_single = np.array([1.0, 2.0, 3.0])</span>
<span class="sd">            &gt;&gt;&gt; n, m = opt._get_shape(y_single)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;n={n}, m={m}&quot;)</span>
<span class="sd">            n=3, m=None</span>
<span class="sd">            &gt;&gt;&gt; y_multi = np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])</span>
<span class="sd">            &gt;&gt;&gt; n, m = opt._get_shape(y_multi)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;n={n}, m={m}&quot;)</span>
<span class="sd">            n=3, m=2</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For higher dimensions, flatten to 1D</span>
            <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_store_mo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_mo</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Store multi-objective values in self.y_mo.</span>

<span class="sd">        If multi-objective values are present (ndim==2), they are stored in self.y_mo.</span>
<span class="sd">        New values are appended to existing ones. For single-objective problems,</span>
<span class="sd">        self.y_mo remains None.</span>

<span class="sd">        Args:</span>
<span class="sd">            y_mo (ndarray): If multi-objective, shape (n_samples, n_objectives).</span>
<span class="sd">                           If single-objective, shape (n_samples,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.column_stack([</span>
<span class="sd">            ...         np.sum(X**2, axis=1),</span>
<span class="sd">            ...         np.sum((X-1)**2, axis=1)</span>
<span class="sd">            ...     ]),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; y_mo_1 = np.array([[1.0, 2.0], [3.0, 4.0]])</span>
<span class="sd">            &gt;&gt;&gt; opt._store_mo(y_mo_1)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;y_mo after first call: {opt.y_mo}&quot;)</span>
<span class="sd">            y_mo after first call: [[1. 2.]</span>
<span class="sd">             [3. 4.]]</span>
<span class="sd">            &gt;&gt;&gt; y_mo_2 = np.array([[5.0, 6.0], [7.0, 8.0]])</span>
<span class="sd">            &gt;&gt;&gt; opt._store_mo(y_mo_2)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;y_mo after second call: {opt.y_mo}&quot;)</span>
<span class="sd">            y_mo after second call: [[1. 2.]</span>
<span class="sd">             [3. 4.]</span>
<span class="sd">             [5. 6.]</span>
<span class="sd">             [7. 8.]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Store y_mo in self.y_mo (append new values) if multi-objective</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_mo</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="o">=</span> <span class="n">y_mo</span>
        <span class="k">elif</span> <span class="n">y_mo</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span><span class="p">,</span> <span class="n">y_mo</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_mo2so</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_mo</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert multi-objective values to single-objective.</span>

<span class="sd">        Converts multi-objective values to a single-objective value by applying a user-defined</span>
<span class="sd">        function from `fun_mo2so`. If no user-defined function is given, the</span>
<span class="sd">        values in the first objective column are used.</span>

<span class="sd">        This method is called after the objective function evaluation. It returns a 1D array</span>
<span class="sd">        with the single-objective values.</span>

<span class="sd">        Args:</span>
<span class="sd">            y_mo (ndarray): If multi-objective, shape (n_samples, n_objectives).</span>
<span class="sd">                           If single-objective, shape (n_samples,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Single-objective values, shape (n_samples,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Multi-objective function</span>
<span class="sd">            &gt;&gt;&gt; def mo_fun(X):</span>
<span class="sd">            ...     return np.column_stack([</span>
<span class="sd">            ...         np.sum(X**2, axis=1),</span>
<span class="sd">            ...         np.sum((X-1)**2, axis=1)</span>
<span class="sd">            ...     ])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 1: Default behavior (use first objective)</span>
<span class="sd">            &gt;&gt;&gt; opt1 = SpotOptim(</span>
<span class="sd">            ...     fun=mo_fun,</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; y_mo = np.array([[1.0, 2.0], [3.0, 4.0]])</span>
<span class="sd">            &gt;&gt;&gt; y_so = opt1._mo2so(y_mo)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Single-objective (default): {y_so}&quot;)</span>
<span class="sd">            Single-objective (default): [1. 3.]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 2: Custom conversion function (sum of objectives)</span>
<span class="sd">            &gt;&gt;&gt; def custom_mo2so(y_mo):</span>
<span class="sd">            ...     return y_mo[:, 0] + y_mo[:, 1]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; opt2 = SpotOptim(</span>
<span class="sd">            ...     fun=mo_fun,</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     fun_mo2so=custom_mo2so</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; y_so_custom = opt2._mo2so(y_mo)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Single-objective (custom): {y_so_custom}&quot;)</span>
<span class="sd">            Single-objective (custom): [3. 7.]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_shape</span><span class="p">(</span><span class="n">y_mo</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_store_mo</span><span class="p">(</span><span class="n">y_mo</span><span class="p">)</span>

        <span class="c1"># Use ndim to check if multi-objective</span>
        <span class="k">if</span> <span class="n">y_mo</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fun_mo2so</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Apply user-defined conversion function</span>
                <span class="n">y0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fun_mo2so</span><span class="p">(</span><span class="n">y_mo</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Default: use first column</span>
                <span class="k">if</span> <span class="n">y_mo</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">y0</span> <span class="o">=</span> <span class="n">y_mo</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">y0</span> <span class="o">=</span> <span class="n">y_mo</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Single-objective, return as-is</span>
            <span class="n">y0</span> <span class="o">=</span> <span class="n">y_mo</span>

        <span class="k">return</span> <span class="n">y0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_ranks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns ranks of numbers within input array x.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (ndarray): Input array.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Ranks array where ranks[i] is the rank of x[i].</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1), bounds=[(-5, 5)])</span>
<span class="sd">            &gt;&gt;&gt; opt._get_ranks(np.array([2, 1]))</span>
<span class="sd">            array([1, 0])</span>
<span class="sd">            &gt;&gt;&gt; opt._get_ranks(np.array([20, 10, 100]))</span>
<span class="sd">            array([1, 0, 2])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ts</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">argsort</span><span class="p">()</span>
        <span class="n">ranks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span>
        <span class="n">ranks</span><span class="p">[</span><span class="n">ts</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ranks</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_ocba</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">means</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">vars</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">delta</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimal Computing Budget Allocation (OCBA).</span>

<span class="sd">        Calculates budget recommendations for given means, variances, and incremental</span>
<span class="sd">        budget using the OCBA algorithm.</span>

<span class="sd">        References:</span>
<span class="sd">            [1] Chun-Hung Chen and Loo Hay Lee: Stochastic Simulation Optimization:</span>
<span class="sd">                An Optimal Computer Budget Allocation, pp. 49 and pp. 215</span>

<span class="sd">        Args:</span>
<span class="sd">            means (ndarray): Array of means.</span>
<span class="sd">            vars (ndarray): Array of variances.</span>
<span class="sd">            delta (int): Incremental budget.</span>
<span class="sd">            verbose (bool): If True, print debug information. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Array of budget recommendations, or None if conditions not met.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1), bounds=[(-5, 5)])</span>
<span class="sd">            &gt;&gt;&gt; means = np.array([1, 2, 3, 4, 5])</span>
<span class="sd">            &gt;&gt;&gt; vars = np.array([1, 1, 9, 9, 4])</span>
<span class="sd">            &gt;&gt;&gt; allocations = opt._get_ocba(means, vars, 50)</span>
<span class="sd">            &gt;&gt;&gt; allocations</span>
<span class="sd">            array([11,  9, 19,  9,  2])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="nb">vars</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">):</span>
            <span class="n">n_designs</span> <span class="o">=</span> <span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">allocations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_designs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">ratios</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_designs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">budget</span> <span class="o">=</span> <span class="n">delta</span>
            <span class="n">ranks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_ranks</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>
            <span class="n">best</span><span class="p">,</span> <span class="n">second_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">ranks</span><span class="p">,</span> <span class="mi">2</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">ratios</span><span class="p">[</span><span class="n">second_best</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="n">select</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_designs</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">best</span><span class="p">,</span> <span class="n">second_best</span><span class="p">]]</span>
            <span class="n">temp</span> <span class="o">=</span> <span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="n">best</span><span class="p">]</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="n">second_best</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="n">best</span><span class="p">]</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="n">select</span><span class="p">])</span>
            <span class="n">ratios</span><span class="p">[</span><span class="n">select</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="nb">vars</span><span class="p">[</span><span class="n">select</span><span class="p">]</span> <span class="o">/</span> <span class="nb">vars</span><span class="p">[</span><span class="n">second_best</span><span class="p">])</span>
            <span class="n">select</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_designs</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">best</span><span class="p">]]</span>
            <span class="n">temp</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">ratios</span><span class="p">[</span><span class="n">select</span><span class="p">])</span> <span class="o">/</span> <span class="nb">vars</span><span class="p">[</span><span class="n">select</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">ratios</span><span class="p">[</span><span class="n">best</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">vars</span><span class="p">[</span><span class="n">best</span><span class="p">]</span> <span class="o">*</span> <span class="n">temp</span><span class="p">)</span>
            <span class="n">more_runs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_designs</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="n">add_budget</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_designs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
            <span class="n">more_alloc</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">In _get_ocba():&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;means: </span><span class="si">{</span><span class="n">means</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;vars: </span><span class="si">{</span><span class="nb">vars</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;delta: </span><span class="si">{</span><span class="n">delta</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_designs: </span><span class="si">{</span><span class="n">n_designs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ratios: </span><span class="si">{</span><span class="n">ratios</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best: </span><span class="si">{</span><span class="n">best</span><span class="si">}</span><span class="s2">, Second best: </span><span class="si">{</span><span class="n">second_best</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">while</span> <span class="n">more_alloc</span><span class="p">:</span>
                <span class="n">more_alloc</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">ratio_s</span> <span class="o">=</span> <span class="p">(</span><span class="n">more_runs</span> <span class="o">*</span> <span class="n">ratios</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="n">add_budget</span><span class="p">[</span><span class="n">more_runs</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">budget</span> <span class="o">/</span> <span class="n">ratio_s</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratios</span><span class="p">[</span><span class="n">more_runs</span><span class="p">]</span>
                <span class="n">add_budget</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">add_budget</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">add_budget</span> <span class="o">&lt;</span> <span class="n">allocations</span>
                <span class="n">add_budget</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">allocations</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
                <span class="n">more_runs</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">more_alloc</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">more_alloc</span><span class="p">:</span>
                    <span class="n">budget</span> <span class="o">=</span> <span class="n">allocations</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">delta</span>
                    <span class="n">budget</span> <span class="o">-=</span> <span class="p">(</span><span class="n">add_budget</span> <span class="o">*</span> <span class="o">~</span><span class="n">more_runs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">t_budget</span> <span class="o">=</span> <span class="n">add_budget</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="c1"># Adjust the best design to match the exact delta</span>
            <span class="c1"># Ensure we don&#39;t go below current allocations</span>
            <span class="n">adjustment</span> <span class="o">=</span> <span class="n">allocations</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">delta</span> <span class="o">-</span> <span class="n">t_budget</span>
            <span class="n">add_budget</span><span class="p">[</span><span class="n">best</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">allocations</span><span class="p">[</span><span class="n">best</span><span class="p">],</span> <span class="n">add_budget</span><span class="p">[</span><span class="n">best</span><span class="p">]</span> <span class="o">+</span> <span class="n">adjustment</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">add_budget</span> <span class="o">-</span> <span class="n">allocations</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_ocba_X</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">means</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="nb">vars</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">delta</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate OCBA allocation and repeat input array X.</span>
<span class="sd">        Used in the optimize() method to generate new design points based on OCBA.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Input array to be repeated, shape (n_designs, n_features).</span>
<span class="sd">            means (ndarray): Array of means for each design.</span>
<span class="sd">            vars (ndarray): Array of variances for each design.</span>
<span class="sd">            delta (int): Incremental budget.</span>
<span class="sd">            verbose (bool): If True, print debug information. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Repeated array of X based on OCBA allocation, or None if</span>
<span class="sd">                     conditions not met.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1), bounds=[(-5, 5)])</span>
<span class="sd">            &gt;&gt;&gt; X = np.array([[1, 2], [4, 5], [7, 8]])</span>
<span class="sd">            &gt;&gt;&gt; means = np.array([1.5, 35, 550])</span>
<span class="sd">            &gt;&gt;&gt; vars = np.array([0.5, 50, 5000])</span>
<span class="sd">            &gt;&gt;&gt; X_new = opt._get_ocba_X(X, means, vars, delta=5, verbose=False)</span>
<span class="sd">            &gt;&gt;&gt; X_new.shape[0] == 5  # Should have 5 additional evaluations</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="nb">vars</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">):</span>
            <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_ocba</span><span class="p">(</span><span class="n">means</span><span class="o">=</span><span class="n">means</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="nb">vars</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="n">delta</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_evaluate_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate objective function at points X.</span>
<span class="sd">        Used in the optimize() method to evaluate the objective function.</span>

<span class="sd">        **Input Space**: `X` is expected in **Transformed and Mapped Space** (Internal scale, Reduced dimensions).</span>
<span class="sd">        **Process**:</span>
<span class="sd">        1. Expands `X` to **Transformed Space** (Full dimensions) if dimension reduction is active.</span>
<span class="sd">        2. Inverse transforms `X` to **Natural Space** (Original scale).</span>
<span class="sd">        3. Evaluates the user function with points in **Natural Space**.</span>

<span class="sd">        If dimension reduction is active, expands X to full dimensions before evaluation.</span>
<span class="sd">        Supports both single-objective and multi-objective functions. For multi-objective</span>
<span class="sd">        functions, converts to single-objective using _mo2so method.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Points to evaluate in **Transformed and Mapped Space**, shape (n_samples, n_reduced_features).</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Function values, shape (n_samples,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Single-objective function</span>
<span class="sd">            &gt;&gt;&gt; opt_so = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X = np.array([[1.0, 2.0], [3.0, 4.0]])</span>
<span class="sd">            &gt;&gt;&gt; y = opt_so._evaluate_function(X)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Single-objective output: {y}&quot;)</span>
<span class="sd">            Single-objective output: [ 5. 25.]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Multi-objective function (default: use first objective)</span>
<span class="sd">            &gt;&gt;&gt; opt_mo = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.column_stack([</span>
<span class="sd">            ...         np.sum(X**2, axis=1),</span>
<span class="sd">            ...         np.sum((X-1)**2, axis=1)</span>
<span class="sd">            ...     ]),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     n_initial=5</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; y_mo = opt_mo._evaluate_function(X)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Multi-objective output (first obj): {y_mo}&quot;)</span>
<span class="sd">            Multi-objective output (first obj): [ 5. 25.]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Ensure X is 2D</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Expand to full dimensions if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Apply inverse transformations to get original scale for function evaluation</span>
        <span class="n">X_original</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse_transform_X</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Map factor variables to original string values</span>
        <span class="n">X_for_eval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_to_factor_values</span><span class="p">(</span><span class="n">X_original</span><span class="p">)</span>

        <span class="c1"># Evaluate function</span>
        <span class="n">y_raw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fun</span><span class="p">(</span><span class="n">X_for_eval</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Convert to numpy array if needed</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_raw</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">y_raw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y_raw</span><span class="p">])</span>

        <span class="c1"># Handle multi-objective case</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mo2so</span><span class="p">(</span><span class="n">y_raw</span><span class="p">)</span>

        <span class="c1"># Ensure y is 1D</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">y</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_select_distant_points</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Selects k points that are distant from each other using K-means clustering.</span>

<span class="sd">        This method performs K-means clustering to find k clusters, then selects</span>
<span class="sd">        the point closest to each cluster center. This ensures a space-filling</span>
<span class="sd">        subset of points for surrogate model training.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design points, shape (n_samples, n_features).</span>
<span class="sd">            y (ndarray): Function values at X, shape (n_samples,).</span>
<span class="sd">            k (int): Number of points to select.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - selected_X (ndarray): Selected design points, shape (k, n_features).</span>
<span class="sd">                - selected_y (ndarray): Function values at selected points, shape (k,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_surrogate_points=5)</span>
<span class="sd">            &gt;&gt;&gt; X = np.random.rand(100, 2)</span>
<span class="sd">            &gt;&gt;&gt; y = np.random.rand(100)</span>
<span class="sd">            &gt;&gt;&gt; X_sel, y_sel = opt._select_distant_points(X, y, 5)</span>
<span class="sd">            &gt;&gt;&gt; X_sel.shape</span>
<span class="sd">            (5, 2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Perform k-means clustering</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Find the closest point to each cluster center</span>
        <span class="n">selected_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">center</span> <span class="ow">in</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">:</span>
            <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">center</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">closest_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
            <span class="n">selected_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">closest_idx</span><span class="p">)</span>

        <span class="n">selected_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">selected_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="n">selected_indices</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">selected_indices</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_select_best_cluster</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Selects all points from the cluster with the smallest mean y value.</span>

<span class="sd">        This method performs K-means clustering and selects all points from the</span>
<span class="sd">        cluster whose center corresponds to the best (smallest) mean objective</span>
<span class="sd">        function value.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design points, shape (n_samples, n_features).</span>
<span class="sd">            y (ndarray): Function values at X, shape (n_samples,).</span>
<span class="sd">            k (int): Number of clusters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - selected_X (ndarray): Selected design points from best cluster, shape (m, n_features).</span>
<span class="sd">                - selected_y (ndarray): Function values at selected points, shape (m,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_surrogate_points=5,</span>
<span class="sd">            ...                 selection_method=&#39;best&#39;)</span>
<span class="sd">            &gt;&gt;&gt; X = np.random.rand(100, 2)</span>
<span class="sd">            &gt;&gt;&gt; y = np.random.rand(100)</span>
<span class="sd">            &gt;&gt;&gt; X_sel, y_sel = opt._select_best_cluster(X, y, 5)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Perform k-means clustering</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

        <span class="c1"># Compute mean y for each cluster</span>
        <span class="n">cluster_means</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">cluster_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
            <span class="n">cluster_y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">cluster_idx</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cluster_y</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">cluster_means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cluster_means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cluster_y</span><span class="p">))</span>

        <span class="c1"># Find cluster with smallest mean y</span>
        <span class="n">best_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">cluster_means</span><span class="p">)</span>

        <span class="c1"># Select all points from the best cluster</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">==</span> <span class="n">best_cluster</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_selection_dispatcher</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Dispatcher for selection methods.</span>

<span class="sd">        Depending on the value of `self.selection_method`, this method calls</span>
<span class="sd">        the appropriate selection function to choose a subset of points for</span>
<span class="sd">        surrogate model training when the total number of points exceeds</span>
<span class="sd">        `self.max_surrogate_points`.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design points, shape (n_samples, n_features).</span>
<span class="sd">            y (ndarray): Function values at X, shape (n_samples,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - selected_X (ndarray): Selected design points.</span>
<span class="sd">                - selected_y (ndarray): Function values at selected points.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_surrogate_points=5)</span>
<span class="sd">            &gt;&gt;&gt; X = np.random.rand(100, 2)</span>
<span class="sd">            &gt;&gt;&gt; y = np.random.rand(100)</span>
<span class="sd">            &gt;&gt;&gt; X_sel, y_sel = opt._selection_dispatcher(X, y)</span>
<span class="sd">            &gt;&gt;&gt; X_sel.shape[0] &lt;= 5</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Resolve active max points</span>
        <span class="n">max_k</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_active_max_surrogate_points&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_surrogate_points</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">max_k</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">selection_method</span> <span class="o">==</span> <span class="s2">&quot;distant&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_distant_points</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">max_k</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">selection_method</span> <span class="o">==</span> <span class="s2">&quot;best&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_best_cluster</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">max_k</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If no valid selection method, return all points</span>
            <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">select_new</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Select rows from A that are not in X.</span>
<span class="sd">        Used in suggest_next_infill_point() to avoid duplicate evaluations.</span>

<span class="sd">        Args:</span>
<span class="sd">            A (ndarray): Array with new values.</span>
<span class="sd">            X (ndarray): Array with known values.</span>
<span class="sd">            tolerance (float, optional): Tolerance value for comparison. Defaults to 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - ndarray: Array with unknown (new) values.</span>
<span class="sd">                - ndarray: Array with True if value is new, otherwise False.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1), bounds=[(-5, 5)])</span>
<span class="sd">            &gt;&gt;&gt; A = np.array([[1, 2], [3, 4], [5, 6]])</span>
<span class="sd">            &gt;&gt;&gt; X = np.array([[3, 4], [7, 8]])</span>
<span class="sd">            &gt;&gt;&gt; new_A, is_new = opt.select_new(A, X)</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;New A:&quot;, new_A)</span>
<span class="sd">            New A: [[1 2]</span>
<span class="sd">             [5 6]]</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Is new:&quot;, is_new)</span>
<span class="sd">            Is new: [ True False  True]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>

        <span class="c1"># Calculate distances using the configured metric</span>
        <span class="c1"># cdist supports &#39;euclidean&#39;, &#39;minkowski&#39;, &#39;chebyshev&#39;, etc.</span>
        <span class="c1"># Note: &#39;chebyshev&#39; is closest to the previous logic but checks absolute difference on all coords</span>
        <span class="c1"># Previous logic: np.all(np.abs(diff) &lt;= tolerance) -&gt; Chebyshev &lt;= tolerance</span>
        <span class="n">dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_tol_metric</span><span class="p">)</span>

        <span class="c1"># Check if min distance to any existing point is &lt;= tolerance (duplicate)</span>
        <span class="c1"># Duplicate if ANY existing point is within tolerance</span>
        <span class="c1"># is_duplicate[i] is True if A[i] is close to at least one point in X</span>
        <span class="n">is_duplicate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">dists</span> <span class="o">&lt;=</span> <span class="n">tolerance</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">ind</span> <span class="o">=</span> <span class="n">is_duplicate</span>
        <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="o">~</span><span class="n">ind</span><span class="p">],</span> <span class="o">~</span><span class="n">ind</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">optimize_acquisition_func</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Optimize the acquisition function to find the next point to evaluate.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: The optimized point(s).</span>
<span class="sd">                If acquisition_fun_return_size == 1, returns 1D array of shape (n_features,).</span>
<span class="sd">                If acquisition_fun_return_size &gt; 1, returns 2D array of shape (N, n_features),</span>
<span class="sd">                where N is min(acquisition_fun_return_size, population_size).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     acquisition=&#39;ei&#39;</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X_train = np.array([[0, 0], [1, 1], [2, 2]])</span>
<span class="sd">            &gt;&gt;&gt; y_train = np.array([0, 2, 8])</span>
<span class="sd">            &gt;&gt;&gt; opt._fit_surrogate(X_train, y_train)</span>
<span class="sd">            &gt;&gt;&gt; x_next = opt.optimize_acquisition_func()</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Next point to evaluate:&quot;, x_next)</span>
<span class="sd">            Next point to evaluate: [some float values]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_optimizer</span> <span class="o">==</span> <span class="s2">&quot;tricands&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_acquisition_tricands</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_optimizer</span> <span class="o">==</span> <span class="s2">&quot;differential_evolution&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_acquisition_de</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_optimizer</span> <span class="o">==</span> <span class="s2">&quot;de_tricands&quot;</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">val</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob_de_tricands</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_acquisition_de</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_acquisition_tricands</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_acquisition_scipy</span><span class="p">()</span>

    <span class="c1"># ====================</span>
    <span class="c1"># Optimization Loop</span>
    <span class="c1"># ====================</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_optimize_run_task</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">timeout_start</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">X0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">y0_known_val</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
        <span class="n">max_iter_override</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">shared_best_y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Accept shared value</span>
        <span class="n">shared_lock</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Accept shared lock</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">OptimizeResult</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper to run a single optimization task with a specific seed. Calls _optimize_single_run.</span>

<span class="sd">        Args:</span>
<span class="sd">            seed (int): Seed for this run.</span>
<span class="sd">            timeout_start (float): Start time for timeout.</span>
<span class="sd">            X0 (Optional[np.ndarray]): Initial design points in Natural Space, shape (n_initial, n_features).</span>
<span class="sd">            y0_known_val (Optional[float]): Known best value for initial design.</span>
<span class="sd">            max_iter_override (Optional[int]): Override for maximum number of iterations.</span>
<span class="sd">            shared_best_y (Optional[float]): Shared best value for parallel runs.</span>
<span class="sd">            shared_lock (Optional[Lock]): Shared lock for parallel runs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[str, OptimizeResult]: Tuple containing status and optimization result.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Set the seed for this run</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_seed</span><span class="p">()</span>

        <span class="c1"># Re-initialize LHS sampler with new seed to ensure diversity in initial design</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;n_dim&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lhs_sampler</span> <span class="o">=</span> <span class="n">LatinHypercube</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_single_run</span><span class="p">(</span>
            <span class="n">timeout_start</span><span class="p">,</span>
            <span class="n">X0</span><span class="p">,</span>
            <span class="n">y0_known</span><span class="o">=</span><span class="n">y0_known_val</span><span class="p">,</span>
            <span class="n">max_iter_override</span><span class="o">=</span><span class="n">max_iter_override</span><span class="p">,</span>
            <span class="n">shared_best_y</span><span class="o">=</span><span class="n">shared_best_y</span><span class="p">,</span>
            <span class="n">shared_lock</span><span class="o">=</span><span class="n">shared_lock</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizeResult</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run the optimization process.</span>

<span class="sd">        The optimization terminates when either:</span>
<span class="sd">        - Total function evaluations reach max_iter (including initial design), OR</span>
<span class="sd">        - Runtime exceeds max_time minutes</span>

<span class="sd">        Input/Output Spaces:</span>
<span class="sd">        - Input X0: Expected in Natural Space (original scale, physical units).</span>
<span class="sd">        - Output result.x: Returned in Natural Space.</span>
<span class="sd">        - Output result.X: Returned in Natural Space.</span>
<span class="sd">        - Internal Optimization: Performed in Transformed and Mapped Space.</span>

<span class="sd">        Args:</span>
<span class="sd">            X0 (ndarray, optional): Initial design points in Natural Space, shape (n_initial, n_features).</span>
<span class="sd">                If None, generates space-filling design. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            OptimizeResult: Optimization result with fields:</span>
<span class="sd">                - x: best point found in Natural Space</span>
<span class="sd">                - fun: best function value</span>
<span class="sd">                - nfev: number of function evaluations (including initial design)</span>
<span class="sd">                - nit: number of sequential optimization iterations (after initial design)</span>
<span class="sd">                - success: whether optimization succeeded</span>
<span class="sd">                - message: termination message indicating reason for stopping, including</span>
<span class="sd">                  statistics (function value, iterations, evaluations)</span>
<span class="sd">                - X: all evaluated points in Natural Space</span>
<span class="sd">                - y: all function values</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     max_iter=20,</span>
<span class="sd">            ...     seed=0,</span>
<span class="sd">            ...     x0=np.array([0.0, 0.0]),</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; print(result.message.splitlines()[0])</span>
<span class="sd">            Optimization terminated: maximum evaluations (20) reached</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Best point:&quot;, result.x)</span>
<span class="sd">            Best point: [0. 0.]</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Best value:&quot;, result.fun)</span>
<span class="sd">            Best value: 0.0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Track results across restarts for final aggregation.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Capture start time for timeout enforcement.</span>
        <span class="n">timeout_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Initial run state.</span>
        <span class="n">current_X0</span> <span class="o">=</span> <span class="n">X0</span>
        <span class="n">status</span> <span class="o">=</span> <span class="s2">&quot;START&quot;</span>

        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1"># Get best result so far if we have results</span>
            <span class="n">best_res</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span>
                <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>

            <span class="c1"># Compute injected best value for restarts, then run one optimization cycle.</span>
            <span class="c1"># y0_known_val carries the current global best objective so the next</span>
            <span class="c1"># run can skip re-evaluating that known point when restart injection is on.</span>
            <span class="n">y0_known_val</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">best_res</span><span class="o">.</span><span class="n">fun</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;RESTART&quot;</span>
                    <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">restart_inject_best</span>
                    <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span>
                <span class="p">)</span>
                <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>

            <span class="c1"># Calculate remaining budget</span>
            <span class="n">total_evals_so_far</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">)</span>
            <span class="n">remaining_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">-</span> <span class="n">total_evals_so_far</span>

            <span class="c1"># If we don&#39;t have enough budget for at least initial design (or some minimal amount), stop</span>
            <span class="k">if</span> <span class="n">remaining_iter</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Global budget exhausted. Stopping restarts.&quot;</span><span class="p">)</span>
                <span class="k">break</span>

            <span class="c1"># Execute one optimization run using the remaining budget; dispatcher</span>
            <span class="c1"># selects sequential vs parallel based on `n_jobs` and returns status/result.</span>
            <span class="n">status</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_optimization_run</span><span class="p">(</span>
                <span class="n">timeout_start</span><span class="p">,</span>
                <span class="n">current_X0</span><span class="p">,</span>
                <span class="n">y0_known</span><span class="o">=</span><span class="n">y0_known_val</span><span class="p">,</span>
                <span class="n">max_iter_override</span><span class="o">=</span><span class="n">remaining_iter</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;FINISHED&quot;</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="k">elif</span> <span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;RESTART&quot;</span><span class="p">:</span>
                <span class="c1"># Prepare for a clean restart: let get_initial_design() regenerate the full design.</span>
                <span class="n">current_X0</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="c1"># Find the global best result across completed restarts.</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">:</span>
                    <span class="n">best_res</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">r</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restart_inject_best</span><span class="p">:</span>
                        <span class="c1"># Inject the current global best into the next run&#39;s initial design.</span>
                        <span class="c1"># best_res.x is in natural scale; _validate_x0 converts to internal scale</span>
                        <span class="c1"># so the injected point can be mixed with LHS samples.</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_x0</span><span class="p">(</span><span class="n">best_res</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
                        <span class="c1"># Keep current_X0 unset so the initial design is rebuilt around the injected x0.</span>
                        <span class="n">current_X0</span> <span class="o">=</span> <span class="kc">None</span>

                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Restart injection: Using best found point so far as starting point (f(x)=</span><span class="si">{</span><span class="n">best_res</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">).&quot;</span>
                            <span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># In sequential mode we advance the seed between restarts to diversify the LHS.</span>
                    <span class="c1"># Parallel mode increments seeds per worker during dispatch.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="c1"># Continue loop</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Should not happen</span>
                <span class="k">break</span>

        <span class="c1"># Return best result</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span>  <span class="c1"># Fallback</span>

        <span class="c1"># Find best result based on &#39;fun&#39;</span>
        <span class="n">best_result</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">r</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>

        <span class="c1"># Merge results from all parallel runs (and sequential runs if any)</span>
        <span class="n">X_all_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">res</span><span class="o">.</span><span class="n">X</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">]</span>
        <span class="n">y_all_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">res</span><span class="o">.</span><span class="n">y</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">]</span>

        <span class="c1"># Concatenate all evaluations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">X_all_list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">y_all_list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

        <span class="c1"># Aggregated iterations (sum of all runs)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="s2">&quot;nit&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">)</span>

        <span class="c1"># Update best solution found</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="o">=</span> <span class="n">best_result</span><span class="o">.</span><span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="o">=</span> <span class="n">best_result</span><span class="o">.</span><span class="n">fun</span>

        <span class="k">return</span> <span class="n">best_result</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_execute_optimization_run</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">timeout_start</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">X0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">y0_known</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_iter_override</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">shared_best_y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># New arg</span>
        <span class="n">shared_lock</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># New arg</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">OptimizeResult</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Dispatcher for optimization run (Sequential vs Steady-State Parallel).</span>
<span class="sd">        Depending on n_jobs, calls _optimize_steady_state (n_jobs &gt; 1) or _optimize_sequential_run (n_jobs == 1).</span>

<span class="sd">        Args:</span>
<span class="sd">            timeout_start (float): Start time for timeout.</span>
<span class="sd">            X0 (Optional[np.ndarray]): Initial design points in Natural Space, shape (n_initial, n_features).</span>
<span class="sd">            y0_known (Optional[float]): Known best value for initial design.</span>
<span class="sd">            max_iter_override (Optional[int]): Override for maximum number of iterations.</span>
<span class="sd">            shared_best_y (Optional[float]): Shared best value for parallel runs.</span>
<span class="sd">            shared_lock (Optional[Lock]): Shared lock for parallel runs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[str, OptimizeResult]: Tuple containing status and optimization result.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import time</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     max_iter=20,</span>
<span class="sd">            ...     seed=0,</span>
<span class="sd">            ...     n_jobs=1,  # Use sequential optimization for deterministic output</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; status, result = opt._execute_optimization_run(timeout_start=time.time())</span>
<span class="sd">            &gt;&gt;&gt; print(status)</span>
<span class="sd">            FINISHED</span>
<span class="sd">            &gt;&gt;&gt; print(result.message.splitlines()[0])</span>
<span class="sd">            Optimization terminated: maximum evaluations (20) reached</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Dispatch to steady-state optimizer if proper parallelization is requested</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_steady_state</span><span class="p">(</span>
                <span class="n">timeout_start</span><span class="p">,</span>
                <span class="n">X0</span><span class="p">,</span>
                <span class="n">y0_known</span><span class="o">=</span><span class="n">y0_known</span><span class="p">,</span>
                <span class="n">max_iter_override</span><span class="o">=</span><span class="n">max_iter_override</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_sequential_run</span><span class="p">(</span>
                <span class="n">timeout_start</span><span class="p">,</span>
                <span class="n">X0</span><span class="p">,</span>
                <span class="n">y0_known</span><span class="o">=</span><span class="n">y0_known</span><span class="p">,</span>
                <span class="n">max_iter_override</span><span class="o">=</span><span class="n">max_iter_override</span><span class="p">,</span>
                <span class="n">shared_best_y</span><span class="o">=</span><span class="n">shared_best_y</span><span class="p">,</span>
                <span class="n">shared_lock</span><span class="o">=</span><span class="n">shared_lock</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_optimize_sequential_run</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">timeout_start</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">X0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">y0_known</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_iter_override</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">shared_best_y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">shared_lock</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">OptimizeResult</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform a single sequential optimization run.</span>
<span class="sd">        Calls _initialize_run, _rm_NA_values, _check_size_initial_design, _init_storage, _get_best_xy_initial_design, and _run_sequential_loop.</span>


<span class="sd">        Args:</span>
<span class="sd">            timeout_start (float): Start time for timeout.</span>
<span class="sd">            X0 (Optional[np.ndarray]): Initial design points in Natural Space, shape (n_initial, n_features).</span>
<span class="sd">            y0_known (Optional[float]): Known best value for initial design.</span>
<span class="sd">            max_iter_override (Optional[int]): Override for maximum number of iterations.</span>
<span class="sd">            shared_best_y (Optional[float]): Shared best value for parallel runs.</span>
<span class="sd">            shared_lock (Optional[Lock]): Shared lock for parallel runs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[str, OptimizeResult]: Tuple containing status and optimization result.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the initial design has no valid points after removing NaN/inf values, or if the initial design is too small to proceed.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import time</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     max_iter=20,</span>
<span class="sd">            ...     seed=0,</span>
<span class="sd">            ...     n_jobs=1,  # Use sequential optimization for deterministic output</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; status, result = opt._optimize_sequential_run(timeout_start=time.time())</span>
<span class="sd">            &gt;&gt;&gt; print(status)</span>
<span class="sd">            FINISHED</span>
<span class="sd">            &gt;&gt;&gt; print(result.message.splitlines()[0])</span>
<span class="sd">            Optimization terminated: maximum evaluations (20) reached</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Store shared variable if provided</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shared_best_y</span> <span class="o">=</span> <span class="n">shared_best_y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shared_lock</span> <span class="o">=</span> <span class="n">shared_lock</span>

        <span class="c1"># Initialize: Set seed, Design, Evaluate Initial Design, Init Storage &amp; TensorBoard</span>
        <span class="n">X0</span><span class="p">,</span> <span class="n">y0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_run</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="n">y0_known</span><span class="p">)</span>

        <span class="c1"># Handle NaN/inf values in initial design (remove invalid points)</span>
        <span class="n">X0</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">n_evaluated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rm_NA_values</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="n">y0</span><span class="p">)</span>

        <span class="c1"># Check if we have enough valid points to continue</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_size_initial_design</span><span class="p">(</span><span class="n">y0</span><span class="p">,</span> <span class="n">n_evaluated</span><span class="p">)</span>

        <span class="c1"># Initialize storage and statistics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_storage</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="n">y0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_zero_success_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Clear success history for new run</span>

        <span class="c1"># Update stats after initial design</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_stats</span><span class="p">()</span>

        <span class="c1"># Log initial design to TensorBoard</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_tensorboard</span><span class="p">()</span>

        <span class="c1"># Determine and report initial best</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_best_xy_initial_design</span><span class="p">()</span>

        <span class="c1"># Run the main sequential optimization loop</span>
        <span class="n">effective_max_iter</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">max_iter_override</span> <span class="k">if</span> <span class="n">max_iter_override</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_sequential_loop</span><span class="p">(</span><span class="n">timeout_start</span><span class="p">,</span> <span class="n">effective_max_iter</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_run</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">y0_known</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize optimization run: seed, design generation, initial evaluation.</span>
<span class="sd">        Called from _optimize_sequential_run.</span>

<span class="sd">        Args:</span>
<span class="sd">            X0 (Optional[np.ndarray]): Initial design points in Natural Space, shape (n_initial, n_features).</span>
<span class="sd">            y0_known (Optional[float]): Known best value for initial design.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[np.ndarray, np.ndarray]: Tuple containing initial design and corresponding objective values.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the initial design has no valid points after removing NaN/inf values, or if the initial design is too small to proceed.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     seed=0,</span>
<span class="sd">            ...     x0=np.array([0.0, 0.0]),</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; X0, y0 = opt._initialize_run(X0=None, y0_known=None)</span>
<span class="sd">            &gt;&gt;&gt; X0.shape</span>
<span class="sd">            (5, 2)</span>
<span class="sd">            &gt;&gt;&gt; np.allclose(y0, np.sum(X0**2, axis=1))</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Set seed for reproducibility</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_seed</span><span class="p">()</span>

        <span class="c1"># Set initial design (generate or process user-provided points)</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_initial_design</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>

        <span class="c1"># Curate initial design (remove duplicates, generate additional points if needed, repeat if necessary)</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_curate_initial_design</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>

        <span class="c1"># Evaluate initial design</span>
        <span class="k">if</span> <span class="n">y0_known</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Identify injected point to skip evaluation</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Use a small tolerance for matching</span>
            <span class="n">matches</span> <span class="o">=</span> <span class="n">dists</span> <span class="o">&lt;</span> <span class="mf">1e-9</span>

            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">matches</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Skipping re-evaluation of injected best point.&quot;</span><span class="p">)</span>

                <span class="c1"># Initialize y0</span>
                <span class="n">y0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X0</span><span class="p">))</span>
                <span class="n">y0</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

                <span class="c1"># Set known values</span>
                <span class="n">y0</span><span class="p">[</span><span class="n">matches</span><span class="p">]</span> <span class="o">=</span> <span class="n">y0_known</span>

                <span class="c1"># Evaluate others</span>
                <span class="n">not_matches</span> <span class="o">=</span> <span class="o">~</span><span class="n">matches</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">not_matches</span><span class="p">):</span>
                    <span class="n">y0_others</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_function</span><span class="p">(</span><span class="n">X0</span><span class="p">[</span><span class="n">not_matches</span><span class="p">])</span>
                    <span class="n">y0</span><span class="p">[</span><span class="n">not_matches</span><span class="p">]</span> <span class="o">=</span> <span class="n">y0_others</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Injected point lost during curation? Should not happen if it was unique</span>
                <span class="n">y0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_function</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_function</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X0</span><span class="p">,</span> <span class="n">y0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_run_sequential_loop</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">timeout_start</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">effective_max_iter</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">OptimizeResult</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute the main sequential optimization loop.</span>

<span class="sd">        Args:</span>
<span class="sd">             timeout_start (float): Start time for timeout.</span>
<span class="sd">             effective_max_iter (int): Maximum number of iterations for this run (may be overridden for restarts).</span>

<span class="sd">         Returns:</span>
<span class="sd">             Tuple[str, OptimizeResult]: Tuple containing status and optimization result.</span>

<span class="sd">         Raises:</span>
<span class="sd">             ValueError:</span>
<span class="sd">                If excessive consecutive failures occur (e.g., due to NaN/inf values in evaluations), indicating a potential issue with the objective function.</span>

<span class="sd">         Examples:</span>
<span class="sd">             &gt;&gt;&gt; import time</span>
<span class="sd">             &gt;&gt;&gt; import numpy as np</span>
<span class="sd">             &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">             &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">             ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">             ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">             ...     n_initial=5,</span>
<span class="sd">             ...     max_iter=20,</span>
<span class="sd">             ...     seed=0,</span>
<span class="sd">             ...     n_jobs=1,  # Use sequential optimization for deterministic output</span>
<span class="sd">             ...     verbose=True</span>
<span class="sd">             ... )</span>
<span class="sd">             &gt;&gt;&gt; X0, y0 = opt._initialize_run(X0=None, y0_known=None)</span>
<span class="sd">             &gt;&gt;&gt; X0, y0, n_evaluated = opt._rm_NA_values(X0, y0)</span>
<span class="sd">             &gt;&gt;&gt; opt._check_size_initial_design(y0, n_evaluated)</span>
<span class="sd">             &gt;&gt;&gt; opt._init_storage(X0, y0)</span>
<span class="sd">             &gt;&gt;&gt; opt._zero_success_count = 0</span>
<span class="sd">             &gt;&gt;&gt; opt._success_history = []</span>
<span class="sd">             &gt;&gt;&gt; opt.update_stats()</span>
<span class="sd">             &gt;&gt;&gt; opt._get_best_xy_initial_design()</span>
<span class="sd">             &gt;&gt;&gt; status, result = opt._run_sequential_loop(timeout_start=time.time(), effective_max_iter=20)</span>
<span class="sd">             &gt;&gt;&gt; print(status)</span>
<span class="sd">             FINISHED</span>
<span class="sd">             &gt;&gt;&gt; print(result.message.splitlines()[0])</span>
<span class="sd">             Optimization terminated: maximum evaluations (20) reached</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">consecutive_failures</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">while</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">effective_max_iter</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">timeout_start</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">*</span> <span class="mi">60</span>
        <span class="p">):</span>
            <span class="c1"># Check for excessive consecutive failures (infinite loop prevention)</span>
            <span class="k">if</span> <span class="n">consecutive_failures</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Optimization stopped due to </span><span class="si">{</span><span class="n">consecutive_failures</span><span class="si">}</span><span class="s2"> consecutive &quot;</span>
                    <span class="s2">&quot;invalid evaluations (NaN/inf). Check your objective function.&quot;</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="s2">&quot;FINISHED&quot;</span><span class="p">,</span> <span class="n">OptimizeResult</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span><span class="p">,</span>
                    <span class="n">fun</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="p">,</span>
                    <span class="n">nfev</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">),</span>
                    <span class="n">nit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="p">,</span>
                    <span class="n">success</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">,</span>
                    <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="c1"># Increment iteration counter. This is not the same as number of function evaluations.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Fit surrogate (use mean_y if noise, otherwise y_)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fit_scheduler</span><span class="p">()</span>

            <span class="c1"># Apply OCBA for noisy functions</span>
            <span class="n">X_ocba</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_ocba</span><span class="p">()</span>

            <span class="c1"># Suggest next point</span>
            <span class="n">x_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">suggest_next_infill_point</span><span class="p">()</span>

            <span class="c1"># Repeat next point if repeats_surrogate &gt; 1</span>
            <span class="n">x_next_repeated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_repeats_infill_points</span><span class="p">(</span><span class="n">x_next</span><span class="p">)</span>

            <span class="c1"># Append OCBA points to new design points (if applicable)</span>
            <span class="k">if</span> <span class="n">X_ocba</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">x_next_repeated</span> <span class="o">=</span> <span class="n">append</span><span class="p">(</span><span class="n">X_ocba</span><span class="p">,</span> <span class="n">x_next_repeated</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Evaluate next point(s) including OCBA points</span>
            <span class="n">y_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_function</span><span class="p">(</span><span class="n">x_next_repeated</span><span class="p">)</span>

            <span class="c1"># Handle NaN/inf values in new evaluations</span>
            <span class="n">x_next_repeated</span><span class="p">,</span> <span class="n">y_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_NA_new_points</span><span class="p">(</span>
                <span class="n">x_next_repeated</span><span class="p">,</span> <span class="n">y_next</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">x_next_repeated</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">consecutive_failures</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">continue</span>  <span class="c1"># Skip iteration if all evaluations were invalid</span>

            <span class="c1"># Reset failure counter if we got valid points</span>
            <span class="n">consecutive_failures</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Update success rate BEFORE updating storage (so it compares against previous best)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_success_rate</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>

            <span class="c1"># Check for restart</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">success_rate</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_zero_success_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_zero_success_count</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_zero_success_count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">restart_after_n</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Restarting optimization: success_rate 0 for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_zero_success_count</span><span class="si">}</span><span class="s2"> iterations.&quot;</span>
                    <span class="p">)</span>

                <span class="n">status_message</span> <span class="o">=</span> <span class="s2">&quot;Restart triggered due to lack of improvement.&quot;</span>

                <span class="c1"># Expand results to full dimensions if needed</span>
                <span class="n">best_x_full</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>
                <span class="p">)</span>
                <span class="n">X_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span>

                <span class="c1"># Map factor variables back to original strings</span>
                <span class="n">best_x_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_to_factor_values</span><span class="p">(</span><span class="n">best_x_full</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span>
                    <span class="mi">0</span>
                <span class="p">]</span>
                <span class="n">X_result</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_map_to_factor_values</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span> <span class="k">else</span> <span class="n">X_full</span>
                <span class="p">)</span>

                <span class="n">res</span> <span class="o">=</span> <span class="n">OptimizeResult</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">best_x_result</span><span class="p">,</span>
                    <span class="n">fun</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="p">,</span>
                    <span class="n">nfev</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">),</span>
                    <span class="n">nit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="p">,</span>
                    <span class="n">success</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">message</span><span class="o">=</span><span class="n">status_message</span><span class="p">,</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X_result</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="s2">&quot;RESTART&quot;</span><span class="p">,</span> <span class="n">res</span>

            <span class="c1"># Update storage</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_storage</span><span class="p">(</span><span class="n">x_next_repeated</span><span class="p">,</span> <span class="n">y_next</span><span class="p">)</span>

            <span class="c1"># Update stats</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_stats</span><span class="p">()</span>

            <span class="c1"># Log to TensorBoard</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Log each new evaluation</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_next</span><span class="p">)):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_hparams</span><span class="p">(</span><span class="n">x_next_repeated</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_next</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_scalars</span><span class="p">()</span>

            <span class="c1"># Update best solution</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_best_main_loop</span><span class="p">(</span>
                <span class="n">x_next_repeated</span><span class="p">,</span> <span class="n">y_next</span><span class="p">,</span> <span class="n">start_time</span><span class="o">=</span><span class="n">timeout_start</span>
            <span class="p">)</span>

        <span class="c1"># Expand results to full dimensions if needed</span>
        <span class="c1"># Note: best_x_ and X_ are already in original scale (stored that way)</span>
        <span class="n">best_x_full</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span>
            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>
        <span class="p">)</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span>

        <span class="c1"># Determine termination reason</span>
        <span class="n">status_message</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_determine_termination</span><span class="p">(</span><span class="n">timeout_start</span><span class="p">)</span>

        <span class="c1"># Append statistics to match scipy.optimize.minimize format</span>
        <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">status_message</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;         Current function value: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;         Iterations: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;         Function evaluations: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="c1"># Close TensorBoard writer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_close_tensorboard_writer</span><span class="p">()</span>

        <span class="c1"># Map factor variables back to original strings for results</span>
        <span class="n">best_x_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_to_factor_values</span><span class="p">(</span><span class="n">best_x_full</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">X_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_to_factor_values</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span> <span class="k">else</span> <span class="n">X_full</span>

        <span class="c1"># Return scipy-style result</span>
        <span class="k">return</span> <span class="s2">&quot;FINISHED&quot;</span><span class="p">,</span> <span class="n">OptimizeResult</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">best_x_result</span><span class="p">,</span>
            <span class="n">fun</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="p">,</span>
            <span class="n">nfev</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">),</span>
            <span class="n">nit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="p">,</span>
            <span class="n">success</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X_result</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_update_storage_steady</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper to safely append single point (for steady state).</span>

<span class="sd">            This method is designed for the steady-state parallel optimization scenario, where new points are evaluated and returned asynchronously.</span>
<span class="sd">            It safely appends new points to the existing storage of evaluated points and their function values,</span>
<span class="sd">            while also updating the current best solution if the new point is better.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (ndarray):</span>
<span class="sd">                New point(s) in original scale, shape (n_features,) or (N, n_features).</span>
<span class="sd">            y (float or ndarray):</span>
<span class="sd">                Corresponding function value(s).</span>

<span class="sd">        Returns:</span>
<span class="sd">            None. This method updates the internal state of the optimizer.</span>

<span class="sd">        Note:</span>
<span class="sd">           - This method assumes that the caller handles any necessary synchronization if used in a parallel context</span>
<span class="sd">           (e.g., using locks when updating shared state).</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the input shapes are inconsistent or if y is not a scalar when x is a single point.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_jobs=2</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; opt._update_storage_steady(np.array([1.0, 2.0]), 5.0)</span>
<span class="sd">            &gt;&gt;&gt; print(opt.X_)</span>
<span class="sd">            [[1. 2.]]</span>
<span class="sd">            &gt;&gt;&gt; print(opt.y_)</span>
<span class="sd">            [5.]</span>
<span class="sd">            &gt;&gt;&gt; print(opt.best_x_)</span>
<span class="sd">            [1. 2.]</span>
<span class="sd">            &gt;&gt;&gt; print(opt.best_y_)</span>
<span class="sd">            5.0</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">x</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="n">x</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># Update best</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="o">=</span> <span class="n">y</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">min_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_optimize_steady_state</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">timeout_start</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">X0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">y0_known</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_iter_override</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">OptimizeResult</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform steady-state asynchronous optimization (n_jobs &gt; 1).</span>

<span class="sd">        This method implements a steady-state parallelization strategy:</span>

<span class="sd">        1.  Parallel Initial Design:</span>
<span class="sd">            The first class of `n_initial * repeats_initial` runs are managed by the executor.</span>
<span class="sd">            The first `n_jobs` are sent to separate processors. If the first job is ready,</span>
<span class="sd">            its result is returned and the next of the initial design runs is dispatched.</span>
<span class="sd">            This is continued until all `n_initial * repeats_initial` runs have returned their values.</span>

<span class="sd">        2.  First Surrogate Fit:</span>
<span class="sd">            The first surrogate model is built (fitted) using the `n_initial * repeats_initial` evaluations</span>
<span class="sd">            collected in step 1.</span>

<span class="sd">        3.  Parallel Search:</span>
<span class="sd">            `n_jobs` searches (optimizations) on this surrogate are initially performed in parallel.</span>

<span class="sd">        4.  Steady-State Loop:</span>
<span class="sd">            - If a Search task is ready, the candidate point `x_cand` is immediately sent to the evaluation function to get `y_new`.</span>
<span class="sd">            - As soon as `y_new` is available, the surrogate is fitted again (including the new `x_cand`, `y_new`).</span>
<span class="sd">            - A new Search task is dispatched with this continuously updated model.</span>
<span class="sd">            - This cycle ensures the surrogate is continuously updated as new points are available.</span>

<span class="sd">        The optimization terminates when either:</span>
<span class="sd">        - Total function evaluations reach `max_iter` (including initial design), OR</span>
<span class="sd">        - Runtime exceeds `max_time` minutes</span>

<span class="sd">        Args:</span>
<span class="sd">            timeout_start (float): Start time for timeout.</span>
<span class="sd">            X0 (Optional[np.ndarray]): Initial design points in Natural Space, shape (n_initial, n_features).</span>
<span class="sd">            y0_known (Optional[float]): Known best value for initial design.</span>
<span class="sd">            max_iter_override (Optional[int]): Override for maximum number of iterations.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If all initial design evaluations fail, likely due to pickling issues or missing imports in the worker process.</span>
<span class="sd">            The error message provides guidance on how to address this issue.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[str, OptimizeResult]: Tuple containing status and optimization result.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import time</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     max_iter=10,</span>
<span class="sd">            ...     seed=0,</span>
<span class="sd">            ...     n_jobs=2,  # Use parallel optimization</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; status, result = opt._optimize_steady_state(timeout_start=time.time(), X0=None)</span>
<span class="sd">            &gt;&gt;&gt; print(status)</span>
<span class="sd">            FINISHED</span>
<span class="sd">            &gt;&gt;&gt; print(result.message.splitlines()[0])</span>
<span class="sd">            Optimization finished (Steady State)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Setup similar to _optimize_single_run</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_seed</span><span class="p">()</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_initial_design</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_curate_initial_design</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>

        <span class="c1"># We need to know how many evaluations to do</span>
        <span class="n">effective_max_iter</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">max_iter_override</span> <span class="k">if</span> <span class="n">max_iter_override</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span>
        <span class="p">)</span>

        <span class="c1"># Import dill locally (assuming installed)</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">dill</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProcessPoolExecutor</span><span class="p">,</span> <span class="n">wait</span><span class="p">,</span> <span class="n">FIRST_COMPLETED</span>

        <span class="k">with</span> <span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
            <span class="n">futures</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># map future -&gt; type (&#39;eval&#39;, &#39;search&#39;)</span>

            <span class="c1"># --- Phase 1: Initial Design Evaluation ---</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Submitted </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span><span class="si">}</span><span class="s2"> initial points for parallel evaluation...&quot;</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X0</span><span class="p">):</span>
                <span class="c1"># Dump args using dill</span>
                <span class="c1"># Temporarily remove tb_writer (not picklable)</span>
                <span class="n">_tb_writer_temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">pickled_args</span> <span class="o">=</span> <span class="n">dill</span><span class="o">.</span><span class="n">dumps</span><span class="p">((</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
                <span class="k">finally</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="n">_tb_writer_temp</span>

                <span class="n">fut</span> <span class="o">=</span> <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">_remote_eval_wrapper</span><span class="p">,</span> <span class="n">pickled_args</span><span class="p">)</span>
                <span class="n">futures</span><span class="p">[</span><span class="n">fut</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;eval&quot;</span>

            <span class="c1"># Wait for all initial to complete</span>
            <span class="n">initial_done_count</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="n">initial_done_count</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X0</span><span class="p">):</span>
                <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">wait</span><span class="p">(</span><span class="n">futures</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">return_when</span><span class="o">=</span><span class="n">FIRST_COMPLETED</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">fut</span> <span class="ow">in</span> <span class="n">done</span><span class="p">:</span>
                    <span class="c1"># Clean up</span>
                    <span class="n">ftype</span> <span class="o">=</span> <span class="n">futures</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">fut</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">ftype</span> <span class="o">!=</span> <span class="s2">&quot;eval&quot;</span><span class="p">:</span>
                        <span class="k">continue</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">x_done</span><span class="p">,</span> <span class="n">y_done</span> <span class="o">=</span> <span class="n">fut</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_done</span><span class="p">,</span> <span class="ne">Exception</span><span class="p">):</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Eval failed: </span><span class="si">{</span><span class="n">y_done</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_update_storage_steady</span><span class="p">(</span><span class="n">x_done</span><span class="p">,</span> <span class="n">y_done</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                    <span class="n">initial_done_count</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Init tensorboard and stats</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_tensorboard</span><span class="p">()</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;All initial design evaluations failed. &quot;</span>
                    <span class="s2">&quot;Check your objective function for pickling issues or missing imports (e.g. numpy) in the worker process. &quot;</span>
                    <span class="s2">&quot;If defining functions in a notebook/script, ensure imports are inside the function.&quot;</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">update_stats</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_get_best_xy_initial_design</span><span class="p">()</span>

            <span class="c1"># Fit first surrogate</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Initial design evaluated. Fitting surrogate... (Data size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fit_scheduler</span><span class="p">()</span>

            <span class="c1"># --- Phase 2: Steady State Loop ---</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting steady-state optimization loop...&quot;</span><span class="p">)</span>

            <span class="k">while</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">effective_max_iter</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">timeout_start</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">*</span> <span class="mi">60</span>
            <span class="p">):</span>
                <span class="c1"># 1. Fill slots - launch/dispatch</span>
                <span class="n">n_active</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">futures</span><span class="p">)</span>
                <span class="n">n_slots</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">-</span> <span class="n">n_active</span>

                <span class="k">if</span> <span class="n">n_slots</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_slots</span><span class="p">):</span>
                        <span class="n">n_pending_evals</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
                            <span class="mi">1</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">futures</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="s2">&quot;eval&quot;</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">+</span> <span class="n">n_pending_evals</span> <span class="o">&lt;</span> <span class="n">effective_max_iter</span><span class="p">:</span>
                            <span class="c1"># Dumpt optimizer (self) using dill</span>
                            <span class="c1"># Note: self can be large, but it&#39;s the only way to send state reliably with dill</span>
                            <span class="c1"># We must temporarily remove tb_writer as it is not picklable</span>
                            <span class="n">_tb_writer_temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="kc">None</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">pickled_opt</span> <span class="o">=</span> <span class="n">dill</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                            <span class="k">finally</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="n">_tb_writer_temp</span>

                            <span class="n">fut</span> <span class="o">=</span> <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">_remote_search_task</span><span class="p">,</span> <span class="n">pickled_opt</span><span class="p">)</span>
                            <span class="n">futures</span><span class="p">[</span><span class="n">fut</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;search&quot;</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">break</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="n">futures</span><span class="p">:</span>
                    <span class="k">break</span>  <span class="c1"># Done</span>

                <span class="c1"># 2. Wait for completion</span>
                <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">wait</span><span class="p">(</span><span class="n">futures</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">return_when</span><span class="o">=</span><span class="n">FIRST_COMPLETED</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">fut</span> <span class="ow">in</span> <span class="n">done</span><span class="p">:</span>
                    <span class="n">ftype</span> <span class="o">=</span> <span class="n">futures</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">fut</span><span class="p">)</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">res</span> <span class="o">=</span> <span class="n">fut</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="ne">Exception</span><span class="p">):</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Remote </span><span class="si">{</span><span class="n">ftype</span><span class="si">}</span><span class="s2"> failed: </span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                            <span class="c1"># If search failed, we just retry loop (next iter will check slots)</span>
                            <span class="c1"># If eval failed, we unfortunately lost a budget count unless we don&#39;t count it?</span>
                            <span class="c1"># Current logic counts evaluations in self.y_ only if successful.</span>
                            <span class="c1"># So failed eval means budget not consumed, will retry.</span>
                            <span class="k">continue</span>

                        <span class="k">if</span> <span class="n">ftype</span> <span class="o">==</span> <span class="s2">&quot;search&quot;</span><span class="p">:</span>
                            <span class="n">x_cand</span> <span class="o">=</span> <span class="n">res</span>
                            <span class="c1"># Submit Eval immediately</span>
                            <span class="n">_tb_writer_temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="kc">None</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">pickled_args</span> <span class="o">=</span> <span class="n">dill</span><span class="o">.</span><span class="n">dumps</span><span class="p">((</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_cand</span><span class="p">))</span>
                            <span class="k">finally</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="n">_tb_writer_temp</span>

                            <span class="n">fut_eval</span> <span class="o">=</span> <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span>
                                <span class="n">_remote_eval_wrapper</span><span class="p">,</span> <span class="n">pickled_args</span>
                            <span class="p">)</span>
                            <span class="n">futures</span><span class="p">[</span><span class="n">fut_eval</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;eval&quot;</span>

                        <span class="k">elif</span> <span class="n">ftype</span> <span class="o">==</span> <span class="s2">&quot;eval&quot;</span><span class="p">:</span>
                            <span class="n">x_new</span><span class="p">,</span> <span class="n">y_new</span> <span class="o">=</span> <span class="n">res</span>
                            <span class="c1"># Update</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_update_success_rate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y_new</span><span class="p">]))</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_update_storage_steady</span><span class="p">(</span><span class="n">x_new</span><span class="p">,</span> <span class="n">y_new</span><span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">+=</span> <span class="mi">1</span>

                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                                <span class="c1"># Calculate progress</span>
                                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
                                    <span class="n">prog_val</span> <span class="o">=</span> <span class="p">(</span>
                                        <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">timeout_start</span><span class="p">)</span>
                                        <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
                                        <span class="o">*</span> <span class="mi">100</span>
                                    <span class="p">)</span>
                                    <span class="n">progress_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Time: </span><span class="si">{</span><span class="n">prog_val</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span>
                                <span class="k">else</span><span class="p">:</span>
                                    <span class="n">prog_val</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">/</span> <span class="n">effective_max_iter</span> <span class="o">*</span> <span class="mi">100</span>
                                    <span class="n">progress_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Evals: </span><span class="si">{</span><span class="n">prog_val</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span>

                                <span class="nb">print</span><span class="p">(</span>
                                    <span class="sa">f</span><span class="s2">&quot;Iter </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">effective_max_iter</span><span class="si">}</span><span class="s2"> | &quot;</span>
                                    <span class="sa">f</span><span class="s2">&quot;Best: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> | &quot;</span>
                                    <span class="sa">f</span><span class="s2">&quot;Curr: </span><span class="si">{</span><span class="n">y_new</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> | &quot;</span>
                                    <span class="sa">f</span><span class="s2">&quot;Rate: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">success_rate</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> | &quot;</span>
                                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">progress_str</span><span class="si">}</span><span class="s2">&quot;</span>
                                <span class="p">)</span>

                            <span class="c1"># Refit surrogate</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_fit_scheduler</span><span class="p">()</span>

                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error processing future: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="s2">&quot;FINISHED&quot;</span><span class="p">,</span> <span class="n">OptimizeResult</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span><span class="p">,</span>
            <span class="n">fun</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="p">,</span>
            <span class="n">nfev</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">),</span>
            <span class="n">nit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="p">,</span>
            <span class="n">success</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">message</span><span class="o">=</span><span class="s2">&quot;Optimization finished (Steady State)&quot;</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">suggest_next_infill_point</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Suggest next point to evaluate (dispatcher).</span>

<span class="sd">        The returned point is in the **Transformed and Mapped Space** (Internal Optimization Space).</span>
<span class="sd">        This means:</span>
<span class="sd">        1. Transformations (e.g., log, sqrt) have been applied.</span>
<span class="sd">        2. Dimension reduction has been applied (fixed variables removed).</span>

<span class="sd">        Process:</span>
<span class="sd">        1. Try candidates from acquisition function optimizer.</span>
<span class="sd">        2. Handle acquisition failure (fallback).</span>
<span class="sd">        3. Return last attempt if all fails.</span>


<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Next point(s) to evaluate in **Transformed and Mapped Space**.</span>
<span class="sd">            Shape is (n_infill_points, n_features).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     n_infill_points=2</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Need to initialize optimization state (X_, y_, surrogate)</span>
<span class="sd">            &gt;&gt;&gt; # Normally done inside optimize()</span>
<span class="sd">            &gt;&gt;&gt; np.random.seed(0)</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.random.rand(10, 2)</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.random.rand(10)</span>
<span class="sd">            &gt;&gt;&gt; opt._fit_surrogate(opt.X_, opt.y_)</span>
<span class="sd">            &gt;&gt;&gt; x_next = opt.suggest_next_infill_point()</span>
<span class="sd">            &gt;&gt;&gt; x_next.shape</span>
<span class="sd">            (2, 2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># 1. Optimizer candidates</span>
        <span class="n">candidates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">opt_candidates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_optimizer_candidates</span><span class="p">(</span>
            <span class="n">n_needed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_infill_points</span><span class="p">,</span> <span class="n">current_batch</span><span class="o">=</span><span class="n">candidates</span>
        <span class="p">)</span>
        <span class="n">candidates</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">opt_candidates</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_infill_points</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span>

        <span class="c1"># 2. Try fallback strategy to fill remaining slots</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_infill_points</span><span class="p">:</span>
            <span class="c1"># Just try one attempt at a time but loop</span>
            <span class="c1"># We pass current batch to avoid dups</span>
            <span class="n">cand</span><span class="p">,</span> <span class="n">x_last</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_fallback_strategy</span><span class="p">(</span>
                <span class="n">max_attempts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">current_batch</span><span class="o">=</span><span class="n">candidates</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">cand</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">candidates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cand</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Fallback failed to find unique point even after retries</span>
                <span class="c1"># Break and fill with last attempts or just return what we have?</span>
                <span class="c1"># If we return partial batch, we might fail downstream if code expects n points?</span>
                <span class="c1"># Actually code should handle any number of points returned by this method?</span>
                <span class="c1"># Or duplicate valid points?</span>
                <span class="c1"># Warn and use duplicate if absolutely necessary?</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="s2">&quot;Warning: Could not fill all infill points with unique candidates.&quot;</span>
                    <span class="p">)</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span>

        <span class="c1"># 3. Return last attempt (duplicate) if absolutely nothing found</span>
        <span class="c1"># This returns a single point (1, d).</span>
        <span class="c1"># Should we return n copies?</span>
        <span class="c1"># If n_infill_points &gt; 1, we should probably output (n, d)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;Warning: Could not find unique point after optimization candidates and fallback attempts. &quot;</span>
                <span class="s2">&quot;Returning last candidate (duplicate).&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Verify x_last is not None</span>
        <span class="k">if</span> <span class="n">x_last</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Should practically not happen</span>
            <span class="n">x_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_acquisition_failure</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">x_next</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Return duplicated x_last to fill n_infill_points? OR just 1?</span>
        <span class="c1"># Let&#39;s return 1 and let loop repeat it?</span>
        <span class="c1"># But loop repeats based on x_next logic.</span>
        <span class="c1"># If we return 1 point, it is treated as 1 point.</span>
        <span class="c1"># If user asked for n_infill_points, maybe we should just return what we have (1 duplicated).</span>

        <span class="k">return</span> <span class="n">x_last</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_handle_NA_new_points</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x_next</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_next</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Handle NaN/inf values in new evaluation points.</span>

<span class="sd">        Applies penalties to NaN/inf values and removes any remaining invalid points.</span>
<span class="sd">        If all evaluations are invalid, returns None for both arrays to signal that</span>
<span class="sd">        the iteration should be skipped.</span>

<span class="sd">        Args:</span>
<span class="sd">            x_next (ndarray): Design points that were evaluated, shape (n_eval, n_features).</span>
<span class="sd">            y_next (ndarray): Function values at x_next, shape (n_eval,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[Optional[ndarray], Optional[ndarray]]: Tuple of (x_clean, y_clean).</span>
<span class="sd">                Both are None if all evaluations were NaN/inf (iteration should be skipped).</span>
<span class="sd">                Otherwise returns filtered arrays with only finite values.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Simulate optimization state</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.array([1.0, 2.0, 3.0])  # Historical values</span>
<span class="sd">            &gt;&gt;&gt; opt.n_iter_ = 1</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Case 1: Some valid values</span>
<span class="sd">            &gt;&gt;&gt; x_next = np.array([[1, 2], [3, 4], [5, 6]])</span>
<span class="sd">            &gt;&gt;&gt; y_next = np.array([5.0, np.nan, 10.0])</span>
<span class="sd">            &gt;&gt;&gt; x_clean, y_clean = opt._handle_NA_new_points(x_next, y_next)</span>
<span class="sd">            &gt;&gt;&gt; x_clean.shape</span>
<span class="sd">            (2, 2)</span>
<span class="sd">            &gt;&gt;&gt; y_clean.shape</span>
<span class="sd">            (2,)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Case 2: All NaN/inf - should skip iteration</span>
<span class="sd">            &gt;&gt;&gt; x_all_bad = np.array([[1, 2], [3, 4]])</span>
<span class="sd">            &gt;&gt;&gt; y_all_bad = np.array([np.nan, np.inf])</span>
<span class="sd">            &gt;&gt;&gt; x_clean, y_clean = opt._handle_NA_new_points(x_all_bad, y_all_bad)</span>
<span class="sd">            Warning: All new evaluations were NaN/inf, skipping iteration 1</span>
<span class="sd">            &gt;&gt;&gt; x_clean is None</span>
<span class="sd">            True</span>
<span class="sd">            &gt;&gt;&gt; y_clean is None</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle NaN/inf values in new evaluations</span>
        <span class="c1"># Use historical y values (self.y_) for computing penalty statistics</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span><span class="p">:</span>
            <span class="n">y_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_penalty_NA</span><span class="p">(</span><span class="n">y_next</span><span class="p">,</span> <span class="n">y_history</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

        <span class="c1"># Identify which points are valid (finite) BEFORE removing them</span>
        <span class="c1"># Note: _remove_nan filters based on y_next finite values</span>

        <span class="c1"># Ensure y_next is a float array (maps non-convertible values like &quot;error&quot; or None to nan)</span>
        <span class="c1"># This is critical if the objective function returns non-numeric values and penalty=False</span>
        <span class="k">if</span> <span class="n">y_next</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="nb">object</span><span class="p">:</span>
            <span class="c1"># Use safe float conversion similar to _apply_penalty_NA</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">_safe_float</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
                <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

            <span class="c1"># Reconstruct as float array</span>
            <span class="n">y_flat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">y_next</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">_safe_float</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">y_flat</span><span class="p">])</span>

        <span class="n">finite_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>

        <span class="n">X_next_clean</span><span class="p">,</span> <span class="n">y_next_clean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_remove_nan</span><span class="p">(</span>
            <span class="n">x_next</span><span class="p">,</span> <span class="n">y_next</span><span class="p">,</span> <span class="n">stop_on_zero_return</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="c1"># If we have multi-objective values, we need to filter them too</span>
        <span class="c1"># The new MO values were appended to self.y_mo in _evaluate_function -&gt; _mo2so -&gt; _store_mo</span>
        <span class="c1"># So self.y_mo currently contains the INVALID points at the end.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_new</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
            <span class="c1"># Check if y_mo has the new points appended</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">n_new</span><span class="p">:</span>
                <span class="c1"># The new points are at the end of y_mo</span>
                <span class="n">y_mo_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span><span class="p">[</span><span class="o">-</span><span class="n">n_new</span><span class="p">:]</span>
                <span class="n">y_mo_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span><span class="p">[:</span><span class="o">-</span><span class="n">n_new</span><span class="p">]</span>

                <span class="c1"># Filter the new MO points using the mask from y_next</span>
                <span class="n">y_mo_new_clean</span> <span class="o">=</span> <span class="n">y_mo_new</span><span class="p">[</span><span class="n">finite_mask</span><span class="p">]</span>

                <span class="c1"># Reconstruct y_mo</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_mo_old</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">y_mo_old</span><span class="p">,</span> <span class="n">y_mo_new_clean</span><span class="p">])</span>
                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_mo_new_clean</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
                        <span class="k">else</span> <span class="n">y_mo_old</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">y_mo</span> <span class="o">=</span> <span class="n">y_mo_new_clean</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="s2">&quot;Warning: y_mo size inconsistent with new points in _handle_NA_new_points&quot;</span>
                    <span class="p">)</span>

        <span class="c1"># Skip this iteration if all new points were NaN/inf</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_next_clean</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Warning: All new evaluations were NaN/inf, skipping iteration </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="n">X_next_clean</span><span class="p">,</span> <span class="n">y_next_clean</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_update_best_main_loop</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x_next_repeated</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">y_next</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">start_time</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update best solution found during main optimization loop.</span>

<span class="sd">        Checks if any new evaluations improve upon the current best solution.</span>
<span class="sd">        If improvement is found, updates best_x_ and best_y_ attributes and</span>
<span class="sd">        prints progress if verbose mode is enabled.</span>

<span class="sd">        Args:</span>
<span class="sd">            x_next_repeated (ndarray): Design points that were evaluated in transformed space,</span>
<span class="sd">                shape (n_eval, n_features).</span>
<span class="sd">            y_next (ndarray): Function values at x_next_repeated, shape (n_eval,).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Simulate optimization state</span>
<span class="sd">            &gt;&gt;&gt; opt.n_iter_ = 1</span>
<span class="sd">            &gt;&gt;&gt; opt.best_x_ = np.array([1.0, 1.0])</span>
<span class="sd">            &gt;&gt;&gt; opt.best_y_ = 2.0</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Case 1: New best found</span>
<span class="sd">            &gt;&gt;&gt; x_new = np.array([[0.1, 0.1], [0.5, 0.5]])</span>
<span class="sd">            &gt;&gt;&gt; y_new = np.array([0.02, 0.5])</span>
<span class="sd">            &gt;&gt;&gt; opt._update_best_main_loop(x_new, y_new)</span>
<span class="sd">            Iteration 1: New best f(x) = 0.020000</span>
<span class="sd">            &gt;&gt;&gt; opt.best_y_</span>
<span class="sd">            0.02</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Case 2: No improvement</span>
<span class="sd">            &gt;&gt;&gt; opt.n_iter_ = 2</span>
<span class="sd">            &gt;&gt;&gt; x_no_improve = np.array([[1.5, 1.5]])</span>
<span class="sd">            &gt;&gt;&gt; y_no_improve = np.array([4.5])</span>
<span class="sd">            &gt;&gt;&gt; opt._update_best_main_loop(x_no_improve, y_no_improve)</span>
<span class="sd">            Iteration 2: f(x) = 4.500000</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Case 3: With noisy function</span>
<span class="sd">            &gt;&gt;&gt; opt_noise = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     noise=True,</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.n_iter_ = 1</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.best_y_ = 2.0</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.min_mean_y = 1.5</span>
<span class="sd">            &gt;&gt;&gt; y_noise = np.array([0.5])</span>
<span class="sd">            &gt;&gt;&gt; x_noise = np.array([[0.5, 0.5]])</span>
<span class="sd">            &gt;&gt;&gt; opt_noise._update_best_main_loop(x_noise, y_noise)</span>
<span class="sd">            Iteration 1: New best f(x) = 0.500000, mean best: f(x) = 1.500000</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Update best</span>
        <span class="c1"># Determine global best value for printing if shared variable exists</span>
        <span class="n">global_best_val</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;shared_best_y&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_best_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Sync with global shared value</span>
            <span class="n">lock_obj</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;shared_lock&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">lock_obj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">lock_obj</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_best_y</span><span class="o">.</span><span class="n">value</span>
                    <span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">shared_best_y</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span>

                    <span class="n">min_y_next</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">min_y_next</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_best_y</span><span class="o">.</span><span class="n">value</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">shared_best_y</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">min_y_next</span>

                    <span class="n">global_best_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_best_y</span><span class="o">.</span><span class="n">value</span>

        <span class="n">current_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">current_best</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="p">:</span>
            <span class="n">best_idx_in_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
            <span class="c1"># x_next_repeated is in transformed space, convert to original for storage</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse_transform_X</span><span class="p">(</span>
                <span class="n">x_next_repeated</span><span class="p">[</span><span class="n">best_idx_in_new</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="o">=</span> <span class="n">current_best</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="c1"># Calculate progress</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="ow">and</span> <span class="n">start_time</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
                    <span class="n">progress_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Time: </span><span class="si">{</span><span class="n">progress</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">prev_evals</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">nfev</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">)</span>
                    <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span><span class="n">prev_evals</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">*</span> <span class="mi">100</span>
                    <span class="n">progress_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Evals: </span><span class="si">{</span><span class="n">progress</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span>

                <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Iter </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">if</span> <span class="n">global_best_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; | GlobalBest: </span><span class="si">{</span><span class="n">global_best_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; | Best: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> | Rate: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">success_rate</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">progress_str</span><span class="si">}</span><span class="s2">&quot;</span>

                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; | Mean Best: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>

                <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="ow">and</span> <span class="n">start_time</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
                <span class="n">progress_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Time: </span><span class="si">{</span><span class="n">progress</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">prev_evals</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">nfev</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">)</span>
                <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span><span class="n">prev_evals</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">*</span> <span class="mi">100</span>
                <span class="n">progress_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Evals: </span><span class="si">{</span><span class="n">progress</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span>

            <span class="n">current_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Iter </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">global_best_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; | GlobalBest: </span><span class="si">{</span><span class="n">global_best_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; | Best: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> | Curr: </span><span class="si">{</span><span class="n">current_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> | Rate: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">success_rate</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">progress_str</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">mean_y_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
                <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; | Mean Curr: </span><span class="si">{</span><span class="n">mean_y_new</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_determine_termination</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout_start</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Determine termination reason for optimization.</span>

<span class="sd">        Checks the termination conditions and returns an appropriate message</span>
<span class="sd">        indicating why the optimization stopped. Three possible termination</span>
<span class="sd">        conditions are checked in order of priority:</span>
<span class="sd">        1. Maximum number of evaluations reached</span>
<span class="sd">        2. Maximum time limit exceeded</span>
<span class="sd">        3. Successful completion (neither limit reached)</span>

<span class="sd">        Args:</span>
<span class="sd">            timeout_start (float): Start time of optimization (from time.time()).</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Message describing the termination reason.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; import time</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=20,</span>
<span class="sd">            ...     max_time=10.0</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Case 1: Maximum evaluations reached</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.zeros(20)  # Simulate 20 evaluations</span>
<span class="sd">            &gt;&gt;&gt; start_time = time.time()</span>
<span class="sd">            &gt;&gt;&gt; msg = opt._determine_termination(start_time)</span>
<span class="sd">            &gt;&gt;&gt; print(msg)</span>
<span class="sd">            Optimization terminated: maximum evaluations (20) reached</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Case 2: Time limit exceeded</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.zeros(10)  # Only 10 evaluations</span>
<span class="sd">            &gt;&gt;&gt; start_time = time.time() - 700  # Simulate 11.67 minutes elapsed</span>
<span class="sd">            &gt;&gt;&gt; msg = opt._determine_termination(start_time)</span>
<span class="sd">            &gt;&gt;&gt; print(msg)</span>
<span class="sd">            Optimization terminated: time limit (10.00 min) reached</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Case 3: Successful completion</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.zeros(10)  # Under max_iter</span>
<span class="sd">            &gt;&gt;&gt; start_time = time.time()  # Just started</span>
<span class="sd">            &gt;&gt;&gt; msg = opt._determine_termination(start_time)</span>
<span class="sd">            &gt;&gt;&gt; print(msg)</span>
<span class="sd">            Optimization finished successfully</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Determine termination reason</span>
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">timeout_start</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Optimization terminated: maximum evaluations (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="si">}</span><span class="s2">) reached&quot;</span>
        <span class="k">elif</span> <span class="n">elapsed_time</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_time</span> <span class="o">*</span> <span class="mi">60</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Optimization terminated: time limit (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> min) reached&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;Optimization finished successfully&quot;</span>

        <span class="k">return</span> <span class="n">message</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_ocba</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply Optimal Computing Budget Allocation for noisy functions.</span>

<span class="sd">        Determines which existing design points should be re-evaluated based on</span>
<span class="sd">        OCBA algorithm. This method computes optimal budget allocation to improve</span>
<span class="sd">        the quality of the estimated best design.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Optional[ndarray]: Array of design points to re-evaluate, shape (n_re_eval, n_features).</span>
<span class="sd">                Returns None if OCBA conditions are not met or OCBA is disabled.</span>

<span class="sd">        Note:</span>
<span class="sd">            OCBA is only applied when:</span>
<span class="sd">            - (self.repeats_initial &gt; 1) or (self.repeats_surrogate &gt; 1)</span>
<span class="sd">            - self.ocba_delta &gt; 0</span>
<span class="sd">            - All variances are &gt; 0</span>
<span class="sd">            - At least 3 design points exist</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1) + np.random.normal(0, 0.1, X.shape[0]),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     noise=True,</span>
<span class="sd">            ...     ocba_delta=5,</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Simulate optimization state (normally done in optimize())</span>
<span class="sd">            &gt;&gt;&gt; opt.mean_X = np.array([[1, 2], [0, 0], [2, 1]])</span>
<span class="sd">            &gt;&gt;&gt; opt.mean_y = np.array([5.0, 0.1, 5.0])</span>
<span class="sd">            &gt;&gt;&gt; opt.var_y = np.array([0.1, 0.05, 0.15])</span>
<span class="sd">            &gt;&gt;&gt; X_ocba = opt._apply_ocba()</span>
<span class="sd">              OCBA: Adding 5 re-evaluation(s)</span>
<span class="sd">            &gt;&gt;&gt; X_ocba.shape[0] == 5</span>
<span class="sd">            True</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # OCBA skipped - insufficient points</span>
<span class="sd">            &gt;&gt;&gt; opt2 = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     noise=True,</span>
<span class="sd">            ...     ocba_delta=5,</span>
<span class="sd">            ...     verbose=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; opt2.mean_X = np.array([[1, 2], [0, 0]])</span>
<span class="sd">            &gt;&gt;&gt; opt2.mean_y = np.array([5.0, 0.1])</span>
<span class="sd">            &gt;&gt;&gt; opt2.var_y = np.array([0.1, 0.05])</span>
<span class="sd">            &gt;&gt;&gt; X_ocba = opt2._apply_ocba()</span>
<span class="sd">            Warning: OCBA skipped (need &gt;2 points with variance &gt; 0)</span>
<span class="sd">            &gt;&gt;&gt; X_ocba is None</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># OCBA: Compute optimal budget allocation for noisy functions</span>
        <span class="c1"># This determines which existing design points should be re-evaluated</span>
        <span class="n">X_ocba</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span>
        <span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">ocba_delta</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Check conditions for OCBA (need variance &gt; 0 and at least 3 points)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: OCBA skipped (need &gt;2 points with variance &gt; 0)&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">):</span>
                <span class="c1"># Get OCBA allocation</span>
                <span class="n">X_ocba</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_ocba_X</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ocba_delta</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="n">X_ocba</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  OCBA: Adding </span><span class="si">{</span><span class="n">X_ocba</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> re-evaluation(s)&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X_ocba</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_penalty_NA</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">y_history</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">penalty_value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sd</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Replace NaN and infinite values with penalty plus random noise.</span>
<span class="sd">        Used in the optimize() method after function evaluations.</span>

<span class="sd">        This method follows the approach from spotpython.utils.repair.apply_penalty_NA,</span>
<span class="sd">        replacing NaN/inf values with a penalty value plus random noise to avoid</span>
<span class="sd">        identical penalty values.</span>

<span class="sd">        Args:</span>
<span class="sd">            y (ndarray): Array of objective function values to be repaired.</span>
<span class="sd">            y_history (ndarray, optional): Historical objective function values used for</span>
<span class="sd">                computing penalty statistics. If None, uses y itself. Default is None.</span>
<span class="sd">            penalty_value (float, optional): Value to replace NaN/inf with.</span>
<span class="sd">                If None, computes penalty as: max(finite_y_history) + 3 * std(finite_y_history).</span>
<span class="sd">                If all values are NaN/inf or only one finite value exists, falls back</span>
<span class="sd">                to self.penalty_val. Default is None.</span>
<span class="sd">            sd (float): Standard deviation for random noise added to penalty.</span>
<span class="sd">                Default is 0.1.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ndarray: Array with NaN/inf replaced by penalty_value + random noise.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1), bounds=[(-5, 5)])</span>
<span class="sd">            &gt;&gt;&gt; y_hist = np.array([1.0, 2.0, 3.0, 5.0])</span>
<span class="sd">            &gt;&gt;&gt; y_new = np.array([4.0, np.nan, np.inf])</span>
<span class="sd">            &gt;&gt;&gt; y_clean = opt._apply_penalty_NA(y_new, y_history=y_hist)</span>
<span class="sd">            &gt;&gt;&gt; np.all(np.isfinite(y_clean))</span>
<span class="sd">            True</span>
<span class="sd">            &gt;&gt;&gt; # NaN/inf replaced with worst value from history + 3*std + noise</span>
<span class="sd">            &gt;&gt;&gt; y_clean[1] &gt; 5.0  # Should be larger than max finite value in history</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Ensure y is a float array (maps non-convertible values like &quot;error&quot; or None to nan)</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">_safe_float</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

        <span class="n">y_flat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">_safe_float</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">y_flat</span><span class="p">])</span>
        <span class="c1"># Identify NaN and inf values in y</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="n">n_bad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

            <span class="c1"># Compute penalty_value if not provided</span>
            <span class="k">if</span> <span class="n">penalty_value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Get finite values from history for statistics</span>
                <span class="c1"># Use y_history if provided, otherwise fall back to y itself</span>
                <span class="k">if</span> <span class="n">y_history</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">finite_values</span> <span class="o">=</span> <span class="n">y_history</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y_history</span><span class="p">)]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Use current y values</span>
                    <span class="n">finite_values</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span>

                <span class="c1"># If we have at least 2 finite values, compute adaptive penalty</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">finite_values</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">max_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">finite_values</span><span class="p">)</span>
                    <span class="n">std_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">finite_values</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">penalty_value</span> <span class="o">=</span> <span class="n">max_y</span> <span class="o">+</span> <span class="mf">3.0</span> <span class="o">*</span> <span class="n">std_y</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Warning: Found </span><span class="si">{</span><span class="n">n_bad</span><span class="si">}</span><span class="s2"> NaN/inf value(s), replacing with &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;adaptive penalty (max + 3*std = </span><span class="si">{</span><span class="n">penalty_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Fallback to self.penalty if insufficient finite values</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">penalty_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty_val</span>
                    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">finite_values</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># Use the single finite value + a large constant</span>
                        <span class="n">penalty_value</span> <span class="o">=</span> <span class="n">finite_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1000.0</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># All values are NaN/inf, use a large default</span>
                        <span class="n">penalty_value</span> <span class="o">=</span> <span class="mf">1e10</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Warning: Found </span><span class="si">{</span><span class="n">n_bad</span><span class="si">}</span><span class="s2"> NaN/inf value(s), insufficient finite values &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;for adaptive penalty. Using penalty_value = </span><span class="si">{</span><span class="n">penalty_value</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Warning: Found </span><span class="si">{</span><span class="n">n_bad</span><span class="si">}</span><span class="s2"> NaN/inf value(s), replacing with </span><span class="si">{</span><span class="n">penalty_value</span><span class="si">}</span><span class="s2"> + noise&quot;</span>
                    <span class="p">)</span>

            <span class="c1"># Generate random noise and add to penalty</span>
            <span class="n">random_noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">penalty_values</span> <span class="o">=</span> <span class="n">penalty_value</span> <span class="o">+</span> <span class="n">random_noise</span>

            <span class="c1"># Replace NaN/inf with penalty + noise</span>
            <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">penalty_values</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">y</span>

    <span class="c1"># ====================</span>
    <span class="c1"># Storage &amp; Statistics</span>
    <span class="c1"># ====================</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init_storage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y0</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize storage for optimization.</span>

<span class="sd">        Sets up the initial data structures needed for optimization tracking:</span>
<span class="sd">        - X_: Evaluated design points (in original scale)</span>
<span class="sd">        - y_: Function values at evaluated points</span>
<span class="sd">        - n_iter_: Iteration counter</span>

<span class="sd">        Then updates statistics by calling update_stats().</span>

<span class="sd">        Args:</span>
<span class="sd">            X0 (ndarray): Initial design points in internal scale, shape (n_samples, n_features).</span>
<span class="sd">            y0 (ndarray): Function values at X0, shape (n_samples,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 n_initial=5)</span>
<span class="sd">            &gt;&gt;&gt; X0 = np.array([[1, 2], [3, 4], [0, 1]])</span>
<span class="sd">            &gt;&gt;&gt; y0 = np.array([5.0, 25.0, 1.0])</span>
<span class="sd">            &gt;&gt;&gt; opt._init_storage(X0, y0)</span>
<span class="sd">            &gt;&gt;&gt; opt.X_.shape</span>
<span class="sd">            (3, 2)</span>
<span class="sd">            &gt;&gt;&gt; opt.y_.shape</span>
<span class="sd">            (3,)</span>
<span class="sd">            &gt;&gt;&gt; opt.n_iter_</span>
<span class="sd">            0</span>
<span class="sd">            &gt;&gt;&gt; opt.counter</span>
<span class="sd">            3</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialize storage (convert to original scale for user-facing storage)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse_transform_X</span><span class="p">(</span><span class="n">X0</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">y0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_update_storage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_new</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_new</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update storage with new evaluation points.</span>

<span class="sd">        Appends new design points and their function values to the storage arrays.</span>
<span class="sd">        Points are converted from internal scale to original scale before storage.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_new (ndarray): New design points in internal scale, shape (n_new, n_features).</span>
<span class="sd">            y_new (ndarray): Function values at X_new, shape (n_new,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 n_initial=5)</span>
<span class="sd">            &gt;&gt;&gt; # Initialize with some data</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.array([[1, 2], [3, 4]])</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.array([5.0, 25.0])</span>
<span class="sd">            &gt;&gt;&gt; # Add new points</span>
<span class="sd">            &gt;&gt;&gt; X_new = np.array([[0, 1], [2, 3]])</span>
<span class="sd">            &gt;&gt;&gt; y_new = np.array([1.0, 13.0])</span>
<span class="sd">            &gt;&gt;&gt; opt._update_storage(X_new, y_new)</span>
<span class="sd">            &gt;&gt;&gt; opt.X_.shape</span>
<span class="sd">            (4, 2)</span>
<span class="sd">            &gt;&gt;&gt; opt.y_.shape</span>
<span class="sd">            (4,)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Update storage (convert to original scale for user-facing storage)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse_transform_X</span><span class="p">(</span><span class="n">X_new</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span> <span class="n">y_new</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update optimization statistics.</span>

<span class="sd">        Updates various statistics related to the optimization progress:</span>
<span class="sd">        - `min_y`: Minimum y value found so far</span>
<span class="sd">        - `min_X`: X value corresponding to minimum y</span>
<span class="sd">        - `counter`: Total number of function evaluations</span>

<span class="sd">        Note: `success_rate` is updated separately via `_update_success_rate()` method,</span>
<span class="sd">        which is called after each batch of function evaluations.</span>

<span class="sd">        If `noise` is True (repeats &gt; 1), additionally computes:</span>
<span class="sd">        1. `mean_X`: Unique design points (aggregated from repeated evaluations)</span>
<span class="sd">        2. `mean_y`: Mean y values per design point</span>
<span class="sd">        3. `var_y`: Variance of y values per design point</span>
<span class="sd">        4. `min_mean_X`: X value of the best mean y value</span>
<span class="sd">        5. `min_mean_y`: Best mean y value</span>
<span class="sd">        6. `min_var_y`: Variance of the best mean y value</span>


<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; # Without noise</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_iter=10, n_initial=5)</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.array([[1, 2], [3, 4], [0, 1]])</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.array([5.0, 25.0, 1.0])</span>
<span class="sd">            &gt;&gt;&gt; opt.update_stats()</span>
<span class="sd">            &gt;&gt;&gt; opt.min_y</span>
<span class="sd">            1.0</span>
<span class="sd">            &gt;&gt;&gt; opt.min_X</span>
<span class="sd">            array([0, 1])</span>
<span class="sd">            &gt;&gt;&gt; opt.counter</span>
<span class="sd">            3</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # With noise</span>
<span class="sd">            &gt;&gt;&gt; opt_noise = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                       bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                       n_initial=5,</span>
<span class="sd">            ...                       repeats_initial=2)</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.noise = True</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.X_ = np.array([[1, 2], [1, 2], [3, 4]])</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.y_ = np.array([5.0, 5.0, 25.0])</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.update_stats()</span>
<span class="sd">            &gt;&gt;&gt; opt_noise.mean_y.shape</span>
<span class="sd">            (2,)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Basic stats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

        <span class="c1"># Aggregated stats for noisy functions</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_mean_var</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span>
            <span class="p">)</span>
            <span class="c1"># X value of the best mean y value so far</span>
            <span class="n">best_mean_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>
            <span class="c1"># Best mean y value so far</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>
            <span class="c1"># Variance of the best mean y value so far</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_var_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_update_success_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_new</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update the rolling success rate of the optimization process.</span>

<span class="sd">        A success is counted only if the new value is better (smaller) than the best</span>
<span class="sd">        found y value so far. The success rate is calculated based on the last</span>
<span class="sd">        `window_size` successes.</span>

<span class="sd">        Important: This method should be called BEFORE updating self.y_ to correctly</span>
<span class="sd">        track improvements against the previous best value.</span>

<span class="sd">        Args:</span>
<span class="sd">            y_new (ndarray): The new function values to consider for the success rate update.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 max_iter=10, n_initial=5)</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.array([[1, 2], [3, 4], [0, 1]])</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.array([5.0, 3.0, 2.0])</span>
<span class="sd">            &gt;&gt;&gt; opt._update_success_rate(np.array([1.5, 2.5]))</span>
<span class="sd">            &gt;&gt;&gt; opt.success_rate &gt; 0</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialize or update the rolling history of successes (1 for success, 0 for failure)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_success_history&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Get the best y value so far (before adding new evaluations)</span>
        <span class="c1"># Since this is called BEFORE updating self.y_, we can safely use min(self.y_)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">best_y_before</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># This is the initial design, no previous best</span>
            <span class="n">best_y_before</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>

        <span class="n">successes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">current_best</span> <span class="o">=</span> <span class="n">best_y_before</span>

        <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">y_new</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">val</span> <span class="o">&lt;</span> <span class="n">current_best</span><span class="p">:</span>
                <span class="n">successes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">current_best</span> <span class="o">=</span> <span class="n">val</span>  <span class="c1"># Update for next comparison within this batch</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">successes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Add new successes to the history</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">successes</span><span class="p">)</span>
        <span class="c1"># Keep only the last window_size successes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="p">:]</span>

        <span class="c1"># Calculate the rolling success rate</span>
        <span class="n">window_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span><span class="p">)</span>
        <span class="n">num_successes</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_success_history</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">success_rate</span> <span class="o">=</span> <span class="n">num_successes</span> <span class="o">/</span> <span class="n">window_size</span> <span class="k">if</span> <span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_success_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the current success rate of the optimization process.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The current success rate.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda x: x,</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)])</span>
<span class="sd">            &gt;&gt;&gt; print(opt._get_success_rate())</span>
<span class="sd">            0.0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;success_rate&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span> <span class="ow">or</span> <span class="mf">0.0</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_aggregate_mean_var</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Aggregate X and y values to compute mean and variance per group.</span>

<span class="sd">        For repeated evaluations at the same design point, this method computes</span>
<span class="sd">        the mean function value and variance (using population variance, ddof=0).</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design points, shape (n_samples, n_features).</span>
<span class="sd">            y (ndarray): Function values, shape (n_samples,).</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing:</span>
<span class="sd">                - X_agg (ndarray): Unique design points, shape (n_groups, n_features)</span>
<span class="sd">                - y_mean (ndarray): Mean y values per group, shape (n_groups,)</span>
<span class="sd">                - y_var (ndarray): Variance of y values per group, shape (n_groups,)</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...                 repeats_initial=2)</span>
<span class="sd">            &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2]])</span>
<span class="sd">            &gt;&gt;&gt; y = np.array([1, 2, 3])</span>
<span class="sd">            &gt;&gt;&gt; X_agg, y_mean, y_var = opt._aggregate_mean_var(X, y)</span>
<span class="sd">            &gt;&gt;&gt; X_agg.shape</span>
<span class="sd">            (2, 2)</span>
<span class="sd">            &gt;&gt;&gt; y_mean</span>
<span class="sd">            array([2., 2.])</span>
<span class="sd">            &gt;&gt;&gt; y_var</span>
<span class="sd">            array([1., 0.])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Input validation</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid input shapes for _aggregate_mean_var&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>

        <span class="c1"># Find unique rows and group indices</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">unique_idx</span><span class="p">,</span> <span class="n">inverse_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">return_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="n">X_agg</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">unique_idx</span><span class="p">]</span>

        <span class="c1"># Calculate mean and variance for each group</span>
        <span class="n">n_groups</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_idx</span><span class="p">)</span>
        <span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_groups</span><span class="p">)</span>
        <span class="n">y_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_groups</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_groups</span><span class="p">):</span>
            <span class="n">group_mask</span> <span class="o">=</span> <span class="n">inverse_idx</span> <span class="o">==</span> <span class="n">i</span>
            <span class="n">group_y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">group_mask</span><span class="p">]</span>
            <span class="n">y_mean</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">group_y</span><span class="p">)</span>
            <span class="c1"># Use population variance (ddof=0) for consistency with Spot</span>
            <span class="n">y_var</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">group_y</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X_agg</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_var</span>

    <span class="c1"># ====================</span>
    <span class="c1"># Results &amp; Analysis</span>
    <span class="c1"># ====================</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_result</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;result&quot;</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">verbosity</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the complete optimization results to a pickle file.</span>

<span class="sd">        A result contains all information from a completed optimization run, including</span>
<span class="sd">        the experiment configuration and all evaluation results. This is useful for</span>
<span class="sd">        saving completed runs for later analysis.</span>

<span class="sd">        The result includes everything in an experiment plus:</span>
<span class="sd">        - All evaluated points (X_)</span>
<span class="sd">        - All function values (y_)</span>
<span class="sd">        - Best point and best value</span>
<span class="sd">        - Iteration count</span>
<span class="sd">        - Success rate statistics</span>
<span class="sd">        - Noise statistics (if applicable)</span>

<span class="sd">        Args:</span>
<span class="sd">            filename (str, optional): Filename for the result file. If None, generates</span>
<span class="sd">                from prefix. Defaults to None.</span>
<span class="sd">            prefix (str): Prefix for auto-generated filename. Defaults to &quot;result&quot;.</span>
<span class="sd">            path (str, optional): Directory path to save the file. If None, saves in current</span>
<span class="sd">                directory. Creates directory if it doesn&#39;t exist. Defaults to None.</span>
<span class="sd">            overwrite (bool): If True, overwrites existing file. If False, raises error if</span>
<span class="sd">                file exists. Defaults to True.</span>
<span class="sd">            verbosity (int): Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Run optimization</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=30,</span>
<span class="sd">            ...     n_initial=10,</span>
<span class="sd">            ...     seed=42</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Save complete results</span>
<span class="sd">            &gt;&gt;&gt; opt.save_result(prefix=&quot;sphere_opt&quot;)</span>
<span class="sd">            Result saved to sphere_opt_res.pkl</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Later: load and analyze</span>
<span class="sd">            &gt;&gt;&gt; # opt_loaded = SpotOptim.load_result(&quot;sphere_opt_res.pkl&quot;)</span>
<span class="sd">            &gt;&gt;&gt; # print(&quot;Best value:&quot;, opt_loaded.best_y_)</span>
<span class="sd">            &gt;&gt;&gt; # opt_loaded.plot_surrogate()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Use save_experiment with file_io unpickleables to preserve results</span>
        <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_result_filename</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">save_experiment</span><span class="p">(</span>
            <span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">overwrite</span><span class="o">=</span><span class="n">overwrite</span><span class="p">,</span>
            <span class="n">unpickleables</span><span class="o">=</span><span class="s2">&quot;file_io&quot;</span><span class="p">,</span>
            <span class="n">verbosity</span><span class="o">=</span><span class="n">verbosity</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Update message</span>
        <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">full_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">full_path</span> <span class="o">=</span> <span class="n">filename</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result saved to </span><span class="si">{</span><span class="n">full_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_result</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SpotOptim&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load complete optimization results from a pickle file.</span>

<span class="sd">        Loads results that were saved with save_result(). The loaded optimizer</span>
<span class="sd">        will have both configuration and all optimization results.</span>

<span class="sd">        Args:</span>
<span class="sd">            filename (str): Path to the result pickle file.</span>

<span class="sd">        Returns:</span>
<span class="sd">            SpotOptim: Loaded optimizer instance with complete results.</span>

<span class="sd">        Raises:</span>
<span class="sd">            FileNotFoundError: If the specified file doesn&#39;t exist.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Load results</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim.load_result(&quot;sphere_opt_res.pkl&quot;)</span>
<span class="sd">            Loaded result from sphere_opt_res.pkl</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Analyze results</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Best point:&quot;, opt.best_x_)</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Best value:&quot;, opt.best_y_)</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Total evaluations:&quot;, opt.counter)</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Success rate:&quot;, opt.success_rate)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Continue optimization if needed</span>
<span class="sd">            &gt;&gt;&gt; # opt.fun = lambda X: np.sum(X**2, axis=1)  # Re-attach if continuing</span>
<span class="sd">            &gt;&gt;&gt; # opt.max_iter = 50  # Increase budget</span>
<span class="sd">            &gt;&gt;&gt; # result = opt.optimize()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result file not found: </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">dill</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded result from </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Reinitialize components that were excluded</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">_reinitialize_components</span><span class="p">()</span>

            <span class="k">return</span> <span class="n">optimizer</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading result: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_experiment</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;experiment&quot;</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">unpickleables</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span><span class="p">,</span>
        <span class="n">verbosity</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the experiment configuration to a pickle file.</span>

<span class="sd">        An experiment contains the optimizer configuration needed to run optimization,</span>
<span class="sd">        but excludes the results. This is useful for defining experiments locally and</span>
<span class="sd">        executing them on remote machines.</span>

<span class="sd">        The experiment includes:</span>
<span class="sd">        - Bounds, variable types, variable names</span>
<span class="sd">        - Optimization parameters (max_iter, n_initial, etc.)</span>
<span class="sd">        - Surrogate and acquisition settings</span>
<span class="sd">        - Random seed</span>

<span class="sd">        The experiment excludes:</span>
<span class="sd">        - Function evaluations (X_, y_)</span>
<span class="sd">        - Optimization results</span>


<span class="sd">        Args:</span>
<span class="sd">            filename (str, optional): Filename for the experiment file. If None, generates</span>
<span class="sd">                from prefix. Defaults to None.</span>
<span class="sd">            prefix (str): Prefix for auto-generated filename. Defaults to &quot;experiment&quot;.</span>
<span class="sd">            path (str, optional): Directory path to save the file. If None, saves in current</span>
<span class="sd">                directory. Creates directory if it doesn&#39;t exist. Defaults to None.</span>
<span class="sd">            overwrite (bool): If True, overwrites existing file. If False, raises error if</span>
<span class="sd">                file exists. Defaults to True.</span>
<span class="sd">            unpickleables (str): Components to exclude for pickling:</span>
<span class="sd">                - &quot;all&quot;: Excludes surrogate, lhs_sampler, tb_writer (experiment only)</span>
<span class="sd">                - &quot;file_io&quot;: Excludes only tb_writer (lighter exclusion)</span>
<span class="sd">                Defaults to &quot;all&quot;.</span>
<span class="sd">            verbosity (int): Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Define experiment locally</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     max_iter=30,</span>
<span class="sd">            ...     n_initial=10,</span>
<span class="sd">            ...     seed=42</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Save experiment (without results)</span>
<span class="sd">            &gt;&gt;&gt; opt.save_experiment(prefix=&quot;sphere_opt&quot;)</span>
<span class="sd">            Experiment saved to sphere_opt_exp.pkl</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # On remote machine: load and run</span>
<span class="sd">            &gt;&gt;&gt; # opt_remote = SpotOptim.load_experiment(&quot;sphere_opt_exp.pkl&quot;)</span>
<span class="sd">            &gt;&gt;&gt; # result = opt_remote.optimize()</span>
<span class="sd">            &gt;&gt;&gt; # opt_remote.save_result(prefix=&quot;sphere_opt&quot;)  # Save results</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Close TensorBoard writer before pickling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_close_and_del_tensorboard_writer</span><span class="p">()</span>

        <span class="c1"># Create pickle-safe copy</span>
        <span class="n">optimizer_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_pickle_safe_optimizer</span><span class="p">(</span>
            <span class="n">unpickleables</span><span class="o">=</span><span class="n">unpickleables</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="n">verbosity</span>
        <span class="p">)</span>

        <span class="c1"># Determine filename</span>
        <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_experiment_filename</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>

        <span class="c1"># Add path if provided</span>
        <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

        <span class="c1"># Check for existing file</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">overwrite</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">FileExistsError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;File </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2"> already exists. Use overwrite=True to overwrite.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Save to pickle file</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
                <span class="n">dill</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">optimizer_copy</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">dill</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment saved to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error during pickling: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_experiment</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SpotOptim&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load an experiment configuration from a pickle file.</span>

<span class="sd">        Loads an experiment that was saved with save_experiment(). The loaded optimizer</span>
<span class="sd">        will have the configuration and the objective function (thanks to dill).</span>


<span class="sd">        Args:</span>
<span class="sd">            filename (str): Path to the experiment pickle file.</span>

<span class="sd">        Returns:</span>
<span class="sd">            SpotOptim: Loaded optimizer instance (without fun attached).</span>

<span class="sd">        Raises:</span>
<span class="sd">            FileNotFoundError: If the specified file doesn&#39;t exist.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Load experiment</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim.load_experiment(&quot;sphere_opt_exp.pkl&quot;)</span>
<span class="sd">            Loaded experiment from sphere_opt_exp.pkl</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Re-attach objective function</span>
<span class="sd">            &gt;&gt;&gt; opt.fun = lambda X: np.sum(X**2, axis=1)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Run optimization</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment file not found: </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">dill</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded experiment from </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Reinitialize components that were excluded</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">_reinitialize_components</span><span class="p">()</span>

            <span class="k">return</span> <span class="n">optimizer</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading experiment: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_result_filename</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate result filename from prefix.</span>

<span class="sd">        Args:</span>
<span class="sd">            prefix (str): Prefix for the filename.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Filename with &#39;_res.pkl&#39; suffix.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda x: x, bounds=[(0, 1)])</span>
<span class="sd">            &gt;&gt;&gt; res_filename = opt._get_result_filename(prefix=&quot;my_experiment&quot;)</span>
<span class="sd">            &gt;&gt;&gt; print(res_filename)</span>
<span class="sd">            my_experiment_res.pkl</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">prefix</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;result_res.pkl&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_res.pkl&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_experiment_filename</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate experiment filename from prefix.</span>

<span class="sd">        Args:</span>
<span class="sd">            prefix (str): Prefix for the filename.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Filename with &#39;_exp.pkl&#39; suffix.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda x: x, bounds=[(0, 1)])</span>
<span class="sd">            &gt;&gt;&gt; exp_filename = opt._get_experiment_filename(prefix=&quot;my_experiment&quot;)</span>
<span class="sd">            &gt;&gt;&gt; print(exp_filename)</span>
<span class="sd">            my_experiment_exp.pkl</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">prefix</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;experiment_exp.pkl&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_exp.pkl&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">print_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Alias for print_results_table for compatibility.</span>
<span class="sd">        Prints the table.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">print_results_table</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">print_best</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">result</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">OptimizeResult</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">transformations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">show_name</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Print the best solution found during optimization.</span>

<span class="sd">        This method displays the best hyperparameters and objective value in a</span>
<span class="sd">        formatted table. It supports custom transformations for parameters</span>
<span class="sd">        (e.g., converting log-scale values back to original scale).</span>

<span class="sd">        Args:</span>
<span class="sd">            result (OptimizeResult, optional): Optimization result object from optimize().</span>
<span class="sd">                If None, uses the stored best values from the optimizer. Defaults to None.</span>
<span class="sd">            transformations (list of callable, optional): List of transformation functions</span>
<span class="sd">                to apply to each parameter. Each function takes a single value and returns</span>
<span class="sd">                the transformed value. Use None for parameters that don&#39;t need transformation.</span>
<span class="sd">                Length must match number of dimensions. Example: [None, None, lambda x: 10**x]</span>
<span class="sd">                to convert the 3rd parameter from log10 scale. Defaults to None.</span>
<span class="sd">            show_name (bool, optional): Whether to display variable names. If False,</span>
<span class="sd">                uses generic names like &#39;x0&#39;, &#39;x1&#39;, etc. Defaults to True.</span>
<span class="sd">            precision (int, optional): Number of decimal places for floating point values.</span>
<span class="sd">                Defaults to 4.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 1: Basic usage</span>
<span class="sd">            &gt;&gt;&gt; def sphere(X):</span>
<span class="sd">            ...     return np.sum(X**2, axis=1)</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=sphere,</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     var_name=[&quot;x1&quot;, &quot;x2&quot;],</span>
<span class="sd">            ...     max_iter=20,</span>
<span class="sd">            ...     n_initial=10</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; opt.print_best(result)</span>
<span class="sd">            &lt;BLANKLINE&gt;</span>
<span class="sd">            Best Solution Found:</span>
<span class="sd">            --------------------------------------------------</span>
<span class="sd">              x1: 0.0123</span>
<span class="sd">              x2: -0.0045</span>
<span class="sd">              Objective Value: 0.000173</span>
<span class="sd">              Total Evaluations: 20</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 2: With log-scale transformations (e.g., for learning rates)</span>
<span class="sd">            &gt;&gt;&gt; def objective(X):</span>
<span class="sd">            ...     # X[:, 0]: neurons (int), X[:, 1]: layers (int),</span>
<span class="sd">            ...     # X[:, 2]: log10(lr), X[:, 3]: log10(alpha)</span>
<span class="sd">            ...     return np.sum(X**2, axis=1)  # Placeholder</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=objective,</span>
<span class="sd">            ...     bounds=[(16, 128), (1, 4), (-3, 0), (-2, 1)],</span>
<span class="sd">            ...     var_type=[&quot;int&quot;, &quot;int&quot;, &quot;float&quot;, &quot;float&quot;],</span>
<span class="sd">            ...     var_name=[&quot;neurons&quot;, &quot;layers&quot;, &quot;log10_lr&quot;, &quot;log10_alpha&quot;],</span>
<span class="sd">            ...     max_iter=30,</span>
<span class="sd">            ...     n_initial=10</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; # Transform log-scale parameters back to original scale</span>
<span class="sd">            &gt;&gt;&gt; transformations = [</span>
<span class="sd">            ...     int,              # neurons -&gt; int</span>
<span class="sd">            ...     int,              # layers -&gt; int</span>
<span class="sd">            ...     lambda x: 10**x,  # log10_lr -&gt; lr</span>
<span class="sd">            ...     lambda x: 10**x   # log10_alpha -&gt; alpha</span>
<span class="sd">            ... ]</span>
<span class="sd">            &gt;&gt;&gt; opt.print_best(result, transformations=transformations)</span>
<span class="sd">            &lt;BLANKLINE&gt;</span>
<span class="sd">            Best Solution Found:</span>
<span class="sd">            --------------------------------------------------</span>
<span class="sd">              neurons: 64</span>
<span class="sd">              layers: 2</span>
<span class="sd">              log10_lr: 0.0012</span>
<span class="sd">              log10_alpha: 0.0345</span>
<span class="sd">              Objective Value: 1.2345</span>
<span class="sd">              Total Evaluations: 30</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 3: Without result object (using stored values)</span>
<span class="sd">            &gt;&gt;&gt; opt.print_best()  # Uses opt.best_x_ and opt.best_y_</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 4: Hide variable names</span>
<span class="sd">            &gt;&gt;&gt; opt.print_best(result, show_name=False)</span>
<span class="sd">            &lt;BLANKLINE&gt;</span>
<span class="sd">            Best Solution Found:</span>
<span class="sd">            --------------------------------------------------</span>
<span class="sd">              x0: 0.0123</span>
<span class="sd">              x1: -0.0045</span>
<span class="sd">              Objective Value: 0.000173</span>
<span class="sd">              Total Evaluations: 20</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get values from result or stored attributes</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">best_x</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>
            <span class="n">best_y</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span>
            <span class="n">n_evals</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">nfev</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No optimization results available. Run optimize() first.&quot;</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="n">best_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>
            <span class="n">best_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span>
            <span class="n">n_evals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span>

        <span class="c1"># Expand to full dimensions if dimension reduction was applied</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="n">best_x_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="n">best_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">best_x_full</span> <span class="o">=</span> <span class="n">best_x</span>

        <span class="c1"># Map factor variables back to original string values</span>
        <span class="n">best_x_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_to_factor_values</span><span class="p">(</span><span class="n">best_x_full</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Determine variable names to use</span>
        <span class="k">if</span> <span class="n">show_name</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">var_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">var_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">best_x_full</span><span class="p">))]</span>

        <span class="c1"># Validate transformations length</span>
        <span class="k">if</span> <span class="n">transformations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">transformations</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_x_full</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Length of transformations (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">transformations</span><span class="p">)</span><span class="si">}</span><span class="s2">) must match &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;number of dimensions (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">best_x_full</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">transformations</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_x_full</span><span class="p">)</span>

        <span class="c1"># Print header</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Solution Found:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

        <span class="c1"># Print each parameter</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="n">var_names</span><span class="p">,</span> <span class="n">best_x_full</span><span class="p">,</span> <span class="n">transformations</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="c1"># Apply transformation if provided</span>
            <span class="k">if</span> <span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">display_value</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Transformation failed for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">display_value</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">display_value</span> <span class="o">=</span> <span class="n">value</span>

            <span class="c1"># Format based on variable type</span>
            <span class="n">var_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;float&quot;</span>

            <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">display_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">display_value</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">display_value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">display_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">display_value</span><span class="si">:</span><span class="s2">.</span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Print objective value and evaluations</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Objective Value: </span><span class="si">{</span><span class="n">best_y</span><span class="si">:</span><span class="s2">.</span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Total Evaluations: </span><span class="si">{</span><span class="n">n_evals</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">print_results_table</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tablefmt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;github&quot;</span><span class="p">,</span>
        <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">show_importance</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Print (and return) a comprehensive table of optimization results.</span>

<span class="sd">        This method calls `get_results_table` to generate the table string, prints it,</span>
<span class="sd">        and then returns it.</span>

<span class="sd">        Args:</span>
<span class="sd">            tablefmt (str, optional): Table format. Defaults to &#39;github&#39;.</span>
<span class="sd">            precision (int, optional): Decimal precision. Defaults to 4.</span>
<span class="sd">            show_importance (bool, optional): Show importance column. Defaults to False.</span>
<span class="sd">            *args: Arguments passed to get_results_table.</span>
<span class="sd">            **kwargs: Keyword arguments passed to get_results_table.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Formatted table string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_results_table</span><span class="p">(</span>
            <span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">,</span>
            <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span>
            <span class="n">show_importance</span><span class="o">=</span><span class="n">show_importance</span><span class="p">,</span>
            <span class="o">*</span><span class="n">args</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">table</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">print_design_table</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tablefmt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;github&quot;</span><span class="p">,</span>
        <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Print (and return) a table showing the search space design before optimization.</span>

<span class="sd">        This method calls `get_design_table` to generate the table string, prints it,</span>
<span class="sd">        and then returns it.</span>

<span class="sd">        Args:</span>
<span class="sd">            tablefmt (str, optional): Table format for tabulate library.</span>
<span class="sd">                Defaults to &#39;github&#39;.</span>
<span class="sd">            precision (int, optional): Number of decimal places for float values.</span>
<span class="sd">                Defaults to 4.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Formatted table string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_design_table</span><span class="p">(</span><span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">table</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_results_table</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tablefmt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;github&quot;</span><span class="p">,</span>
        <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">show_importance</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get a comprehensive table string of optimization results.</span>

<span class="sd">        This method generates a formatted table of the search space configuration,</span>
<span class="sd">        best values found, and optionally variable importance scores.</span>

<span class="sd">        Args:</span>
<span class="sd">            tablefmt (str, optional): Table format for tabulate library. Options include:</span>
<span class="sd">                &#39;github&#39;, &#39;grid&#39;, &#39;simple&#39;, &#39;plain&#39;, &#39;html&#39;, &#39;latex&#39;, etc.</span>
<span class="sd">                Defaults to &#39;github&#39;.</span>
<span class="sd">            precision (int, optional): Number of decimal places for float values.</span>
<span class="sd">                Defaults to 4.</span>
<span class="sd">            show_importance (bool, optional): Whether to include importance scores.</span>
<span class="sd">                Importance is calculated as the normalized standard deviation of each</span>
<span class="sd">                parameter&#39;s effect on the objective. Requires multiple evaluations.</span>
<span class="sd">                Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Formatted table string that can be printed or saved.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 1: Basic usage after optimization</span>
<span class="sd">            &gt;&gt;&gt; def sphere(X):</span>
<span class="sd">            ...     return np.sum(X**2, axis=1)</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=sphere,</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5), (-5, 5)],</span>
<span class="sd">            ...     var_name=[&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;],</span>
<span class="sd">            ...     var_type=[&quot;float&quot;, &quot;float&quot;, &quot;float&quot;],</span>
<span class="sd">            ...     max_iter=30,</span>
<span class="sd">            ...     n_initial=10</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; table = opt.get_results_table()</span>
<span class="sd">            &gt;&gt;&gt; print(table)</span>
<span class="sd">            | name   | type   |   lower |   upper |   tuned |</span>
<span class="sd">            |--------|--------|---------|---------|---------|</span>
<span class="sd">            | x1     | num    |    -5.0 |     5.0 |  0.0123 |</span>
<span class="sd">            | x2     | num    |    -5.0 |     5.0 | -0.0234 |</span>
<span class="sd">            | x3     | num    |    -5.0 |     5.0 |  0.0345 |</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 2: With importance scores</span>
<span class="sd">            &gt;&gt;&gt; table = opt.get_results_table(show_importance=True)</span>
<span class="sd">            &gt;&gt;&gt; print(table)</span>
<span class="sd">            | name   | type   |   lower |   upper |   tuned |   importance | stars   |</span>
<span class="sd">            |--------|--------|---------|---------|---------|--------------|---------|</span>
<span class="sd">            | x1     | num    |    -5.0 |     5.0 |  0.0123 |        45.23 | **      |</span>
<span class="sd">            | x2     | num    |    -5.0 |     5.0 | -0.0234 |        32.17 | *       |</span>
<span class="sd">            | x3     | num    |    -5.0 |     5.0 |  0.0345 |        22.60 | *       |</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 3: Different table format</span>
<span class="sd">            &gt;&gt;&gt; table = opt.get_results_table(tablefmt=&quot;grid&quot;)</span>
<span class="sd">            &gt;&gt;&gt; print(table)</span>
<span class="sd">            +--------+--------+---------+---------+---------+</span>
<span class="sd">            | name   | type   |   lower |   upper |   tuned |</span>
<span class="sd">            +========+========+=========+=========+=========+</span>
<span class="sd">            | x1     | num    |    -5.0 |     5.0 |  0.0123 |</span>
<span class="sd">            +--------+--------+---------+---------+---------+</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 4: With factor variables</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (&quot;red&quot;, &quot;green&quot;, &quot;blue&quot;)],</span>
<span class="sd">            ...     var_name=[&quot;size&quot;, &quot;color&quot;],</span>
<span class="sd">            ...     var_type=[&quot;float&quot;, &quot;factor&quot;],</span>
<span class="sd">            ...     max_iter=20,</span>
<span class="sd">            ...     n_initial=10</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; table = opt.get_results_table()</span>
<span class="sd">            &gt;&gt;&gt; print(table)</span>
<span class="sd">            | name   | type   | lower   | upper   | tuned   |</span>
<span class="sd">            |--------|--------|---------|---------|---------|</span>
<span class="sd">            | size   | num    | -5.0    | 5.0     | 0.0123  |</span>
<span class="sd">            | color  | factor | red     | blue    | green   |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;No optimization results available. Run optimize() first.&quot;</span>

        <span class="c1"># Get best solution in full dimensions</span>
        <span class="c1"># Note: best_x_ is already in original scale</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="n">best_x_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">best_x_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>

        <span class="c1"># Map factor variables back to original string values</span>
        <span class="n">best_x_display</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_to_factor_values</span><span class="p">(</span><span class="n">best_x_full</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Prepare all variable transformations (use all_var_trans if dimension reduction occurred)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;all_var_trans&quot;</span><span class="p">):</span>
            <span class="n">all_var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_trans</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">all_var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span>

        <span class="c1"># Prepare table data</span>
        <span class="n">table_data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
                <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">best_x_display</span><span class="p">))]</span>
            <span class="p">),</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span>
                <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_x_display</span><span class="p">)</span>
            <span class="p">),</span>
            <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;lower&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;upper&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;tuned&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;transform&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;-&quot;</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">all_var_trans</span><span class="p">],</span>
        <span class="p">}</span>

        <span class="c1"># Helper to format values</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">fmt_val</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">)):</span>
                <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.</span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="n">v</span>

        <span class="c1"># Process bounds, defaults, and tuned values</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">best_x_display</span><span class="p">)):</span>
            <span class="n">var_type</span> <span class="o">=</span> <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># Handle bounds and defaults based on variable type</span>
            <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span><span class="p">:</span>
                <span class="c1"># For factors, show original string values</span>
                <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">:</span>
                    <span class="n">factor_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                    <span class="c1"># Default is middle level logic (matching get_design_table)</span>
                    <span class="n">mid_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">factor_map</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
                    <span class="n">default_str</span> <span class="o">=</span> <span class="n">factor_map</span><span class="p">[</span><span class="n">mid_idx</span><span class="p">]</span>

                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">default_str</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;N/A&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_upper</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
                <span class="c1"># Default is midpoint logic</span>
                <span class="n">default_val</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_upper</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>
                <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">default_val</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="n">default_val</span><span class="p">))</span>

            <span class="c1"># Format tuned value</span>
            <span class="n">tuned_val</span> <span class="o">=</span> <span class="n">best_x_display</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;tuned&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">tuned_val</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span><span class="p">:</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;tuned&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">tuned_val</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;tuned&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="n">tuned_val</span><span class="p">))</span>

        <span class="c1"># Add importance if requested</span>
        <span class="k">if</span> <span class="n">show_importance</span><span class="p">:</span>
            <span class="n">importance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_importance</span><span class="p">()</span>
            <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">importance</span><span class="p">]</span>
            <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;stars&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_stars</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span>

        <span class="c1"># Generate table</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">tabulate</span><span class="p">(</span>
            <span class="n">table_data</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">,</span>
            <span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">,</span>
            <span class="n">numalign</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
            <span class="n">stralign</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Add interpretation if importance is shown</span>
        <span class="k">if</span> <span class="n">show_importance</span><span class="p">:</span>
            <span class="n">table</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Interpretation: ***: &gt;99%, **: &gt;75%, *: &gt;50%, .: &gt;10%&quot;</span>

        <span class="k">return</span> <span class="n">table</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_design_table</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tablefmt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;github&quot;</span><span class="p">,</span>
        <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get a table string showing the search space design before optimization.</span>

<span class="sd">        This method generates a table displaying the variable names, types, bounds,</span>
<span class="sd">        and defaults without requiring an optimization run. Useful for inspecting</span>
<span class="sd">        and documenting the search space configuration.</span>

<span class="sd">        Args:</span>
<span class="sd">            tablefmt (str, optional): Table format for tabulate library.</span>
<span class="sd">                Defaults to &#39;github&#39;.</span>
<span class="sd">            precision (int, optional): Number of decimal places for float values.</span>
<span class="sd">                Defaults to 4.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Formatted table string.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 1: Numeric parameters</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-10, 10), (0, 1)],</span>
<span class="sd">            ...     var_name=[&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;],</span>
<span class="sd">            ...     var_type=[&quot;float&quot;, &quot;int&quot;, &quot;float&quot;],</span>
<span class="sd">            ...     max_iter=20,</span>
<span class="sd">            ...     n_initial=10</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; table = opt.get_design_table()</span>
<span class="sd">            &gt;&gt;&gt; print(table)</span>
<span class="sd">            | name   | type   |   lower |   upper |   default |</span>
<span class="sd">            |--------|--------|---------|---------|-----------|</span>
<span class="sd">            | x1     | num    |    -5.0 |     5.0 |       0.0 |</span>
<span class="sd">            | x2     | int    |   -10.0 |    10.0 |       0.0 |</span>
<span class="sd">            | x3     | num    |     0.0 |     1.0 |       0.5 |</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 2: With factor variables</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(10, 100), (&quot;SGD&quot;, &quot;Adam&quot;, &quot;RMSprop&quot;), (0.001, 0.1)],</span>
<span class="sd">            ...     var_name=[&quot;neurons&quot;, &quot;optimizer&quot;, &quot;lr&quot;],</span>
<span class="sd">            ...     var_type=[&quot;int&quot;, &quot;factor&quot;, &quot;float&quot;],</span>
<span class="sd">            ...     max_iter=30,</span>
<span class="sd">            ...     n_initial=10</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; table = opt.get_design_table()</span>
<span class="sd">            &gt;&gt;&gt; print(table)</span>
<span class="sd">            | name      | type   | lower   | upper   | default   |</span>
<span class="sd">            |-----------|--------|---------|---------|-----------|</span>
<span class="sd">            | neurons   | int    | 10.0    | 100.0   | 55.0      |</span>
<span class="sd">            | optimizer | factor | SGD     | RMSprop | Adam      |</span>
<span class="sd">            | lr        | num    | 0.001   | 0.1     | 0.0505    |</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 3: Before running optimization</span>
<span class="sd">            &gt;&gt;&gt; def hyperparameter_objective(X):</span>
<span class="sd">            ...     # X[:, 0]: layers, X[:, 1]: neurons, X[:, 2]: dropout</span>
<span class="sd">            ...     return np.sum(X**2, axis=1)  # Placeholder</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=hyperparameter_objective,</span>
<span class="sd">            ...     bounds=[(1, 5), (16, 256), (0.0, 0.5)],</span>
<span class="sd">            ...     var_name=[&quot;layers&quot;, &quot;neurons&quot;, &quot;dropout&quot;],</span>
<span class="sd">            ...     var_type=[&quot;int&quot;, &quot;int&quot;, &quot;float&quot;],</span>
<span class="sd">            ...     max_iter=50,</span>
<span class="sd">            ...     n_initial=15</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Get design table before optimization</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;Search Space Configuration:&quot;)</span>
<span class="sd">            &gt;&gt;&gt; table = opt.get_design_table()</span>
<span class="sd">            &gt;&gt;&gt; print(table)</span>
<span class="sd">            Search Space Configuration:</span>
<span class="sd">            | name    | type   |   lower |   upper |   default |</span>
<span class="sd">            |---------|--------|---------|---------|-----------|</span>
<span class="sd">            | layers  | int    |     1.0 |     5.0 |       3.0 |</span>
<span class="sd">            | neurons | int    |    16.0 |   256.0 |     136.0 |</span>
<span class="sd">            | dropout | num    |     0.0 |     0.5 |      0.25 |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Prepare all variable transformations (use all_var_trans if dimension reduction occurred)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;all_var_trans&quot;</span><span class="p">):</span>
            <span class="n">all_var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_trans</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">all_var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span>

        <span class="c1"># Prepare table data</span>
        <span class="n">table_data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
                <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">))]</span>
            <span class="p">),</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span>
                <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">)</span>
            <span class="p">),</span>
            <span class="s2">&quot;lower&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;upper&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;transform&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;-&quot;</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">all_var_trans</span><span class="p">],</span>
        <span class="p">}</span>

        <span class="c1"># Helper to format values</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">fmt_val</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">)):</span>
                <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.</span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">return</span> <span class="n">v</span>

        <span class="c1"># Process bounds and compute defaults (use original bounds for display)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span><span class="p">)):</span>
            <span class="n">var_type</span> <span class="o">=</span> <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span><span class="p">:</span>
                <span class="c1"># For factors, show original string values</span>
                <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">:</span>
                    <span class="n">factor_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                    <span class="c1"># Default is middle level</span>
                    <span class="n">mid_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">factor_map</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
                    <span class="n">default_str</span> <span class="o">=</span> <span class="n">factor_map</span><span class="p">[</span><span class="n">mid_idx</span><span class="p">]</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">default_str</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;N/A&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_upper</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
                <span class="c1"># Default is midpoint</span>
                <span class="n">default_val</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_upper</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>
                <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">default_val</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="n">default_val</span><span class="p">))</span>

        <span class="c1"># Generate table</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">tabulate</span><span class="p">(</span>
            <span class="n">table_data</span><span class="p">,</span>
            <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">,</span>
            <span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">,</span>
            <span class="n">numalign</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
            <span class="n">stralign</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">table</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">gen_design_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">tablefmt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;github&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate a table of the design or results.</span>

<span class="sd">        If optimization has been run (results available), returns the results table.</span>
<span class="sd">        Otherwise, returns the design table (search space configuration).</span>

<span class="sd">        Args:</span>
<span class="sd">            tablefmt (str, optional): Table format. Defaults to &#39;github&#39;.</span>
<span class="sd">            precision (int, optional): Number of decimal places for float values.</span>
<span class="sd">                Defaults to 4.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Formatted table string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_results_table</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_design_table</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_importance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate variable importance scores.</span>

<span class="sd">        Importance is computed as the normalized sensitivity of each parameter</span>
<span class="sd">        based on the variation in objective values across the evaluated points.</span>
<span class="sd">        Higher scores indicate parameters that have more influence on the objective.</span>

<span class="sd">        The importance is calculated as:</span>
<span class="sd">        1. For each dimension, compute the correlation between parameter values</span>
<span class="sd">           and objective values</span>
<span class="sd">        2. Normalize to percentage scale (0-100)</span>
<span class="sd">        3. Higher values indicate more important parameters</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[float]: Importance scores for each dimension (0-100 scale).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 1: Identify important parameters</span>
<span class="sd">            &gt;&gt;&gt; def test_func(X):</span>
<span class="sd">            ...     # x0 has strong effect, x1 has weak effect</span>
<span class="sd">            ...     return 10 * X[:, 0]**2 + 0.1 * X[:, 1]**2</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=test_func,</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     var_name=[&quot;x0&quot;, &quot;x1&quot;],</span>
<span class="sd">            ...     max_iter=30,</span>
<span class="sd">            ...     n_initial=10,</span>
<span class="sd">            ...     seed=42</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; importance = opt.get_importance()</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;x0 importance: {importance[0]:.2f}&quot;)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;x1 importance: {importance[1]:.2f}&quot;)</span>
<span class="sd">            x0 importance: 89.23</span>
<span class="sd">            x1 importance: 10.77</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 2: With more dimensions</span>
<span class="sd">            &gt;&gt;&gt; def rosenbrock(X):</span>
<span class="sd">            ...     return np.sum(100*(X[:, 1:] - X[:, :-1]**2)**2 + (1 - X[:, :-1])**2, axis=1)</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=rosenbrock,</span>
<span class="sd">            ...     bounds=[(-2, 2)] * 4,</span>
<span class="sd">            ...     var_name=[&quot;x0&quot;, &quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;],</span>
<span class="sd">            ...     max_iter=50,</span>
<span class="sd">            ...     n_initial=20,</span>
<span class="sd">            ...     seed=42</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; importance = opt.get_importance()</span>
<span class="sd">            &gt;&gt;&gt; for i, imp in enumerate(importance):</span>
<span class="sd">            ...     print(f&quot;x{i}: {imp:.2f}%&quot;)</span>
<span class="sd">            x0: 32.15%</span>
<span class="sd">            x1: 28.43%</span>
<span class="sd">            x2: 25.67%</span>
<span class="sd">            x3: 13.75%</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Example 3: Use in results table</span>
<span class="sd">            &gt;&gt;&gt; table = opt.print_results_table(show_importance=True)</span>
<span class="sd">            &gt;&gt;&gt; print(table)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="c1"># Not enough data to compute importance</span>
            <span class="k">return</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">)</span>

        <span class="c1"># Use full-dimensional data</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
            <span class="n">X_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">])</span>

        <span class="c1"># Calculate sensitivity for each dimension</span>
        <span class="n">sensitivities</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_full</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">x_i</span> <span class="o">=</span> <span class="n">X_full</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>

            <span class="c1"># Handle factor variables: map strings to integers</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_factor_maps&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">:</span>
                <span class="c1"># _factor_maps[i] is {int: str}, we need {str: int}</span>
                <span class="n">str_to_int</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Map values, handle potential missing values if any (though shouldn&#39;t simplify be there)</span>
                    <span class="n">x_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">str_to_int</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">x_i</span><span class="p">])</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="c1"># Fallback if mapping fails</span>
                    <span class="n">sensitivities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                    <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Ensure numeric type for non-factors</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">x_i</span> <span class="o">=</span> <span class="n">x_i</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                    <span class="c1"># If conversion fails, likely a string column without factor map?</span>
                    <span class="n">sensitivities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                    <span class="k">continue</span>

            <span class="c1"># Skip if no variation in this dimension</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x_i</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
                <span class="n">sensitivities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="c1"># Compute correlation with objective</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">correlation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">correlation</span><span class="p">):</span>
                    <span class="n">correlation</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">correlation</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="n">sensitivities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correlation</span><span class="p">)</span>

        <span class="c1"># Normalize to percentage</span>
        <span class="n">total</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sensitivities</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">total</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">importance</span> <span class="o">=</span> <span class="p">[(</span><span class="n">s</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sensitivities</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">importance</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">sensitivities</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">importance</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sensitivity_spearman</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute and print Spearman correlation between parameters and objective values.</span>

<span class="sd">        This method analyzes the sensitivity of the objective function to each</span>
<span class="sd">        hyperparameter by computing Spearman rank correlations. For categorical</span>
<span class="sd">        (factor) variables, correlation is not computed as they require visual</span>
<span class="sd">        inspection instead.</span>

<span class="sd">        The method automatically handles different parameter types:</span>
<span class="sd">        - Integer/float parameters: Direct correlation with objective values</span>
<span class="sd">        - Log-transformed parameters (log10, log, ln): Correlation in log-space</span>
<span class="sd">        - Factor (categorical) parameters: Skipped with informative message</span>

<span class="sd">        Significance levels:</span>
<span class="sd">        - ***: p &lt; 0.001 (highly significant)</span>
<span class="sd">        - **: p &lt; 0.01 (significant)</span>
<span class="sd">        - *: p &lt; 0.05 (marginally significant)</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # After running optimization</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(...)</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; opt.sensitivity_spearman()</span>
<span class="sd">            Sensitivity Analysis (Spearman Correlation):</span>
<span class="sd">            --------------------------------------------------</span>
<span class="sd">              l1 (neurons)        : +0.005 (p=0.959)</span>
<span class="sd">              num_layers          : -0.192 (p=0.056)</span>
<span class="sd">              activation          : (categorical variable, use visual inspection)</span>
<span class="sd">              lr_unified          : -0.040 (p=0.689)</span>
<span class="sd">              alpha               : -0.233 (p=0.020) *</span>

<span class="sd">        Note:</span>
<span class="sd">            Requires scipy to be installed. If not available, raises ImportError.</span>
<span class="sd">            Only meaningful after optimize() has been called with sufficient evaluations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">spearmanr</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;scipy is required for sensitivity_spearman(). &quot;</span>
                <span class="s2">&quot;Install it with: pip install scipy&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No optimization data available. Run optimize() first.&quot;</span><span class="p">)</span>

        <span class="c1"># Get optimization history and parameters</span>
        <span class="n">history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span>
        <span class="n">all_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span>

        <span class="c1"># Get parameter names</span>
        <span class="n">param_names</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">)]</span>
        <span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sensitivity Analysis (Spearman Correlation):&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">param_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">param_names</span><span class="p">[</span><span class="n">param_idx</span><span class="p">]</span>
            <span class="n">param_values</span> <span class="o">=</span> <span class="n">all_params</span><span class="p">[:,</span> <span class="n">param_idx</span><span class="p">]</span>

            <span class="c1"># Check if it&#39;s a factor variable</span>
            <span class="n">var_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">param_idx</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="k">else</span> <span class="s2">&quot;float&quot;</span>

            <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span><span class="p">:</span>
                <span class="c1"># For categorical variables, skip correlation</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: (categorical variable, use visual inspection)&quot;</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="c1"># Check if parameter has log transformation</span>
            <span class="n">var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">[</span><span class="n">param_idx</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="c1"># Compute correlation based on transformation</span>
            <span class="k">if</span> <span class="n">var_trans</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;log10&quot;</span><span class="p">,</span> <span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="s2">&quot;ln&quot;</span><span class="p">]:</span>
                <span class="c1"># For log-transformed parameters, use log-space correlation</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">param_values_numeric</span> <span class="o">=</span> <span class="n">param_values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
                    <span class="c1"># Filter out non-positive values</span>
                    <span class="n">valid_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">param_values_numeric</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">history</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">valid_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: (insufficient valid data for log correlation)&quot;</span>
                        <span class="p">)</span>
                        <span class="k">continue</span>

                    <span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">param_values_numeric</span><span class="p">[</span><span class="n">valid_mask</span><span class="p">]),</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="n">valid_mask</span><span class="p">]),</span>
                    <span class="p">)</span>
                <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: (error computing log correlation)&quot;</span><span class="p">)</span>
                    <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># For integer/float parameters, direct correlation</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">param_values_numeric</span> <span class="o">=</span> <span class="n">param_values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
                    <span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">param_values_numeric</span><span class="p">,</span> <span class="n">history</span><span class="p">)</span>
                <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: (error computing correlation)&quot;</span><span class="p">)</span>
                    <span class="k">continue</span>

            <span class="c1"># Determine significance level</span>
            <span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.001</span><span class="p">:</span>
                <span class="n">significance</span> <span class="o">=</span> <span class="s2">&quot; ***&quot;</span>
            <span class="k">elif</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">:</span>
                <span class="n">significance</span> <span class="o">=</span> <span class="s2">&quot; **&quot;</span>
            <span class="k">elif</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
                <span class="n">significance</span> <span class="o">=</span> <span class="s2">&quot; *&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">significance</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">corr</span><span class="si">:</span><span class="s2">+.3f</span><span class="si">}</span><span class="s2"> (p=</span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)</span><span class="si">{</span><span class="n">significance</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_stars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a list of values to a list of stars.</span>

<span class="sd">        Used to visualize the importance of a variable.</span>
<span class="sd">        Thresholds: &gt;99: ***, &gt;75: **, &gt;50: *, &gt;10: .</span>

<span class="sd">        Args:</span>
<span class="sd">            input_list (list): A list of importance scores (0-100).</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: A list of star strings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">input_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">99</span><span class="p">:</span>
                <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;***&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">75</span><span class="p">:</span>
                <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;**&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">50</span><span class="p">:</span>
                <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
                <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output_list</span>

    <span class="c1"># ====================</span>
    <span class="c1"># TensorBoard Integration</span>
    <span class="c1"># ====================</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_clean_tensorboard_logs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clean old TensorBoard log directories from the runs folder.</span>

<span class="sd">        Removes all subdirectories in the &#39;runs&#39; directory if tensorboard_clean is True.</span>
<span class="sd">        This is useful for removing old logs before starting a new optimization run.</span>

<span class="sd">        Warning:</span>
<span class="sd">            This will permanently delete all subdirectories in the &#39;runs&#39; folder.</span>
<span class="sd">            Use with caution.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     tensorboard_log=True,</span>
<span class="sd">            ...     tensorboard_clean=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Old logs in &#39;runs&#39; will be removed before optimization starts</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_clean</span><span class="p">:</span>
            <span class="n">runs_dir</span> <span class="o">=</span> <span class="s2">&quot;runs&quot;</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">runs_dir</span><span class="p">)</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">runs_dir</span><span class="p">):</span>
                <span class="c1"># Get all subdirectories in runs</span>
                <span class="n">subdirs</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">runs_dir</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">runs_dir</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">runs_dir</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
                <span class="p">]</span>

                <span class="k">if</span> <span class="n">subdirs</span><span class="p">:</span>
                    <span class="n">removed_count</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="k">for</span> <span class="n">subdir</span> <span class="ow">in</span> <span class="n">subdirs</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">subdir</span><span class="p">)</span>
                            <span class="n">removed_count</span> <span class="o">+=</span> <span class="mi">1</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Removed old TensorBoard logs: </span><span class="si">{</span><span class="n">subdir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Could not remove </span><span class="si">{</span><span class="n">subdir</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="n">removed_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Cleaned </span><span class="si">{</span><span class="n">removed_count</span><span class="si">}</span><span class="s2"> old TensorBoard log director</span><span class="si">{</span><span class="s1">&#39;y&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">removed_count</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;ies&#39;</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No old TensorBoard logs to clean in &#39;runs&#39; directory&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&#39;runs&#39; directory does not exist, nothing to clean&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init_tensorboard_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize TensorBoard SummaryWriter if logging is enabled.</span>

<span class="sd">        Creates a unique log directory based on timestamp if tensorboard_log is True.</span>
<span class="sd">        The log directory will be in the format: runs/spotoptim_YYYYMMDD_HHMMSS</span>


<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     tensorboard_log=True</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; hasattr(opt, &#39;tb_writer&#39;)</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_log</span><span class="p">:</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Create default path with timestamp</span>
                <span class="n">timestamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">_%H%M%S&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;runs/spotoptim_</span><span class="si">{</span><span class="n">timestamp</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="c1"># Create directory if it doesn&#39;t exist</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorBoard logging enabled: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TensorBoard logging disabled&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_write_tensorboard_scalars</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write scalar metrics to TensorBoard.</span>

<span class="sd">        Logs the following metrics:</span>
<span class="sd">        - Best y value found so far (min_y)</span>
<span class="sd">        - Last y value evaluated</span>
<span class="sd">        - Best X coordinates (for each dimension)</span>
<span class="sd">        - If noise=True: also logs mean values and variance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span>
        <span class="n">y_last</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
            <span class="c1"># Non-noisy optimization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalars</span><span class="p">(</span>
                <span class="s2">&quot;y_values&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;min&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_y</span><span class="p">,</span> <span class="s2">&quot;last&quot;</span><span class="p">:</span> <span class="n">y_last</span><span class="p">},</span> <span class="n">step</span>
            <span class="p">)</span>
            <span class="c1"># Log success rate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;success_rate&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">success_rate</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="c1"># Log best X coordinates using var_name if available</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">):</span>
                <span class="n">param_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;X_best/</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">step</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Noisy optimization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalars</span><span class="p">(</span>
                <span class="s2">&quot;y_values&quot;</span><span class="p">,</span>
                <span class="p">{</span><span class="s2">&quot;min&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_y</span><span class="p">,</span> <span class="s2">&quot;mean_best&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span><span class="p">,</span> <span class="s2">&quot;last&quot;</span><span class="p">:</span> <span class="n">y_last</span><span class="p">},</span>
                <span class="n">step</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Log variance of best mean</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;y_variance_at_best&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_var_y</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="c1"># Log success rate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;success_rate&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">success_rate</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

            <span class="c1"># Log best X coordinates (by mean) using var_name if available</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">):</span>
                <span class="n">param_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;X_mean_best/</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">step</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_write_tensorboard_hparams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write hyperparameters and metric to TensorBoard.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (ndarray): Design point coordinates, shape (n_features,)</span>
<span class="sd">            y (float): Function value at X</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Create hyperparameter dict with variable names</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">var_name</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="nb">float</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">)}</span>
        <span class="n">metric_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;hp_metric&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">y</span><span class="p">)}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">(</span><span class="n">hparam_dict</span><span class="p">,</span> <span class="n">metric_dict</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_close_tensorboard_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Close TensorBoard writer and cleanup.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tb_writer&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;TensorBoard writer closed. View logs with: tensorboard --logdir=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init_tensorboard</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Log initial design to TensorBoard.</span>

<span class="sd">        Logs all initial design points (hyperparameters and function values)</span>
<span class="sd">        and scalar metrics to TensorBoard. Only executes if TensorBoard logging</span>
<span class="sd">        is enabled (tb_writer is not None).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">            ...     n_initial=5,</span>
<span class="sd">            ...     tensorboard_log=True,</span>
<span class="sd">            ...     verbose=False</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Simulate initial design (normally done in optimize())</span>
<span class="sd">            &gt;&gt;&gt; opt.X_ = np.array([[1, 2], [0, 0], [2, 1]])</span>
<span class="sd">            &gt;&gt;&gt; opt.y_ = np.array([5.0, 0.0, 5.0])</span>
<span class="sd">            &gt;&gt;&gt; opt._init_tensorboard()</span>
<span class="sd">            &gt;&gt;&gt; # TensorBoard logs created for all initial points</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create writer if not exists</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_log</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Determine log directory</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span><span class="p">:</span>
                <span class="n">log_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="kn">import</span><span class="w"> </span><span class="nn">datetime</span>

                <span class="n">timestamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">_%H%M%S&quot;</span><span class="p">)</span>
                <span class="n">log_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;runs/spotoptim_</span><span class="si">{</span><span class="n">timestamp</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">tensorboard_path</span> <span class="o">=</span> <span class="n">log_dir</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_path</span> <span class="o">=</span> <span class="n">log_dir</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.tensorboard</span><span class="w"> </span><span class="kn">import</span> <span class="n">SummaryWriter</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="n">log_dir</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorBoard logging enabled: </span><span class="si">{</span><span class="n">log_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: torch or tensorboard not installed. Logging disabled.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">tensorboard_log</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_log</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_hparams</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_write_tensorboard_scalars</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_close_and_del_tensorboard_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Close and delete TensorBoard writer to prepare for pickling.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(fun=lambda x: x, bounds=[(0, 1)])</span>
<span class="sd">            &gt;&gt;&gt; # Assume tb_writer is initialized</span>
<span class="sd">            &gt;&gt;&gt; opt.tb_writer = SomeTensorBoardWriter()</span>
<span class="sd">            &gt;&gt;&gt; # Close and delete tb_writer before pickling</span>
<span class="sd">            &gt;&gt;&gt; opt._close_and_del_tensorboard_writer()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tb_writer&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># ====================</span>
    <span class="c1"># Plotting</span>
    <span class="c1"># ====================</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">plot_progress</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">log_y</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
        <span class="n">ylabel</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Objective Value&quot;</span><span class="p">,</span>
        <span class="n">mo</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot optimization progress using spotoptim.plot.visualization.plot_progress.&quot;&quot;&quot;</span>
        <span class="n">plot_progress</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="n">show</span><span class="p">,</span> <span class="n">log_y</span><span class="o">=</span><span class="n">log_y</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="n">ylabel</span><span class="p">,</span> <span class="n">mo</span><span class="o">=</span><span class="n">mo</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">plot_surrogate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">i</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">j</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="n">var_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cmap</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;jet&quot;</span><span class="p">,</span>
        <span class="n">num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">vmin</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">vmax</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">add_points</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">grid_visible</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">contour_levels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot the surrogate model for two dimensions.</span>

<span class="sd">        Delegates to spotoptim.plot.visualization.plot_surrogate.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">plot_surrogate</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
            <span class="n">j</span><span class="o">=</span><span class="n">j</span><span class="p">,</span>
            <span class="n">show</span><span class="o">=</span><span class="n">show</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
            <span class="n">var_name</span><span class="o">=</span><span class="n">var_name</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
            <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">,</span>
            <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span>
            <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span>
            <span class="n">add_points</span><span class="o">=</span><span class="n">add_points</span><span class="p">,</span>
            <span class="n">grid_visible</span><span class="o">=</span><span class="n">grid_visible</span><span class="p">,</span>
            <span class="n">contour_levels</span><span class="o">=</span><span class="n">contour_levels</span><span class="p">,</span>
            <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">plot_important_hyperparameter_contour</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">max_imp</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="n">cmap</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;jet&quot;</span><span class="p">,</span>
        <span class="n">num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">add_points</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">grid_visible</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">contour_levels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot surrogate contours using spotoptim.plot.visualization.plot_important_hyperparameter_contour.&quot;&quot;&quot;</span>
        <span class="n">plot_important_hyperparameter_contour</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">max_imp</span><span class="o">=</span><span class="n">max_imp</span><span class="p">,</span>
            <span class="n">show</span><span class="o">=</span><span class="n">show</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
            <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">,</span>
            <span class="n">add_points</span><span class="o">=</span><span class="n">add_points</span><span class="p">,</span>
            <span class="n">grid_visible</span><span class="o">=</span><span class="n">grid_visible</span><span class="p">,</span>
            <span class="n">contour_levels</span><span class="o">=</span><span class="n">contour_levels</span><span class="p">,</span>
            <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_plot_surrogate_with_factors</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">j</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="n">cmap</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;jet&quot;</span><span class="p">,</span>
        <span class="n">num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">add_points</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">grid_visible</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">contour_levels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Delegates to spotoptim.plot.visualization._plot_surrogate_with_factors.&quot;&quot;&quot;</span>
        <span class="n">_plot_surrogate_with_factors</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
            <span class="n">j</span><span class="o">=</span><span class="n">j</span><span class="p">,</span>
            <span class="n">show</span><span class="o">=</span><span class="n">show</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
            <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">,</span>
            <span class="n">add_points</span><span class="o">=</span><span class="n">add_points</span><span class="p">,</span>
            <span class="n">grid_visible</span><span class="o">=</span><span class="n">grid_visible</span><span class="p">,</span>
            <span class="n">contour_levels</span><span class="o">=</span><span class="n">contour_levels</span><span class="p">,</span>
            <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">plot_importance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot variable importance.</span>

<span class="sd">        Args:</span>
<span class="sd">            threshold (float): Minimum importance percentage to include in plot.</span>
<span class="sd">            figsize (tuple): Figure size.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_importance</span><span class="p">()</span>
        <span class="n">names</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
            <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">importance</span><span class="p">))]</span>
        <span class="p">)</span>

        <span class="c1"># Filter by threshold</span>
        <span class="n">filtered_data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">importance</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">]</span>
        <span class="n">filtered_data</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">filtered_data</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No variables met the importance threshold.&quot;</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="n">names</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">filtered_data</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
        <span class="n">y_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">y_pos</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">y_pos</span><span class="p">,</span> <span class="n">names</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Importance (%)&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Variable Importance&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>  <span class="c1"># Best on top</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">plot_parameter_scatter</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">result</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">OptimizeResult</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">ylabel</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Objective Value&quot;</span><span class="p">,</span>
        <span class="n">cmap</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;viridis_r&quot;</span><span class="p">,</span>
        <span class="n">show_correlation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">log_y</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot parameter distributions showing relationship between each parameter and objective.</span>

<span class="sd">        Creates a grid of scatter plots, one for each parameter dimension, showing how</span>
<span class="sd">        the objective function value varies with each parameter. The best configuration</span>
<span class="sd">        is marked with a red star. Parameters with log-scale transformations (var_trans)</span>
<span class="sd">        are automatically displayed on a log x-axis.</span>

<span class="sd">        Optionally displays Spearman correlation coefficients in plot titles for</span>
<span class="sd">        sensitivity analysis. For factor (categorical) variables, correlation is not</span>
<span class="sd">        computed and they are displayed with discrete positions on the x-axis.</span>

<span class="sd">        Args:</span>
<span class="sd">            result (OptimizeResult, optional): Optimization result containing best parameters.</span>
<span class="sd">                If None, uses the best found values from self.best_x_ and self.best_y_.</span>
<span class="sd">            show (bool, optional): Whether to display the plot. Defaults to True.</span>
<span class="sd">            figsize (tuple, optional): Figure size as (width, height). Defaults to (12, 10).</span>
<span class="sd">            ylabel (str, optional): Label for y-axis. Defaults to &quot;Objective Value&quot;.</span>
<span class="sd">            cmap (str, optional): Colormap for scatter plot. Defaults to &quot;viridis_r&quot;.</span>
<span class="sd">            show_correlation (bool, optional): Whether to compute and display Spearman</span>
<span class="sd">                correlation coefficients in plot titles. Requires scipy. Defaults to False.</span>
<span class="sd">            log_y (bool, optional): Whether to use logarithmic scale for y-axis.</span>
<span class="sd">                Defaults to False.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If no optimization data is available.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">            &gt;&gt;&gt; def objective(X):</span>
<span class="sd">            ...     return np.sum(X**2, axis=1)</span>
<span class="sd">            &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">            ...     fun=objective,</span>
<span class="sd">            ...     bounds=[(-5, 5), (-5, 5), (-5, 5), (-5, 5)],</span>
<span class="sd">            ...     var_name=[&quot;x0&quot;, &quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;],</span>
<span class="sd">            ...     max_iter=30,</span>
<span class="sd">            ...     n_initial=10,</span>
<span class="sd">            ...     seed=42</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">            &gt;&gt;&gt; # Plot parameter distributions</span>
<span class="sd">            &gt;&gt;&gt; opt.plot_parameter_scatter(result)</span>
<span class="sd">            &gt;&gt;&gt; # Plot with custom settings</span>
<span class="sd">            &gt;&gt;&gt; opt.plot_parameter_scatter(result, cmap=&quot;plasma&quot;, ylabel=&quot;Error&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;matplotlib is required for plot_parameter_scatter(). &quot;</span>
                <span class="s2">&quot;Install it with: pip install matplotlib&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Import scipy if correlation is requested</span>
        <span class="k">if</span> <span class="n">show_correlation</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">spearmanr</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                    <span class="s2">&quot;scipy is required for show_correlation=True. &quot;</span>
                    <span class="s2">&quot;Install it with: pip install scipy&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No optimization data available. Run optimize() first.&quot;</span><span class="p">)</span>

        <span class="c1"># Get best values</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">best_x</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>
            <span class="n">best_y</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">best_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>
            <span class="n">best_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No best solution available.&quot;</span><span class="p">)</span>

        <span class="n">all_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span>
        <span class="n">history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span>

        <span class="c1"># Determine grid dimensions</span>
        <span class="n">n_params</span> <span class="o">=</span> <span class="n">all_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">n_cols</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_params</span><span class="p">)</span>
        <span class="n">n_rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_params</span> <span class="o">/</span> <span class="n">n_cols</span><span class="p">))</span>

        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>

        <span class="c1"># Make axes always iterable</span>
        <span class="k">if</span> <span class="n">n_params</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">axes</span><span class="p">])</span>
        <span class="n">axes_flat</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">if</span> <span class="n">n_params</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">axes</span>

        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_params</span><span class="p">):</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">axes_flat</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">param_values</span> <span class="o">=</span> <span class="n">all_params</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span>
            <span class="n">param_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">var_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="k">else</span> <span class="s2">&quot;float&quot;</span>
            <span class="n">var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="c1"># Check if this is a factor variable</span>
            <span class="n">is_factor</span> <span class="o">=</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span>

            <span class="c1"># Compute correlation if requested</span>
            <span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">if</span> <span class="n">show_correlation</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_factor</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">var_trans</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;log10&quot;</span><span class="p">,</span> <span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="s2">&quot;ln&quot;</span><span class="p">]:</span>
                        <span class="c1"># For log-transformed parameters, correlate in log-space</span>
                        <span class="n">param_values_numeric</span> <span class="o">=</span> <span class="n">param_values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
                        <span class="n">valid_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">param_values_numeric</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">history</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">valid_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
                            <span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span>
                                <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">param_values_numeric</span><span class="p">[</span><span class="n">valid_mask</span><span class="p">]),</span>
                                <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="n">valid_mask</span><span class="p">]),</span>
                            <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Direct correlation for non-transformed parameters</span>
                        <span class="n">param_values_numeric</span> <span class="o">=</span> <span class="n">param_values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
                        <span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">param_values_numeric</span><span class="p">,</span> <span class="n">history</span><span class="p">)</span>
                <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
                    <span class="k">pass</span>  <span class="c1"># Keep corr as nan</span>

            <span class="c1"># Handle factor variables differently</span>
            <span class="k">if</span> <span class="n">is_factor</span><span class="p">:</span>
                <span class="c1"># Map factor levels to integer positions</span>
                <span class="n">unique_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">param_values</span><span class="p">)</span>
                <span class="n">positions</span> <span class="o">=</span> <span class="p">{</span><span class="n">val</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">)}</span>
                <span class="n">numeric_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">positions</span><span class="p">[</span><span class="n">val</span><span class="p">]</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">param_values</span><span class="p">])</span>

                <span class="c1"># Scatter plot with discrete x positions</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                    <span class="n">numeric_vals</span><span class="p">,</span>
                    <span class="n">history</span><span class="p">,</span>
                    <span class="n">c</span><span class="o">=</span><span class="n">history</span><span class="p">,</span>
                    <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                    <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                    <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># Mark best configuration</span>
                <span class="n">best_val</span> <span class="o">=</span> <span class="n">best_x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">best_val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">positions</span><span class="p">:</span>
                    <span class="n">positions</span><span class="p">[</span><span class="n">best_val</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">positions</span><span class="p">)</span>
                    <span class="n">unique_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">,</span> <span class="n">best_val</span><span class="p">)</span>

                <span class="n">best_pos</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">best_val</span><span class="p">]</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">best_pos</span><span class="p">],</span>
                    <span class="p">[</span><span class="n">best_y</span><span class="p">],</span>
                    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
                    <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                    <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Best&quot;</span><span class="p">,</span>
                    <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># Set categorical x-axis labels</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">)))</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Standard scatter plot for numeric variables</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                    <span class="n">param_values</span><span class="p">,</span>
                    <span class="n">history</span><span class="p">,</span>
                    <span class="n">c</span><span class="o">=</span><span class="n">history</span><span class="p">,</span>
                    <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                    <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                    <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># Mark best configuration</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">best_x</span><span class="p">[</span><span class="n">idx</span><span class="p">]],</span>
                    <span class="p">[</span><span class="n">best_y</span><span class="p">],</span>
                    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
                    <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                    <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Best&quot;</span><span class="p">,</span>
                    <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># Use log scale for parameters with log transformations</span>
                <span class="k">if</span> <span class="n">var_trans</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;log10&quot;</span><span class="p">,</span> <span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="s2">&quot;ln&quot;</span><span class="p">]:</span>
                    <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>

            <span class="c1"># Set labels</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>

            <span class="c1"># Set title with optional correlation</span>
            <span class="k">if</span> <span class="n">show_correlation</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">corr</span><span class="p">):</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="se">\n</span><span class="s2">Corr: </span><span class="si">{</span><span class="n">corr</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (p=</span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">show_correlation</span> <span class="ow">and</span> <span class="n">is_factor</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="se">\n</span><span class="s2">(categorical)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2"> vs </span><span class="si">{</span><span class="n">ylabel</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

            <span class="c1"># Use log scale for y-axis if requested</span>
            <span class="k">if</span> <span class="n">log_y</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>

        <span class="c1"># Hide unused subplots</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_params</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes_flat</span><span class="p">)):</span>
            <span class="n">axes_flat</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_mesh_grid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
        <span class="c1"># Wrapper for _generate_mesh_grid from visualization module.</span>
        <span class="k">return</span> <span class="n">_generate_mesh_grid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_mesh_grid_with_factors</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">is_factor_i</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">is_factor_j</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="p">):</span>
        <span class="c1"># Wrapper for _generate_mesh_grid_with_factors from visualization module.</span>
        <span class="k">return</span> <span class="n">_generate_mesh_grid_with_factors</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">is_factor_i</span><span class="p">,</span> <span class="n">is_factor_j</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.__dir__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__dir__</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.__dir__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Include config and state attributes in dir().</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Include config and state attributes in dir().&quot;&quot;&quot;</span>
    <span class="n">d</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">())</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">)</span>
        <span class="n">d</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dir</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;state&quot;</span><span class="p">)</span>
        <span class="c1"># Filter internal methods/fields from dir if desired, but good for now</span>
        <span class="n">d</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dir</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.__getattr__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__getattr__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.__getattr__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Proxy attribute access to config and state.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">941</span>
<span class="normal">942</span>
<span class="normal">943</span>
<span class="normal">944</span>
<span class="normal">945</span>
<span class="normal">946</span>
<span class="normal">947</span>
<span class="normal">948</span>
<span class="normal">949</span>
<span class="normal">950</span>
<span class="normal">951</span>
<span class="normal">952</span>
<span class="normal">953</span>
<span class="normal">954</span>
<span class="normal">955</span>
<span class="normal">956</span>
<span class="normal">957</span>
<span class="normal">958</span>
<span class="normal">959</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Proxy attribute access to config and state.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;state&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&#39; object has no attribute &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.__setattr__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.__setattr__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Proxy attribute assignment to config and state.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">961</span>
<span class="normal">962</span>
<span class="normal">963</span>
<span class="normal">964</span>
<span class="normal">965</span>
<span class="normal">966</span>
<span class="normal">967</span>
<span class="normal">968</span>
<span class="normal">969</span>
<span class="normal">970</span>
<span class="normal">971</span>
<span class="normal">972</span>
<span class="normal">973</span>
<span class="normal">974</span>
<span class="normal">975</span>
<span class="normal">976</span>
<span class="normal">977</span>
<span class="normal">978</span>
<span class="normal">979</span>
<span class="normal">980</span>
<span class="normal">981</span>
<span class="normal">982</span>
<span class="normal">983</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Proxy attribute assignment to config and state.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="s2">&quot;state&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;config&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
            <span class="k">return</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;state&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
            <span class="k">return</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.detect_var_type" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">detect_var_type</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.detect_var_type" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Auto-detect variable types based on factor mappings.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>list</code></td>            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of variable types (&lsquo;factor&rsquo; or &lsquo;float&rsquo;) for each dimension.
  Dimensions with factor mappings are assigned &lsquo;factor&rsquo;, others &lsquo;float&rsquo;.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">detect_var_type</span><span class="p">()</span>
<span class="go">[&#39;factor&#39;, &#39;float&#39;]</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">detect_var_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Auto-detect variable types based on factor mappings.</span>

<span class="sd">    Returns:</span>
<span class="sd">        list: List of variable types (&#39;factor&#39; or &#39;float&#39;) for each dimension.</span>
<span class="sd">              Dimensions with factor mappings are assigned &#39;factor&#39;, others &#39;float&#39;.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;), (0, 10)])</span>
<span class="sd">        &gt;&gt;&gt; spot.detect_var_type()</span>
<span class="sd">        [&#39;factor&#39;, &#39;float&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="s2">&quot;factor&quot;</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span> <span class="k">else</span> <span class="s2">&quot;float&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">)</span>
    <span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.gen_design_table" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">gen_design_table</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;github&#39;</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.gen_design_table" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generate a table of the design or results.</p>
<p>If optimization has been run (results available), returns the results table.
Otherwise, returns the design table (search space configuration).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tablefmt</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Table format. Defaults to &lsquo;github&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;github&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>precision</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of decimal places for float values.
Defaults to 4.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>str</code></td>            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Formatted table string.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">6519</span>
<span class="normal">6520</span>
<span class="normal">6521</span>
<span class="normal">6522</span>
<span class="normal">6523</span>
<span class="normal">6524</span>
<span class="normal">6525</span>
<span class="normal">6526</span>
<span class="normal">6527</span>
<span class="normal">6528</span>
<span class="normal">6529</span>
<span class="normal">6530</span>
<span class="normal">6531</span>
<span class="normal">6532</span>
<span class="normal">6533</span>
<span class="normal">6534</span>
<span class="normal">6535</span>
<span class="normal">6536</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">gen_design_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">tablefmt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;github&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate a table of the design or results.</span>

<span class="sd">    If optimization has been run (results available), returns the results table.</span>
<span class="sd">    Otherwise, returns the design table (search space configuration).</span>

<span class="sd">    Args:</span>
<span class="sd">        tablefmt (str, optional): Table format. Defaults to &#39;github&#39;.</span>
<span class="sd">        precision (int, optional): Number of decimal places for float values.</span>
<span class="sd">            Defaults to 4.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: Formatted table string.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_results_table</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_design_table</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.get_best_hyperparameters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_best_hyperparameters</span><span class="p">(</span><span class="n">as_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.get_best_hyperparameters" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get the best hyperparameter configuration found during optimization.</p>
<p>If noise handling is active (repeats_initial &gt; 1 or OCBA), this returns the parameter
configuration associated with the best <em>mean</em> objective value. Otherwise, it returns
the configuration associated with the absolute best observed value.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>as_dict</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns a dictionary mapping parameter names
to their values. If False, returns the raw numpy array. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>], <span title="numpy.ndarray">ndarray</span>, None]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Union[Dict[str, Any], np.ndarray, None]: The best hyperparameter configuration.
Returns None if optimization hasn&rsquo;t started (no data).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span> <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best_params</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_best_hyperparameters</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span> <span class="c1"># Should be close to 0</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_best_hyperparameters</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">as_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the best hyperparameter configuration found during optimization.</span>

<span class="sd">    If noise handling is active (repeats_initial &gt; 1 or OCBA), this returns the parameter</span>
<span class="sd">    configuration associated with the best *mean* objective value. Otherwise, it returns</span>
<span class="sd">    the configuration associated with the absolute best observed value.</span>

<span class="sd">    Args:</span>
<span class="sd">        as_dict (bool, optional): If True, returns a dictionary mapping parameter names</span>
<span class="sd">            to their values. If False, returns the raw numpy array. Defaults to True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[Dict[str, Any], np.ndarray, None]: The best hyperparameter configuration.</span>
<span class="sd">            Returns None if optimization hasn&#39;t started (no data).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(fun=lambda x: np.sum(x**2), bounds=[(-5, 5)], var_name=[&quot;x&quot;])</span>
<span class="sd">        &gt;&gt;&gt; opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; best_params = opt.get_best_hyperparameters()</span>
<span class="sd">        &gt;&gt;&gt; print(best_params[&#39;x&#39;]) # Should be close to 0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># Determine which &quot;best&quot; to use</span>
    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;min_mean_X&quot;</span>
    <span class="p">):</span>
        <span class="n">best_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_X</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">best_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">as_dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">best_x</span>

    <span class="c1"># Map factors using existing method (handles 2D, returns 2D)</span>
    <span class="c1"># We pass best_x as (1, D) and get (1, D) back</span>
    <span class="n">mapped_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_to_factor_values</span><span class="p">(</span><span class="n">best_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Convert to dictionary with types</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;p</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">best_x</span><span class="p">))]</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">names</span><span class="p">):</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">mapped_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="c1"># Handle types if available (specifically int, as factors are already mapped)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">:</span>
            <span class="n">v_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">v_type</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
                <span class="n">val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">val</span><span class="p">))</span>

        <span class="n">params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>

    <span class="k">return</span> <span class="n">params</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.get_design_table" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_design_table</span><span class="p">(</span><span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;github&#39;</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.get_design_table" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get a table string showing the search space design before optimization.</p>
<p>This method generates a table displaying the variable names, types, bounds,
and defaults without requiring an optimization run. Useful for inspecting
and documenting the search space configuration.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tablefmt</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Table format for tabulate library.
Defaults to &lsquo;github&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;github&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>precision</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of decimal places for float values.
Defaults to 4.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>str</code></td>            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Formatted table string.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 1: Numeric parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;x3&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">var_type</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">table</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_design_table</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="go">| name   | type   |   lower |   upper |   default |</span>
<span class="go">|--------|--------|---------|---------|-----------|</span>
<span class="go">| x1     | num    |    -5.0 |     5.0 |       0.0 |</span>
<span class="go">| x2     | int    |   -10.0 |    10.0 |       0.0 |</span>
<span class="go">| x3     | num    |     0.0 |     1.0 |       0.5 |</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 2: With factor variables</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;SGD&quot;</span><span class="p">,</span> <span class="s2">&quot;Adam&quot;</span><span class="p">,</span> <span class="s2">&quot;RMSprop&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;neurons&quot;</span><span class="p">,</span> <span class="s2">&quot;optimizer&quot;</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">var_type</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="s2">&quot;factor&quot;</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">table</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_design_table</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="go">| name      | type   | lower   | upper   | default   |</span>
<span class="go">|-----------|--------|---------|---------|-----------|</span>
<span class="go">| neurons   | int    | 10.0    | 100.0   | 55.0      |</span>
<span class="go">| optimizer | factor | SGD     | RMSprop | Adam      |</span>
<span class="go">| lr        | num    | 0.001   | 0.1     | 0.0505    |</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 3: Before running optimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">hyperparameter_objective</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="c1"># X[:, 0]: layers, X[:, 1]: neurons, X[:, 2]: dropout</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Placeholder</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">hyperparameter_objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;layers&quot;</span><span class="p">,</span> <span class="s2">&quot;neurons&quot;</span><span class="p">,</span> <span class="s2">&quot;dropout&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">var_type</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">15</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get design table before optimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Search Space Configuration:&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">table</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_design_table</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="go">Search Space Configuration:</span>
<span class="go">| name    | type   |   lower |   upper |   default |</span>
<span class="go">|---------|--------|---------|---------|-----------|</span>
<span class="go">| layers  | int    |     1.0 |     5.0 |       3.0 |</span>
<span class="go">| neurons | int    |    16.0 |   256.0 |     136.0 |</span>
<span class="go">| dropout | num    |     0.0 |     0.5 |      0.25 |</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">6369</span>
<span class="normal">6370</span>
<span class="normal">6371</span>
<span class="normal">6372</span>
<span class="normal">6373</span>
<span class="normal">6374</span>
<span class="normal">6375</span>
<span class="normal">6376</span>
<span class="normal">6377</span>
<span class="normal">6378</span>
<span class="normal">6379</span>
<span class="normal">6380</span>
<span class="normal">6381</span>
<span class="normal">6382</span>
<span class="normal">6383</span>
<span class="normal">6384</span>
<span class="normal">6385</span>
<span class="normal">6386</span>
<span class="normal">6387</span>
<span class="normal">6388</span>
<span class="normal">6389</span>
<span class="normal">6390</span>
<span class="normal">6391</span>
<span class="normal">6392</span>
<span class="normal">6393</span>
<span class="normal">6394</span>
<span class="normal">6395</span>
<span class="normal">6396</span>
<span class="normal">6397</span>
<span class="normal">6398</span>
<span class="normal">6399</span>
<span class="normal">6400</span>
<span class="normal">6401</span>
<span class="normal">6402</span>
<span class="normal">6403</span>
<span class="normal">6404</span>
<span class="normal">6405</span>
<span class="normal">6406</span>
<span class="normal">6407</span>
<span class="normal">6408</span>
<span class="normal">6409</span>
<span class="normal">6410</span>
<span class="normal">6411</span>
<span class="normal">6412</span>
<span class="normal">6413</span>
<span class="normal">6414</span>
<span class="normal">6415</span>
<span class="normal">6416</span>
<span class="normal">6417</span>
<span class="normal">6418</span>
<span class="normal">6419</span>
<span class="normal">6420</span>
<span class="normal">6421</span>
<span class="normal">6422</span>
<span class="normal">6423</span>
<span class="normal">6424</span>
<span class="normal">6425</span>
<span class="normal">6426</span>
<span class="normal">6427</span>
<span class="normal">6428</span>
<span class="normal">6429</span>
<span class="normal">6430</span>
<span class="normal">6431</span>
<span class="normal">6432</span>
<span class="normal">6433</span>
<span class="normal">6434</span>
<span class="normal">6435</span>
<span class="normal">6436</span>
<span class="normal">6437</span>
<span class="normal">6438</span>
<span class="normal">6439</span>
<span class="normal">6440</span>
<span class="normal">6441</span>
<span class="normal">6442</span>
<span class="normal">6443</span>
<span class="normal">6444</span>
<span class="normal">6445</span>
<span class="normal">6446</span>
<span class="normal">6447</span>
<span class="normal">6448</span>
<span class="normal">6449</span>
<span class="normal">6450</span>
<span class="normal">6451</span>
<span class="normal">6452</span>
<span class="normal">6453</span>
<span class="normal">6454</span>
<span class="normal">6455</span>
<span class="normal">6456</span>
<span class="normal">6457</span>
<span class="normal">6458</span>
<span class="normal">6459</span>
<span class="normal">6460</span>
<span class="normal">6461</span>
<span class="normal">6462</span>
<span class="normal">6463</span>
<span class="normal">6464</span>
<span class="normal">6465</span>
<span class="normal">6466</span>
<span class="normal">6467</span>
<span class="normal">6468</span>
<span class="normal">6469</span>
<span class="normal">6470</span>
<span class="normal">6471</span>
<span class="normal">6472</span>
<span class="normal">6473</span>
<span class="normal">6474</span>
<span class="normal">6475</span>
<span class="normal">6476</span>
<span class="normal">6477</span>
<span class="normal">6478</span>
<span class="normal">6479</span>
<span class="normal">6480</span>
<span class="normal">6481</span>
<span class="normal">6482</span>
<span class="normal">6483</span>
<span class="normal">6484</span>
<span class="normal">6485</span>
<span class="normal">6486</span>
<span class="normal">6487</span>
<span class="normal">6488</span>
<span class="normal">6489</span>
<span class="normal">6490</span>
<span class="normal">6491</span>
<span class="normal">6492</span>
<span class="normal">6493</span>
<span class="normal">6494</span>
<span class="normal">6495</span>
<span class="normal">6496</span>
<span class="normal">6497</span>
<span class="normal">6498</span>
<span class="normal">6499</span>
<span class="normal">6500</span>
<span class="normal">6501</span>
<span class="normal">6502</span>
<span class="normal">6503</span>
<span class="normal">6504</span>
<span class="normal">6505</span>
<span class="normal">6506</span>
<span class="normal">6507</span>
<span class="normal">6508</span>
<span class="normal">6509</span>
<span class="normal">6510</span>
<span class="normal">6511</span>
<span class="normal">6512</span>
<span class="normal">6513</span>
<span class="normal">6514</span>
<span class="normal">6515</span>
<span class="normal">6516</span>
<span class="normal">6517</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_design_table</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">tablefmt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;github&quot;</span><span class="p">,</span>
    <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a table string showing the search space design before optimization.</span>

<span class="sd">    This method generates a table displaying the variable names, types, bounds,</span>
<span class="sd">    and defaults without requiring an optimization run. Useful for inspecting</span>
<span class="sd">    and documenting the search space configuration.</span>

<span class="sd">    Args:</span>
<span class="sd">        tablefmt (str, optional): Table format for tabulate library.</span>
<span class="sd">            Defaults to &#39;github&#39;.</span>
<span class="sd">        precision (int, optional): Number of decimal places for float values.</span>
<span class="sd">            Defaults to 4.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: Formatted table string.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 1: Numeric parameters</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (-10, 10), (0, 1)],</span>
<span class="sd">        ...     var_name=[&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;],</span>
<span class="sd">        ...     var_type=[&quot;float&quot;, &quot;int&quot;, &quot;float&quot;],</span>
<span class="sd">        ...     max_iter=20,</span>
<span class="sd">        ...     n_initial=10</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; table = opt.get_design_table()</span>
<span class="sd">        &gt;&gt;&gt; print(table)</span>
<span class="sd">        | name   | type   |   lower |   upper |   default |</span>
<span class="sd">        |--------|--------|---------|---------|-----------|</span>
<span class="sd">        | x1     | num    |    -5.0 |     5.0 |       0.0 |</span>
<span class="sd">        | x2     | int    |   -10.0 |    10.0 |       0.0 |</span>
<span class="sd">        | x3     | num    |     0.0 |     1.0 |       0.5 |</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 2: With factor variables</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(10, 100), (&quot;SGD&quot;, &quot;Adam&quot;, &quot;RMSprop&quot;), (0.001, 0.1)],</span>
<span class="sd">        ...     var_name=[&quot;neurons&quot;, &quot;optimizer&quot;, &quot;lr&quot;],</span>
<span class="sd">        ...     var_type=[&quot;int&quot;, &quot;factor&quot;, &quot;float&quot;],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; table = opt.get_design_table()</span>
<span class="sd">        &gt;&gt;&gt; print(table)</span>
<span class="sd">        | name      | type   | lower   | upper   | default   |</span>
<span class="sd">        |-----------|--------|---------|---------|-----------|</span>
<span class="sd">        | neurons   | int    | 10.0    | 100.0   | 55.0      |</span>
<span class="sd">        | optimizer | factor | SGD     | RMSprop | Adam      |</span>
<span class="sd">        | lr        | num    | 0.001   | 0.1     | 0.0505    |</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 3: Before running optimization</span>
<span class="sd">        &gt;&gt;&gt; def hyperparameter_objective(X):</span>
<span class="sd">        ...     # X[:, 0]: layers, X[:, 1]: neurons, X[:, 2]: dropout</span>
<span class="sd">        ...     return np.sum(X**2, axis=1)  # Placeholder</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=hyperparameter_objective,</span>
<span class="sd">        ...     bounds=[(1, 5), (16, 256), (0.0, 0.5)],</span>
<span class="sd">        ...     var_name=[&quot;layers&quot;, &quot;neurons&quot;, &quot;dropout&quot;],</span>
<span class="sd">        ...     var_type=[&quot;int&quot;, &quot;int&quot;, &quot;float&quot;],</span>
<span class="sd">        ...     max_iter=50,</span>
<span class="sd">        ...     n_initial=15</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; # Get design table before optimization</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Search Space Configuration:&quot;)</span>
<span class="sd">        &gt;&gt;&gt; table = opt.get_design_table()</span>
<span class="sd">        &gt;&gt;&gt; print(table)</span>
<span class="sd">        Search Space Configuration:</span>
<span class="sd">        | name    | type   |   lower |   upper |   default |</span>
<span class="sd">        |---------|--------|---------|---------|-----------|</span>
<span class="sd">        | layers  | int    |     1.0 |     5.0 |       3.0 |</span>
<span class="sd">        | neurons | int    |    16.0 |   256.0 |     136.0 |</span>
<span class="sd">        | dropout | num    |     0.0 |     0.5 |      0.25 |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Prepare all variable transformations (use all_var_trans if dimension reduction occurred)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;all_var_trans&quot;</span><span class="p">):</span>
        <span class="n">all_var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_trans</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">all_var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span>

    <span class="c1"># Prepare table data</span>
    <span class="n">table_data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
            <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">))]</span>
        <span class="p">),</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span>
            <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">)</span>
        <span class="p">),</span>
        <span class="s2">&quot;lower&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;upper&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;transform&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;-&quot;</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">all_var_trans</span><span class="p">],</span>
    <span class="p">}</span>

    <span class="c1"># Helper to format values</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">fmt_val</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">)):</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.</span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="n">v</span>

    <span class="c1"># Process bounds and compute defaults (use original bounds for display)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span><span class="p">)):</span>
        <span class="n">var_type</span> <span class="o">=</span> <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span><span class="p">:</span>
            <span class="c1"># For factors, show original string values</span>
            <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">:</span>
                <span class="n">factor_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="c1"># Default is middle level</span>
                <span class="n">mid_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">factor_map</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
                <span class="n">default_str</span> <span class="o">=</span> <span class="n">factor_map</span><span class="p">[</span><span class="n">mid_idx</span><span class="p">]</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">default_str</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;N/A&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
            <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_upper</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
            <span class="c1"># Default is midpoint</span>
            <span class="n">default_val</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_upper</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">default_val</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="n">default_val</span><span class="p">))</span>

    <span class="c1"># Generate table</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">tabulate</span><span class="p">(</span>
        <span class="n">table_data</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">,</span>
        <span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">,</span>
        <span class="n">numalign</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
        <span class="n">stralign</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">table</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.get_importance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_importance</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.get_importance" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Calculate variable importance scores.</p>
<p>Importance is computed as the normalized sensitivity of each parameter
based on the variation in objective values across the evaluated points.
Higher scores indicate parameters that have more influence on the objective.</p>
<p>The importance is calculated as:
1. For each dimension, compute the correlation between parameter values
   and objective values
2. Normalize to percentage scale (0-100)
3. Higher values indicate more important parameters</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List[float]: Importance scores for each dimension (0-100 scale).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 1: Identify important parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">test_func</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="c1"># x0 has strong effect, x1 has weak effect</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">test_func</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x0&quot;</span><span class="p">,</span> <span class="s2">&quot;x1&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">importance</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_importance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x0 importance: </span><span class="si">{</span><span class="n">importance</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x1 importance: </span><span class="si">{</span><span class="n">importance</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">x0 importance: 89.23</span>
<span class="go">x1 importance: 10.77</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 2: With more dimensions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">rosenbrock</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">rosenbrock</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x0&quot;</span><span class="p">,</span> <span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;x3&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">importance</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_importance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">imp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">importance</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">imp</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="go">x0: 32.15%</span>
<span class="go">x1: 28.43%</span>
<span class="go">x2: 25.67%</span>
<span class="go">x3: 13.75%</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 3: Use in results table</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">table</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">print_results_table</span><span class="p">(</span><span class="n">show_importance</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">6538</span>
<span class="normal">6539</span>
<span class="normal">6540</span>
<span class="normal">6541</span>
<span class="normal">6542</span>
<span class="normal">6543</span>
<span class="normal">6544</span>
<span class="normal">6545</span>
<span class="normal">6546</span>
<span class="normal">6547</span>
<span class="normal">6548</span>
<span class="normal">6549</span>
<span class="normal">6550</span>
<span class="normal">6551</span>
<span class="normal">6552</span>
<span class="normal">6553</span>
<span class="normal">6554</span>
<span class="normal">6555</span>
<span class="normal">6556</span>
<span class="normal">6557</span>
<span class="normal">6558</span>
<span class="normal">6559</span>
<span class="normal">6560</span>
<span class="normal">6561</span>
<span class="normal">6562</span>
<span class="normal">6563</span>
<span class="normal">6564</span>
<span class="normal">6565</span>
<span class="normal">6566</span>
<span class="normal">6567</span>
<span class="normal">6568</span>
<span class="normal">6569</span>
<span class="normal">6570</span>
<span class="normal">6571</span>
<span class="normal">6572</span>
<span class="normal">6573</span>
<span class="normal">6574</span>
<span class="normal">6575</span>
<span class="normal">6576</span>
<span class="normal">6577</span>
<span class="normal">6578</span>
<span class="normal">6579</span>
<span class="normal">6580</span>
<span class="normal">6581</span>
<span class="normal">6582</span>
<span class="normal">6583</span>
<span class="normal">6584</span>
<span class="normal">6585</span>
<span class="normal">6586</span>
<span class="normal">6587</span>
<span class="normal">6588</span>
<span class="normal">6589</span>
<span class="normal">6590</span>
<span class="normal">6591</span>
<span class="normal">6592</span>
<span class="normal">6593</span>
<span class="normal">6594</span>
<span class="normal">6595</span>
<span class="normal">6596</span>
<span class="normal">6597</span>
<span class="normal">6598</span>
<span class="normal">6599</span>
<span class="normal">6600</span>
<span class="normal">6601</span>
<span class="normal">6602</span>
<span class="normal">6603</span>
<span class="normal">6604</span>
<span class="normal">6605</span>
<span class="normal">6606</span>
<span class="normal">6607</span>
<span class="normal">6608</span>
<span class="normal">6609</span>
<span class="normal">6610</span>
<span class="normal">6611</span>
<span class="normal">6612</span>
<span class="normal">6613</span>
<span class="normal">6614</span>
<span class="normal">6615</span>
<span class="normal">6616</span>
<span class="normal">6617</span>
<span class="normal">6618</span>
<span class="normal">6619</span>
<span class="normal">6620</span>
<span class="normal">6621</span>
<span class="normal">6622</span>
<span class="normal">6623</span>
<span class="normal">6624</span>
<span class="normal">6625</span>
<span class="normal">6626</span>
<span class="normal">6627</span>
<span class="normal">6628</span>
<span class="normal">6629</span>
<span class="normal">6630</span>
<span class="normal">6631</span>
<span class="normal">6632</span>
<span class="normal">6633</span>
<span class="normal">6634</span>
<span class="normal">6635</span>
<span class="normal">6636</span>
<span class="normal">6637</span>
<span class="normal">6638</span>
<span class="normal">6639</span>
<span class="normal">6640</span>
<span class="normal">6641</span>
<span class="normal">6642</span>
<span class="normal">6643</span>
<span class="normal">6644</span>
<span class="normal">6645</span>
<span class="normal">6646</span>
<span class="normal">6647</span>
<span class="normal">6648</span>
<span class="normal">6649</span>
<span class="normal">6650</span>
<span class="normal">6651</span>
<span class="normal">6652</span>
<span class="normal">6653</span>
<span class="normal">6654</span>
<span class="normal">6655</span>
<span class="normal">6656</span>
<span class="normal">6657</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_importance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate variable importance scores.</span>

<span class="sd">    Importance is computed as the normalized sensitivity of each parameter</span>
<span class="sd">    based on the variation in objective values across the evaluated points.</span>
<span class="sd">    Higher scores indicate parameters that have more influence on the objective.</span>

<span class="sd">    The importance is calculated as:</span>
<span class="sd">    1. For each dimension, compute the correlation between parameter values</span>
<span class="sd">       and objective values</span>
<span class="sd">    2. Normalize to percentage scale (0-100)</span>
<span class="sd">    3. Higher values indicate more important parameters</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[float]: Importance scores for each dimension (0-100 scale).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 1: Identify important parameters</span>
<span class="sd">        &gt;&gt;&gt; def test_func(X):</span>
<span class="sd">        ...     # x0 has strong effect, x1 has weak effect</span>
<span class="sd">        ...     return 10 * X[:, 0]**2 + 0.1 * X[:, 1]**2</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=test_func,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     var_name=[&quot;x0&quot;, &quot;x1&quot;],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     seed=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; importance = opt.get_importance()</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;x0 importance: {importance[0]:.2f}&quot;)</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;x1 importance: {importance[1]:.2f}&quot;)</span>
<span class="sd">        x0 importance: 89.23</span>
<span class="sd">        x1 importance: 10.77</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 2: With more dimensions</span>
<span class="sd">        &gt;&gt;&gt; def rosenbrock(X):</span>
<span class="sd">        ...     return np.sum(100*(X[:, 1:] - X[:, :-1]**2)**2 + (1 - X[:, :-1])**2, axis=1)</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=rosenbrock,</span>
<span class="sd">        ...     bounds=[(-2, 2)] * 4,</span>
<span class="sd">        ...     var_name=[&quot;x0&quot;, &quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;],</span>
<span class="sd">        ...     max_iter=50,</span>
<span class="sd">        ...     n_initial=20,</span>
<span class="sd">        ...     seed=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; importance = opt.get_importance()</span>
<span class="sd">        &gt;&gt;&gt; for i, imp in enumerate(importance):</span>
<span class="sd">        ...     print(f&quot;x{i}: {imp:.2f}%&quot;)</span>
<span class="sd">        x0: 32.15%</span>
<span class="sd">        x1: 28.43%</span>
<span class="sd">        x2: 25.67%</span>
<span class="sd">        x3: 13.75%</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 3: Use in results table</span>
<span class="sd">        &gt;&gt;&gt; table = opt.print_results_table(show_importance=True)</span>
<span class="sd">        &gt;&gt;&gt; print(table)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="c1"># Not enough data to compute importance</span>
        <span class="k">return</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">)</span>

    <span class="c1"># Use full-dimensional data</span>
    <span class="n">X_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">])</span>

    <span class="c1"># Calculate sensitivity for each dimension</span>
    <span class="n">sensitivities</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_full</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">x_i</span> <span class="o">=</span> <span class="n">X_full</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>

        <span class="c1"># Handle factor variables: map strings to integers</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_factor_maps&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">:</span>
            <span class="c1"># _factor_maps[i] is {int: str}, we need {str: int}</span>
            <span class="n">str_to_int</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Map values, handle potential missing values if any (though shouldn&#39;t simplify be there)</span>
                <span class="n">x_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">str_to_int</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">x_i</span><span class="p">])</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="c1"># Fallback if mapping fails</span>
                <span class="n">sensitivities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                <span class="k">continue</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Ensure numeric type for non-factors</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">x_i</span> <span class="o">=</span> <span class="n">x_i</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                <span class="c1"># If conversion fails, likely a string column without factor map?</span>
                <span class="n">sensitivities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                <span class="k">continue</span>

        <span class="c1"># Skip if no variation in this dimension</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x_i</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
            <span class="n">sensitivities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="c1"># Compute correlation with objective</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">correlation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">correlation</span><span class="p">):</span>
                <span class="n">correlation</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">correlation</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="n">sensitivities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correlation</span><span class="p">)</span>

    <span class="c1"># Normalize to percentage</span>
    <span class="n">total</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sensitivities</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">total</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="p">[(</span><span class="n">s</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sensitivities</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">sensitivities</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">importance</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.get_initial_design" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_initial_design</span><span class="p">(</span><span class="n">X0</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.get_initial_design" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generate or process initial design points.</p>
<p>Handles three scenarios:
1. X0 is None: Generate space-filling design using LHS
2. X0 is None but x0 is provided: Generate LHS and include x0 as first point
3. X0 is provided: Transform and prepare user-provided initial design</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X0</code>
            </td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>User-provided initial design points in original scale,
shape (n_initial, n_features). If None, generates space-filling design.
Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ndarray</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial design points in internal (transformed and reduced) scale,
shape (n_initial, n_features_reduced).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate default LHS design</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X0</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_initial_design</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X0</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(10, 2)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Provide custom initial design</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X0_custom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X0_processed</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_initial_design</span><span class="p">(</span><span class="n">X0_custom</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X0_processed</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(3, 2)</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1943</span>
<span class="normal">1944</span>
<span class="normal">1945</span>
<span class="normal">1946</span>
<span class="normal">1947</span>
<span class="normal">1948</span>
<span class="normal">1949</span>
<span class="normal">1950</span>
<span class="normal">1951</span>
<span class="normal">1952</span>
<span class="normal">1953</span>
<span class="normal">1954</span>
<span class="normal">1955</span>
<span class="normal">1956</span>
<span class="normal">1957</span>
<span class="normal">1958</span>
<span class="normal">1959</span>
<span class="normal">1960</span>
<span class="normal">1961</span>
<span class="normal">1962</span>
<span class="normal">1963</span>
<span class="normal">1964</span>
<span class="normal">1965</span>
<span class="normal">1966</span>
<span class="normal">1967</span>
<span class="normal">1968</span>
<span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span>
<span class="normal">2002</span>
<span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_initial_design</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate or process initial design points.</span>

<span class="sd">    Handles three scenarios:</span>
<span class="sd">    1. X0 is None: Generate space-filling design using LHS</span>
<span class="sd">    2. X0 is None but x0 is provided: Generate LHS and include x0 as first point</span>
<span class="sd">    3. X0 is provided: Transform and prepare user-provided initial design</span>

<span class="sd">    Args:</span>
<span class="sd">        X0 (ndarray, optional): User-provided initial design points in original scale,</span>
<span class="sd">            shape (n_initial, n_features). If None, generates space-filling design.</span>
<span class="sd">            Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ndarray: Initial design points in internal (transformed and reduced) scale,</span>
<span class="sd">            shape (n_initial, n_features_reduced).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     n_initial=10</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; # Generate default LHS design</span>
<span class="sd">        &gt;&gt;&gt; X0 = opt.get_initial_design()</span>
<span class="sd">        &gt;&gt;&gt; X0.shape</span>
<span class="sd">        (10, 2)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Provide custom initial design</span>
<span class="sd">        &gt;&gt;&gt; X0_custom = np.array([[0, 0], [1, 1], [2, 2]])</span>
<span class="sd">        &gt;&gt;&gt; X0_processed = opt.get_initial_design(X0_custom)</span>
<span class="sd">        &gt;&gt;&gt; X0_processed.shape</span>
<span class="sd">        (3, 2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Generate or use provided initial design</span>
    <span class="k">if</span> <span class="n">X0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_initial_design</span><span class="p">()</span>

        <span class="c1"># If starting point x0 was provided, include it in initial design</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># x0 is already validated and in internal scale</span>
            <span class="c1"># Check if x0 is 1D or 2D</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x0_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x0_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span>

            <span class="n">n_x0</span> <span class="o">=</span> <span class="n">x0_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># If we have more x0 points than n_initial, use all x0 points</span>
            <span class="k">if</span> <span class="n">n_x0</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="p">:</span>
                <span class="n">X0</span> <span class="o">=</span> <span class="n">x0_points</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using provided x0 points (</span><span class="si">{</span><span class="n">n_x0</span><span class="si">}</span><span class="s2">) as initial design.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Replace the first n_x0 points of LHS with x0 points</span>
                <span class="n">X0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">x0_points</span><span class="p">,</span> <span class="n">X0</span><span class="p">[:</span><span class="o">-</span><span class="n">n_x0</span><span class="p">]])</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Including </span><span class="si">{</span><span class="n">n_x0</span><span class="si">}</span><span class="s2"> starting points from x0 in initial design.&quot;</span>
                    <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
        <span class="c1"># If user provided X0, it&#39;s in original scale - transform it</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_X</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
        <span class="c1"># If X0 is in full dimensions and we have dimension reduction, reduce it</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="ow">and</span> <span class="n">X0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">):</span>
            <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_red_dim</span><span class="p">(</span><span class="n">X0</span><span class="p">)</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repair_non_numeric</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">X0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.get_results_table" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_results_table</span><span class="p">(</span><span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;github&#39;</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">show_importance</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.get_results_table" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get a comprehensive table string of optimization results.</p>
<p>This method generates a formatted table of the search space configuration,
best values found, and optionally variable importance scores.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tablefmt</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Table format for tabulate library. Options include:
&lsquo;github&rsquo;, &lsquo;grid&rsquo;, &lsquo;simple&rsquo;, &lsquo;plain&rsquo;, &lsquo;html&rsquo;, &lsquo;latex&rsquo;, etc.
Defaults to &lsquo;github&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;github&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>precision</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of decimal places for float values.
Defaults to 4.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>show_importance</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to include importance scores.
Importance is calculated as the normalized standard deviation of each
parameter&rsquo;s effect on the objective. Requires multiple evaluations.
Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>str</code></td>            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Formatted table string that can be printed or saved.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 1: Basic usage after optimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">sphere</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">sphere</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;x3&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">var_type</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">table</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_results_table</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="go">| name   | type   |   lower |   upper |   tuned |</span>
<span class="go">|--------|--------|---------|---------|---------|</span>
<span class="go">| x1     | num    |    -5.0 |     5.0 |  0.0123 |</span>
<span class="go">| x2     | num    |    -5.0 |     5.0 | -0.0234 |</span>
<span class="go">| x3     | num    |    -5.0 |     5.0 |  0.0345 |</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 2: With importance scores</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">table</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_results_table</span><span class="p">(</span><span class="n">show_importance</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="go">| name   | type   |   lower |   upper |   tuned |   importance | stars   |</span>
<span class="go">|--------|--------|---------|---------|---------|--------------|---------|</span>
<span class="go">| x1     | num    |    -5.0 |     5.0 |  0.0123 |        45.23 | **      |</span>
<span class="go">| x2     | num    |    -5.0 |     5.0 | -0.0234 |        32.17 | *       |</span>
<span class="go">| x3     | num    |    -5.0 |     5.0 |  0.0345 |        22.60 | *       |</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 3: Different table format</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">table</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_results_table</span><span class="p">(</span><span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="go">+--------+--------+---------+---------+---------+</span>
<span class="go">| name   | type   |   lower |   upper |   tuned |</span>
<span class="go">+========+========+=========+=========+=========+</span>
<span class="go">| x1     | num    |    -5.0 |     5.0 |  0.0123 |</span>
<span class="go">+--------+--------+---------+---------+---------+</span>
<span class="go">...</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 4: With factor variables</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="s2">&quot;blue&quot;</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;size&quot;</span><span class="p">,</span> <span class="s2">&quot;color&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">var_type</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="s2">&quot;factor&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">table</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_results_table</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="go">| name   | type   | lower   | upper   | tuned   |</span>
<span class="go">|--------|--------|---------|---------|---------|</span>
<span class="go">| size   | num    | -5.0    | 5.0     | 0.0123  |</span>
<span class="go">| color  | factor | red     | blue    | green   |</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">6180</span>
<span class="normal">6181</span>
<span class="normal">6182</span>
<span class="normal">6183</span>
<span class="normal">6184</span>
<span class="normal">6185</span>
<span class="normal">6186</span>
<span class="normal">6187</span>
<span class="normal">6188</span>
<span class="normal">6189</span>
<span class="normal">6190</span>
<span class="normal">6191</span>
<span class="normal">6192</span>
<span class="normal">6193</span>
<span class="normal">6194</span>
<span class="normal">6195</span>
<span class="normal">6196</span>
<span class="normal">6197</span>
<span class="normal">6198</span>
<span class="normal">6199</span>
<span class="normal">6200</span>
<span class="normal">6201</span>
<span class="normal">6202</span>
<span class="normal">6203</span>
<span class="normal">6204</span>
<span class="normal">6205</span>
<span class="normal">6206</span>
<span class="normal">6207</span>
<span class="normal">6208</span>
<span class="normal">6209</span>
<span class="normal">6210</span>
<span class="normal">6211</span>
<span class="normal">6212</span>
<span class="normal">6213</span>
<span class="normal">6214</span>
<span class="normal">6215</span>
<span class="normal">6216</span>
<span class="normal">6217</span>
<span class="normal">6218</span>
<span class="normal">6219</span>
<span class="normal">6220</span>
<span class="normal">6221</span>
<span class="normal">6222</span>
<span class="normal">6223</span>
<span class="normal">6224</span>
<span class="normal">6225</span>
<span class="normal">6226</span>
<span class="normal">6227</span>
<span class="normal">6228</span>
<span class="normal">6229</span>
<span class="normal">6230</span>
<span class="normal">6231</span>
<span class="normal">6232</span>
<span class="normal">6233</span>
<span class="normal">6234</span>
<span class="normal">6235</span>
<span class="normal">6236</span>
<span class="normal">6237</span>
<span class="normal">6238</span>
<span class="normal">6239</span>
<span class="normal">6240</span>
<span class="normal">6241</span>
<span class="normal">6242</span>
<span class="normal">6243</span>
<span class="normal">6244</span>
<span class="normal">6245</span>
<span class="normal">6246</span>
<span class="normal">6247</span>
<span class="normal">6248</span>
<span class="normal">6249</span>
<span class="normal">6250</span>
<span class="normal">6251</span>
<span class="normal">6252</span>
<span class="normal">6253</span>
<span class="normal">6254</span>
<span class="normal">6255</span>
<span class="normal">6256</span>
<span class="normal">6257</span>
<span class="normal">6258</span>
<span class="normal">6259</span>
<span class="normal">6260</span>
<span class="normal">6261</span>
<span class="normal">6262</span>
<span class="normal">6263</span>
<span class="normal">6264</span>
<span class="normal">6265</span>
<span class="normal">6266</span>
<span class="normal">6267</span>
<span class="normal">6268</span>
<span class="normal">6269</span>
<span class="normal">6270</span>
<span class="normal">6271</span>
<span class="normal">6272</span>
<span class="normal">6273</span>
<span class="normal">6274</span>
<span class="normal">6275</span>
<span class="normal">6276</span>
<span class="normal">6277</span>
<span class="normal">6278</span>
<span class="normal">6279</span>
<span class="normal">6280</span>
<span class="normal">6281</span>
<span class="normal">6282</span>
<span class="normal">6283</span>
<span class="normal">6284</span>
<span class="normal">6285</span>
<span class="normal">6286</span>
<span class="normal">6287</span>
<span class="normal">6288</span>
<span class="normal">6289</span>
<span class="normal">6290</span>
<span class="normal">6291</span>
<span class="normal">6292</span>
<span class="normal">6293</span>
<span class="normal">6294</span>
<span class="normal">6295</span>
<span class="normal">6296</span>
<span class="normal">6297</span>
<span class="normal">6298</span>
<span class="normal">6299</span>
<span class="normal">6300</span>
<span class="normal">6301</span>
<span class="normal">6302</span>
<span class="normal">6303</span>
<span class="normal">6304</span>
<span class="normal">6305</span>
<span class="normal">6306</span>
<span class="normal">6307</span>
<span class="normal">6308</span>
<span class="normal">6309</span>
<span class="normal">6310</span>
<span class="normal">6311</span>
<span class="normal">6312</span>
<span class="normal">6313</span>
<span class="normal">6314</span>
<span class="normal">6315</span>
<span class="normal">6316</span>
<span class="normal">6317</span>
<span class="normal">6318</span>
<span class="normal">6319</span>
<span class="normal">6320</span>
<span class="normal">6321</span>
<span class="normal">6322</span>
<span class="normal">6323</span>
<span class="normal">6324</span>
<span class="normal">6325</span>
<span class="normal">6326</span>
<span class="normal">6327</span>
<span class="normal">6328</span>
<span class="normal">6329</span>
<span class="normal">6330</span>
<span class="normal">6331</span>
<span class="normal">6332</span>
<span class="normal">6333</span>
<span class="normal">6334</span>
<span class="normal">6335</span>
<span class="normal">6336</span>
<span class="normal">6337</span>
<span class="normal">6338</span>
<span class="normal">6339</span>
<span class="normal">6340</span>
<span class="normal">6341</span>
<span class="normal">6342</span>
<span class="normal">6343</span>
<span class="normal">6344</span>
<span class="normal">6345</span>
<span class="normal">6346</span>
<span class="normal">6347</span>
<span class="normal">6348</span>
<span class="normal">6349</span>
<span class="normal">6350</span>
<span class="normal">6351</span>
<span class="normal">6352</span>
<span class="normal">6353</span>
<span class="normal">6354</span>
<span class="normal">6355</span>
<span class="normal">6356</span>
<span class="normal">6357</span>
<span class="normal">6358</span>
<span class="normal">6359</span>
<span class="normal">6360</span>
<span class="normal">6361</span>
<span class="normal">6362</span>
<span class="normal">6363</span>
<span class="normal">6364</span>
<span class="normal">6365</span>
<span class="normal">6366</span>
<span class="normal">6367</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_results_table</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">tablefmt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;github&quot;</span><span class="p">,</span>
    <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">show_importance</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a comprehensive table string of optimization results.</span>

<span class="sd">    This method generates a formatted table of the search space configuration,</span>
<span class="sd">    best values found, and optionally variable importance scores.</span>

<span class="sd">    Args:</span>
<span class="sd">        tablefmt (str, optional): Table format for tabulate library. Options include:</span>
<span class="sd">            &#39;github&#39;, &#39;grid&#39;, &#39;simple&#39;, &#39;plain&#39;, &#39;html&#39;, &#39;latex&#39;, etc.</span>
<span class="sd">            Defaults to &#39;github&#39;.</span>
<span class="sd">        precision (int, optional): Number of decimal places for float values.</span>
<span class="sd">            Defaults to 4.</span>
<span class="sd">        show_importance (bool, optional): Whether to include importance scores.</span>
<span class="sd">            Importance is calculated as the normalized standard deviation of each</span>
<span class="sd">            parameter&#39;s effect on the objective. Requires multiple evaluations.</span>
<span class="sd">            Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: Formatted table string that can be printed or saved.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 1: Basic usage after optimization</span>
<span class="sd">        &gt;&gt;&gt; def sphere(X):</span>
<span class="sd">        ...     return np.sum(X**2, axis=1)</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=sphere,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5), (-5, 5)],</span>
<span class="sd">        ...     var_name=[&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;],</span>
<span class="sd">        ...     var_type=[&quot;float&quot;, &quot;float&quot;, &quot;float&quot;],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; table = opt.get_results_table()</span>
<span class="sd">        &gt;&gt;&gt; print(table)</span>
<span class="sd">        | name   | type   |   lower |   upper |   tuned |</span>
<span class="sd">        |--------|--------|---------|---------|---------|</span>
<span class="sd">        | x1     | num    |    -5.0 |     5.0 |  0.0123 |</span>
<span class="sd">        | x2     | num    |    -5.0 |     5.0 | -0.0234 |</span>
<span class="sd">        | x3     | num    |    -5.0 |     5.0 |  0.0345 |</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 2: With importance scores</span>
<span class="sd">        &gt;&gt;&gt; table = opt.get_results_table(show_importance=True)</span>
<span class="sd">        &gt;&gt;&gt; print(table)</span>
<span class="sd">        | name   | type   |   lower |   upper |   tuned |   importance | stars   |</span>
<span class="sd">        |--------|--------|---------|---------|---------|--------------|---------|</span>
<span class="sd">        | x1     | num    |    -5.0 |     5.0 |  0.0123 |        45.23 | **      |</span>
<span class="sd">        | x2     | num    |    -5.0 |     5.0 | -0.0234 |        32.17 | *       |</span>
<span class="sd">        | x3     | num    |    -5.0 |     5.0 |  0.0345 |        22.60 | *       |</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 3: Different table format</span>
<span class="sd">        &gt;&gt;&gt; table = opt.get_results_table(tablefmt=&quot;grid&quot;)</span>
<span class="sd">        &gt;&gt;&gt; print(table)</span>
<span class="sd">        +--------+--------+---------+---------+---------+</span>
<span class="sd">        | name   | type   |   lower |   upper |   tuned |</span>
<span class="sd">        +========+========+=========+=========+=========+</span>
<span class="sd">        | x1     | num    |    -5.0 |     5.0 |  0.0123 |</span>
<span class="sd">        +--------+--------+---------+---------+---------+</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 4: With factor variables</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (&quot;red&quot;, &quot;green&quot;, &quot;blue&quot;)],</span>
<span class="sd">        ...     var_name=[&quot;size&quot;, &quot;color&quot;],</span>
<span class="sd">        ...     var_type=[&quot;float&quot;, &quot;factor&quot;],</span>
<span class="sd">        ...     max_iter=20,</span>
<span class="sd">        ...     n_initial=10</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; table = opt.get_results_table()</span>
<span class="sd">        &gt;&gt;&gt; print(table)</span>
<span class="sd">        | name   | type   | lower   | upper   | tuned   |</span>
<span class="sd">        |--------|--------|---------|---------|---------|</span>
<span class="sd">        | size   | num    | -5.0    | 5.0     | 0.0123  |</span>
<span class="sd">        | color  | factor | red     | blue    | green   |</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;No optimization results available. Run optimize() first.&quot;</span>

    <span class="c1"># Get best solution in full dimensions</span>
    <span class="c1"># Note: best_x_ is already in original scale</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
        <span class="n">best_x_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">best_x_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>

    <span class="c1"># Map factor variables back to original string values</span>
    <span class="n">best_x_display</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_to_factor_values</span><span class="p">(</span><span class="n">best_x_full</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Prepare all variable transformations (use all_var_trans if dimension reduction occurred)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;all_var_trans&quot;</span><span class="p">):</span>
        <span class="n">all_var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_trans</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">all_var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span>

    <span class="c1"># Prepare table data</span>
    <span class="n">table_data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
            <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">best_x_display</span><span class="p">))]</span>
        <span class="p">),</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span>
            <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_x_display</span><span class="p">)</span>
        <span class="p">),</span>
        <span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;lower&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;upper&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;tuned&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;transform&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;-&quot;</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">all_var_trans</span><span class="p">],</span>
    <span class="p">}</span>

    <span class="c1"># Helper to format values</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">fmt_val</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">)):</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.</span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="n">v</span>

    <span class="c1"># Process bounds, defaults, and tuned values</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">best_x_display</span><span class="p">)):</span>
        <span class="n">var_type</span> <span class="o">=</span> <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>

        <span class="c1"># Handle bounds and defaults based on variable type</span>
        <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span><span class="p">:</span>
            <span class="c1"># For factors, show original string values</span>
            <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">:</span>
                <span class="n">factor_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="c1"># Default is middle level logic (matching get_design_table)</span>
                <span class="n">mid_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">factor_map</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
                <span class="n">default_str</span> <span class="o">=</span> <span class="n">factor_map</span><span class="p">[</span><span class="n">mid_idx</span><span class="p">]</span>

                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">default_str</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;N/A&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
            <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_upper</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
            <span class="c1"># Default is midpoint logic</span>
            <span class="n">default_val</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_upper</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">default_val</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="n">default_val</span><span class="p">))</span>

        <span class="c1"># Format tuned value</span>
        <span class="n">tuned_val</span> <span class="o">=</span> <span class="n">best_x_display</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
            <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;tuned&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">tuned_val</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span><span class="p">:</span>
            <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;tuned&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">tuned_val</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;tuned&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fmt_val</span><span class="p">(</span><span class="n">tuned_val</span><span class="p">))</span>

    <span class="c1"># Add importance if requested</span>
    <span class="k">if</span> <span class="n">show_importance</span><span class="p">:</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_importance</span><span class="p">()</span>
        <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">importance</span><span class="p">]</span>
        <span class="n">table_data</span><span class="p">[</span><span class="s2">&quot;stars&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_stars</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span>

    <span class="c1"># Generate table</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">tabulate</span><span class="p">(</span>
        <span class="n">table_data</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">,</span>
        <span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">,</span>
        <span class="n">numalign</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
        <span class="n">stralign</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Add interpretation if importance is shown</span>
    <span class="k">if</span> <span class="n">show_importance</span><span class="p">:</span>
        <span class="n">table</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Interpretation: ***: &gt;99%, **: &gt;75%, *: &gt;50%, .: &gt;10%&quot;</span>

    <span class="k">return</span> <span class="n">table</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.get_stars" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_stars</span><span class="p">(</span><span class="n">input_list</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.get_stars" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Converts a list of values to a list of stars.</p>
<p>Used to visualize the importance of a variable.
Thresholds: &gt;99: <em><strong>, &gt;75: </strong>, &gt;50: </em>, &gt;10: .</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_list</code>
            </td>
            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A list of importance scores (0-100).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>list</code></td>            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A list of star strings.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">6776</span>
<span class="normal">6777</span>
<span class="normal">6778</span>
<span class="normal">6779</span>
<span class="normal">6780</span>
<span class="normal">6781</span>
<span class="normal">6782</span>
<span class="normal">6783</span>
<span class="normal">6784</span>
<span class="normal">6785</span>
<span class="normal">6786</span>
<span class="normal">6787</span>
<span class="normal">6788</span>
<span class="normal">6789</span>
<span class="normal">6790</span>
<span class="normal">6791</span>
<span class="normal">6792</span>
<span class="normal">6793</span>
<span class="normal">6794</span>
<span class="normal">6795</span>
<span class="normal">6796</span>
<span class="normal">6797</span>
<span class="normal">6798</span>
<span class="normal">6799</span>
<span class="normal">6800</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_stars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Converts a list of values to a list of stars.</span>

<span class="sd">    Used to visualize the importance of a variable.</span>
<span class="sd">    Thresholds: &gt;99: ***, &gt;75: **, &gt;50: *, &gt;10: .</span>

<span class="sd">    Args:</span>
<span class="sd">        input_list (list): A list of importance scores (0-100).</span>

<span class="sd">    Returns:</span>
<span class="sd">        list: A list of star strings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">input_list</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">99</span><span class="p">:</span>
            <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;***&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">75</span><span class="p">:</span>
            <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;**&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">50</span><span class="p">:</span>
            <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output_list</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.handle_default_var_trans" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">handle_default_var_trans</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.handle_default_var_trans" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Handle default variable transformations.</p>
<p>Sets var_trans to a list of None values if not specified, or normalizes
transformation names by converting &lsquo;id&rsquo;, &lsquo;None&rsquo;, or None to None.</p>
<p>Also validates that var_trans length matches the number of dimensions.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If var_trans length doesn&rsquo;t match n_dim.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Default behavior - all None</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">var_trans</span>
<span class="go">[None, None]</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Normalize transformation names</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)],</span>
<span class="gp">... </span>                 <span class="n">var_trans</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;log10&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;None&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">var_trans</span>
<span class="go">[&#39;log10&#39;, None, None, None]</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">handle_default_var_trans</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Handle default variable transformations.</span>

<span class="sd">    Sets var_trans to a list of None values if not specified, or normalizes</span>
<span class="sd">    transformation names by converting &#39;id&#39;, &#39;None&#39;, or None to None.</span>

<span class="sd">    Also validates that var_trans length matches the number of dimensions.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If var_trans length doesn&#39;t match n_dim.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; # Default behavior - all None</span>
<span class="sd">        &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(0, 10), (0, 10)])</span>
<span class="sd">        &gt;&gt;&gt; spot.var_trans</span>
<span class="sd">        [None, None]</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Normalize transformation names</span>
<span class="sd">        &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10), (1, 100)],</span>
<span class="sd">        ...                  var_trans=[&#39;log10&#39;, &#39;id&#39;, None, &#39;None&#39;])</span>
<span class="sd">        &gt;&gt;&gt; spot.var_trans</span>
<span class="sd">        [&#39;log10&#39;, None, None, None]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Default variable transformations (None means no transformation)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Normalize transformation names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="o">=</span> <span class="p">[</span>
            <span class="kc">None</span> <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">t</span> <span class="o">==</span> <span class="s2">&quot;id&quot;</span> <span class="ow">or</span> <span class="n">t</span> <span class="o">==</span> <span class="s2">&quot;None&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">t</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span>
        <span class="p">]</span>

    <span class="c1"># Validate var_trans length</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Length of var_trans (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">)</span><span class="si">}</span><span class="s2">) must match &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;number of dimensions (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.inverse_transform_value" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inverse_transform_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.inverse_transform_value" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Apply inverse transformation to a single float value.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Transformed value</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>trans</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Transformation name.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Original value</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="notes" open>
  <summary>Notes</summary>
  <p>See also transform_value.</p>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">inverse_transform_value</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;log10&#39;</span><span class="p">)</span>
<span class="go">10.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">inverse_transform_value</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="s1">&#39;log(x)&#39;</span><span class="p">)</span>
<span class="go">10.0</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">inverse_transform_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">trans</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply inverse transformation to a single float value.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: Transformed value</span>
<span class="sd">        trans: Transformation name.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Original value</span>

<span class="sd">    Notes:</span>
<span class="sd">        See also transform_value.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10)])</span>
<span class="sd">        &gt;&gt;&gt; spot.inverse_transform_value(10, &#39;log10&#39;)</span>
<span class="sd">        10.0</span>
<span class="sd">        &gt;&gt;&gt; spot.inverse_transform_value(100, &#39;log(x)&#39;)</span>
<span class="sd">        10.0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Ensure x is a float</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;transform_value expects a float, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (value: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>
    <span class="k">if</span> <span class="n">trans</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;id&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log10&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">10</span><span class="o">**</span><span class="n">x</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log&quot;</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;ln&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;square&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;cube&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">3.0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;inv&quot;</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;reciprocal&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">x</span>

    <span class="c1"># Dynamic Transformations (Inverses)</span>
    <span class="k">if</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log(x)&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;sqrt(x)&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;pow\(x,\s*([0-9.]+)\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;pow\(([0-9.]+),\s*x\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
        <span class="n">base</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">base</span><span class="p">)</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;log\(x,\s*([0-9.]+)\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
        <span class="n">base</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">base</span><span class="o">**</span><span class="n">x</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown transformation: </span><span class="si">{</span><span class="n">trans</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.load_experiment" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_experiment</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#spotoptim.SpotOptim.SpotOptim.load_experiment" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load an experiment configuration from a pickle file.</p>
<p>Loads an experiment that was saved with save_experiment(). The loaded optimizer
will have the configuration and the objective function (thanks to dill).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>filename</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to the experiment pickle file.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>SpotOptim</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" title="SpotOptim (spotoptim.SpotOptim.SpotOptim)" href="#spotoptim.SpotOptim.SpotOptim">SpotOptim</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Loaded optimizer instance (without fun attached).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="FileNotFoundError">FileNotFoundError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the specified file doesn&rsquo;t exist.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Load experiment</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="o">.</span><span class="n">load_experiment</span><span class="p">(</span><span class="s2">&quot;sphere_opt_exp.pkl&quot;</span><span class="p">)</span>
<span class="go">Loaded experiment from sphere_opt_exp.pkl</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Re-attach objective function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">fun</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Run optimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">5866</span>
<span class="normal">5867</span>
<span class="normal">5868</span>
<span class="normal">5869</span>
<span class="normal">5870</span>
<span class="normal">5871</span>
<span class="normal">5872</span>
<span class="normal">5873</span>
<span class="normal">5874</span>
<span class="normal">5875</span>
<span class="normal">5876</span>
<span class="normal">5877</span>
<span class="normal">5878</span>
<span class="normal">5879</span>
<span class="normal">5880</span>
<span class="normal">5881</span>
<span class="normal">5882</span>
<span class="normal">5883</span>
<span class="normal">5884</span>
<span class="normal">5885</span>
<span class="normal">5886</span>
<span class="normal">5887</span>
<span class="normal">5888</span>
<span class="normal">5889</span>
<span class="normal">5890</span>
<span class="normal">5891</span>
<span class="normal">5892</span>
<span class="normal">5893</span>
<span class="normal">5894</span>
<span class="normal">5895</span>
<span class="normal">5896</span>
<span class="normal">5897</span>
<span class="normal">5898</span>
<span class="normal">5899</span>
<span class="normal">5900</span>
<span class="normal">5901</span>
<span class="normal">5902</span>
<span class="normal">5903</span>
<span class="normal">5904</span>
<span class="normal">5905</span>
<span class="normal">5906</span>
<span class="normal">5907</span>
<span class="normal">5908</span>
<span class="normal">5909</span>
<span class="normal">5910</span>
<span class="normal">5911</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_experiment</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SpotOptim&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load an experiment configuration from a pickle file.</span>

<span class="sd">    Loads an experiment that was saved with save_experiment(). The loaded optimizer</span>
<span class="sd">    will have the configuration and the objective function (thanks to dill).</span>


<span class="sd">    Args:</span>
<span class="sd">        filename (str): Path to the experiment pickle file.</span>

<span class="sd">    Returns:</span>
<span class="sd">        SpotOptim: Loaded optimizer instance (without fun attached).</span>

<span class="sd">    Raises:</span>
<span class="sd">        FileNotFoundError: If the specified file doesn&#39;t exist.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Load experiment</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim.load_experiment(&quot;sphere_opt_exp.pkl&quot;)</span>
<span class="sd">        Loaded experiment from sphere_opt_exp.pkl</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Re-attach objective function</span>
<span class="sd">        &gt;&gt;&gt; opt.fun = lambda X: np.sum(X**2, axis=1)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Run optimization</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment file not found: </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">dill</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded experiment from </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Reinitialize components that were excluded</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">_reinitialize_components</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">optimizer</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading experiment: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.load_result" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_result</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#spotoptim.SpotOptim.SpotOptim.load_result" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load complete optimization results from a pickle file.</p>
<p>Loads results that were saved with save_result(). The loaded optimizer
will have both configuration and all optimization results.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>filename</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path to the result pickle file.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>SpotOptim</code></td>            <td>
                  <code><a class="autorefs autorefs-internal" title="SpotOptim (spotoptim.SpotOptim.SpotOptim)" href="#spotoptim.SpotOptim.SpotOptim">SpotOptim</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Loaded optimizer instance with complete results.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="FileNotFoundError">FileNotFoundError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the specified file doesn&rsquo;t exist.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Load results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="o">.</span><span class="n">load_result</span><span class="p">(</span><span class="s2">&quot;sphere_opt_res.pkl&quot;</span><span class="p">)</span>
<span class="go">Loaded result from sphere_opt_res.pkl</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Analyze results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best point:&quot;</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">best_x_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best value:&quot;</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">best_y_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total evaluations:&quot;</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">counter</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Success rate:&quot;</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">success_rate</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Continue optimization if needed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt.fun = lambda X: np.sum(X**2, axis=1)  # Re-attach if continuing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt.max_iter = 50  # Increase budget</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result = opt.optimize()</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">5717</span>
<span class="normal">5718</span>
<span class="normal">5719</span>
<span class="normal">5720</span>
<span class="normal">5721</span>
<span class="normal">5722</span>
<span class="normal">5723</span>
<span class="normal">5724</span>
<span class="normal">5725</span>
<span class="normal">5726</span>
<span class="normal">5727</span>
<span class="normal">5728</span>
<span class="normal">5729</span>
<span class="normal">5730</span>
<span class="normal">5731</span>
<span class="normal">5732</span>
<span class="normal">5733</span>
<span class="normal">5734</span>
<span class="normal">5735</span>
<span class="normal">5736</span>
<span class="normal">5737</span>
<span class="normal">5738</span>
<span class="normal">5739</span>
<span class="normal">5740</span>
<span class="normal">5741</span>
<span class="normal">5742</span>
<span class="normal">5743</span>
<span class="normal">5744</span>
<span class="normal">5745</span>
<span class="normal">5746</span>
<span class="normal">5747</span>
<span class="normal">5748</span>
<span class="normal">5749</span>
<span class="normal">5750</span>
<span class="normal">5751</span>
<span class="normal">5752</span>
<span class="normal">5753</span>
<span class="normal">5754</span>
<span class="normal">5755</span>
<span class="normal">5756</span>
<span class="normal">5757</span>
<span class="normal">5758</span>
<span class="normal">5759</span>
<span class="normal">5760</span>
<span class="normal">5761</span>
<span class="normal">5762</span>
<span class="normal">5763</span>
<span class="normal">5764</span>
<span class="normal">5765</span>
<span class="normal">5766</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_result</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SpotOptim&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load complete optimization results from a pickle file.</span>

<span class="sd">    Loads results that were saved with save_result(). The loaded optimizer</span>
<span class="sd">    will have both configuration and all optimization results.</span>

<span class="sd">    Args:</span>
<span class="sd">        filename (str): Path to the result pickle file.</span>

<span class="sd">    Returns:</span>
<span class="sd">        SpotOptim: Loaded optimizer instance with complete results.</span>

<span class="sd">    Raises:</span>
<span class="sd">        FileNotFoundError: If the specified file doesn&#39;t exist.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Load results</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim.load_result(&quot;sphere_opt_res.pkl&quot;)</span>
<span class="sd">        Loaded result from sphere_opt_res.pkl</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Analyze results</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best point:&quot;, opt.best_x_)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best value:&quot;, opt.best_y_)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Total evaluations:&quot;, opt.counter)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Success rate:&quot;, opt.success_rate)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Continue optimization if needed</span>
<span class="sd">        &gt;&gt;&gt; # opt.fun = lambda X: np.sum(X**2, axis=1)  # Re-attach if continuing</span>
<span class="sd">        &gt;&gt;&gt; # opt.max_iter = 50  # Increase budget</span>
<span class="sd">        &gt;&gt;&gt; # result = opt.optimize()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result file not found: </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">dill</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded result from </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Reinitialize components that were excluded</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">_reinitialize_components</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">optimizer</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading result: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.modify_bounds_based_on_var_type" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">modify_bounds_based_on_var_type</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.modify_bounds_based_on_var_type" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Modify bounds based on variable types.</p>
<p>Adjusts bounds for each dimension according to its var_type:
- &lsquo;int&rsquo;: Ensures bounds are integers (ceiling for lower, floor for upper)
- &lsquo;factor&rsquo;: Bounds already set to (0, n_levels-1) by process_factor_bounds
- &lsquo;float&rsquo;: Explicitly converts bounds to float</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If an unsupported var_type is encountered.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">10.5</span><span class="p">)],</span> <span class="n">var_type</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;int&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">bounds</span>
<span class="go">[(1, 10)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)],</span> <span class="n">var_type</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">bounds</span>
<span class="go">[(0.0, 10.0)]</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">modify_bounds_based_on_var_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Modify bounds based on variable types.</span>

<span class="sd">    Adjusts bounds for each dimension according to its var_type:</span>
<span class="sd">    - &#39;int&#39;: Ensures bounds are integers (ceiling for lower, floor for upper)</span>
<span class="sd">    - &#39;factor&#39;: Bounds already set to (0, n_levels-1) by process_factor_bounds</span>
<span class="sd">    - &#39;float&#39;: Explicitly converts bounds to float</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If an unsupported var_type is encountered.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(0.5, 10.5)], var_type=[&#39;int&#39;])</span>
<span class="sd">        &gt;&gt;&gt; spot.bounds</span>
<span class="sd">        [(1, 10)]</span>
<span class="sd">        &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(0, 10)], var_type=[&#39;float&#39;])</span>
<span class="sd">        &gt;&gt;&gt; spot.bounds</span>
<span class="sd">        [(0.0, 10.0)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">vtype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">vtype</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
            <span class="c1"># For integer variables, ensure bounds are integers</span>
            <span class="c1"># Use Python&#39;s int() to convert numpy types to native Python int</span>
            <span class="n">lower</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
            <span class="n">upper</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">vtype</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span><span class="p">:</span>
            <span class="c1"># For factor variables, bounds are already set to (0, n_levels-1)</span>
            <span class="c1"># Ensure they are Python int, not numpy int64</span>
            <span class="n">lower</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">upper</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">vtype</span> <span class="o">==</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
            <span class="c1"># Continuous variable, convert explicitly to float bounds</span>
            <span class="c1"># Use Python&#39;s float() to convert numpy types to native Python float</span>
            <span class="n">lower</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">upper</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unsupported var_type &#39;</span><span class="si">{</span><span class="n">vtype</span><span class="si">}</span><span class="s2">&#39; at dimension </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Supported types are &#39;float&#39;, &#39;int&#39;, &#39;factor&#39;.&quot;</span>
            <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.optimize" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">optimize</span><span class="p">(</span><span class="n">X0</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.optimize" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run the optimization process.</p>
<p>The optimization terminates when either:
- Total function evaluations reach max_iter (including initial design), OR
- Runtime exceeds max_time minutes</p>
<p>Input/Output Spaces:
- Input X0: Expected in Natural Space (original scale, physical units).
- Output result.x: Returned in Natural Space.
- Output result.X: Returned in Natural Space.
- Internal Optimization: Performed in Transformed and Mapped Space.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X0</code>
            </td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial design points in Natural Space, shape (n_initial, n_features).
If None, generates space-filling design. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>OptimizeResult</code></td>            <td>
                  <code><span title="scipy.optimize.OptimizeResult">OptimizeResult</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optimization result with fields:
- x: best point found in Natural Space
- fun: best function value
- nfev: number of function evaluations (including initial design)
- nit: number of sequential optimization iterations (after initial design)
- success: whether optimization succeeded
- message: termination message indicating reason for stopping, including
  statistics (function value, iterations, evaluations)
- X: all evaluated points in Natural Space
- y: all function values</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">x0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),</span>
<span class="gp">... </span>    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">Optimization terminated: maximum evaluations (20) reached</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best point:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
<span class="go">Best point: [0. 0.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best value:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>
<span class="go">Best value: 0.0</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">3872</span>
<span class="normal">3873</span>
<span class="normal">3874</span>
<span class="normal">3875</span>
<span class="normal">3876</span>
<span class="normal">3877</span>
<span class="normal">3878</span>
<span class="normal">3879</span>
<span class="normal">3880</span>
<span class="normal">3881</span>
<span class="normal">3882</span>
<span class="normal">3883</span>
<span class="normal">3884</span>
<span class="normal">3885</span>
<span class="normal">3886</span>
<span class="normal">3887</span>
<span class="normal">3888</span>
<span class="normal">3889</span>
<span class="normal">3890</span>
<span class="normal">3891</span>
<span class="normal">3892</span>
<span class="normal">3893</span>
<span class="normal">3894</span>
<span class="normal">3895</span>
<span class="normal">3896</span>
<span class="normal">3897</span>
<span class="normal">3898</span>
<span class="normal">3899</span>
<span class="normal">3900</span>
<span class="normal">3901</span>
<span class="normal">3902</span>
<span class="normal">3903</span>
<span class="normal">3904</span>
<span class="normal">3905</span>
<span class="normal">3906</span>
<span class="normal">3907</span>
<span class="normal">3908</span>
<span class="normal">3909</span>
<span class="normal">3910</span>
<span class="normal">3911</span>
<span class="normal">3912</span>
<span class="normal">3913</span>
<span class="normal">3914</span>
<span class="normal">3915</span>
<span class="normal">3916</span>
<span class="normal">3917</span>
<span class="normal">3918</span>
<span class="normal">3919</span>
<span class="normal">3920</span>
<span class="normal">3921</span>
<span class="normal">3922</span>
<span class="normal">3923</span>
<span class="normal">3924</span>
<span class="normal">3925</span>
<span class="normal">3926</span>
<span class="normal">3927</span>
<span class="normal">3928</span>
<span class="normal">3929</span>
<span class="normal">3930</span>
<span class="normal">3931</span>
<span class="normal">3932</span>
<span class="normal">3933</span>
<span class="normal">3934</span>
<span class="normal">3935</span>
<span class="normal">3936</span>
<span class="normal">3937</span>
<span class="normal">3938</span>
<span class="normal">3939</span>
<span class="normal">3940</span>
<span class="normal">3941</span>
<span class="normal">3942</span>
<span class="normal">3943</span>
<span class="normal">3944</span>
<span class="normal">3945</span>
<span class="normal">3946</span>
<span class="normal">3947</span>
<span class="normal">3948</span>
<span class="normal">3949</span>
<span class="normal">3950</span>
<span class="normal">3951</span>
<span class="normal">3952</span>
<span class="normal">3953</span>
<span class="normal">3954</span>
<span class="normal">3955</span>
<span class="normal">3956</span>
<span class="normal">3957</span>
<span class="normal">3958</span>
<span class="normal">3959</span>
<span class="normal">3960</span>
<span class="normal">3961</span>
<span class="normal">3962</span>
<span class="normal">3963</span>
<span class="normal">3964</span>
<span class="normal">3965</span>
<span class="normal">3966</span>
<span class="normal">3967</span>
<span class="normal">3968</span>
<span class="normal">3969</span>
<span class="normal">3970</span>
<span class="normal">3971</span>
<span class="normal">3972</span>
<span class="normal">3973</span>
<span class="normal">3974</span>
<span class="normal">3975</span>
<span class="normal">3976</span>
<span class="normal">3977</span>
<span class="normal">3978</span>
<span class="normal">3979</span>
<span class="normal">3980</span>
<span class="normal">3981</span>
<span class="normal">3982</span>
<span class="normal">3983</span>
<span class="normal">3984</span>
<span class="normal">3985</span>
<span class="normal">3986</span>
<span class="normal">3987</span>
<span class="normal">3988</span>
<span class="normal">3989</span>
<span class="normal">3990</span>
<span class="normal">3991</span>
<span class="normal">3992</span>
<span class="normal">3993</span>
<span class="normal">3994</span>
<span class="normal">3995</span>
<span class="normal">3996</span>
<span class="normal">3997</span>
<span class="normal">3998</span>
<span class="normal">3999</span>
<span class="normal">4000</span>
<span class="normal">4001</span>
<span class="normal">4002</span>
<span class="normal">4003</span>
<span class="normal">4004</span>
<span class="normal">4005</span>
<span class="normal">4006</span>
<span class="normal">4007</span>
<span class="normal">4008</span>
<span class="normal">4009</span>
<span class="normal">4010</span>
<span class="normal">4011</span>
<span class="normal">4012</span>
<span class="normal">4013</span>
<span class="normal">4014</span>
<span class="normal">4015</span>
<span class="normal">4016</span>
<span class="normal">4017</span>
<span class="normal">4018</span>
<span class="normal">4019</span>
<span class="normal">4020</span>
<span class="normal">4021</span>
<span class="normal">4022</span>
<span class="normal">4023</span>
<span class="normal">4024</span>
<span class="normal">4025</span>
<span class="normal">4026</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizeResult</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run the optimization process.</span>

<span class="sd">    The optimization terminates when either:</span>
<span class="sd">    - Total function evaluations reach max_iter (including initial design), OR</span>
<span class="sd">    - Runtime exceeds max_time minutes</span>

<span class="sd">    Input/Output Spaces:</span>
<span class="sd">    - Input X0: Expected in Natural Space (original scale, physical units).</span>
<span class="sd">    - Output result.x: Returned in Natural Space.</span>
<span class="sd">    - Output result.X: Returned in Natural Space.</span>
<span class="sd">    - Internal Optimization: Performed in Transformed and Mapped Space.</span>

<span class="sd">    Args:</span>
<span class="sd">        X0 (ndarray, optional): Initial design points in Natural Space, shape (n_initial, n_features).</span>
<span class="sd">            If None, generates space-filling design. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        OptimizeResult: Optimization result with fields:</span>
<span class="sd">            - x: best point found in Natural Space</span>
<span class="sd">            - fun: best function value</span>
<span class="sd">            - nfev: number of function evaluations (including initial design)</span>
<span class="sd">            - nit: number of sequential optimization iterations (after initial design)</span>
<span class="sd">            - success: whether optimization succeeded</span>
<span class="sd">            - message: termination message indicating reason for stopping, including</span>
<span class="sd">              statistics (function value, iterations, evaluations)</span>
<span class="sd">            - X: all evaluated points in Natural Space</span>
<span class="sd">            - y: all function values</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     n_initial=5,</span>
<span class="sd">        ...     max_iter=20,</span>
<span class="sd">        ...     seed=0,</span>
<span class="sd">        ...     x0=np.array([0.0, 0.0]),</span>
<span class="sd">        ...     verbose=True</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; print(result.message.splitlines()[0])</span>
<span class="sd">        Optimization terminated: maximum evaluations (20) reached</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best point:&quot;, result.x)</span>
<span class="sd">        Best point: [0. 0.]</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Best value:&quot;, result.fun)</span>
<span class="sd">        Best value: 0.0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Track results across restarts for final aggregation.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Capture start time for timeout enforcement.</span>
    <span class="n">timeout_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="c1"># Initial run state.</span>
    <span class="n">current_X0</span> <span class="o">=</span> <span class="n">X0</span>
    <span class="n">status</span> <span class="o">=</span> <span class="s2">&quot;START&quot;</span>

    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Get best result so far if we have results</span>
        <span class="n">best_res</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="c1"># Compute injected best value for restarts, then run one optimization cycle.</span>
        <span class="c1"># y0_known_val carries the current global best objective so the next</span>
        <span class="c1"># run can skip re-evaluating that known point when restart injection is on.</span>
        <span class="n">y0_known_val</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">best_res</span><span class="o">.</span><span class="n">fun</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;RESTART&quot;</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">restart_inject_best</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span>
            <span class="p">)</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="c1"># Calculate remaining budget</span>
        <span class="n">total_evals_so_far</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">)</span>
        <span class="n">remaining_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">-</span> <span class="n">total_evals_so_far</span>

        <span class="c1"># If we don&#39;t have enough budget for at least initial design (or some minimal amount), stop</span>
        <span class="k">if</span> <span class="n">remaining_iter</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_initial</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Global budget exhausted. Stopping restarts.&quot;</span><span class="p">)</span>
            <span class="k">break</span>

        <span class="c1"># Execute one optimization run using the remaining budget; dispatcher</span>
        <span class="c1"># selects sequential vs parallel based on `n_jobs` and returns status/result.</span>
        <span class="n">status</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_optimization_run</span><span class="p">(</span>
            <span class="n">timeout_start</span><span class="p">,</span>
            <span class="n">current_X0</span><span class="p">,</span>
            <span class="n">y0_known</span><span class="o">=</span><span class="n">y0_known_val</span><span class="p">,</span>
            <span class="n">max_iter_override</span><span class="o">=</span><span class="n">remaining_iter</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;FINISHED&quot;</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="k">elif</span> <span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;RESTART&quot;</span><span class="p">:</span>
            <span class="c1"># Prepare for a clean restart: let get_initial_design() regenerate the full design.</span>
            <span class="n">current_X0</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># Find the global best result across completed restarts.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">:</span>
                <span class="n">best_res</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">r</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restart_inject_best</span><span class="p">:</span>
                    <span class="c1"># Inject the current global best into the next run&#39;s initial design.</span>
                    <span class="c1"># best_res.x is in natural scale; _validate_x0 converts to internal scale</span>
                    <span class="c1"># so the injected point can be mixed with LHS samples.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_x0</span><span class="p">(</span><span class="n">best_res</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
                    <span class="c1"># Keep current_X0 unset so the initial design is rebuilt around the injected x0.</span>
                    <span class="n">current_X0</span> <span class="o">=</span> <span class="kc">None</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Restart injection: Using best found point so far as starting point (f(x)=</span><span class="si">{</span><span class="n">best_res</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">).&quot;</span>
                        <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># In sequential mode we advance the seed between restarts to diversify the LHS.</span>
                <span class="c1"># Parallel mode increments seeds per worker during dispatch.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="c1"># Continue loop</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Should not happen</span>
            <span class="k">break</span>

    <span class="c1"># Return best result</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">result</span>  <span class="c1"># Fallback</span>

    <span class="c1"># Find best result based on &#39;fun&#39;</span>
    <span class="n">best_result</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">r</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>

    <span class="c1"># Merge results from all parallel runs (and sequential runs if any)</span>
    <span class="n">X_all_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">res</span><span class="o">.</span><span class="n">X</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">]</span>
    <span class="n">y_all_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">res</span><span class="o">.</span><span class="n">y</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">]</span>

    <span class="c1"># Concatenate all evaluations</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">X_all_list</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">y_all_list</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

    <span class="c1"># Aggregated iterations (sum of all runs)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="s2">&quot;nit&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">restarts_results_</span><span class="p">)</span>

    <span class="c1"># Update best solution found</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="o">=</span> <span class="n">best_result</span><span class="o">.</span><span class="n">x</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="o">=</span> <span class="n">best_result</span><span class="o">.</span><span class="n">fun</span>

    <span class="k">return</span> <span class="n">best_result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.optimize_acquisition_func" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">optimize_acquisition_func</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.optimize_acquisition_func" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Optimize the acquisition function to find the next point to evaluate.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ndarray</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The optimized point(s).
If acquisition_fun_return_size == 1, returns 1D array of shape (n_features,).
If acquisition_fun_return_size &gt; 1, returns 2D array of shape (N, n_features),
where N is min(acquisition_fun_return_size, population_size).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">acquisition</span><span class="o">=</span><span class="s1">&#39;ei&#39;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">_fit_surrogate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_next</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize_acquisition_func</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Next point to evaluate:&quot;</span><span class="p">,</span> <span class="n">x_next</span><span class="p">)</span>
<span class="go">Next point to evaluate: [some float values]</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">3790</span>
<span class="normal">3791</span>
<span class="normal">3792</span>
<span class="normal">3793</span>
<span class="normal">3794</span>
<span class="normal">3795</span>
<span class="normal">3796</span>
<span class="normal">3797</span>
<span class="normal">3798</span>
<span class="normal">3799</span>
<span class="normal">3800</span>
<span class="normal">3801</span>
<span class="normal">3802</span>
<span class="normal">3803</span>
<span class="normal">3804</span>
<span class="normal">3805</span>
<span class="normal">3806</span>
<span class="normal">3807</span>
<span class="normal">3808</span>
<span class="normal">3809</span>
<span class="normal">3810</span>
<span class="normal">3811</span>
<span class="normal">3812</span>
<span class="normal">3813</span>
<span class="normal">3814</span>
<span class="normal">3815</span>
<span class="normal">3816</span>
<span class="normal">3817</span>
<span class="normal">3818</span>
<span class="normal">3819</span>
<span class="normal">3820</span>
<span class="normal">3821</span>
<span class="normal">3822</span>
<span class="normal">3823</span>
<span class="normal">3824</span>
<span class="normal">3825</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">optimize_acquisition_func</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimize the acquisition function to find the next point to evaluate.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ndarray: The optimized point(s).</span>
<span class="sd">            If acquisition_fun_return_size == 1, returns 1D array of shape (n_features,).</span>
<span class="sd">            If acquisition_fun_return_size &gt; 1, returns 2D array of shape (N, n_features),</span>
<span class="sd">            where N is min(acquisition_fun_return_size, population_size).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     acquisition=&#39;ei&#39;</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; X_train = np.array([[0, 0], [1, 1], [2, 2]])</span>
<span class="sd">        &gt;&gt;&gt; y_train = np.array([0, 2, 8])</span>
<span class="sd">        &gt;&gt;&gt; opt._fit_surrogate(X_train, y_train)</span>
<span class="sd">        &gt;&gt;&gt; x_next = opt.optimize_acquisition_func()</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Next point to evaluate:&quot;, x_next)</span>
<span class="sd">        Next point to evaluate: [some float values]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_optimizer</span> <span class="o">==</span> <span class="s2">&quot;tricands&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_acquisition_tricands</span><span class="p">()</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_optimizer</span> <span class="o">==</span> <span class="s2">&quot;differential_evolution&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_acquisition_de</span><span class="p">()</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_optimizer</span> <span class="o">==</span> <span class="s2">&quot;de_tricands&quot;</span><span class="p">:</span>
        <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">val</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob_de_tricands</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_acquisition_de</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_acquisition_tricands</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_acquisition_scipy</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.plot_importance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot_importance</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.plot_importance" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Plot variable importance.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>threshold</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Minimum importance percentage to include in plot.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>figsize</code>
            </td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Figure size.</p>
              </div>
            </td>
            <td>
                  <code>(10, 6)</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">7151</span>
<span class="normal">7152</span>
<span class="normal">7153</span>
<span class="normal">7154</span>
<span class="normal">7155</span>
<span class="normal">7156</span>
<span class="normal">7157</span>
<span class="normal">7158</span>
<span class="normal">7159</span>
<span class="normal">7160</span>
<span class="normal">7161</span>
<span class="normal">7162</span>
<span class="normal">7163</span>
<span class="normal">7164</span>
<span class="normal">7165</span>
<span class="normal">7166</span>
<span class="normal">7167</span>
<span class="normal">7168</span>
<span class="normal">7169</span>
<span class="normal">7170</span>
<span class="normal">7171</span>
<span class="normal">7172</span>
<span class="normal">7173</span>
<span class="normal">7174</span>
<span class="normal">7175</span>
<span class="normal">7176</span>
<span class="normal">7177</span>
<span class="normal">7178</span>
<span class="normal">7179</span>
<span class="normal">7180</span>
<span class="normal">7181</span>
<span class="normal">7182</span>
<span class="normal">7183</span>
<span class="normal">7184</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">plot_importance</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot variable importance.</span>

<span class="sd">    Args:</span>
<span class="sd">        threshold (float): Minimum importance percentage to include in plot.</span>
<span class="sd">        figsize (tuple): Figure size.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">importance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_importance</span><span class="p">()</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
        <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">importance</span><span class="p">))]</span>
    <span class="p">)</span>

    <span class="c1"># Filter by threshold</span>
    <span class="n">filtered_data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">importance</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">]</span>
    <span class="n">filtered_data</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">filtered_data</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No variables met the importance threshold.&quot;</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="n">names</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">filtered_data</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="n">y_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">y_pos</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">y_pos</span><span class="p">,</span> <span class="n">names</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Importance (%)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Variable Importance&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>  <span class="c1"># Best on top</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.plot_important_hyperparameter_contour" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot_important_hyperparameter_contour</span><span class="p">(</span><span class="n">max_imp</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">add_points</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">grid_visible</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">contour_levels</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.plot_important_hyperparameter_contour" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Plot surrogate contours using spotoptim.plot.visualization.plot_important_hyperparameter_contour.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">7097</span>
<span class="normal">7098</span>
<span class="normal">7099</span>
<span class="normal">7100</span>
<span class="normal">7101</span>
<span class="normal">7102</span>
<span class="normal">7103</span>
<span class="normal">7104</span>
<span class="normal">7105</span>
<span class="normal">7106</span>
<span class="normal">7107</span>
<span class="normal">7108</span>
<span class="normal">7109</span>
<span class="normal">7110</span>
<span class="normal">7111</span>
<span class="normal">7112</span>
<span class="normal">7113</span>
<span class="normal">7114</span>
<span class="normal">7115</span>
<span class="normal">7116</span>
<span class="normal">7117</span>
<span class="normal">7118</span>
<span class="normal">7119</span>
<span class="normal">7120</span>
<span class="normal">7121</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">plot_important_hyperparameter_contour</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">max_imp</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="n">cmap</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;jet&quot;</span><span class="p">,</span>
    <span class="n">num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">add_points</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">grid_visible</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">contour_levels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot surrogate contours using spotoptim.plot.visualization.plot_important_hyperparameter_contour.&quot;&quot;&quot;</span>
    <span class="n">plot_important_hyperparameter_contour</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">max_imp</span><span class="o">=</span><span class="n">max_imp</span><span class="p">,</span>
        <span class="n">show</span><span class="o">=</span><span class="n">show</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
        <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
        <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">,</span>
        <span class="n">add_points</span><span class="o">=</span><span class="n">add_points</span><span class="p">,</span>
        <span class="n">grid_visible</span><span class="o">=</span><span class="n">grid_visible</span><span class="p">,</span>
        <span class="n">contour_levels</span><span class="o">=</span><span class="n">contour_levels</span><span class="p">,</span>
        <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.plot_parameter_scatter" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot_parameter_scatter</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Objective Value&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis_r&#39;</span><span class="p">,</span> <span class="n">show_correlation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log_y</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.plot_parameter_scatter" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Plot parameter distributions showing relationship between each parameter and objective.</p>
<p>Creates a grid of scatter plots, one for each parameter dimension, showing how
the objective function value varies with each parameter. The best configuration
is marked with a red star. Parameters with log-scale transformations (var_trans)
are automatically displayed on a log x-axis.</p>
<p>Optionally displays Spearman correlation coefficients in plot titles for
sensitivity analysis. For factor (categorical) variables, correlation is not
computed and they are displayed with discrete positions on the x-axis.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>result</code>
            </td>
            <td>
                  <code><span title="scipy.optimize.OptimizeResult">OptimizeResult</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optimization result containing best parameters.
If None, uses the best found values from self.best_x_ and self.best_y_.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>show</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to display the plot. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>figsize</code>
            </td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Figure size as (width, height). Defaults to (12, 10).</p>
              </div>
            </td>
            <td>
                  <code>(12, 10)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ylabel</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Label for y-axis. Defaults to &ldquo;Objective Value&rdquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;Objective Value&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>cmap</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Colormap for scatter plot. Defaults to &ldquo;viridis_r&rdquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;viridis_r&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>show_correlation</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to compute and display Spearman
correlation coefficients in plot titles. Requires scipy. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>log_y</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use logarithmic scale for y-axis.
Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If no optimization data is available.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">objective</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x0&quot;</span><span class="p">,</span> <span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;x3&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Plot parameter distributions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">plot_parameter_scatter</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Plot with custom settings</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">plot_parameter_scatter</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;plasma&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Error&quot;</span><span class="p">)</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">7186</span>
<span class="normal">7187</span>
<span class="normal">7188</span>
<span class="normal">7189</span>
<span class="normal">7190</span>
<span class="normal">7191</span>
<span class="normal">7192</span>
<span class="normal">7193</span>
<span class="normal">7194</span>
<span class="normal">7195</span>
<span class="normal">7196</span>
<span class="normal">7197</span>
<span class="normal">7198</span>
<span class="normal">7199</span>
<span class="normal">7200</span>
<span class="normal">7201</span>
<span class="normal">7202</span>
<span class="normal">7203</span>
<span class="normal">7204</span>
<span class="normal">7205</span>
<span class="normal">7206</span>
<span class="normal">7207</span>
<span class="normal">7208</span>
<span class="normal">7209</span>
<span class="normal">7210</span>
<span class="normal">7211</span>
<span class="normal">7212</span>
<span class="normal">7213</span>
<span class="normal">7214</span>
<span class="normal">7215</span>
<span class="normal">7216</span>
<span class="normal">7217</span>
<span class="normal">7218</span>
<span class="normal">7219</span>
<span class="normal">7220</span>
<span class="normal">7221</span>
<span class="normal">7222</span>
<span class="normal">7223</span>
<span class="normal">7224</span>
<span class="normal">7225</span>
<span class="normal">7226</span>
<span class="normal">7227</span>
<span class="normal">7228</span>
<span class="normal">7229</span>
<span class="normal">7230</span>
<span class="normal">7231</span>
<span class="normal">7232</span>
<span class="normal">7233</span>
<span class="normal">7234</span>
<span class="normal">7235</span>
<span class="normal">7236</span>
<span class="normal">7237</span>
<span class="normal">7238</span>
<span class="normal">7239</span>
<span class="normal">7240</span>
<span class="normal">7241</span>
<span class="normal">7242</span>
<span class="normal">7243</span>
<span class="normal">7244</span>
<span class="normal">7245</span>
<span class="normal">7246</span>
<span class="normal">7247</span>
<span class="normal">7248</span>
<span class="normal">7249</span>
<span class="normal">7250</span>
<span class="normal">7251</span>
<span class="normal">7252</span>
<span class="normal">7253</span>
<span class="normal">7254</span>
<span class="normal">7255</span>
<span class="normal">7256</span>
<span class="normal">7257</span>
<span class="normal">7258</span>
<span class="normal">7259</span>
<span class="normal">7260</span>
<span class="normal">7261</span>
<span class="normal">7262</span>
<span class="normal">7263</span>
<span class="normal">7264</span>
<span class="normal">7265</span>
<span class="normal">7266</span>
<span class="normal">7267</span>
<span class="normal">7268</span>
<span class="normal">7269</span>
<span class="normal">7270</span>
<span class="normal">7271</span>
<span class="normal">7272</span>
<span class="normal">7273</span>
<span class="normal">7274</span>
<span class="normal">7275</span>
<span class="normal">7276</span>
<span class="normal">7277</span>
<span class="normal">7278</span>
<span class="normal">7279</span>
<span class="normal">7280</span>
<span class="normal">7281</span>
<span class="normal">7282</span>
<span class="normal">7283</span>
<span class="normal">7284</span>
<span class="normal">7285</span>
<span class="normal">7286</span>
<span class="normal">7287</span>
<span class="normal">7288</span>
<span class="normal">7289</span>
<span class="normal">7290</span>
<span class="normal">7291</span>
<span class="normal">7292</span>
<span class="normal">7293</span>
<span class="normal">7294</span>
<span class="normal">7295</span>
<span class="normal">7296</span>
<span class="normal">7297</span>
<span class="normal">7298</span>
<span class="normal">7299</span>
<span class="normal">7300</span>
<span class="normal">7301</span>
<span class="normal">7302</span>
<span class="normal">7303</span>
<span class="normal">7304</span>
<span class="normal">7305</span>
<span class="normal">7306</span>
<span class="normal">7307</span>
<span class="normal">7308</span>
<span class="normal">7309</span>
<span class="normal">7310</span>
<span class="normal">7311</span>
<span class="normal">7312</span>
<span class="normal">7313</span>
<span class="normal">7314</span>
<span class="normal">7315</span>
<span class="normal">7316</span>
<span class="normal">7317</span>
<span class="normal">7318</span>
<span class="normal">7319</span>
<span class="normal">7320</span>
<span class="normal">7321</span>
<span class="normal">7322</span>
<span class="normal">7323</span>
<span class="normal">7324</span>
<span class="normal">7325</span>
<span class="normal">7326</span>
<span class="normal">7327</span>
<span class="normal">7328</span>
<span class="normal">7329</span>
<span class="normal">7330</span>
<span class="normal">7331</span>
<span class="normal">7332</span>
<span class="normal">7333</span>
<span class="normal">7334</span>
<span class="normal">7335</span>
<span class="normal">7336</span>
<span class="normal">7337</span>
<span class="normal">7338</span>
<span class="normal">7339</span>
<span class="normal">7340</span>
<span class="normal">7341</span>
<span class="normal">7342</span>
<span class="normal">7343</span>
<span class="normal">7344</span>
<span class="normal">7345</span>
<span class="normal">7346</span>
<span class="normal">7347</span>
<span class="normal">7348</span>
<span class="normal">7349</span>
<span class="normal">7350</span>
<span class="normal">7351</span>
<span class="normal">7352</span>
<span class="normal">7353</span>
<span class="normal">7354</span>
<span class="normal">7355</span>
<span class="normal">7356</span>
<span class="normal">7357</span>
<span class="normal">7358</span>
<span class="normal">7359</span>
<span class="normal">7360</span>
<span class="normal">7361</span>
<span class="normal">7362</span>
<span class="normal">7363</span>
<span class="normal">7364</span>
<span class="normal">7365</span>
<span class="normal">7366</span>
<span class="normal">7367</span>
<span class="normal">7368</span>
<span class="normal">7369</span>
<span class="normal">7370</span>
<span class="normal">7371</span>
<span class="normal">7372</span>
<span class="normal">7373</span>
<span class="normal">7374</span>
<span class="normal">7375</span>
<span class="normal">7376</span>
<span class="normal">7377</span>
<span class="normal">7378</span>
<span class="normal">7379</span>
<span class="normal">7380</span>
<span class="normal">7381</span>
<span class="normal">7382</span>
<span class="normal">7383</span>
<span class="normal">7384</span>
<span class="normal">7385</span>
<span class="normal">7386</span>
<span class="normal">7387</span>
<span class="normal">7388</span>
<span class="normal">7389</span>
<span class="normal">7390</span>
<span class="normal">7391</span>
<span class="normal">7392</span>
<span class="normal">7393</span>
<span class="normal">7394</span>
<span class="normal">7395</span>
<span class="normal">7396</span>
<span class="normal">7397</span>
<span class="normal">7398</span>
<span class="normal">7399</span>
<span class="normal">7400</span>
<span class="normal">7401</span>
<span class="normal">7402</span>
<span class="normal">7403</span>
<span class="normal">7404</span>
<span class="normal">7405</span>
<span class="normal">7406</span>
<span class="normal">7407</span>
<span class="normal">7408</span>
<span class="normal">7409</span>
<span class="normal">7410</span>
<span class="normal">7411</span>
<span class="normal">7412</span>
<span class="normal">7413</span>
<span class="normal">7414</span>
<span class="normal">7415</span>
<span class="normal">7416</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">plot_parameter_scatter</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">result</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">OptimizeResult</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">ylabel</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Objective Value&quot;</span><span class="p">,</span>
    <span class="n">cmap</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;viridis_r&quot;</span><span class="p">,</span>
    <span class="n">show_correlation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">log_y</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot parameter distributions showing relationship between each parameter and objective.</span>

<span class="sd">    Creates a grid of scatter plots, one for each parameter dimension, showing how</span>
<span class="sd">    the objective function value varies with each parameter. The best configuration</span>
<span class="sd">    is marked with a red star. Parameters with log-scale transformations (var_trans)</span>
<span class="sd">    are automatically displayed on a log x-axis.</span>

<span class="sd">    Optionally displays Spearman correlation coefficients in plot titles for</span>
<span class="sd">    sensitivity analysis. For factor (categorical) variables, correlation is not</span>
<span class="sd">    computed and they are displayed with discrete positions on the x-axis.</span>

<span class="sd">    Args:</span>
<span class="sd">        result (OptimizeResult, optional): Optimization result containing best parameters.</span>
<span class="sd">            If None, uses the best found values from self.best_x_ and self.best_y_.</span>
<span class="sd">        show (bool, optional): Whether to display the plot. Defaults to True.</span>
<span class="sd">        figsize (tuple, optional): Figure size as (width, height). Defaults to (12, 10).</span>
<span class="sd">        ylabel (str, optional): Label for y-axis. Defaults to &quot;Objective Value&quot;.</span>
<span class="sd">        cmap (str, optional): Colormap for scatter plot. Defaults to &quot;viridis_r&quot;.</span>
<span class="sd">        show_correlation (bool, optional): Whether to compute and display Spearman</span>
<span class="sd">            correlation coefficients in plot titles. Requires scipy. Defaults to False.</span>
<span class="sd">        log_y (bool, optional): Whether to use logarithmic scale for y-axis.</span>
<span class="sd">            Defaults to False.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If no optimization data is available.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; def objective(X):</span>
<span class="sd">        ...     return np.sum(X**2, axis=1)</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=objective,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5), (-5, 5), (-5, 5)],</span>
<span class="sd">        ...     var_name=[&quot;x0&quot;, &quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     seed=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # Plot parameter distributions</span>
<span class="sd">        &gt;&gt;&gt; opt.plot_parameter_scatter(result)</span>
<span class="sd">        &gt;&gt;&gt; # Plot with custom settings</span>
<span class="sd">        &gt;&gt;&gt; opt.plot_parameter_scatter(result, cmap=&quot;plasma&quot;, ylabel=&quot;Error&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
            <span class="s2">&quot;matplotlib is required for plot_parameter_scatter(). &quot;</span>
            <span class="s2">&quot;Install it with: pip install matplotlib&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Import scipy if correlation is requested</span>
    <span class="k">if</span> <span class="n">show_correlation</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">spearmanr</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;scipy is required for show_correlation=True. &quot;</span>
                <span class="s2">&quot;Install it with: pip install scipy&quot;</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No optimization data available. Run optimize() first.&quot;</span><span class="p">)</span>

    <span class="c1"># Get best values</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">best_x</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>
        <span class="n">best_y</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">best_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>
        <span class="n">best_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No best solution available.&quot;</span><span class="p">)</span>

    <span class="n">all_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span>
    <span class="n">history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span>

    <span class="c1"># Determine grid dimensions</span>
    <span class="n">n_params</span> <span class="o">=</span> <span class="n">all_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">n_cols</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_params</span><span class="p">)</span>
    <span class="n">n_rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_params</span> <span class="o">/</span> <span class="n">n_cols</span><span class="p">))</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>

    <span class="c1"># Make axes always iterable</span>
    <span class="k">if</span> <span class="n">n_params</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">axes</span><span class="p">])</span>
    <span class="n">axes_flat</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">if</span> <span class="n">n_params</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">axes</span>

    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_params</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes_flat</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">param_values</span> <span class="o">=</span> <span class="n">all_params</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span>
        <span class="n">param_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">var_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="k">else</span> <span class="s2">&quot;float&quot;</span>
        <span class="n">var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="c1"># Check if this is a factor variable</span>
        <span class="n">is_factor</span> <span class="o">=</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span>

        <span class="c1"># Compute correlation if requested</span>
        <span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">if</span> <span class="n">show_correlation</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_factor</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">var_trans</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;log10&quot;</span><span class="p">,</span> <span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="s2">&quot;ln&quot;</span><span class="p">]:</span>
                    <span class="c1"># For log-transformed parameters, correlate in log-space</span>
                    <span class="n">param_values_numeric</span> <span class="o">=</span> <span class="n">param_values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
                    <span class="n">valid_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">param_values_numeric</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">history</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">valid_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
                        <span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">param_values_numeric</span><span class="p">[</span><span class="n">valid_mask</span><span class="p">]),</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="n">valid_mask</span><span class="p">]),</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Direct correlation for non-transformed parameters</span>
                    <span class="n">param_values_numeric</span> <span class="o">=</span> <span class="n">param_values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
                    <span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">param_values_numeric</span><span class="p">,</span> <span class="n">history</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
                <span class="k">pass</span>  <span class="c1"># Keep corr as nan</span>

        <span class="c1"># Handle factor variables differently</span>
        <span class="k">if</span> <span class="n">is_factor</span><span class="p">:</span>
            <span class="c1"># Map factor levels to integer positions</span>
            <span class="n">unique_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">param_values</span><span class="p">)</span>
            <span class="n">positions</span> <span class="o">=</span> <span class="p">{</span><span class="n">val</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">)}</span>
            <span class="n">numeric_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">positions</span><span class="p">[</span><span class="n">val</span><span class="p">]</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">param_values</span><span class="p">])</span>

            <span class="c1"># Scatter plot with discrete x positions</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">numeric_vals</span><span class="p">,</span>
                <span class="n">history</span><span class="p">,</span>
                <span class="n">c</span><span class="o">=</span><span class="n">history</span><span class="p">,</span>
                <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
                <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Mark best configuration</span>
            <span class="n">best_val</span> <span class="o">=</span> <span class="n">best_x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">best_val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">positions</span><span class="p">:</span>
                <span class="n">positions</span><span class="p">[</span><span class="n">best_val</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">positions</span><span class="p">)</span>
                <span class="n">unique_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">,</span> <span class="n">best_val</span><span class="p">)</span>

            <span class="n">best_pos</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">best_val</span><span class="p">]</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="p">[</span><span class="n">best_pos</span><span class="p">],</span>
                <span class="p">[</span><span class="n">best_y</span><span class="p">],</span>
                <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
                <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
                <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Best&quot;</span><span class="p">,</span>
                <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Set categorical x-axis labels</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">)))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">unique_vals</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Standard scatter plot for numeric variables</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">param_values</span><span class="p">,</span>
                <span class="n">history</span><span class="p">,</span>
                <span class="n">c</span><span class="o">=</span><span class="n">history</span><span class="p">,</span>
                <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
                <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Mark best configuration</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="p">[</span><span class="n">best_x</span><span class="p">[</span><span class="n">idx</span><span class="p">]],</span>
                <span class="p">[</span><span class="n">best_y</span><span class="p">],</span>
                <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
                <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
                <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Best&quot;</span><span class="p">,</span>
                <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Use log scale for parameters with log transformations</span>
            <span class="k">if</span> <span class="n">var_trans</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;log10&quot;</span><span class="p">,</span> <span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="s2">&quot;ln&quot;</span><span class="p">]:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>

        <span class="c1"># Set labels</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>

        <span class="c1"># Set title with optional correlation</span>
        <span class="k">if</span> <span class="n">show_correlation</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">corr</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="se">\n</span><span class="s2">Corr: </span><span class="si">{</span><span class="n">corr</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (p=</span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">show_correlation</span> <span class="ow">and</span> <span class="n">is_factor</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="se">\n</span><span class="s2">(categorical)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2"> vs </span><span class="si">{</span><span class="n">ylabel</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

        <span class="c1"># Use log scale for y-axis if requested</span>
        <span class="k">if</span> <span class="n">log_y</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>

    <span class="c1"># Hide unused subplots</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_params</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes_flat</span><span class="p">)):</span>
        <span class="n">axes_flat</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.plot_progress" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot_progress</span><span class="p">(</span><span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">log_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Objective Value&#39;</span><span class="p">,</span> <span class="n">mo</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.plot_progress" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Plot optimization progress using spotoptim.plot.visualization.plot_progress.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">7047</span>
<span class="normal">7048</span>
<span class="normal">7049</span>
<span class="normal">7050</span>
<span class="normal">7051</span>
<span class="normal">7052</span>
<span class="normal">7053</span>
<span class="normal">7054</span>
<span class="normal">7055</span>
<span class="normal">7056</span>
<span class="normal">7057</span>
<span class="normal">7058</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">plot_progress</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">log_y</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
    <span class="n">ylabel</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Objective Value&quot;</span><span class="p">,</span>
    <span class="n">mo</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot optimization progress using spotoptim.plot.visualization.plot_progress.&quot;&quot;&quot;</span>
    <span class="n">plot_progress</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="n">show</span><span class="p">,</span> <span class="n">log_y</span><span class="o">=</span><span class="n">log_y</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="n">ylabel</span><span class="p">,</span> <span class="n">mo</span><span class="o">=</span><span class="n">mo</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.plot_surrogate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot_surrogate</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">var_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">add_points</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">grid_visible</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">contour_levels</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.plot_surrogate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Plot the surrogate model for two dimensions.</p>
<p>Delegates to spotoptim.plot.visualization.plot_surrogate.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">7060</span>
<span class="normal">7061</span>
<span class="normal">7062</span>
<span class="normal">7063</span>
<span class="normal">7064</span>
<span class="normal">7065</span>
<span class="normal">7066</span>
<span class="normal">7067</span>
<span class="normal">7068</span>
<span class="normal">7069</span>
<span class="normal">7070</span>
<span class="normal">7071</span>
<span class="normal">7072</span>
<span class="normal">7073</span>
<span class="normal">7074</span>
<span class="normal">7075</span>
<span class="normal">7076</span>
<span class="normal">7077</span>
<span class="normal">7078</span>
<span class="normal">7079</span>
<span class="normal">7080</span>
<span class="normal">7081</span>
<span class="normal">7082</span>
<span class="normal">7083</span>
<span class="normal">7084</span>
<span class="normal">7085</span>
<span class="normal">7086</span>
<span class="normal">7087</span>
<span class="normal">7088</span>
<span class="normal">7089</span>
<span class="normal">7090</span>
<span class="normal">7091</span>
<span class="normal">7092</span>
<span class="normal">7093</span>
<span class="normal">7094</span>
<span class="normal">7095</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">plot_surrogate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">i</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">j</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">show</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="n">var_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cmap</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;jet&quot;</span><span class="p">,</span>
    <span class="n">num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">vmin</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">vmax</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">add_points</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">grid_visible</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">contour_levels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot the surrogate model for two dimensions.</span>

<span class="sd">    Delegates to spotoptim.plot.visualization.plot_surrogate.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">plot_surrogate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
        <span class="n">j</span><span class="o">=</span><span class="n">j</span><span class="p">,</span>
        <span class="n">show</span><span class="o">=</span><span class="n">show</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
        <span class="n">var_name</span><span class="o">=</span><span class="n">var_name</span><span class="p">,</span>
        <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
        <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">,</span>
        <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span>
        <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span>
        <span class="n">add_points</span><span class="o">=</span><span class="n">add_points</span><span class="p">,</span>
        <span class="n">grid_visible</span><span class="o">=</span><span class="n">grid_visible</span><span class="p">,</span>
        <span class="n">contour_levels</span><span class="o">=</span><span class="n">contour_levels</span><span class="p">,</span>
        <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.print_best" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">print_best</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transformations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">show_name</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.print_best" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Print the best solution found during optimization.</p>
<p>This method displays the best hyperparameters and objective value in a
formatted table. It supports custom transformations for parameters
(e.g., converting log-scale values back to original scale).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>result</code>
            </td>
            <td>
                  <code><span title="scipy.optimize.OptimizeResult">OptimizeResult</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optimization result object from optimize().
If None, uses the stored best values from the optimizer. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>transformations</code>
            </td>
            <td>
                  <code>list of callable</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of transformation functions
to apply to each parameter. Each function takes a single value and returns
the transformed value. Use None for parameters that don&rsquo;t need transformation.
Length must match number of dimensions. Example: [None, None, lambda x: 10**x]
to convert the 3rd parameter from log10 scale. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>show_name</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to display variable names. If False,
uses generic names like &lsquo;x0&rsquo;, &lsquo;x1&rsquo;, etc. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>precision</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of decimal places for floating point values.
Defaults to 4.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 1: Basic usage</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">sphere</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">sphere</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">print_best</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="go">Best Solution Found:</span>
<span class="go">--------------------------------------------------</span>
<span class="go">  x1: 0.0123</span>
<span class="go">  x2: -0.0045</span>
<span class="go">  Objective Value: 0.000173</span>
<span class="go">  Total Evaluations: 20</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 2: With log-scale transformations (e.g., for learning rates)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">objective</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="c1"># X[:, 0]: neurons (int), X[:, 1]: layers (int),</span>
<span class="gp">... </span>    <span class="c1"># X[:, 2]: log10(lr), X[:, 3]: log10(alpha)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Placeholder</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">var_type</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">var_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;neurons&quot;</span><span class="p">,</span> <span class="s2">&quot;layers&quot;</span><span class="p">,</span> <span class="s2">&quot;log10_lr&quot;</span><span class="p">,</span> <span class="s2">&quot;log10_alpha&quot;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Transform log-scale parameters back to original scale</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformations</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>    <span class="nb">int</span><span class="p">,</span>              <span class="c1"># neurons -&gt; int</span>
<span class="gp">... </span>    <span class="nb">int</span><span class="p">,</span>              <span class="c1"># layers -&gt; int</span>
<span class="gp">... </span>    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">10</span><span class="o">**</span><span class="n">x</span><span class="p">,</span>  <span class="c1"># log10_lr -&gt; lr</span>
<span class="gp">... </span>    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">10</span><span class="o">**</span><span class="n">x</span>   <span class="c1"># log10_alpha -&gt; alpha</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">print_best</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">transformations</span><span class="o">=</span><span class="n">transformations</span><span class="p">)</span>

<span class="go">Best Solution Found:</span>
<span class="go">--------------------------------------------------</span>
<span class="go">  neurons: 64</span>
<span class="go">  layers: 2</span>
<span class="go">  log10_lr: 0.0012</span>
<span class="go">  log10_alpha: 0.0345</span>
<span class="go">  Objective Value: 1.2345</span>
<span class="go">  Total Evaluations: 30</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 3: Without result object (using stored values)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">print_best</span><span class="p">()</span>  <span class="c1"># Uses opt.best_x_ and opt.best_y_</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example 4: Hide variable names</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">print_best</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">show_name</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="go">Best Solution Found:</span>
<span class="go">--------------------------------------------------</span>
<span class="go">  x0: 0.0123</span>
<span class="go">  x1: -0.0045</span>
<span class="go">  Objective Value: 0.000173</span>
<span class="go">  Total Evaluations: 20</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">5959</span>
<span class="normal">5960</span>
<span class="normal">5961</span>
<span class="normal">5962</span>
<span class="normal">5963</span>
<span class="normal">5964</span>
<span class="normal">5965</span>
<span class="normal">5966</span>
<span class="normal">5967</span>
<span class="normal">5968</span>
<span class="normal">5969</span>
<span class="normal">5970</span>
<span class="normal">5971</span>
<span class="normal">5972</span>
<span class="normal">5973</span>
<span class="normal">5974</span>
<span class="normal">5975</span>
<span class="normal">5976</span>
<span class="normal">5977</span>
<span class="normal">5978</span>
<span class="normal">5979</span>
<span class="normal">5980</span>
<span class="normal">5981</span>
<span class="normal">5982</span>
<span class="normal">5983</span>
<span class="normal">5984</span>
<span class="normal">5985</span>
<span class="normal">5986</span>
<span class="normal">5987</span>
<span class="normal">5988</span>
<span class="normal">5989</span>
<span class="normal">5990</span>
<span class="normal">5991</span>
<span class="normal">5992</span>
<span class="normal">5993</span>
<span class="normal">5994</span>
<span class="normal">5995</span>
<span class="normal">5996</span>
<span class="normal">5997</span>
<span class="normal">5998</span>
<span class="normal">5999</span>
<span class="normal">6000</span>
<span class="normal">6001</span>
<span class="normal">6002</span>
<span class="normal">6003</span>
<span class="normal">6004</span>
<span class="normal">6005</span>
<span class="normal">6006</span>
<span class="normal">6007</span>
<span class="normal">6008</span>
<span class="normal">6009</span>
<span class="normal">6010</span>
<span class="normal">6011</span>
<span class="normal">6012</span>
<span class="normal">6013</span>
<span class="normal">6014</span>
<span class="normal">6015</span>
<span class="normal">6016</span>
<span class="normal">6017</span>
<span class="normal">6018</span>
<span class="normal">6019</span>
<span class="normal">6020</span>
<span class="normal">6021</span>
<span class="normal">6022</span>
<span class="normal">6023</span>
<span class="normal">6024</span>
<span class="normal">6025</span>
<span class="normal">6026</span>
<span class="normal">6027</span>
<span class="normal">6028</span>
<span class="normal">6029</span>
<span class="normal">6030</span>
<span class="normal">6031</span>
<span class="normal">6032</span>
<span class="normal">6033</span>
<span class="normal">6034</span>
<span class="normal">6035</span>
<span class="normal">6036</span>
<span class="normal">6037</span>
<span class="normal">6038</span>
<span class="normal">6039</span>
<span class="normal">6040</span>
<span class="normal">6041</span>
<span class="normal">6042</span>
<span class="normal">6043</span>
<span class="normal">6044</span>
<span class="normal">6045</span>
<span class="normal">6046</span>
<span class="normal">6047</span>
<span class="normal">6048</span>
<span class="normal">6049</span>
<span class="normal">6050</span>
<span class="normal">6051</span>
<span class="normal">6052</span>
<span class="normal">6053</span>
<span class="normal">6054</span>
<span class="normal">6055</span>
<span class="normal">6056</span>
<span class="normal">6057</span>
<span class="normal">6058</span>
<span class="normal">6059</span>
<span class="normal">6060</span>
<span class="normal">6061</span>
<span class="normal">6062</span>
<span class="normal">6063</span>
<span class="normal">6064</span>
<span class="normal">6065</span>
<span class="normal">6066</span>
<span class="normal">6067</span>
<span class="normal">6068</span>
<span class="normal">6069</span>
<span class="normal">6070</span>
<span class="normal">6071</span>
<span class="normal">6072</span>
<span class="normal">6073</span>
<span class="normal">6074</span>
<span class="normal">6075</span>
<span class="normal">6076</span>
<span class="normal">6077</span>
<span class="normal">6078</span>
<span class="normal">6079</span>
<span class="normal">6080</span>
<span class="normal">6081</span>
<span class="normal">6082</span>
<span class="normal">6083</span>
<span class="normal">6084</span>
<span class="normal">6085</span>
<span class="normal">6086</span>
<span class="normal">6087</span>
<span class="normal">6088</span>
<span class="normal">6089</span>
<span class="normal">6090</span>
<span class="normal">6091</span>
<span class="normal">6092</span>
<span class="normal">6093</span>
<span class="normal">6094</span>
<span class="normal">6095</span>
<span class="normal">6096</span>
<span class="normal">6097</span>
<span class="normal">6098</span>
<span class="normal">6099</span>
<span class="normal">6100</span>
<span class="normal">6101</span>
<span class="normal">6102</span>
<span class="normal">6103</span>
<span class="normal">6104</span>
<span class="normal">6105</span>
<span class="normal">6106</span>
<span class="normal">6107</span>
<span class="normal">6108</span>
<span class="normal">6109</span>
<span class="normal">6110</span>
<span class="normal">6111</span>
<span class="normal">6112</span>
<span class="normal">6113</span>
<span class="normal">6114</span>
<span class="normal">6115</span>
<span class="normal">6116</span>
<span class="normal">6117</span>
<span class="normal">6118</span>
<span class="normal">6119</span>
<span class="normal">6120</span>
<span class="normal">6121</span>
<span class="normal">6122</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">print_best</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">result</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">OptimizeResult</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">transformations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">show_name</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Print the best solution found during optimization.</span>

<span class="sd">    This method displays the best hyperparameters and objective value in a</span>
<span class="sd">    formatted table. It supports custom transformations for parameters</span>
<span class="sd">    (e.g., converting log-scale values back to original scale).</span>

<span class="sd">    Args:</span>
<span class="sd">        result (OptimizeResult, optional): Optimization result object from optimize().</span>
<span class="sd">            If None, uses the stored best values from the optimizer. Defaults to None.</span>
<span class="sd">        transformations (list of callable, optional): List of transformation functions</span>
<span class="sd">            to apply to each parameter. Each function takes a single value and returns</span>
<span class="sd">            the transformed value. Use None for parameters that don&#39;t need transformation.</span>
<span class="sd">            Length must match number of dimensions. Example: [None, None, lambda x: 10**x]</span>
<span class="sd">            to convert the 3rd parameter from log10 scale. Defaults to None.</span>
<span class="sd">        show_name (bool, optional): Whether to display variable names. If False,</span>
<span class="sd">            uses generic names like &#39;x0&#39;, &#39;x1&#39;, etc. Defaults to True.</span>
<span class="sd">        precision (int, optional): Number of decimal places for floating point values.</span>
<span class="sd">            Defaults to 4.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 1: Basic usage</span>
<span class="sd">        &gt;&gt;&gt; def sphere(X):</span>
<span class="sd">        ...     return np.sum(X**2, axis=1)</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=sphere,</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     var_name=[&quot;x1&quot;, &quot;x2&quot;],</span>
<span class="sd">        ...     max_iter=20,</span>
<span class="sd">        ...     n_initial=10</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; opt.print_best(result)</span>
<span class="sd">        &lt;BLANKLINE&gt;</span>
<span class="sd">        Best Solution Found:</span>
<span class="sd">        --------------------------------------------------</span>
<span class="sd">          x1: 0.0123</span>
<span class="sd">          x2: -0.0045</span>
<span class="sd">          Objective Value: 0.000173</span>
<span class="sd">          Total Evaluations: 20</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 2: With log-scale transformations (e.g., for learning rates)</span>
<span class="sd">        &gt;&gt;&gt; def objective(X):</span>
<span class="sd">        ...     # X[:, 0]: neurons (int), X[:, 1]: layers (int),</span>
<span class="sd">        ...     # X[:, 2]: log10(lr), X[:, 3]: log10(alpha)</span>
<span class="sd">        ...     return np.sum(X**2, axis=1)  # Placeholder</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=objective,</span>
<span class="sd">        ...     bounds=[(16, 128), (1, 4), (-3, 0), (-2, 1)],</span>
<span class="sd">        ...     var_type=[&quot;int&quot;, &quot;int&quot;, &quot;float&quot;, &quot;float&quot;],</span>
<span class="sd">        ...     var_name=[&quot;neurons&quot;, &quot;layers&quot;, &quot;log10_lr&quot;, &quot;log10_alpha&quot;],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # Transform log-scale parameters back to original scale</span>
<span class="sd">        &gt;&gt;&gt; transformations = [</span>
<span class="sd">        ...     int,              # neurons -&gt; int</span>
<span class="sd">        ...     int,              # layers -&gt; int</span>
<span class="sd">        ...     lambda x: 10**x,  # log10_lr -&gt; lr</span>
<span class="sd">        ...     lambda x: 10**x   # log10_alpha -&gt; alpha</span>
<span class="sd">        ... ]</span>
<span class="sd">        &gt;&gt;&gt; opt.print_best(result, transformations=transformations)</span>
<span class="sd">        &lt;BLANKLINE&gt;</span>
<span class="sd">        Best Solution Found:</span>
<span class="sd">        --------------------------------------------------</span>
<span class="sd">          neurons: 64</span>
<span class="sd">          layers: 2</span>
<span class="sd">          log10_lr: 0.0012</span>
<span class="sd">          log10_alpha: 0.0345</span>
<span class="sd">          Objective Value: 1.2345</span>
<span class="sd">          Total Evaluations: 30</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 3: Without result object (using stored values)</span>
<span class="sd">        &gt;&gt;&gt; opt.print_best()  # Uses opt.best_x_ and opt.best_y_</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 4: Hide variable names</span>
<span class="sd">        &gt;&gt;&gt; opt.print_best(result, show_name=False)</span>
<span class="sd">        &lt;BLANKLINE&gt;</span>
<span class="sd">        Best Solution Found:</span>
<span class="sd">        --------------------------------------------------</span>
<span class="sd">          x0: 0.0123</span>
<span class="sd">          x1: -0.0045</span>
<span class="sd">          Objective Value: 0.000173</span>
<span class="sd">          Total Evaluations: 20</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Get values from result or stored attributes</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">best_x</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>
        <span class="n">best_y</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span>
        <span class="n">n_evals</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">nfev</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No optimization results available. Run optimize() first.&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="n">best_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_x_</span>
        <span class="n">best_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_y_</span>
        <span class="n">n_evals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span>

    <span class="c1"># Expand to full dimensions if dimension reduction was applied</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
        <span class="n">best_x_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="n">best_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">best_x_full</span> <span class="o">=</span> <span class="n">best_x</span>

    <span class="c1"># Map factor variables back to original string values</span>
    <span class="n">best_x_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_to_factor_values</span><span class="p">(</span><span class="n">best_x_full</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Determine variable names to use</span>
    <span class="k">if</span> <span class="n">show_name</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">var_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_name</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">var_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">best_x_full</span><span class="p">))]</span>

    <span class="c1"># Validate transformations length</span>
    <span class="k">if</span> <span class="n">transformations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">transformations</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_x_full</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Length of transformations (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">transformations</span><span class="p">)</span><span class="si">}</span><span class="s2">) must match &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;number of dimensions (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">best_x_full</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">transformations</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_x_full</span><span class="p">)</span>

    <span class="c1"># Print header</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Solution Found:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

    <span class="c1"># Print each parameter</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
        <span class="nb">zip</span><span class="p">(</span><span class="n">var_names</span><span class="p">,</span> <span class="n">best_x_full</span><span class="p">,</span> <span class="n">transformations</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="c1"># Apply transformation if provided</span>
        <span class="k">if</span> <span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">display_value</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Transformation failed for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">display_value</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">display_value</span> <span class="o">=</span> <span class="n">value</span>

        <span class="c1"># Format based on variable type</span>
        <span class="n">var_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_var_type</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;float&quot;</span>

        <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">display_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">display_value</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">display_value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">display_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">display_value</span><span class="si">:</span><span class="s2">.</span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Print objective value and evaluations</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Objective Value: </span><span class="si">{</span><span class="n">best_y</span><span class="si">:</span><span class="s2">.</span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Total Evaluations: </span><span class="si">{</span><span class="n">n_evals</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.print_design_table" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">print_design_table</span><span class="p">(</span><span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;github&#39;</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.print_design_table" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Print (and return) a table showing the search space design before optimization.</p>
<p>This method calls <code>get_design_table</code> to generate the table string, prints it,
and then returns it.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tablefmt</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Table format for tabulate library.
Defaults to &lsquo;github&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;github&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>precision</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of decimal places for float values.
Defaults to 4.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>str</code></td>            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Formatted table string.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">6157</span>
<span class="normal">6158</span>
<span class="normal">6159</span>
<span class="normal">6160</span>
<span class="normal">6161</span>
<span class="normal">6162</span>
<span class="normal">6163</span>
<span class="normal">6164</span>
<span class="normal">6165</span>
<span class="normal">6166</span>
<span class="normal">6167</span>
<span class="normal">6168</span>
<span class="normal">6169</span>
<span class="normal">6170</span>
<span class="normal">6171</span>
<span class="normal">6172</span>
<span class="normal">6173</span>
<span class="normal">6174</span>
<span class="normal">6175</span>
<span class="normal">6176</span>
<span class="normal">6177</span>
<span class="normal">6178</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">print_design_table</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">tablefmt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;github&quot;</span><span class="p">,</span>
    <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Print (and return) a table showing the search space design before optimization.</span>

<span class="sd">    This method calls `get_design_table` to generate the table string, prints it,</span>
<span class="sd">    and then returns it.</span>

<span class="sd">    Args:</span>
<span class="sd">        tablefmt (str, optional): Table format for tabulate library.</span>
<span class="sd">            Defaults to &#39;github&#39;.</span>
<span class="sd">        precision (int, optional): Number of decimal places for float values.</span>
<span class="sd">            Defaults to 4.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: Formatted table string.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_design_table</span><span class="p">(</span><span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">table</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.print_results" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">print_results</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.print_results" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Alias for print_results_table for compatibility.
Prints the table.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">5953</span>
<span class="normal">5954</span>
<span class="normal">5955</span>
<span class="normal">5956</span>
<span class="normal">5957</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">print_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Alias for print_results_table for compatibility.</span>
<span class="sd">    Prints the table.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">print_results_table</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.print_results_table" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">print_results_table</span><span class="p">(</span><span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;github&#39;</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">show_importance</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.print_results_table" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Print (and return) a comprehensive table of optimization results.</p>
<p>This method calls <code>get_results_table</code> to generate the table string, prints it,
and then returns it.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tablefmt</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Table format. Defaults to &lsquo;github&rsquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;github&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>precision</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Decimal precision. Defaults to 4.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>show_importance</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Show importance column. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>*args</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Arguments passed to get_results_table.</p>
              </div>
            </td>
            <td>
                  <code>()</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Keyword arguments passed to get_results_table.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>str</code></td>            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Formatted table string.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">6124</span>
<span class="normal">6125</span>
<span class="normal">6126</span>
<span class="normal">6127</span>
<span class="normal">6128</span>
<span class="normal">6129</span>
<span class="normal">6130</span>
<span class="normal">6131</span>
<span class="normal">6132</span>
<span class="normal">6133</span>
<span class="normal">6134</span>
<span class="normal">6135</span>
<span class="normal">6136</span>
<span class="normal">6137</span>
<span class="normal">6138</span>
<span class="normal">6139</span>
<span class="normal">6140</span>
<span class="normal">6141</span>
<span class="normal">6142</span>
<span class="normal">6143</span>
<span class="normal">6144</span>
<span class="normal">6145</span>
<span class="normal">6146</span>
<span class="normal">6147</span>
<span class="normal">6148</span>
<span class="normal">6149</span>
<span class="normal">6150</span>
<span class="normal">6151</span>
<span class="normal">6152</span>
<span class="normal">6153</span>
<span class="normal">6154</span>
<span class="normal">6155</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">print_results_table</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">tablefmt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;github&quot;</span><span class="p">,</span>
    <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">show_importance</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Print (and return) a comprehensive table of optimization results.</span>

<span class="sd">    This method calls `get_results_table` to generate the table string, prints it,</span>
<span class="sd">    and then returns it.</span>

<span class="sd">    Args:</span>
<span class="sd">        tablefmt (str, optional): Table format. Defaults to &#39;github&#39;.</span>
<span class="sd">        precision (int, optional): Decimal precision. Defaults to 4.</span>
<span class="sd">        show_importance (bool, optional): Show importance column. Defaults to False.</span>
<span class="sd">        *args: Arguments passed to get_results_table.</span>
<span class="sd">        **kwargs: Keyword arguments passed to get_results_table.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: Formatted table string.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_results_table</span><span class="p">(</span>
        <span class="n">tablefmt</span><span class="o">=</span><span class="n">tablefmt</span><span class="p">,</span>
        <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span>
        <span class="n">show_importance</span><span class="o">=</span><span class="n">show_importance</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">table</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.process_factor_bounds" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">process_factor_bounds</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.process_factor_bounds" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Process bounds to handle factor variables.</p>
<p>For dimensions with tuple bounds (factor variables), creates internal
integer mappings and replaces bounds with (0, n_levels-1).</p>
<p>Stores mappings in self._factor_maps: {dim_idx: {int_val: str_val}}</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If bounds are invalidly formatted.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">process_factor_bounds</span><span class="p">()</span>
<span class="go">Factor variable at dimension 0:</span>
<span class="go">  Levels: [&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;]</span>
<span class="go">  Mapped to integers: 0 to 2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">spot</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span>
<span class="go">[(0, 2), (0, 10)]</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">process_factor_bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Process bounds to handle factor variables.</span>

<span class="sd">    For dimensions with tuple bounds (factor variables), creates internal</span>
<span class="sd">    integer mappings and replaces bounds with (0, n_levels-1).</span>

<span class="sd">    Stores mappings in self._factor_maps: {dim_idx: {int_val: str_val}}</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If bounds are invalidly formatted.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;), (0, 10)])</span>
<span class="sd">        &gt;&gt;&gt; spot.process_factor_bounds()</span>
<span class="sd">        Factor variable at dimension 0:</span>
<span class="sd">          Levels: [&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;]</span>
<span class="sd">          Mapped to integers: 0 to 2</span>
<span class="sd">        &gt;&gt;&gt; print(spot.bounds)</span>
<span class="sd">        [(0, 2), (0, 10)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">processed_bounds</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">dim_idx</span><span class="p">,</span> <span class="n">bound</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bound</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">bound</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Check if this is a factor variable (contains strings)</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">bound</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">bound</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Factor variable: create integer mapping</span>
                <span class="n">factor_levels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">bound</span><span class="p">)</span>
                <span class="n">n_levels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">factor_levels</span><span class="p">)</span>

                <span class="c1"># Create mapping: {0: &quot;level1&quot;, 1: &quot;level2&quot;, ...}</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_factor_maps</span><span class="p">[</span><span class="n">dim_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">i</span><span class="p">:</span> <span class="n">level</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">level</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">factor_levels</span><span class="p">)</span>
                <span class="p">}</span>

                <span class="c1"># Replace with integer bounds (use Python int, not numpy types)</span>
                <span class="n">processed_bounds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_levels</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Factor variable at dimension </span><span class="si">{</span><span class="n">dim_idx</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Levels: </span><span class="si">{</span><span class="n">factor_levels</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mapped to integers: 0 to </span><span class="si">{</span><span class="n">n_levels</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">bound</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">))</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">bound</span>
            <span class="p">):</span>
                <span class="c1"># Numeric bound tuple (accepts Python and numpy numeric types)</span>
                <span class="c1"># Always cast to Python float/int</span>
                <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">bound</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="n">bound</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

                <span class="c1"># Convert to int if both are integer-valued</span>
                <span class="k">if</span> <span class="n">low</span><span class="o">.</span><span class="n">is_integer</span><span class="p">()</span> <span class="ow">and</span> <span class="n">high</span><span class="o">.</span><span class="n">is_integer</span><span class="p">():</span>
                    <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">low</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">high</span><span class="p">)</span>

                <span class="n">processed_bounds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Invalid bound at dimension </span><span class="si">{</span><span class="n">dim_idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">bound</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected either (lower, upper) for numeric variables or &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;tuple of strings for factor variables.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Invalid bound at dimension </span><span class="si">{</span><span class="n">dim_idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">bound</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Expected a tuple/list with at least 1 element.&quot;</span>
            <span class="p">)</span>

    <span class="c1"># Update bounds with processed values</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="n">processed_bounds</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.save_experiment" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_experiment</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;experiment&#39;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unpickleables</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.save_experiment" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the experiment configuration to a pickle file.</p>
<p>An experiment contains the optimizer configuration needed to run optimization,
but excludes the results. This is useful for defining experiments locally and
executing them on remote machines.</p>
<p>The experiment includes:
- Bounds, variable types, variable names
- Optimization parameters (max_iter, n_initial, etc.)
- Surrogate and acquisition settings
- Random seed</p>
<p>The experiment excludes:
- Function evaluations (X_, y_)
- Optimization results</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>filename</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Filename for the experiment file. If None, generates
from prefix. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prefix</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Prefix for auto-generated filename. Defaults to &ldquo;experiment&rdquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;experiment&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Directory path to save the file. If None, saves in current
directory. Creates directory if it doesn&rsquo;t exist. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>overwrite</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, overwrites existing file. If False, raises error if
file exists. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>unpickleables</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Components to exclude for pickling:
- &ldquo;all&rdquo;: Excludes surrogate, lhs_sampler, tb_writer (experiment only)
- &ldquo;file_io&rdquo;: Excludes only tb_writer (lighter exclusion)
Defaults to &ldquo;all&rdquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;all&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbosity</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Define experiment locally</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Save experiment (without results)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">save_experiment</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;sphere_opt&quot;</span><span class="p">)</span>
<span class="go">Experiment saved to sphere_opt_exp.pkl</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># On remote machine: load and run</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt_remote = SpotOptim.load_experiment(&quot;sphere_opt_exp.pkl&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result = opt_remote.optimize()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt_remote.save_result(prefix=&quot;sphere_opt&quot;)  # Save results</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">5768</span>
<span class="normal">5769</span>
<span class="normal">5770</span>
<span class="normal">5771</span>
<span class="normal">5772</span>
<span class="normal">5773</span>
<span class="normal">5774</span>
<span class="normal">5775</span>
<span class="normal">5776</span>
<span class="normal">5777</span>
<span class="normal">5778</span>
<span class="normal">5779</span>
<span class="normal">5780</span>
<span class="normal">5781</span>
<span class="normal">5782</span>
<span class="normal">5783</span>
<span class="normal">5784</span>
<span class="normal">5785</span>
<span class="normal">5786</span>
<span class="normal">5787</span>
<span class="normal">5788</span>
<span class="normal">5789</span>
<span class="normal">5790</span>
<span class="normal">5791</span>
<span class="normal">5792</span>
<span class="normal">5793</span>
<span class="normal">5794</span>
<span class="normal">5795</span>
<span class="normal">5796</span>
<span class="normal">5797</span>
<span class="normal">5798</span>
<span class="normal">5799</span>
<span class="normal">5800</span>
<span class="normal">5801</span>
<span class="normal">5802</span>
<span class="normal">5803</span>
<span class="normal">5804</span>
<span class="normal">5805</span>
<span class="normal">5806</span>
<span class="normal">5807</span>
<span class="normal">5808</span>
<span class="normal">5809</span>
<span class="normal">5810</span>
<span class="normal">5811</span>
<span class="normal">5812</span>
<span class="normal">5813</span>
<span class="normal">5814</span>
<span class="normal">5815</span>
<span class="normal">5816</span>
<span class="normal">5817</span>
<span class="normal">5818</span>
<span class="normal">5819</span>
<span class="normal">5820</span>
<span class="normal">5821</span>
<span class="normal">5822</span>
<span class="normal">5823</span>
<span class="normal">5824</span>
<span class="normal">5825</span>
<span class="normal">5826</span>
<span class="normal">5827</span>
<span class="normal">5828</span>
<span class="normal">5829</span>
<span class="normal">5830</span>
<span class="normal">5831</span>
<span class="normal">5832</span>
<span class="normal">5833</span>
<span class="normal">5834</span>
<span class="normal">5835</span>
<span class="normal">5836</span>
<span class="normal">5837</span>
<span class="normal">5838</span>
<span class="normal">5839</span>
<span class="normal">5840</span>
<span class="normal">5841</span>
<span class="normal">5842</span>
<span class="normal">5843</span>
<span class="normal">5844</span>
<span class="normal">5845</span>
<span class="normal">5846</span>
<span class="normal">5847</span>
<span class="normal">5848</span>
<span class="normal">5849</span>
<span class="normal">5850</span>
<span class="normal">5851</span>
<span class="normal">5852</span>
<span class="normal">5853</span>
<span class="normal">5854</span>
<span class="normal">5855</span>
<span class="normal">5856</span>
<span class="normal">5857</span>
<span class="normal">5858</span>
<span class="normal">5859</span>
<span class="normal">5860</span>
<span class="normal">5861</span>
<span class="normal">5862</span>
<span class="normal">5863</span>
<span class="normal">5864</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_experiment</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;experiment&quot;</span><span class="p">,</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">unpickleables</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span><span class="p">,</span>
    <span class="n">verbosity</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save the experiment configuration to a pickle file.</span>

<span class="sd">    An experiment contains the optimizer configuration needed to run optimization,</span>
<span class="sd">    but excludes the results. This is useful for defining experiments locally and</span>
<span class="sd">    executing them on remote machines.</span>

<span class="sd">    The experiment includes:</span>
<span class="sd">    - Bounds, variable types, variable names</span>
<span class="sd">    - Optimization parameters (max_iter, n_initial, etc.)</span>
<span class="sd">    - Surrogate and acquisition settings</span>
<span class="sd">    - Random seed</span>

<span class="sd">    The experiment excludes:</span>
<span class="sd">    - Function evaluations (X_, y_)</span>
<span class="sd">    - Optimization results</span>


<span class="sd">    Args:</span>
<span class="sd">        filename (str, optional): Filename for the experiment file. If None, generates</span>
<span class="sd">            from prefix. Defaults to None.</span>
<span class="sd">        prefix (str): Prefix for auto-generated filename. Defaults to &quot;experiment&quot;.</span>
<span class="sd">        path (str, optional): Directory path to save the file. If None, saves in current</span>
<span class="sd">            directory. Creates directory if it doesn&#39;t exist. Defaults to None.</span>
<span class="sd">        overwrite (bool): If True, overwrites existing file. If False, raises error if</span>
<span class="sd">            file exists. Defaults to True.</span>
<span class="sd">        unpickleables (str): Components to exclude for pickling:</span>
<span class="sd">            - &quot;all&quot;: Excludes surrogate, lhs_sampler, tb_writer (experiment only)</span>
<span class="sd">            - &quot;file_io&quot;: Excludes only tb_writer (lighter exclusion)</span>
<span class="sd">            Defaults to &quot;all&quot;.</span>
<span class="sd">        verbosity (int): Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Define experiment locally</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     seed=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Save experiment (without results)</span>
<span class="sd">        &gt;&gt;&gt; opt.save_experiment(prefix=&quot;sphere_opt&quot;)</span>
<span class="sd">        Experiment saved to sphere_opt_exp.pkl</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # On remote machine: load and run</span>
<span class="sd">        &gt;&gt;&gt; # opt_remote = SpotOptim.load_experiment(&quot;sphere_opt_exp.pkl&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # result = opt_remote.optimize()</span>
<span class="sd">        &gt;&gt;&gt; # opt_remote.save_result(prefix=&quot;sphere_opt&quot;)  # Save results</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Close TensorBoard writer before pickling</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_close_and_del_tensorboard_writer</span><span class="p">()</span>

    <span class="c1"># Create pickle-safe copy</span>
    <span class="n">optimizer_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_pickle_safe_optimizer</span><span class="p">(</span>
        <span class="n">unpickleables</span><span class="o">=</span><span class="n">unpickleables</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="n">verbosity</span>
    <span class="p">)</span>

    <span class="c1"># Determine filename</span>
    <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_experiment_filename</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>

    <span class="c1"># Add path if provided</span>
    <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

    <span class="c1"># Check for existing file</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">overwrite</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">FileExistsError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;File </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2"> already exists. Use overwrite=True to overwrite.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Save to pickle file</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
            <span class="n">dill</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">optimizer_copy</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">dill</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment saved to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error during pickling: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.save_result" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_result</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;result&#39;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.save_result" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the complete optimization results to a pickle file.</p>
<p>A result contains all information from a completed optimization run, including
the experiment configuration and all evaluation results. This is useful for
saving completed runs for later analysis.</p>
<p>The result includes everything in an experiment plus:
- All evaluated points (X_)
- All function values (y_)
- Best point and best value
- Iteration count
- Success rate statistics
- Noise statistics (if applicable)</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>filename</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Filename for the result file. If None, generates
from prefix. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prefix</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Prefix for auto-generated filename. Defaults to &ldquo;result&rdquo;.</p>
              </div>
            </td>
            <td>
                  <code>&#39;result&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Directory path to save the file. If None, saves in current
directory. Creates directory if it doesn&rsquo;t exist. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>overwrite</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, overwrites existing file. If False, raises error if
file exists. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbosity</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Run optimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Save complete results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">save_result</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;sphere_opt&quot;</span><span class="p">)</span>
<span class="go">Result saved to sphere_opt_res.pkl</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Later: load and analyze</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt_loaded = SpotOptim.load_result(&quot;sphere_opt_res.pkl&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print(&quot;Best value:&quot;, opt_loaded.best_y_)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># opt_loaded.plot_surrogate()</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">5640</span>
<span class="normal">5641</span>
<span class="normal">5642</span>
<span class="normal">5643</span>
<span class="normal">5644</span>
<span class="normal">5645</span>
<span class="normal">5646</span>
<span class="normal">5647</span>
<span class="normal">5648</span>
<span class="normal">5649</span>
<span class="normal">5650</span>
<span class="normal">5651</span>
<span class="normal">5652</span>
<span class="normal">5653</span>
<span class="normal">5654</span>
<span class="normal">5655</span>
<span class="normal">5656</span>
<span class="normal">5657</span>
<span class="normal">5658</span>
<span class="normal">5659</span>
<span class="normal">5660</span>
<span class="normal">5661</span>
<span class="normal">5662</span>
<span class="normal">5663</span>
<span class="normal">5664</span>
<span class="normal">5665</span>
<span class="normal">5666</span>
<span class="normal">5667</span>
<span class="normal">5668</span>
<span class="normal">5669</span>
<span class="normal">5670</span>
<span class="normal">5671</span>
<span class="normal">5672</span>
<span class="normal">5673</span>
<span class="normal">5674</span>
<span class="normal">5675</span>
<span class="normal">5676</span>
<span class="normal">5677</span>
<span class="normal">5678</span>
<span class="normal">5679</span>
<span class="normal">5680</span>
<span class="normal">5681</span>
<span class="normal">5682</span>
<span class="normal">5683</span>
<span class="normal">5684</span>
<span class="normal">5685</span>
<span class="normal">5686</span>
<span class="normal">5687</span>
<span class="normal">5688</span>
<span class="normal">5689</span>
<span class="normal">5690</span>
<span class="normal">5691</span>
<span class="normal">5692</span>
<span class="normal">5693</span>
<span class="normal">5694</span>
<span class="normal">5695</span>
<span class="normal">5696</span>
<span class="normal">5697</span>
<span class="normal">5698</span>
<span class="normal">5699</span>
<span class="normal">5700</span>
<span class="normal">5701</span>
<span class="normal">5702</span>
<span class="normal">5703</span>
<span class="normal">5704</span>
<span class="normal">5705</span>
<span class="normal">5706</span>
<span class="normal">5707</span>
<span class="normal">5708</span>
<span class="normal">5709</span>
<span class="normal">5710</span>
<span class="normal">5711</span>
<span class="normal">5712</span>
<span class="normal">5713</span>
<span class="normal">5714</span>
<span class="normal">5715</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_result</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;result&quot;</span><span class="p">,</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">verbosity</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save the complete optimization results to a pickle file.</span>

<span class="sd">    A result contains all information from a completed optimization run, including</span>
<span class="sd">    the experiment configuration and all evaluation results. This is useful for</span>
<span class="sd">    saving completed runs for later analysis.</span>

<span class="sd">    The result includes everything in an experiment plus:</span>
<span class="sd">    - All evaluated points (X_)</span>
<span class="sd">    - All function values (y_)</span>
<span class="sd">    - Best point and best value</span>
<span class="sd">    - Iteration count</span>
<span class="sd">    - Success rate statistics</span>
<span class="sd">    - Noise statistics (if applicable)</span>

<span class="sd">    Args:</span>
<span class="sd">        filename (str, optional): Filename for the result file. If None, generates</span>
<span class="sd">            from prefix. Defaults to None.</span>
<span class="sd">        prefix (str): Prefix for auto-generated filename. Defaults to &quot;result&quot;.</span>
<span class="sd">        path (str, optional): Directory path to save the file. If None, saves in current</span>
<span class="sd">            directory. Creates directory if it doesn&#39;t exist. Defaults to None.</span>
<span class="sd">        overwrite (bool): If True, overwrites existing file. If False, raises error if</span>
<span class="sd">            file exists. Defaults to True.</span>
<span class="sd">        verbosity (int): Verbosity level (0=silent, 1=basic, 2=detailed). Defaults to 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Run optimization</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     max_iter=30,</span>
<span class="sd">        ...     n_initial=10,</span>
<span class="sd">        ...     seed=42</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Save complete results</span>
<span class="sd">        &gt;&gt;&gt; opt.save_result(prefix=&quot;sphere_opt&quot;)</span>
<span class="sd">        Result saved to sphere_opt_res.pkl</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Later: load and analyze</span>
<span class="sd">        &gt;&gt;&gt; # opt_loaded = SpotOptim.load_result(&quot;sphere_opt_res.pkl&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # print(&quot;Best value:&quot;, opt_loaded.best_y_)</span>
<span class="sd">        &gt;&gt;&gt; # opt_loaded.plot_surrogate()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Use save_experiment with file_io unpickleables to preserve results</span>
    <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_result_filename</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">save_experiment</span><span class="p">(</span>
        <span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span>
        <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
        <span class="n">overwrite</span><span class="o">=</span><span class="n">overwrite</span><span class="p">,</span>
        <span class="n">unpickleables</span><span class="o">=</span><span class="s2">&quot;file_io&quot;</span><span class="p">,</span>
        <span class="n">verbosity</span><span class="o">=</span><span class="n">verbosity</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Update message</span>
    <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">full_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">full_path</span> <span class="o">=</span> <span class="n">filename</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result saved to </span><span class="si">{</span><span class="n">full_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.select_new" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">select_new</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.select_new" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Select rows from A that are not in X.
Used in suggest_next_infill_point() to avoid duplicate evaluations.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>A</code>
            </td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Array with new values.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>X</code>
            </td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Array with known values.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tolerance value for comparison. Defaults to 0.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>tuple</code></td>            <td>
                  <code><span title="typing.Tuple">Tuple</span>[<span title="numpy.ndarray">ndarray</span>, <span title="numpy.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A tuple containing:
- ndarray: Array with unknown (new) values.
- ndarray: Array with True if value is new, otherwise False.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_A</span><span class="p">,</span> <span class="n">is_new</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">select_new</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New A:&quot;</span><span class="p">,</span> <span class="n">new_A</span><span class="p">)</span>
<span class="go">New A: [[1 2]</span>
<span class="go"> [5 6]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Is new:&quot;</span><span class="p">,</span> <span class="n">is_new</span><span class="p">)</span>
<span class="go">Is new: [ True False  True]</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">3744</span>
<span class="normal">3745</span>
<span class="normal">3746</span>
<span class="normal">3747</span>
<span class="normal">3748</span>
<span class="normal">3749</span>
<span class="normal">3750</span>
<span class="normal">3751</span>
<span class="normal">3752</span>
<span class="normal">3753</span>
<span class="normal">3754</span>
<span class="normal">3755</span>
<span class="normal">3756</span>
<span class="normal">3757</span>
<span class="normal">3758</span>
<span class="normal">3759</span>
<span class="normal">3760</span>
<span class="normal">3761</span>
<span class="normal">3762</span>
<span class="normal">3763</span>
<span class="normal">3764</span>
<span class="normal">3765</span>
<span class="normal">3766</span>
<span class="normal">3767</span>
<span class="normal">3768</span>
<span class="normal">3769</span>
<span class="normal">3770</span>
<span class="normal">3771</span>
<span class="normal">3772</span>
<span class="normal">3773</span>
<span class="normal">3774</span>
<span class="normal">3775</span>
<span class="normal">3776</span>
<span class="normal">3777</span>
<span class="normal">3778</span>
<span class="normal">3779</span>
<span class="normal">3780</span>
<span class="normal">3781</span>
<span class="normal">3782</span>
<span class="normal">3783</span>
<span class="normal">3784</span>
<span class="normal">3785</span>
<span class="normal">3786</span>
<span class="normal">3787</span>
<span class="normal">3788</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">select_new</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Select rows from A that are not in X.</span>
<span class="sd">    Used in suggest_next_infill_point() to avoid duplicate evaluations.</span>

<span class="sd">    Args:</span>
<span class="sd">        A (ndarray): Array with new values.</span>
<span class="sd">        X (ndarray): Array with known values.</span>
<span class="sd">        tolerance (float, optional): Tolerance value for comparison. Defaults to 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: A tuple containing:</span>
<span class="sd">            - ndarray: Array with unknown (new) values.</span>
<span class="sd">            - ndarray: Array with True if value is new, otherwise False.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1), bounds=[(-5, 5)])</span>
<span class="sd">        &gt;&gt;&gt; A = np.array([[1, 2], [3, 4], [5, 6]])</span>
<span class="sd">        &gt;&gt;&gt; X = np.array([[3, 4], [7, 8]])</span>
<span class="sd">        &gt;&gt;&gt; new_A, is_new = opt.select_new(A, X)</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;New A:&quot;, new_A)</span>
<span class="sd">        New A: [[1 2]</span>
<span class="sd">         [5 6]]</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Is new:&quot;, is_new)</span>
<span class="sd">        Is new: [ True False  True]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>

    <span class="c1"># Calculate distances using the configured metric</span>
    <span class="c1"># cdist supports &#39;euclidean&#39;, &#39;minkowski&#39;, &#39;chebyshev&#39;, etc.</span>
    <span class="c1"># Note: &#39;chebyshev&#39; is closest to the previous logic but checks absolute difference on all coords</span>
    <span class="c1"># Previous logic: np.all(np.abs(diff) &lt;= tolerance) -&gt; Chebyshev &lt;= tolerance</span>
    <span class="n">dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_tol_metric</span><span class="p">)</span>

    <span class="c1"># Check if min distance to any existing point is &lt;= tolerance (duplicate)</span>
    <span class="c1"># Duplicate if ANY existing point is within tolerance</span>
    <span class="c1"># is_duplicate[i] is True if A[i] is close to at least one point in X</span>
    <span class="n">is_duplicate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">dists</span> <span class="o">&lt;=</span> <span class="n">tolerance</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">ind</span> <span class="o">=</span> <span class="n">is_duplicate</span>
    <span class="k">return</span> <span class="n">A</span><span class="p">[</span><span class="o">~</span><span class="n">ind</span><span class="p">],</span> <span class="o">~</span><span class="n">ind</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.sensitivity_spearman" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sensitivity_spearman</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.sensitivity_spearman" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Compute and print Spearman correlation between parameters and objective values.</p>
<p>This method analyzes the sensitivity of the objective function to each
hyperparameter by computing Spearman rank correlations. For categorical
(factor) variables, correlation is not computed as they require visual
inspection instead.</p>
<p>The method automatically handles different parameter types:
- Integer/float parameters: Direct correlation with objective values
- Log-transformed parameters (log10, log, ln): Correlation in log-space
- Factor (categorical) parameters: Skipped with informative message</p>
<p>Significance levels:
- <em><strong>: p &lt; 0.001 (highly significant)
- </strong>: p &lt; 0.01 (significant)
- </em>: p &lt; 0.05 (marginally significant)</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># After running optimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">sensitivity_spearman</span><span class="p">()</span>
<span class="go">Sensitivity Analysis (Spearman Correlation):</span>
<span class="go">--------------------------------------------------</span>
<span class="go">  l1 (neurons)        : +0.005 (p=0.959)</span>
<span class="go">  num_layers          : -0.192 (p=0.056)</span>
<span class="go">  activation          : (categorical variable, use visual inspection)</span>
<span class="go">  lr_unified          : -0.040 (p=0.689)</span>
<span class="go">  alpha               : -0.233 (p=0.020) *</span>
</code></pre></div>


<details class="note" open>
  <summary>Note</summary>
  <p>Requires scipy to be installed. If not available, raises ImportError.
Only meaningful after optimize() has been called with sufficient evaluations.</p>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">6659</span>
<span class="normal">6660</span>
<span class="normal">6661</span>
<span class="normal">6662</span>
<span class="normal">6663</span>
<span class="normal">6664</span>
<span class="normal">6665</span>
<span class="normal">6666</span>
<span class="normal">6667</span>
<span class="normal">6668</span>
<span class="normal">6669</span>
<span class="normal">6670</span>
<span class="normal">6671</span>
<span class="normal">6672</span>
<span class="normal">6673</span>
<span class="normal">6674</span>
<span class="normal">6675</span>
<span class="normal">6676</span>
<span class="normal">6677</span>
<span class="normal">6678</span>
<span class="normal">6679</span>
<span class="normal">6680</span>
<span class="normal">6681</span>
<span class="normal">6682</span>
<span class="normal">6683</span>
<span class="normal">6684</span>
<span class="normal">6685</span>
<span class="normal">6686</span>
<span class="normal">6687</span>
<span class="normal">6688</span>
<span class="normal">6689</span>
<span class="normal">6690</span>
<span class="normal">6691</span>
<span class="normal">6692</span>
<span class="normal">6693</span>
<span class="normal">6694</span>
<span class="normal">6695</span>
<span class="normal">6696</span>
<span class="normal">6697</span>
<span class="normal">6698</span>
<span class="normal">6699</span>
<span class="normal">6700</span>
<span class="normal">6701</span>
<span class="normal">6702</span>
<span class="normal">6703</span>
<span class="normal">6704</span>
<span class="normal">6705</span>
<span class="normal">6706</span>
<span class="normal">6707</span>
<span class="normal">6708</span>
<span class="normal">6709</span>
<span class="normal">6710</span>
<span class="normal">6711</span>
<span class="normal">6712</span>
<span class="normal">6713</span>
<span class="normal">6714</span>
<span class="normal">6715</span>
<span class="normal">6716</span>
<span class="normal">6717</span>
<span class="normal">6718</span>
<span class="normal">6719</span>
<span class="normal">6720</span>
<span class="normal">6721</span>
<span class="normal">6722</span>
<span class="normal">6723</span>
<span class="normal">6724</span>
<span class="normal">6725</span>
<span class="normal">6726</span>
<span class="normal">6727</span>
<span class="normal">6728</span>
<span class="normal">6729</span>
<span class="normal">6730</span>
<span class="normal">6731</span>
<span class="normal">6732</span>
<span class="normal">6733</span>
<span class="normal">6734</span>
<span class="normal">6735</span>
<span class="normal">6736</span>
<span class="normal">6737</span>
<span class="normal">6738</span>
<span class="normal">6739</span>
<span class="normal">6740</span>
<span class="normal">6741</span>
<span class="normal">6742</span>
<span class="normal">6743</span>
<span class="normal">6744</span>
<span class="normal">6745</span>
<span class="normal">6746</span>
<span class="normal">6747</span>
<span class="normal">6748</span>
<span class="normal">6749</span>
<span class="normal">6750</span>
<span class="normal">6751</span>
<span class="normal">6752</span>
<span class="normal">6753</span>
<span class="normal">6754</span>
<span class="normal">6755</span>
<span class="normal">6756</span>
<span class="normal">6757</span>
<span class="normal">6758</span>
<span class="normal">6759</span>
<span class="normal">6760</span>
<span class="normal">6761</span>
<span class="normal">6762</span>
<span class="normal">6763</span>
<span class="normal">6764</span>
<span class="normal">6765</span>
<span class="normal">6766</span>
<span class="normal">6767</span>
<span class="normal">6768</span>
<span class="normal">6769</span>
<span class="normal">6770</span>
<span class="normal">6771</span>
<span class="normal">6772</span>
<span class="normal">6773</span>
<span class="normal">6774</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">sensitivity_spearman</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute and print Spearman correlation between parameters and objective values.</span>

<span class="sd">    This method analyzes the sensitivity of the objective function to each</span>
<span class="sd">    hyperparameter by computing Spearman rank correlations. For categorical</span>
<span class="sd">    (factor) variables, correlation is not computed as they require visual</span>
<span class="sd">    inspection instead.</span>

<span class="sd">    The method automatically handles different parameter types:</span>
<span class="sd">    - Integer/float parameters: Direct correlation with objective values</span>
<span class="sd">    - Log-transformed parameters (log10, log, ln): Correlation in log-space</span>
<span class="sd">    - Factor (categorical) parameters: Skipped with informative message</span>

<span class="sd">    Significance levels:</span>
<span class="sd">    - ***: p &lt; 0.001 (highly significant)</span>
<span class="sd">    - **: p &lt; 0.01 (significant)</span>
<span class="sd">    - *: p &lt; 0.05 (marginally significant)</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # After running optimization</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(...)</span>
<span class="sd">        &gt;&gt;&gt; result = opt.optimize()</span>
<span class="sd">        &gt;&gt;&gt; opt.sensitivity_spearman()</span>
<span class="sd">        Sensitivity Analysis (Spearman Correlation):</span>
<span class="sd">        --------------------------------------------------</span>
<span class="sd">          l1 (neurons)        : +0.005 (p=0.959)</span>
<span class="sd">          num_layers          : -0.192 (p=0.056)</span>
<span class="sd">          activation          : (categorical variable, use visual inspection)</span>
<span class="sd">          lr_unified          : -0.040 (p=0.689)</span>
<span class="sd">          alpha               : -0.233 (p=0.020) *</span>

<span class="sd">    Note:</span>
<span class="sd">        Requires scipy to be installed. If not available, raises ImportError.</span>
<span class="sd">        Only meaningful after optimize() has been called with sufficient evaluations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">spearmanr</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
            <span class="s2">&quot;scipy is required for sensitivity_spearman(). &quot;</span>
            <span class="s2">&quot;Install it with: pip install scipy&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No optimization data available. Run optimize() first.&quot;</span><span class="p">)</span>

    <span class="c1"># Get optimization history and parameters</span>
    <span class="n">history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span>
    <span class="n">all_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span>

    <span class="c1"># Get parameter names</span>
    <span class="n">param_names</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_name</span> <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">)]</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sensitivity Analysis (Spearman Correlation):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">param_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dim</span><span class="p">):</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">param_names</span><span class="p">[</span><span class="n">param_idx</span><span class="p">]</span>
        <span class="n">param_values</span> <span class="o">=</span> <span class="n">all_params</span><span class="p">[:,</span> <span class="n">param_idx</span><span class="p">]</span>

        <span class="c1"># Check if it&#39;s a factor variable</span>
        <span class="n">var_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">param_idx</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span> <span class="k">else</span> <span class="s2">&quot;float&quot;</span>

        <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span><span class="p">:</span>
            <span class="c1"># For categorical variables, skip correlation</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: (categorical variable, use visual inspection)&quot;</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="c1"># Check if parameter has log transformation</span>
        <span class="n">var_trans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">[</span><span class="n">param_idx</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="c1"># Compute correlation based on transformation</span>
        <span class="k">if</span> <span class="n">var_trans</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;log10&quot;</span><span class="p">,</span> <span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="s2">&quot;ln&quot;</span><span class="p">]:</span>
            <span class="c1"># For log-transformed parameters, use log-space correlation</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">param_values_numeric</span> <span class="o">=</span> <span class="n">param_values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
                <span class="c1"># Filter out non-positive values</span>
                <span class="n">valid_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">param_values_numeric</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">history</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">valid_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: (insufficient valid data for log correlation)&quot;</span>
                    <span class="p">)</span>
                    <span class="k">continue</span>

                <span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">param_values_numeric</span><span class="p">[</span><span class="n">valid_mask</span><span class="p">]),</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="n">valid_mask</span><span class="p">]),</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: (error computing log correlation)&quot;</span><span class="p">)</span>
                <span class="k">continue</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For integer/float parameters, direct correlation</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">param_values_numeric</span> <span class="o">=</span> <span class="n">param_values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
                <span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">param_values_numeric</span><span class="p">,</span> <span class="n">history</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: (error computing correlation)&quot;</span><span class="p">)</span>
                <span class="k">continue</span>

        <span class="c1"># Determine significance level</span>
        <span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.001</span><span class="p">:</span>
            <span class="n">significance</span> <span class="o">=</span> <span class="s2">&quot; ***&quot;</span>
        <span class="k">elif</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">:</span>
            <span class="n">significance</span> <span class="o">=</span> <span class="s2">&quot; **&quot;</span>
        <span class="k">elif</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
            <span class="n">significance</span> <span class="o">=</span> <span class="s2">&quot; *&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">significance</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">corr</span><span class="si">:</span><span class="s2">+.3f</span><span class="si">}</span><span class="s2"> (p=</span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)</span><span class="si">{</span><span class="n">significance</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.suggest_next_infill_point" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">suggest_next_infill_point</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.suggest_next_infill_point" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Suggest next point to evaluate (dispatcher).</p>
<p>The returned point is in the <strong>Transformed and Mapped Space</strong> (Internal Optimization Space).
This means:
1. Transformations (e.g., log, sqrt) have been applied.
2. Dimension reduction has been applied (fixed variables removed).</p>
<p>Process:
1. Try candidates from acquisition function optimizer.
2. Handle acquisition failure (fallback).
3. Return last attempt if all fails.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ndarray</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Next point(s) to evaluate in <strong>Transformed and Mapped Space</strong>.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Shape is (n_infill_points, n_features).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_infill_points</span><span class="o">=</span><span class="mi">2</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Need to initialize optimization state (X_, y_, surrogate)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Normally done inside optimize()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">_fit_surrogate</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_next</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">suggest_next_infill_point</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_next</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 2)</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">4757</span>
<span class="normal">4758</span>
<span class="normal">4759</span>
<span class="normal">4760</span>
<span class="normal">4761</span>
<span class="normal">4762</span>
<span class="normal">4763</span>
<span class="normal">4764</span>
<span class="normal">4765</span>
<span class="normal">4766</span>
<span class="normal">4767</span>
<span class="normal">4768</span>
<span class="normal">4769</span>
<span class="normal">4770</span>
<span class="normal">4771</span>
<span class="normal">4772</span>
<span class="normal">4773</span>
<span class="normal">4774</span>
<span class="normal">4775</span>
<span class="normal">4776</span>
<span class="normal">4777</span>
<span class="normal">4778</span>
<span class="normal">4779</span>
<span class="normal">4780</span>
<span class="normal">4781</span>
<span class="normal">4782</span>
<span class="normal">4783</span>
<span class="normal">4784</span>
<span class="normal">4785</span>
<span class="normal">4786</span>
<span class="normal">4787</span>
<span class="normal">4788</span>
<span class="normal">4789</span>
<span class="normal">4790</span>
<span class="normal">4791</span>
<span class="normal">4792</span>
<span class="normal">4793</span>
<span class="normal">4794</span>
<span class="normal">4795</span>
<span class="normal">4796</span>
<span class="normal">4797</span>
<span class="normal">4798</span>
<span class="normal">4799</span>
<span class="normal">4800</span>
<span class="normal">4801</span>
<span class="normal">4802</span>
<span class="normal">4803</span>
<span class="normal">4804</span>
<span class="normal">4805</span>
<span class="normal">4806</span>
<span class="normal">4807</span>
<span class="normal">4808</span>
<span class="normal">4809</span>
<span class="normal">4810</span>
<span class="normal">4811</span>
<span class="normal">4812</span>
<span class="normal">4813</span>
<span class="normal">4814</span>
<span class="normal">4815</span>
<span class="normal">4816</span>
<span class="normal">4817</span>
<span class="normal">4818</span>
<span class="normal">4819</span>
<span class="normal">4820</span>
<span class="normal">4821</span>
<span class="normal">4822</span>
<span class="normal">4823</span>
<span class="normal">4824</span>
<span class="normal">4825</span>
<span class="normal">4826</span>
<span class="normal">4827</span>
<span class="normal">4828</span>
<span class="normal">4829</span>
<span class="normal">4830</span>
<span class="normal">4831</span>
<span class="normal">4832</span>
<span class="normal">4833</span>
<span class="normal">4834</span>
<span class="normal">4835</span>
<span class="normal">4836</span>
<span class="normal">4837</span>
<span class="normal">4838</span>
<span class="normal">4839</span>
<span class="normal">4840</span>
<span class="normal">4841</span>
<span class="normal">4842</span>
<span class="normal">4843</span>
<span class="normal">4844</span>
<span class="normal">4845</span>
<span class="normal">4846</span>
<span class="normal">4847</span>
<span class="normal">4848</span>
<span class="normal">4849</span>
<span class="normal">4850</span>
<span class="normal">4851</span>
<span class="normal">4852</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">suggest_next_infill_point</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Suggest next point to evaluate (dispatcher).</span>

<span class="sd">    The returned point is in the **Transformed and Mapped Space** (Internal Optimization Space).</span>
<span class="sd">    This means:</span>
<span class="sd">    1. Transformations (e.g., log, sqrt) have been applied.</span>
<span class="sd">    2. Dimension reduction has been applied (fixed variables removed).</span>

<span class="sd">    Process:</span>
<span class="sd">    1. Try candidates from acquisition function optimizer.</span>
<span class="sd">    2. Handle acquisition failure (fallback).</span>
<span class="sd">    3. Return last attempt if all fails.</span>


<span class="sd">    Returns:</span>
<span class="sd">        ndarray: Next point(s) to evaluate in **Transformed and Mapped Space**.</span>
<span class="sd">        Shape is (n_infill_points, n_features).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...     n_initial=5,</span>
<span class="sd">        ...     n_infill_points=2</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; # Need to initialize optimization state (X_, y_, surrogate)</span>
<span class="sd">        &gt;&gt;&gt; # Normally done inside optimize()</span>
<span class="sd">        &gt;&gt;&gt; np.random.seed(0)</span>
<span class="sd">        &gt;&gt;&gt; opt.X_ = np.random.rand(10, 2)</span>
<span class="sd">        &gt;&gt;&gt; opt.y_ = np.random.rand(10)</span>
<span class="sd">        &gt;&gt;&gt; opt._fit_surrogate(opt.X_, opt.y_)</span>
<span class="sd">        &gt;&gt;&gt; x_next = opt.suggest_next_infill_point()</span>
<span class="sd">        &gt;&gt;&gt; x_next.shape</span>
<span class="sd">        (2, 2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1. Optimizer candidates</span>
    <span class="n">candidates</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">opt_candidates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_optimizer_candidates</span><span class="p">(</span>
        <span class="n">n_needed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_infill_points</span><span class="p">,</span> <span class="n">current_batch</span><span class="o">=</span><span class="n">candidates</span>
    <span class="p">)</span>
    <span class="n">candidates</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">opt_candidates</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_infill_points</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span>

    <span class="c1"># 2. Try fallback strategy to fill remaining slots</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_infill_points</span><span class="p">:</span>
        <span class="c1"># Just try one attempt at a time but loop</span>
        <span class="c1"># We pass current batch to avoid dups</span>
        <span class="n">cand</span><span class="p">,</span> <span class="n">x_last</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_try_fallback_strategy</span><span class="p">(</span>
            <span class="n">max_attempts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">current_batch</span><span class="o">=</span><span class="n">candidates</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">cand</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">candidates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cand</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Fallback failed to find unique point even after retries</span>
            <span class="c1"># Break and fill with last attempts or just return what we have?</span>
            <span class="c1"># If we return partial batch, we might fail downstream if code expects n points?</span>
            <span class="c1"># Actually code should handle any number of points returned by this method?</span>
            <span class="c1"># Or duplicate valid points?</span>
            <span class="c1"># Warn and use duplicate if absolutely necessary?</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;Warning: Could not fill all infill points with unique candidates.&quot;</span>
                <span class="p">)</span>
            <span class="k">break</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span>

    <span class="c1"># 3. Return last attempt (duplicate) if absolutely nothing found</span>
    <span class="c1"># This returns a single point (1, d).</span>
    <span class="c1"># Should we return n copies?</span>
    <span class="c1"># If n_infill_points &gt; 1, we should probably output (n, d)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Warning: Could not find unique point after optimization candidates and fallback attempts. &quot;</span>
            <span class="s2">&quot;Returning last candidate (duplicate).&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Verify x_last is not None</span>
    <span class="k">if</span> <span class="n">x_last</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Should practically not happen</span>
        <span class="n">x_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_acquisition_failure</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">x_next</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Return duplicated x_last to fill n_infill_points? OR just 1?</span>
    <span class="c1"># Let&#39;s return 1 and let loop repeat it?</span>
    <span class="c1"># But loop repeats based on x_next logic.</span>
    <span class="c1"># If we return 1 point, it is treated as 1 point.</span>
    <span class="c1"># If user asked for n_infill_points, maybe we should just return what we have (1 duplicated).</span>

    <span class="k">return</span> <span class="n">x_last</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.to_all_dim" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">to_all_dim</span><span class="p">(</span><span class="n">X_red</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.to_all_dim" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Expand reduced-dimensional points to full-dimensional representation.</p>
<p>This method restores points from the reduced optimization space to the
full-dimensional space by inserting fixed values for constant dimensions.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X_red</code>
            </td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Points in reduced space, shape (n_samples, n_reduced_dims).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ndarray</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Points in full space, shape (n_samples, n_original_dims).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create problem with one fixed dimension</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>  <span class="c1"># x1 is fixed at 2</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">3</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_red</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]])</span>  <span class="c1"># Only x0 and x2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_full</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">to_all_dim</span><span class="p">(</span><span class="n">X_red</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_full</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_full</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Middle dimension should be 2.0</span>
<span class="go">array([2., 2.])</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">to_all_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_red</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Expand reduced-dimensional points to full-dimensional representation.</span>

<span class="sd">    This method restores points from the reduced optimization space to the</span>
<span class="sd">    full-dimensional space by inserting fixed values for constant dimensions.</span>

<span class="sd">    Args:</span>
<span class="sd">        X_red (ndarray): Points in reduced space, shape (n_samples, n_reduced_dims).</span>

<span class="sd">    Returns:</span>
<span class="sd">        ndarray: Points in full space, shape (n_samples, n_original_dims).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; # Create problem with one fixed dimension</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (2, 2), (-5, 5)],  # x1 is fixed at 2</span>
<span class="sd">        ...     max_iter=1,</span>
<span class="sd">        ...     n_initial=3</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; X_red = np.array([[1.0, 3.0], [2.0, 4.0]])  # Only x0 and x2</span>
<span class="sd">        &gt;&gt;&gt; X_full = opt.to_all_dim(X_red)</span>
<span class="sd">        &gt;&gt;&gt; X_full.shape</span>
<span class="sd">        (2, 3)</span>
<span class="sd">        &gt;&gt;&gt; X_full[:, 1]  # Middle dimension should be 2.0</span>
<span class="sd">        array([2., 2.])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
        <span class="c1"># No reduction occurred, return as-is</span>
        <span class="k">return</span> <span class="n">X_red</span>

    <span class="c1"># Number of samples and full dimensions</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_red</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_full_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">)</span>

    <span class="c1"># Initialize full-dimensional array</span>
    <span class="n">X_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_full_dims</span><span class="p">))</span>

    <span class="c1"># Track index in reduced array</span>
    <span class="n">red_idx</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Fill in values dimension by dimension</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_full_dims</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="c1"># Fixed dimension: use stored value</span>
            <span class="n">X_full</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_lower</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Varying dimension: use value from reduced array</span>
            <span class="n">X_full</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_red</span><span class="p">[:,</span> <span class="n">red_idx</span><span class="p">]</span>
            <span class="n">red_idx</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">X_full</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.to_red_dim" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">to_red_dim</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.to_red_dim" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Reduce full-dimensional points to optimization space.</p>
<p>This method removes fixed dimensions from full-dimensional points,
extracting only the varying dimensions used in optimization.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X_full</code>
            </td>
            <td>
                  <code><span title="ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Points in full space, shape (n_samples, n_original_dims).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ndarray</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Points in reduced space, shape (n_samples, n_reduced_dims).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create problem with one fixed dimension</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>  <span class="c1"># x1 is fixed at 2</span>
<span class="gp">... </span>    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_initial</span><span class="o">=</span><span class="mi">3</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_red</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">to_red_dim</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_red</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">X_red</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]]))</span>
<span class="go">True</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">to_red_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_full</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reduce full-dimensional points to optimization space.</span>

<span class="sd">    This method removes fixed dimensions from full-dimensional points,</span>
<span class="sd">    extracting only the varying dimensions used in optimization.</span>

<span class="sd">    Args:</span>
<span class="sd">        X_full (ndarray): Points in full space, shape (n_samples, n_original_dims).</span>

<span class="sd">    Returns:</span>
<span class="sd">        ndarray: Points in reduced space, shape (n_samples, n_reduced_dims).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; # Create problem with one fixed dimension</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(</span>
<span class="sd">        ...     fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...     bounds=[(-5, 5), (2, 2), (-5, 5)],  # x1 is fixed at 2</span>
<span class="sd">        ...     max_iter=1,</span>
<span class="sd">        ...     n_initial=3</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; X_full = np.array([[1.0, 2.0, 3.0], [4.0, 2.0, 5.0]])</span>
<span class="sd">        &gt;&gt;&gt; X_red = opt.to_red_dim(X_full)</span>
<span class="sd">        &gt;&gt;&gt; X_red.shape</span>
<span class="sd">        (2, 2)</span>
<span class="sd">        &gt;&gt;&gt; np.array_equal(X_red, np.array([[1.0, 3.0], [4.0, 5.0]]))</span>
<span class="sd">        True</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_dim</span><span class="p">:</span>
        <span class="c1"># No reduction occurred, return as-is</span>
        <span class="k">return</span> <span class="n">X_full</span>

    <span class="c1"># Handle 1D array</span>
    <span class="k">if</span> <span class="n">X_full</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X_full</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">]</span>

    <span class="c1"># Select only non-fixed dimensions (2D)</span>
    <span class="k">return</span> <span class="n">X_full</span><span class="p">[:,</span> <span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">ident</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.transform_bounds" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">transform_bounds</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.transform_bounds" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Transform bounds from original to internal scale.</p>
<p>Updates <code>self.bounds</code> (and <code>self.lower</code>, <code>self.upper</code>) from <strong>Natural Space</strong>
to <strong>Transformed Space</strong>.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">var_trans</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;log10&#39;</span><span class="p">,</span> <span class="s1">&#39;sqrt&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">transform_bounds</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">spot</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span>
<span class="go">[(0.0, 1.0), (0.31622776601683794, 10.0)]</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span>
<span class="normal">1854</span>
<span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span>
<span class="normal">1879</span>
<span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">transform_bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transform bounds from original to internal scale.</span>

<span class="sd">    Updates `self.bounds` (and `self.lower`, `self.upper`) from **Natural Space**</span>
<span class="sd">    to **Transformed Space**.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10), (0.1, 100)])</span>
<span class="sd">        &gt;&gt;&gt; spot.var_trans = [&#39;log10&#39;, &#39;sqrt&#39;]</span>
<span class="sd">        &gt;&gt;&gt; spot.transform_bounds()</span>
<span class="sd">        &gt;&gt;&gt; print(spot.bounds)</span>
<span class="sd">        [(0.0, 1.0), (0.31622776601683794, 10.0)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">trans</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_trans</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">trans</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lower_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">trans</span><span class="p">)</span>
            <span class="n">upper_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">trans</span><span class="p">)</span>

            <span class="c1"># Handle reversed bounds (e.g., reciprocal transformation)</span>
            <span class="k">if</span> <span class="n">lower_t</span> <span class="o">&gt;</span> <span class="n">upper_t</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">upper_t</span><span class="p">,</span> <span class="n">lower_t</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">lower_t</span><span class="p">,</span> <span class="n">upper_t</span>

    <span class="c1"># Update self.bounds to reflect transformed bounds</span>
    <span class="c1"># Convert numpy types to Python native types (int or float based on var_type)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">)):</span>
        <span class="c1"># Check if var_type has this index (handle mismatched lengths)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;factor&quot;</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lower</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upper</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.transform_value" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">transform_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.transform_value" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Apply transformation to a single float value.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Value to transform</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>trans</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Transformation name. Can be one of &lsquo;id&rsquo;, &lsquo;log10&rsquo;, &lsquo;log&rsquo;, &lsquo;ln&rsquo;, &lsquo;sqrt&rsquo;,
   &lsquo;exp&rsquo;, &lsquo;square&rsquo;, &lsquo;cube&rsquo;, &lsquo;inv&rsquo;, &lsquo;reciprocal&rsquo;, or None.
   Also supports dynamic strings like &lsquo;log(x)&rsquo;, &lsquo;sqrt(x)&rsquo;, &lsquo;pow(x, p)&rsquo;.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Transformed value</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="TypeError">TypeError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If x is not a float.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If an unknown transformation is specified.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="notes" open>
  <summary>Notes</summary>
  <p>See also inverse_transform_value.</p>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">transform_value</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;log10&#39;</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spot</span><span class="o">.</span><span class="n">transform_value</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="s1">&#39;log(x)&#39;</span><span class="p">)</span>
<span class="go">4.605170185988092</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">transform_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">trans</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply transformation to a single float value.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: Value to transform</span>
<span class="sd">        trans: Transformation name. Can be one of &#39;id&#39;, &#39;log10&#39;, &#39;log&#39;, &#39;ln&#39;, &#39;sqrt&#39;,</span>
<span class="sd">               &#39;exp&#39;, &#39;square&#39;, &#39;cube&#39;, &#39;inv&#39;, &#39;reciprocal&#39;, or None.</span>
<span class="sd">               Also supports dynamic strings like &#39;log(x)&#39;, &#39;sqrt(x)&#39;, &#39;pow(x, p)&#39;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Transformed value</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If x is not a float.</span>
<span class="sd">        ValueError: If an unknown transformation is specified.</span>

<span class="sd">    Notes:</span>
<span class="sd">        See also inverse_transform_value.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; spot = SpotOptim(fun=lambda x: x, bounds=[(1, 10)])</span>
<span class="sd">        &gt;&gt;&gt; spot.transform_value(10, &#39;log10&#39;)</span>
<span class="sd">        1.0</span>
<span class="sd">        &gt;&gt;&gt; spot.transform_value(100, &#39;log(x)&#39;)</span>
<span class="sd">        4.605170185988092</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Ensure x is a float</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;transform_value expects a float, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (value: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>
    <span class="k">if</span> <span class="n">trans</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;id&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log10&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log&quot;</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;ln&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;square&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;cube&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">3</span>
    <span class="k">elif</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;inv&quot;</span> <span class="ow">or</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;reciprocal&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">x</span>

    <span class="c1"># Dynamic Transformations</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

    <span class="k">if</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;log(x)&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">trans</span> <span class="o">==</span> <span class="s2">&quot;sqrt(x)&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;pow\(x,\s*([0-9.]+)\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="n">p</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;pow\(([0-9.]+),\s*x\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
        <span class="n">base</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">base</span><span class="o">**</span><span class="n">x</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;log\(x,\s*([0-9.]+)\)&quot;</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
        <span class="n">base</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">base</span><span class="p">)</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown transformation: </span><span class="si">{</span><span class="n">trans</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="spotoptim.SpotOptim.SpotOptim.update_stats" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update_stats</span><span class="p">()</span></code>

<a href="#spotoptim.SpotOptim.SpotOptim.update_stats" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Update optimization statistics.</p>
<p>Updates various statistics related to the optimization progress:
- <code>min_y</code>: Minimum y value found so far
- <code>min_X</code>: X value corresponding to minimum y
- <code>counter</code>: Total number of function evaluations</p>
<p>Note: <code>success_rate</code> is updated separately via <code>_update_success_rate()</code> method,
which is called after each batch of function evaluations.</p>
<p>If <code>noise</code> is True (repeats &gt; 1), additionally computes:
1. <code>mean_X</code>: Unique design points (aggregated from repeated evaluations)
2. <code>mean_y</code>: Mean y values per design point
3. <code>var_y</code>: Variance of y values per design point
4. <code>min_mean_X</code>: X value of the best mean y value
5. <code>min_mean_y</code>: Best mean y value
6. <code>min_var_y</code>: Variance of the best mean y value</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">spotoptim</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpotOptim</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>                <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>                <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_initial</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">25.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">update_stats</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">min_y</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">min_X</span>
<span class="go">array([0, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span><span class="o">.</span><span class="n">counter</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span> <span class="o">=</span> <span class="n">SpotOptim</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>                      <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
<span class="gp">... </span>                      <span class="n">n_initial</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">repeats_initial</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">25.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span><span class="o">.</span><span class="n">update_stats</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt_noise</span><span class="o">.</span><span class="n">mean_y</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2,)</span>
</code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">5426</span>
<span class="normal">5427</span>
<span class="normal">5428</span>
<span class="normal">5429</span>
<span class="normal">5430</span>
<span class="normal">5431</span>
<span class="normal">5432</span>
<span class="normal">5433</span>
<span class="normal">5434</span>
<span class="normal">5435</span>
<span class="normal">5436</span>
<span class="normal">5437</span>
<span class="normal">5438</span>
<span class="normal">5439</span>
<span class="normal">5440</span>
<span class="normal">5441</span>
<span class="normal">5442</span>
<span class="normal">5443</span>
<span class="normal">5444</span>
<span class="normal">5445</span>
<span class="normal">5446</span>
<span class="normal">5447</span>
<span class="normal">5448</span>
<span class="normal">5449</span>
<span class="normal">5450</span>
<span class="normal">5451</span>
<span class="normal">5452</span>
<span class="normal">5453</span>
<span class="normal">5454</span>
<span class="normal">5455</span>
<span class="normal">5456</span>
<span class="normal">5457</span>
<span class="normal">5458</span>
<span class="normal">5459</span>
<span class="normal">5460</span>
<span class="normal">5461</span>
<span class="normal">5462</span>
<span class="normal">5463</span>
<span class="normal">5464</span>
<span class="normal">5465</span>
<span class="normal">5466</span>
<span class="normal">5467</span>
<span class="normal">5468</span>
<span class="normal">5469</span>
<span class="normal">5470</span>
<span class="normal">5471</span>
<span class="normal">5472</span>
<span class="normal">5473</span>
<span class="normal">5474</span>
<span class="normal">5475</span>
<span class="normal">5476</span>
<span class="normal">5477</span>
<span class="normal">5478</span>
<span class="normal">5479</span>
<span class="normal">5480</span>
<span class="normal">5481</span>
<span class="normal">5482</span>
<span class="normal">5483</span>
<span class="normal">5484</span>
<span class="normal">5485</span>
<span class="normal">5486</span>
<span class="normal">5487</span>
<span class="normal">5488</span>
<span class="normal">5489</span>
<span class="normal">5490</span>
<span class="normal">5491</span>
<span class="normal">5492</span>
<span class="normal">5493</span>
<span class="normal">5494</span>
<span class="normal">5495</span>
<span class="normal">5496</span>
<span class="normal">5497</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">update_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Update optimization statistics.</span>

<span class="sd">    Updates various statistics related to the optimization progress:</span>
<span class="sd">    - `min_y`: Minimum y value found so far</span>
<span class="sd">    - `min_X`: X value corresponding to minimum y</span>
<span class="sd">    - `counter`: Total number of function evaluations</span>

<span class="sd">    Note: `success_rate` is updated separately via `_update_success_rate()` method,</span>
<span class="sd">    which is called after each batch of function evaluations.</span>

<span class="sd">    If `noise` is True (repeats &gt; 1), additionally computes:</span>
<span class="sd">    1. `mean_X`: Unique design points (aggregated from repeated evaluations)</span>
<span class="sd">    2. `mean_y`: Mean y values per design point</span>
<span class="sd">    3. `var_y`: Variance of y values per design point</span>
<span class="sd">    4. `min_mean_X`: X value of the best mean y value</span>
<span class="sd">    5. `min_mean_y`: Best mean y value</span>
<span class="sd">    6. `min_var_y`: Variance of the best mean y value</span>


<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from spotoptim import SpotOptim</span>
<span class="sd">        &gt;&gt;&gt; # Without noise</span>
<span class="sd">        &gt;&gt;&gt; opt = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...                 bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...                 max_iter=10, n_initial=5)</span>
<span class="sd">        &gt;&gt;&gt; opt.X_ = np.array([[1, 2], [3, 4], [0, 1]])</span>
<span class="sd">        &gt;&gt;&gt; opt.y_ = np.array([5.0, 25.0, 1.0])</span>
<span class="sd">        &gt;&gt;&gt; opt.update_stats()</span>
<span class="sd">        &gt;&gt;&gt; opt.min_y</span>
<span class="sd">        1.0</span>
<span class="sd">        &gt;&gt;&gt; opt.min_X</span>
<span class="sd">        array([0, 1])</span>
<span class="sd">        &gt;&gt;&gt; opt.counter</span>
<span class="sd">        3</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # With noise</span>
<span class="sd">        &gt;&gt;&gt; opt_noise = SpotOptim(fun=lambda X: np.sum(X**2, axis=1),</span>
<span class="sd">        ...                       bounds=[(-5, 5), (-5, 5)],</span>
<span class="sd">        ...                       n_initial=5,</span>
<span class="sd">        ...                       repeats_initial=2)</span>
<span class="sd">        &gt;&gt;&gt; opt_noise.noise = True</span>
<span class="sd">        &gt;&gt;&gt; opt_noise.X_ = np.array([[1, 2], [1, 2], [3, 4]])</span>
<span class="sd">        &gt;&gt;&gt; opt_noise.y_ = np.array([5.0, 5.0, 25.0])</span>
<span class="sd">        &gt;&gt;&gt; opt_noise.update_stats()</span>
<span class="sd">        &gt;&gt;&gt; opt_noise.mean_y.shape</span>
<span class="sd">        (2,)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="c1"># Basic stats</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>

    <span class="c1"># Aggregated stats for noisy functions</span>
    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_initial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">repeats_surrogate</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_mean_var</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span>
        <span class="p">)</span>
        <span class="c1"># X value of the best mean y value so far</span>
        <span class="n">best_mean_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_X</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>
        <span class="c1"># Best mean y value so far</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_y</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>
        <span class="c1"># Variance of the best mean y value so far</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_var_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var_y</span><span class="p">[</span><span class="n">best_mean_idx</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="spotoptim.SpotOptim.SpotOptimConfig" class="doc doc-heading">
            <code>SpotOptimConfig</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

<a href="#spotoptim.SpotOptim.SpotOptimConfig" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">



        <p>Configuration parameters for SpotOptim.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SpotOptimConfig</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configuration parameters for SpotOptim.&quot;&quot;&quot;</span>

    <span class="n">bounds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">n_initial</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">surrogate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">object</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">acquisition</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;y&quot;</span>
    <span class="n">var_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">var_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">var_trans</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">tolerance_x</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">max_time</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">repeats_initial</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">repeats_surrogate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">ocba_delta</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">tensorboard_log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">tensorboard_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">tensorboard_clean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">fun_mo2so</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">warnings_filter</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ignore&quot;</span>
    <span class="n">n_infill_points</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">max_surrogate_points</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">selection_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;distant&quot;</span>
    <span class="n">acquisition_failure_strategy</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;random&quot;</span>
    <span class="n">penalty</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">penalty_val</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">acquisition_fun_return_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">acquisition_optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;differential_evolution&quot;</span>
    <span class="n">restart_after_n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">restart_inject_best</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">x0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">de_x0_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">tricands_fringe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">prob_de_tricands</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span>
    <span class="n">window_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">min_tol_metric</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span>
    <span class="n">prob_surrogate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">acquisition_optimizer_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span> <span class="o">=</span> <span class="p">()</span>
    <span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="spotoptim.SpotOptim.SpotOptimState" class="doc doc-heading">
            <code>SpotOptimState</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

<a href="#spotoptim.SpotOptim.SpotOptimState" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">



        <p>Mutable state of the optimization process.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/spotoptim/SpotOptim.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SpotOptimState</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mutable state of the optimization process.&quot;&quot;&quot;</span>

    <span class="n">X_</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">y_</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">y_mo</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">best_x_</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">best_y_</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">n_iter_</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">counter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Success tracking</span>
    <span class="n">success_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">success_counter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">_success_history</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">_zero_success_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Noise statistics</span>
    <span class="n">mean_X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">mean_y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">var_y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">min_mean_X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">min_mean_y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">min_var_y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Best found</span>
    <span class="n">min_X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">min_y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Restart history</span>
    <span class="n">restarts_results_</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2004 - 2025
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/bartzbeielstein" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/thomas-bartz-beielstein-3157b541/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["content.code.copy", "navigation.instant", "navigation.indexes", "navigation.path", "navigation.prune", "navigation.expand"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>