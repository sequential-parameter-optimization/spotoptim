{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6b5800",
   "metadata": {},
   "source": [
    "# SpotOptim Demonstrations\n",
    "\n",
    "This notebook demonstrates the usage of the SpotOptim optimizer for various optimization problems.\n",
    "\n",
    "## Example 1: 2-Dimensional Rosenbrock Function\n",
    "\n",
    "This example shows basic optimization on the classic 2D Rosenbrock function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotoptim.SpotOptim import SpotOptim\n",
    "\n",
    "# Define Rosenbrock function\n",
    "def rosenbrock(X):\n",
    "    \"\"\"Rosenbrock function for optimization.\"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    x = X[:, 0]\n",
    "    y = X[:, 1]\n",
    "    return (1 - x)**2 + 100 * (y - x**2)**2\n",
    "\n",
    "# Set up bounds for 2D problem\n",
    "bounds = [(-2, 2), (-2, 2)]\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = SpotOptim(\n",
    "    fun=rosenbrock,\n",
    "    bounds=bounds,\n",
    "    max_iter=50,\n",
    "    n_initial=5,\n",
    "    acquisition='ei',\n",
    "    seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "result = optimizer.optimize()\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Optimization Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best point found: {result.x}\")\n",
    "print(f\"Best function value: {result.fun:.6f}\")\n",
    "print(f\"Number of function evaluations: {result.nfev}\")\n",
    "print(f\"Number of iterations: {result.nit}\")\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Message: {result.message}\")\n",
    "print(\"\\nTrue optimum: [1, 1] with f(x) = 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b656a7",
   "metadata": {},
   "source": [
    "## Example 2: 6-Dimensional Rosenbrock Function\n",
    "\n",
    "This example demonstrates optimization of the 6-dimensional Rosenbrock function with a budget of 100 total function evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb69c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotoptim.SpotOptim import SpotOptim\n",
    "\n",
    "# Define 6-dimensional Rosenbrock function\n",
    "def rosenbrock_6d(X):\n",
    "    \"\"\"\n",
    "    6-dimensional Rosenbrock function for optimization.\n",
    "    \n",
    "    The Rosenbrock function is defined as:\n",
    "    f(x) = sum_{i=1}^{n-1} [100*(x_{i+1} - x_i^2)^2 + (1 - x_i)^2]\n",
    "    \n",
    "    Global minimum: f(1, 1, 1, 1, 1, 1) = 0\n",
    "    \"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    n_samples, n_dim = X.shape\n",
    "    \n",
    "    result = np.zeros(n_samples)\n",
    "    for i in range(n_samples):\n",
    "        x = X[i]\n",
    "        total = 0\n",
    "        for j in range(n_dim - 1):\n",
    "            total += 100 * (x[j+1] - x[j]**2)**2 + (1 - x[j])**2\n",
    "        result[i] = total\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Set up bounds for 6D problem\n",
    "# Typical search domain for Rosenbrock is [-5, 10] for each dimension\n",
    "bounds_6d = [(-2, 2)] * 6\n",
    "\n",
    "# Budget: 100 total function evaluations\n",
    "# Split into initial design and optimization iterations\n",
    "n_total = 100\n",
    "n_initial = 6  # Initial Latin Hypercube Design points\n",
    "max_iter = n_total - n_initial   # Optimization iterations: 6 + 94 = 100 total evaluations\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"6D Rosenbrock Function Optimization\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Problem dimension: 6\")\n",
    "print(f\"Search bounds: [-2, 2] for each dimension\")\n",
    "print(f\"Total budget: {n_initial + max_iter} function evaluations\")\n",
    "print(f\"  - Initial design: {n_initial} points\")\n",
    "print(f\"  - Optimization iterations: {max_iter}\")\n",
    "print(f\"Global optimum: x* = [1, 1, 1, 1, 1, 1], f(x*) = 0\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create optimizer with Expected Improvement acquisition\n",
    "optimizer_6d = SpotOptim(\n",
    "    fun=rosenbrock_6d,\n",
    "    bounds=bounds_6d,\n",
    "    max_iter=max_iter,\n",
    "    n_initial=n_initial,\n",
    "    acquisition='y',  # Expected Improvement\n",
    "    seed=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "print(\"\\nStarting optimization...\\n\")\n",
    "result_6d = optimizer_6d.optimize()\n",
    "\n",
    "# Print final results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Optimization Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best point found: {result_6d.x}\")\n",
    "print(f\"Best function value: {result_6d.fun:.6e}\")\n",
    "print(f\"Number of function evaluations: {result_6d.nfev}\")\n",
    "print(f\"Number of iterations: {result_6d.nit}\")\n",
    "print(f\"Success: {result_6d.success}\")\n",
    "\n",
    "# Calculate distance from true optimum\n",
    "true_optimum = np.ones(6)\n",
    "distance_to_optimum = np.linalg.norm(result_6d.x - true_optimum)\n",
    "print(f\"\\nDistance to true optimum [1,1,1,1,1,1]: {distance_to_optimum:.6f}\")\n",
    "\n",
    "# Show improvement over initial design\n",
    "initial_best = np.min(result_6d.y[:n_initial])\n",
    "final_best = result_6d.fun\n",
    "improvement = initial_best - final_best\n",
    "improvement_pct = (improvement / initial_best) * 100\n",
    "\n",
    "print(f\"\\nImprovement analysis:\")\n",
    "print(f\"  Best initial value: {initial_best:.6e}\")\n",
    "print(f\"  Final best value: {final_best:.6e}\")\n",
    "print(f\"  Absolute improvement: {improvement:.6e}\")\n",
    "print(f\"  Relative improvement: {improvement_pct:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9e047e",
   "metadata": {},
   "source": [
    "## Example 3: Using Kriging Surrogate\n",
    "\n",
    "This example demonstrates how to use the Kriging surrogate model instead of the default Gaussian Process from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotoptim import SpotOptim, Kriging\n",
    "\n",
    "# Define 2D Sphere function\n",
    "def sphere_2d(X):\n",
    "    \"\"\"\n",
    "    2D Sphere function: f(x, y) = x^2 + y^2\n",
    "    Global minimum: f(0, 0) = 0\n",
    "    \"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    return np.sum(X**2, axis=1)\n",
    "\n",
    "# Set up bounds\n",
    "bounds_sphere = [(-5, 5), (-5, 5)]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Optimization with Kriging Surrogate\")\n",
    "print(\"=\"*60)\n",
    "print(\"Function: 2D Sphere (f(x,y) = x² + y²)\")\n",
    "print(\"Search bounds: [-5, 5] for each dimension\")\n",
    "print(\"Global optimum: x* = [0, 0], f(x*) = 0\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create Kriging surrogate with custom parameters\n",
    "kriging_surrogate = Kriging(\n",
    "    noise=1e-6,          # Small regularization\n",
    "    min_theta=-3.0,      # Bounds for length scale optimization\n",
    "    max_theta=2.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create optimizer with Kriging surrogate\n",
    "optimizer_kriging = SpotOptim(\n",
    "    fun=sphere_2d,\n",
    "    bounds=bounds_sphere,\n",
    "    max_iter=20,\n",
    "    n_initial=10,\n",
    "    surrogate=kriging_surrogate,  # Use Kriging instead of default GP\n",
    "    acquisition='ei',\n",
    "    seed=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "print(\"\\nStarting optimization with Kriging surrogate...\\n\")\n",
    "result_kriging = optimizer_kriging.optimize()\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Results (Kriging Surrogate)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best point found: {result_kriging.x}\")\n",
    "print(f\"Best function value: {result_kriging.fun:.6e}\")\n",
    "print(f\"Distance to optimum [0, 0]: {np.linalg.norm(result_kriging.x):.6f}\")\n",
    "print(f\"Number of function evaluations: {result_kriging.nfev}\")\n",
    "print(f\"Number of iterations: {result_kriging.nit}\")\n",
    "\n",
    "# Compare with default GP surrogate\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Comparison: Running with Default GP Surrogate\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "optimizer_gp = SpotOptim(\n",
    "    fun=sphere_2d,\n",
    "    bounds=bounds_sphere,\n",
    "    max_iter=20,\n",
    "    n_initial=10,\n",
    "    acquisition='ei',\n",
    "    seed=42,\n",
    "    verbose=False  # Quiet for comparison\n",
    ")\n",
    "\n",
    "result_gp = optimizer_gp.optimize()\n",
    "\n",
    "print(f\"GP Best value: {result_gp.fun:.6e}\")\n",
    "print(f\"GP Distance to optimum: {np.linalg.norm(result_gp.x):.6f}\")\n",
    "print(f\"\\nKriging Best value: {result_kriging.fun:.6e}\")\n",
    "print(f\"Kriging Distance to optimum: {np.linalg.norm(result_kriging.x):.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Summary\")\n",
    "print(\"=\"*60)\n",
    "print(\"Both Kriging and GP surrogates successfully found the optimum.\")\n",
    "print(\"Kriging offers a simplified, self-contained surrogate model\")\n",
    "print(\"that can be customized with different hyperparameters.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotoptim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
