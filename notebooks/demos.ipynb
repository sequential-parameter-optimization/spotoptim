{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6b5800",
   "metadata": {},
   "source": [
    "# SpotOptim Demonstrations\n",
    "\n",
    "This notebook demonstrates the usage of the SpotOptim optimizer for various optimization problems.\n",
    "\n",
    "## Example 1: 2-Dimensional Rosenbrock Function\n",
    "\n",
    "This example shows basic optimization on the classic 2D Rosenbrock function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotoptim.SpotOptim import SpotOptim\n",
    "\n",
    "# Define Rosenbrock function\n",
    "def rosenbrock(X):\n",
    "    \"\"\"Rosenbrock function for optimization.\"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    x = X[:, 0]\n",
    "    y = X[:, 1]\n",
    "    return (1 - x)**2 + 100 * (y - x**2)**2\n",
    "\n",
    "# Set up bounds for 2D problem\n",
    "bounds = [(-2, 2), (-2, 2)]\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = SpotOptim(\n",
    "    fun=rosenbrock,\n",
    "    bounds=bounds,\n",
    "    max_iter=50,\n",
    "    n_initial=5,\n",
    "    acquisition='ei',\n",
    "    seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "result = optimizer.optimize()\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Optimization Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best point found: {result.x}\")\n",
    "print(f\"Best function value: {result.fun:.6f}\")\n",
    "print(f\"Number of function evaluations: {result.nfev}\")\n",
    "print(f\"Number of iterations: {result.nit}\")\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Message: {result.message}\")\n",
    "print(\"\\nTrue optimum: [1, 1] with f(x) = 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b656a7",
   "metadata": {},
   "source": [
    "## Example 2: 6-Dimensional Rosenbrock Function\n",
    "\n",
    "This example demonstrates optimization of the 6-dimensional Rosenbrock function with a budget of 100 total function evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53fb69c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "6D Rosenbrock Function Optimization\n",
      "============================================================\n",
      "Problem dimension: 6\n",
      "Search bounds: [-2, 2] for each dimension\n",
      "Total budget: 100 function evaluations\n",
      "  - Initial design: 6 points\n",
      "  - Optimization iterations: 94\n",
      "Global optimum: x* = [1, 1, 1, 1, 1, 1], f(x*) = 0\n",
      "============================================================\n",
      "\n",
      "Starting optimization...\n",
      "\n",
      "Initial best: f(x) = 881.567459\n",
      "Iteration 1: f(x) = 2103.440995\n",
      "Iteration 2: New best f(x) = 881.329928\n",
      "Iteration 3: f(x) = 969.604447\n",
      "Iteration 4: New best f(x) = 596.767694\n",
      "Iteration 5: New best f(x) = 381.514887\n",
      "Iteration 6: New best f(x) = 346.681434\n",
      "Iteration 7: f(x) = 402.306119\n",
      "Iteration 5: New best f(x) = 381.514887\n",
      "Iteration 6: New best f(x) = 346.681434\n",
      "Iteration 7: f(x) = 402.306119\n",
      "Iteration 8: New best f(x) = 164.872575\n",
      "Iteration 9: New best f(x) = 97.516991\n",
      "Iteration 8: New best f(x) = 164.872575\n",
      "Iteration 9: New best f(x) = 97.516991\n",
      "Iteration 10: New best f(x) = 79.141491\n",
      "Iteration 11: New best f(x) = 76.288180\n",
      "Iteration 10: New best f(x) = 79.141491\n",
      "Iteration 11: New best f(x) = 76.288180\n",
      "Iteration 12: New best f(x) = 73.303886\n",
      "Iteration 13: New best f(x) = 70.188459\n",
      "Iteration 12: New best f(x) = 73.303886\n",
      "Iteration 13: New best f(x) = 70.188459\n",
      "Iteration 14: New best f(x) = 69.393292\n",
      "Iteration 15: New best f(x) = 69.230374\n",
      "Iteration 14: New best f(x) = 69.393292\n",
      "Iteration 15: New best f(x) = 69.230374\n",
      "Iteration 16: New best f(x) = 67.503813\n",
      "Iteration 17: New best f(x) = 56.809988\n",
      "Iteration 16: New best f(x) = 67.503813\n",
      "Iteration 17: New best f(x) = 56.809988\n",
      "Iteration 18: New best f(x) = 52.932777\n",
      "Iteration 19: New best f(x) = 49.234962\n",
      "Iteration 18: New best f(x) = 52.932777\n",
      "Iteration 19: New best f(x) = 49.234962\n",
      "Iteration 20: New best f(x) = 25.326240\n",
      "Iteration 21: New best f(x) = 24.202068\n",
      "Iteration 20: New best f(x) = 25.326240\n",
      "Iteration 21: New best f(x) = 24.202068\n",
      "Iteration 22: New best f(x) = 23.267545\n",
      "Iteration 23: f(x) = 23.346959\n",
      "Iteration 22: New best f(x) = 23.267545\n",
      "Iteration 23: f(x) = 23.346959\n",
      "Iteration 24: New best f(x) = 22.379831\n",
      "Iteration 25: New best f(x) = 21.894816\n",
      "Iteration 24: New best f(x) = 22.379831\n",
      "Iteration 25: New best f(x) = 21.894816\n",
      "Iteration 26: f(x) = 22.064813\n",
      "Iteration 27: New best f(x) = 16.505162\n",
      "Iteration 26: f(x) = 22.064813\n",
      "Iteration 27: New best f(x) = 16.505162\n",
      "Iteration 28: New best f(x) = 10.649613\n",
      "Iteration 29: New best f(x) = 8.401844\n",
      "Iteration 28: New best f(x) = 10.649613\n",
      "Iteration 29: New best f(x) = 8.401844\n",
      "Iteration 30: New best f(x) = 8.130415\n",
      "Iteration 31: New best f(x) = 7.930996\n",
      "Iteration 30: New best f(x) = 8.130415\n",
      "Iteration 31: New best f(x) = 7.930996\n",
      "Iteration 32: f(x) = 8.090370\n",
      "Iteration 33: New best f(x) = 7.160027\n",
      "Iteration 32: f(x) = 8.090370\n",
      "Iteration 33: New best f(x) = 7.160027\n",
      "Iteration 34: New best f(x) = 6.809901\n",
      "Iteration 35: New best f(x) = 6.683773\n",
      "Iteration 34: New best f(x) = 6.809901\n",
      "Iteration 35: New best f(x) = 6.683773\n",
      "Iteration 36: New best f(x) = 6.544019\n",
      "Iteration 37: New best f(x) = 5.233123\n",
      "Iteration 36: New best f(x) = 6.544019\n",
      "Iteration 37: New best f(x) = 5.233123\n",
      "Iteration 38: f(x) = 5.579746\n",
      "Iteration 39: f(x) = 5.557497\n",
      "Iteration 38: f(x) = 5.579746\n",
      "Iteration 39: f(x) = 5.557497\n",
      "Iteration 40: New best f(x) = 4.989795\n",
      "Iteration 40: New best f(x) = 4.989795\n",
      "Iteration 41: f(x) = 5.359845\n",
      "Iteration 41: f(x) = 5.359845\n",
      "Iteration 42: New best f(x) = 4.567932\n",
      "Iteration 42: New best f(x) = 4.567932\n",
      "Iteration 43: f(x) = 4.659882\n",
      "Iteration 44: f(x) = 6.996969\n",
      "Iteration 43: f(x) = 4.659882\n",
      "Iteration 44: f(x) = 6.996969\n",
      "Iteration 45: f(x) = 4.701809\n",
      "Iteration 45: f(x) = 4.701809\n",
      "Iteration 46: New best f(x) = 4.501173\n",
      "Iteration 47: f(x) = 4.520282\n",
      "Iteration 46: New best f(x) = 4.501173\n",
      "Iteration 47: f(x) = 4.520282\n",
      "Iteration 48: New best f(x) = 4.497305\n",
      "Iteration 48: New best f(x) = 4.497305\n",
      "Iteration 49: f(x) = 4.525355\n",
      "Iteration 50: New best f(x) = 4.440748\n",
      "Iteration 49: f(x) = 4.525355\n",
      "Iteration 50: New best f(x) = 4.440748\n",
      "Iteration 51: f(x) = 4.461997\n",
      "Iteration 51: f(x) = 4.461997\n",
      "Iteration 52: New best f(x) = 4.439082\n",
      "Iteration 52: New best f(x) = 4.439082\n",
      "Iteration 53: f(x) = 4.462050\n",
      "Iteration 53: f(x) = 4.462050\n",
      "Iteration 54: New best f(x) = 4.425695\n",
      "Iteration 54: New best f(x) = 4.425695\n",
      "Iteration 55: New best f(x) = 4.391987\n",
      "Iteration 55: New best f(x) = 4.391987\n",
      "Iteration 56: New best f(x) = 4.389585\n",
      "Iteration 57: New best f(x) = 4.363668\n",
      "Iteration 56: New best f(x) = 4.389585\n",
      "Iteration 57: New best f(x) = 4.363668\n",
      "Iteration 58: f(x) = 4.423819\n",
      "Iteration 59: New best f(x) = 4.330311\n",
      "Iteration 58: f(x) = 4.423819\n",
      "Iteration 59: New best f(x) = 4.330311\n",
      "Iteration 60: New best f(x) = 4.289820\n",
      "Iteration 60: New best f(x) = 4.289820\n",
      "Iteration 61: New best f(x) = 4.265407\n",
      "Iteration 62: New best f(x) = 4.253097\n",
      "Iteration 61: New best f(x) = 4.265407\n",
      "Iteration 62: New best f(x) = 4.253097\n",
      "Iteration 63: New best f(x) = 4.247454\n",
      "Iteration 63: New best f(x) = 4.247454\n",
      "Iteration 64: f(x) = 4.255082\n",
      "Iteration 64: f(x) = 4.255082\n",
      "Iteration 65: f(x) = 4.266250\n",
      "Iteration 65: f(x) = 4.266250\n",
      "Iteration 66: f(x) = 4.250810\n",
      "Iteration 66: f(x) = 4.250810\n",
      "Proposed point too close, generating random point\n",
      "Iteration 67: f(x) = 459.852243\n",
      "Proposed point too close, generating random point\n",
      "Iteration 67: f(x) = 459.852243\n",
      "Iteration 68: New best f(x) = 4.216391\n",
      "Iteration 68: New best f(x) = 4.216391\n",
      "Iteration 69: New best f(x) = 4.167712\n",
      "Iteration 69: New best f(x) = 4.167712\n",
      "Iteration 70: New best f(x) = 4.158031\n",
      "Iteration 70: New best f(x) = 4.158031\n",
      "Iteration 71: f(x) = 4.169039\n",
      "Iteration 71: f(x) = 4.169039\n",
      "Iteration 72: New best f(x) = 4.109568\n",
      "Iteration 73: f(x) = 4.127043\n",
      "Iteration 72: New best f(x) = 4.109568\n",
      "Iteration 73: f(x) = 4.127043\n",
      "Iteration 74: New best f(x) = 4.068812\n",
      "Iteration 75: New best f(x) = 3.921019\n",
      "Iteration 74: New best f(x) = 4.068812\n",
      "Iteration 75: New best f(x) = 3.921019\n",
      "Iteration 76: New best f(x) = 3.864676\n",
      "Iteration 76: New best f(x) = 3.864676\n",
      "Iteration 77: New best f(x) = 3.837160\n",
      "Iteration 77: New best f(x) = 3.837160\n",
      "Iteration 78: New best f(x) = 3.818164\n",
      "Iteration 78: New best f(x) = 3.818164\n",
      "Iteration 79: f(x) = 3.823223\n",
      "Iteration 79: f(x) = 3.823223\n",
      "Iteration 80: f(x) = 3.821876\n",
      "Iteration 80: f(x) = 3.821876\n",
      "Iteration 81: f(x) = 3.857576\n",
      "Iteration 81: f(x) = 3.857576\n",
      "Iteration 82: New best f(x) = 3.785723\n",
      "Iteration 82: New best f(x) = 3.785723\n",
      "Iteration 83: New best f(x) = 3.687534\n",
      "Iteration 83: New best f(x) = 3.687534\n",
      "Iteration 84: New best f(x) = 3.565945\n",
      "Iteration 84: New best f(x) = 3.565945\n",
      "Iteration 85: New best f(x) = 3.515415\n",
      "Iteration 85: New best f(x) = 3.515415\n",
      "Iteration 86: New best f(x) = 3.485539\n",
      "Iteration 86: New best f(x) = 3.485539\n",
      "Iteration 87: New best f(x) = 3.470264\n",
      "Iteration 87: New best f(x) = 3.470264\n",
      "Iteration 88: f(x) = 3.494593\n",
      "Iteration 88: f(x) = 3.494593\n",
      "Iteration 89: New best f(x) = 3.388296\n",
      "Iteration 89: New best f(x) = 3.388296\n",
      "Iteration 90: New best f(x) = 3.359267\n",
      "Iteration 90: New best f(x) = 3.359267\n",
      "Iteration 91: f(x) = 3.391482\n",
      "Iteration 91: f(x) = 3.391482\n",
      "Iteration 92: New best f(x) = 3.296204\n",
      "Iteration 92: New best f(x) = 3.296204\n",
      "Iteration 93: New best f(x) = 3.292003\n",
      "Iteration 93: New best f(x) = 3.292003\n",
      "Iteration 94: New best f(x) = 3.288971\n",
      "\n",
      "============================================================\n",
      "Final Optimization Results\n",
      "============================================================\n",
      "Best point found: [ 0.62987281  0.3997962   0.14175079  0.00902228  0.02568963 -0.01044991]\n",
      "Best function value: 3.288971e+00\n",
      "Number of function evaluations: 100\n",
      "Number of iterations: 94\n",
      "Success: True\n",
      "\n",
      "Distance to true optimum [1,1,1,1,1,1]: 2.046010\n",
      "\n",
      "Improvement analysis:\n",
      "  Best initial value: 8.815675e+02\n",
      "  Final best value: 3.288971e+00\n",
      "  Absolute improvement: 8.782785e+02\n",
      "  Relative improvement: 99.63%\n",
      "============================================================\n",
      "Iteration 94: New best f(x) = 3.288971\n",
      "\n",
      "============================================================\n",
      "Final Optimization Results\n",
      "============================================================\n",
      "Best point found: [ 0.62987281  0.3997962   0.14175079  0.00902228  0.02568963 -0.01044991]\n",
      "Best function value: 3.288971e+00\n",
      "Number of function evaluations: 100\n",
      "Number of iterations: 94\n",
      "Success: True\n",
      "\n",
      "Distance to true optimum [1,1,1,1,1,1]: 2.046010\n",
      "\n",
      "Improvement analysis:\n",
      "  Best initial value: 8.815675e+02\n",
      "  Final best value: 3.288971e+00\n",
      "  Absolute improvement: 8.782785e+02\n",
      "  Relative improvement: 99.63%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from spotoptim.SpotOptim import SpotOptim\n",
    "\n",
    "# Define 6-dimensional Rosenbrock function\n",
    "def rosenbrock_6d(X):\n",
    "    \"\"\"\n",
    "    6-dimensional Rosenbrock function for optimization.\n",
    "    \n",
    "    The Rosenbrock function is defined as:\n",
    "    f(x) = sum_{i=1}^{n-1} [100*(x_{i+1} - x_i^2)^2 + (1 - x_i)^2]\n",
    "    \n",
    "    Global minimum: f(1, 1, 1, 1, 1, 1) = 0\n",
    "    \"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    n_samples, n_dim = X.shape\n",
    "    \n",
    "    result = np.zeros(n_samples)\n",
    "    for i in range(n_samples):\n",
    "        x = X[i]\n",
    "        total = 0\n",
    "        for j in range(n_dim - 1):\n",
    "            total += 100 * (x[j+1] - x[j]**2)**2 + (1 - x[j])**2\n",
    "        result[i] = total\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Set up bounds for 6D problem\n",
    "# Typical search domain for Rosenbrock is [-5, 10] for each dimension\n",
    "bounds_6d = [(-2, 2)] * 6\n",
    "\n",
    "# Budget: 100 total function evaluations\n",
    "# Split into initial design and optimization iterations\n",
    "n_total = 100\n",
    "n_initial = 6  # Initial Latin Hypercube Design points\n",
    "max_iter = n_total - n_initial   # Optimization iterations: 6 + 94 = 100 total evaluations\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"6D Rosenbrock Function Optimization\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Problem dimension: 6\")\n",
    "print(f\"Search bounds: [-2, 2] for each dimension\")\n",
    "print(f\"Total budget: {n_initial + max_iter} function evaluations\")\n",
    "print(f\"  - Initial design: {n_initial} points\")\n",
    "print(f\"  - Optimization iterations: {max_iter}\")\n",
    "print(f\"Global optimum: x* = [1, 1, 1, 1, 1, 1], f(x*) = 0\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create optimizer with Expected Improvement acquisition\n",
    "optimizer_6d = SpotOptim(\n",
    "    fun=rosenbrock_6d,\n",
    "    bounds=bounds_6d,\n",
    "    max_iter=max_iter,\n",
    "    n_initial=n_initial,\n",
    "    acquisition='y',  # Expected Improvement\n",
    "    seed=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "print(\"\\nStarting optimization...\\n\")\n",
    "result_6d = optimizer_6d.optimize()\n",
    "\n",
    "# Print final results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Optimization Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best point found: {result_6d.x}\")\n",
    "print(f\"Best function value: {result_6d.fun:.6e}\")\n",
    "print(f\"Number of function evaluations: {result_6d.nfev}\")\n",
    "print(f\"Number of iterations: {result_6d.nit}\")\n",
    "print(f\"Success: {result_6d.success}\")\n",
    "\n",
    "# Calculate distance from true optimum\n",
    "true_optimum = np.ones(6)\n",
    "distance_to_optimum = np.linalg.norm(result_6d.x - true_optimum)\n",
    "print(f\"\\nDistance to true optimum [1,1,1,1,1,1]: {distance_to_optimum:.6f}\")\n",
    "\n",
    "# Show improvement over initial design\n",
    "initial_best = np.min(result_6d.y[:n_initial])\n",
    "final_best = result_6d.fun\n",
    "improvement = initial_best - final_best\n",
    "improvement_pct = (improvement / initial_best) * 100\n",
    "\n",
    "print(f\"\\nImprovement analysis:\")\n",
    "print(f\"  Best initial value: {initial_best:.6e}\")\n",
    "print(f\"  Final best value: {final_best:.6e}\")\n",
    "print(f\"  Absolute improvement: {improvement:.6e}\")\n",
    "print(f\"  Relative improvement: {improvement_pct:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotoptim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
