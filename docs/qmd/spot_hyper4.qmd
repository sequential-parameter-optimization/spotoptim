---
title: "SpotOptim Hyperparameter Tuning (Desirability & Pareto)"
format: html
---

```{python}
import warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_diabetes

# New SpotOptim Interfaces
from spotoptim.core.data import SpotDataFromArray
from spotoptim.core.experiment import ExperimentControl
from spotoptim.hyperparameters.parameters import ParameterSet
from spotoptim.nn.linear_regressor import LinearRegressor
from spotoptim.function.torch_objective import TorchObjective
from spotoptim.SpotOptim import SpotOptim
from spotoptim.plot.mo import plot_mo

# External Desirability
from spotdesirability.utils.desirability import DOverall, DMin

warnings.filterwarnings("ignore")
```

# Introduction

This tutorial broadens the scope to **Multi-Objective Optimization** using **Desirability Functions** and visualizes the **Pareto Front**.

## 1. Data Loading

```{python}
# Load data
diabetes = load_diabetes()
X = diabetes.data.astype(np.float32)
y = diabetes.target.reshape(-1, 1).astype(np.float32)

# Create SpotDataSet
data = SpotDataFromArray(x_train=X, y_train=y)
print(f"Data shape: {X.shape} -> {y.shape}")
```

## 2. Define Hyperparameters

We include `epochs` in the search space to trade off training time vs. accuracy.

```{python}
params = ParameterSet() \
    .add_float("lr", 1e-4, 1e-1, transform="log") \
    .add_int("l1", 8, 64) \
    .add_int("num_hidden_layers", 0, 2) \
    .add_categorical("activation", ["ReLU", "Tanh", "Sigmoid"]) \
    .add_categorical("optimizer", ["Adam", "SGD"]) \
    .add_int("epochs", 3, 30)

print("Variables:", params.var_name)
```

## 3. Experiment Configuration

We configure the experiment to return **MSE** (Loss) and **Epochs**.

```{python}
exp = ExperimentControl(
    dataset=data,
    model_class=LinearRegressor,
    hyperparameters=params,
    batch_size=32,
    metrics=["mse", "epochs"]
)

objective = TorchObjective(exp)
```

## 4. Multi-Objective with Desirability Functions

Instead of a simple weighted sum, we use **Desirability Functions** to map each objective to a [0, 1] scale and combine them.

### Define Desirability

We use `DMin` to define that we want to minimize both Loss and Epochs within specific ranges.

```{python}
def desirability(y):
    # y is (n_samples, 2) -> [MSE, Epochs]
    # We define desirability functions inside or globally.
    # Note: DMin(low, high) -> transforms value to [0,1].
    # target is to MINIMIZE, so low is good (1), high is bad (0).
    
    # Loss: desirable below 2000, unacceptable above 6000? 
    # Adjusted ranges based on typical Diabetes dataset values ~3000-6000
    lossD = DMin(2500, 6000) 
    
    # Epochs: desirable 3, unacceptable 30
    epochsD = DMin(3, 30)
    
    # Geometric mean of individual desirabilities
    overallD = DOverall(lossD, epochsD)
    
    # SpotOptim minimizes the objective, so we return (1 - desirability)
    # y is passed as (n, 2)
    return 1.0 - overallD.predict(y, all=False)
```

### Visualize Desirability Functions

```{python}
#| label: fig-des-loss
#| fig-cap: "Desirability for MSE Loss"
lossD = DMin(2500, 6000)
lossD.plot(xlabel="MSE Loss", ylabel="Desirability", figsize=(6,4))
```

```{python}
#| label: fig-des-epochs
#| fig-cap: "Desirability for Epochs"
epochsD = DMin(3, 30)
epochsD.plot(xlabel="Epochs", ylabel="Desirability", figsize=(6,4))
```

### Run Optimization

```{python}
optimizer = SpotOptim(
    fun=objective,
    bounds=params.bounds,
    var_type=params.var_type,
    var_name=params.var_name,
    max_iter=30,     # More iterations to see Pareto front better
    n_initial=10,
    seed=42,
    fun_mo2so=desirability # Use desirability aggregation
)

optimizer.optimize()
```

### Results

```{python}
print(f"Best Desirability Score (Minimizing 1-D): {optimizer.best_y_:.4f}")

# Inspect the best point
best_idx = np.argmin(optimizer.y_)
best_objectives = optimizer.y_mo[best_idx]
print(f"Best Objectives: MSE={best_objectives[0]:.2f}, Epochs={best_objectives[1]:.0f}")
```

## 5. Pareto Front Visualization

We visualize the trade-off using `plot_mo`.

```{python}
#| label: fig-pareto
#| fig-cap: "Pareto Front: MSE vs Epochs"

y_orig = optimizer.y_mo
df_z = pd.DataFrame(y_orig, columns=["MSE", "Epochs"])

# plot_mo expects a DataFrame
plot_mo(
    y_orig=df_z, 
    target_names=["MSE (log)", "Epochs (log)"], 
    combinations=[(0,1)], 
    pareto="min", 
    pareto_front_orig=True, 
    title="Pareto Front (Diabetes)", 
    pareto_label=True, 
    x_axis_transformation="log",
    y_axis_transformation="log"
)
```

::: {.callout-note}
### Interpretation
The Pareto front highlights the non-dominated solutions. You can see how lower MSE values generally require more epochs (or specific hyperparameters that coincide with higher training cost), while very few epochs yield higher MSE.
:::
